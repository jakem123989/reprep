MULTIPLYING NON-INDEPENDENT PROBABILITIES
MOST PEOPLE KNOW that to measure the probability that several events will occur, the separate probabilities of each event should be multiplied together. For instance, if you are pregnant with a single child, there is a 1 out of 2 chance you will give birth to a girl. Thus if you have two children at different times, the probability of having 2 girls is ½ squared, which is ¼, or 1 chance out of 4.
We do this type of calculation all the time, almost without thinking. But there’s a caveat: this multiplication is correct only if the events you’re comparing are totally independent from each other, like having separate pregnancies. If they are not independent, the situation changes. Suppose, for example, that you happen to know from an ultrasound that you are pregnant with identical twins. Now the birth of your two children does not constitute two independent events, and of course it would be wrong to say that the probability of your having two girls is ¼; it is in fact ½, because the two babies share the same genes, so they will necessarily be of the same sex; thus they can only be either two girls or two boys.
If you multiply the probabilities of events that are not independent of each other, you will get a significantly smaller probability than is accurate. But it’s easy to fall into the trap of assuming that a set of separate events occurred or will occur independently of one another. Some events may seem independent but have a single underlying cause. For example, a card player may go on a winning streak that defies all odds—but the reason could be that he’s cheating.
It’s risky to assume that events are independent when all the data is not in. Yet it has been done, even by highly respected people, in courts of law. And sometimes it has resulted in disaster.
 
 
The Case of Sally Clark: Motherhood Under Attack
Steve and Sally Clark were a loving couple of bright, ambitious young lawyers. Both worked demanding jobs in London, but eventually they bought themselves a little house called Hope Cottage, well away from the bustle of the city, and decided to raise a family. On September 22, 1996, Sally gave birth to a son, Christopher. She decided to stop working for a few months and stay home with her child.
From the beginning the baby appeared fragile and delicate, with the face of an angel. He was extremely quiet, slept a great deal, and almost never cried. In early December he developed what seemed to be sniffles and a bad cold, but the doctor told Sally not to worry. Everything seemed normal enough until December 13, when she went down to the kitchen for ten minutes to prepare herself a drink, and returned to the bedroom to find the baby gray-faced in his basket. She called for an ambulance and the baby was rushed to the hospital, but sadly he could not be saved. An autopsy indicated that he had been suffering from an infection of the lungs.
After Christopher’s death Sally returned to work, but although she functioned adequately, she underwent a period of grieving, depression, and despair, occasionally drinking heavily. A new pregnancy helped her snap out of it, and she underwent therapy to bolster a complete renunciation of alcohol. Healthy baby Harry was born on November 29, 1997.
Like all younger siblings of babies who have died in England, this second baby was closely monitored under the program known as Care of Next Infants (CONI). Steve and Sally were taught the basic gestures of resuscitation, and Harry was given an apnea alarm to wear permanently, which was supposed to start ringing if he stopped breathing. As a matter of fact, the alarm went off quite frequently, but the health visitors and nurses who stopped by the house both regularly and for random checkups found nothing wrong with the baby, so everyone assumed that the apnea alarm was malfunctioning. Little Harry appeared strong and hearty, was noisy and active, cried loudly, and demanded frequent feedings. Sally devoted herself to him and kept a close eye on his health, filling out the many charts required by the CONI program and keeping him well away from any chance of infection by contact with other sick people. As Steve was in a cast with a torn Achilles tendon, the Clarks hired daily help during the first weeks of Harry’s life to give Sally a hand with all the housework. On January 26, 1998, Sally took Harry to the community health center for his standard vaccinations.
After the vaccinations he was much quieter than usual, appearing lethargic and pale as Sally wheeled him home. Five hours later Steve was trying to amuse the baby and play with him, but Harry didn’t seem interested, so Steve put him down in his bouncy chair and went to the kitchen. Not five minutes later he heard Sally calling him desperately. Little Harry had gone limp and white; his head was falling forward. Steve rushed back to the bedroom, laid the baby on the floor, and tried to resuscitate him, first gently and then with increasing strength, while Sally called for help. The ambulance arrived and rushed the family to the hospital. But for the second time, doctors were unable to save the life of the couple’s baby.
This time the autopsy gave surprising, and seemingly contradictory, evidence. The pathologist, Dr. Williams, claimed that he could see retinal hemorrhage in Harry’s eyes, a frequent sign of smothering, and could feel a broken rib, though whether recent or old he could not say; it did not show up on X-ray. Harry also had large amounts of bacteria in his nose, throat, lungs, and stomach, but no notice was taken of this. The pathologist believed there was sufficient evidence of abuse to warrant a complete investigation.
Steve and Sally Clark were arrested for the murder of their two children. After intensive interrogation, during which they answered all questions freely and openly and did not ask for a lawyer, they were released on bail while the investigation proceeded.



Steve and Sally Clark
They returned home, minus their passports and with the obligation of registering regularly at the police station, and tried to pick up the remains of their shattered lives. But to their horror, as the investigation continued and they were repeatedly called in for questioning, they realized that their desperate need to understand the medical causes for the death of their sons was gradually being overshadowed by the new, urgent necessity of defending themselves from the accusations of severe child abuse being leveled against them by the police. They realized that they had no adequate defense against such an accusation—there is no actual proof that a dead baby has not been smothered! They could hardly believe that the investigation would result in a trial, yet on the advice of their friends they eventually went to a criminal lawyer. Solicitor Mike Mackey agreed to take their case and help them, come what may.
Two important events followed: a third little boy, born a year to the day after Harry’s birth, and a formal charge of double murder against Sally.
Steve, exonerated from any wrongdoing and not charged, was helpless to prevent the destruction of his family and the persecution of his wife. The new baby was placed in foster care, and a date was set for Sally’s trial for the murder of her sons.
Sally’s trial took place at Chester Crown Court, before a judge and jury. She was defended by brilliant lawyers who put their finger squarely on each and every one of the contradictions in the massive and complex medical testimony, obliging the medical experts to contradict each other, and pointing out a series of errors of interpretation in Harry’s autopsy. Most of the prosecution’s experts were forced to admit that the deaths of the babies could not be definitively attributed to shaking, smothering, or other abuse, and Sally’s behavior as a mother was vouched for by many witnesses, such as the nanny who had helped her with Harry, and the health care professionals who had kept him under regular observation for the CONI program. Listening to them, Sally felt certain that her innocence could only be obvious to the jury. It was this certainty, this faith in the justice system, that gave her the strength to sit through grueling hours of description of the autopsies of her sons, in which every sign of possible violence was discussed in gruesome but unavoidable detail. During those hours of testimony from the prosecution’s medical experts, Sally was forced to listen to the hateful picture that was being painted for the jury of the person she was supposed to be—obsessively tidy, professionally ambitious, a control freak, unfit to be a mother—and the actions she was accused of having committed. Not only she, but also the spectators at the trial were horrified by a system that imposes such torment on parents who have lost their children. Was it really necessary for Steve Clark, gagging on the witness stand, to be shown photographs of his dead babies’ medically dismembered little bodies?
Everything the medical experts were saying seemed wrong to Sally— drastically, obviously, cruelly, horribly, and offensively wrong. Until the renowned pediatrician Sir Roy Meadow took the stand.
Charming and avuncular, Meadow appeared filled with sympathy for the plight of the accused, pronouncing words of condemnation with a seeming reluctance that made his allegations all the more effective. He exuded competence, experience, ability, and kindness. Listening to his testimony, Sally was struck dumb. “If I didn’t know I was innocent,” she later said, “listening to him I would have believed myself guilty.”
And up on the witness stand, Meadow spoke the words that swung the balance of justice irrevocably against Sally.



Dr. Roy Meadow, pediatrician
IN ORDER to understand what Roy Meadow was doing when he told the judge and jury his own opinions about Sally Clark and the death of her babies, and why his statements carried such weight, it is important to know who he was, where he was coming from, and where his sphere of competency lay. A specialist in child abuse, he had studied under legendary child psychoanalyst Anna Freud, and was greatly influenced by her teaching. “A child needs mothering—not a mother,” he used to quote her as saying, though it is not absolutely certain that Freud ever really pronounced this sentence; perhaps those words were merely Meadow’s own interpretation of what she taught. In any case, they seem to have left their mark.
While Roy Meadow began as a pediatrician, working first as a general practitioner, and later at Guy’s Hospital, the Hospital for Sick Children in London, and the Royal Alexandra Hospital in Brighton, his main interest changed to child abuse as his career advanced, and he focused his attention on the detection, analysis, and proof of the misdeeds and cruelties of mothers. It was in 1977, while working as a senior lecturer and consultant pediatrician at Leeds University, that Meadow came up with the idea that eventually led him to fame. This was the discovery—or the invention—of a new malady, which he baptized Munchausen Syndrome by Proxy.
Munchausen Syndrome is the name given by Dr. Richard Asher in 1951 to a psychological condition by which a person who is actually in perfectly good health claims to suffer from all kinds of symptoms of illness that he imagines to be truly present, or sometimes even purposely brings on through acts of self-injury. The name is a reference to the yarns told by the eighteenth-century German soldier and nobleman Baron Munchausen, who astounded his listeners upon his return from the wars by describing flights on cannonballs, trips to the moon, and impressive feats of marksmanship such as shooting fifty brace of ducks with a single bullet. There is actually not a lot of resemblance between Munchausen’s tales and those told by sufferers from Munchausen Syndrome—except, perhaps, for their tallness.
Psychological analysis has determined that Munchausen Syndrome arises from an intense need for sympathy, care, and attention from a competent and protective figure, a role that is ideally played by a doctor. Exactly the kind of medical test or procedure that most people would prefer to avoid—blood tests, biopsies, colonoscopies—is reassuring and consoling to sufferers of Munchausen Syndrome, and they tend to seek such procedures repeatedly and unnecessarily.
What Roy Meadow noticed in his seminal 1977 paper was that some people display a variant form of Munchausen Syndrome, seeking constant medical attention not for themselves, but for another person, a “proxy.” These people constantly go to doctors and describe symptoms in their proxy that are either nonexistent or artificially induced. Obviously the proxy must be someone unable to explain the true state of affairs; for this reason, proxies tend to be helpless invalids or children.
This was the mental condition that Meadow dubbed Munchausen Syndrome by Proxy (MSbP). He published his discovery in the medical journal The Lancet, and the title of the article reveals that his interest in the syndrome itself was inspired by a profound concern with the frightening realities of child abuse. The article, “Munchausen Syndrome by Proxy: the hinterland of child abuse,” described two cases in which he had taken a particular interest. In one of them, a mother persistently altered her six-year-old daughter’s perfectly healthy urine samples, leading doctors to perform an endless stream of invasive medical examinations on the child and subject her to long-term medicinal treatments ranging from antibiotics to chemotherapy. The deception stopped only when the daughter was admitted to a hospital and kept for two or three days in the absence of her mother, who previously had rarely left her side. The child’s healthy samples during the period of her mother’s absence, and her instant relapse the moment her mother returned, finally led caregivers to the truth. In the second case, a seemingly devoted mother brought her toddler to the hospital at least once a month with attacks of illness that were diagnosed as salt poisoning. When the child was kept in the hospital, he became healthy, and when his mother visited, he relapsed. The hospital contacted social services to organize surveillance and placement for the child, but before the discussions could lead to a concrete result, the little boy was brought in with an attack so severe that he died.
If the hospital workers took as long as they did to detect what was going on, Roy Meadow explained, it was partly because both mothers seemed to be agreeable, intelligent women and loving and tender parents (albeit with a history of hysterical behavior, had anyone only thought to check). No one suspected them, because no one had the habit of suspecting mothers. Roy Meadow stressed the fact that mothers must be suspected. “We may teach, and I believe should teach, that mothers are always right,” he wrote, “but at the same time we must recognize that when mothers are wrong they can be terribly wrong.”
For ten or twelve years after Meadow wrote his article, Munchausen Syndrome by Proxy received little or no attention, either in the profession or from the public. And then suddenly, he was given the opportunity to put his theory into practice, because of a grisly and terrible murder case that finally allowed the whole idea to spring forth and capture the attention of a country.
IN FEBRUARY 1991, a young nurse called Beverley Allitt was engaged in Children’s Ward 4 of the severely understaffed Grantham and Kesteven Hospital in Lincolnshire. Although she appeared kind and competent, she inexplicably went on a killing spree that, in the space of barely two months, took the lives of four tiny children and severely injured one more.
Recalling what it was like to work alongside Beverley Allitt for those two months, nurse and coworker Mary Reet expressed an intuitive feel for Allitt’s psychological motivation. “Part of the kick she would’ve had was that when those babies were brought back to life, she was there, and she was the savior,” she later wrote. It wasn’t the babies’ deaths that Allitt wanted: it was attention. And this was exactly how Roy Meadow presented it when he testified as a medical expert at her trial. He showed how she displayed all the symptoms of both Munchausen Syndrome and MSbP, and explained that Beverley’s coldness in the face of the death of her victims was typical; people with MSbP are not able to grasp the harm they are inflicting; they are closed off to it. Roy Meadow stated that he did not believe Beverley Allitt could be cured. She would always be a danger to others. Allitt was convicted and given thirteen life sentences.
Roy Meadow’s diagnosis made a lot of sense. On top of that, the visibility of the case, the terrible and shocking nature of the crimes, and his role as expert witness at the trial conferred upon him not just fame, but a great deal of influence and power as well.
From the moment Beverley Allitt was condemned to life in prison, Roy Meadow’s theory of Munchausen Syndrome by Proxy took a tremendous leap into both the public and the medical consciousness. It is perhaps not fully realized how rapidly the notion took hold and the number of diagnosed cases grew. MSbP became a byword in social work, where it was cited as a reason to interfere in the lives of innumerable families. Thousands of children were removed from their parents, and the practice soon spread from Britain to the United States, then to Australia, New Zealand, Germany, and Canada, and as far as Nigeria and India, where it was very popular.
In the name of the new diagnosis, horrific mistakes were made. One example was the “legal kidnapping” of little Philip P. in the autumn of 1996. Philip was a child less than one year old whose mother, Julie P., had made countless trips to hospitals in the state of Tennessee, where she lived, seeking treatment for her baby’s severe birth defects and chronic gastrointestinal troubles. Seeing the child’s lengthy medical history, doctors concluded that Julie must suffer from MSbP, and shortly after the baby’s arrival at the hospital they contacted the Department of Children’s Services to have custody of the baby removed from his parents and given to the hospital. The family was kept at a distance and the nurses were even instructed to give them no medical details over the phone. Unfortunately, as it happened, the baby was really very ill; separation from the mother had no curative effects, and exactly one month later he died, alone and far from his parents. It was one of many cases in which the notion of MSbP was abused.
ALLITT WAS convicted in 1993, and by 1996 some doctors were already beginning to sound a warning bell, even as allegations of MSbP continued to increase at a terrifying pace. Dr. C. J. Morley published an article titled “Practical concerns about the diagnosis of Munchausen syndrome by proxy,” in which he warned that after the condemnation of Beverley Allitt, the diagnosis had become “charged with emotion” and that “those who are accused are tarnished with her reputation.” In the article, he discussed the so-called symptoms of MSbP one by one, showing that each of them might arise for a perfectly legitimate reason. He even warned against a diagnosis of MSbP in the instance where a child separated from his mother is cured of his illness, as there can be any number of reasons for such an event, including the natural recovery from many infantile illnesses that tend to occur around the age of one year.
In their 1995 article “Is Munchausen syndrome by proxy really a syndrome?” G. Fisher and I. Mitchell also analyzed the weaknesses of the diagnosis, ending by suggesting it be dropped altogether: “It is recommended that pediatricians abandon making diagnoses of Munchausen Syndrome by Proxy and instead diagnose the specific fabricated or induced medical illness(es) or condition(s) they encounter.”
But such calls for restraint were not heeded. Allegations of MSbP continued apace, and in fact a new aspect appeared and soon came to occupy a central position in allegations of child abuse: the role of Munchausen in unexplained deaths of babies, often referred to as cot death, crib death, or SIDS—Sudden Infant Death Syndrome.
BABIES HAVE always been fragile beings. The death rate of children under the age of one year old in the nineteenth century was startlingly high—as many as one hundred per thousand babies in the upper social classes and three hundred per thousand among the poor. Even in the early twentieth century the numbers remained significant. Only after the Second World War did doctors and hospitals begin to make tremendous strides in infant care, and rates began to decrease.
Yet even today, a small number of seemingly healthy very young babies die suddenly from unexplained causes. The phenomenon of crib death was not treated as a medical phenomenon in and of itself until 1963, when a first conference on the subject was organized in Seattle, Washington. The official term “Sudden Infant Death Syndrome” (SIDS) was adopted at a second conference in 1969. Obviously, the question of what proportion of SIDS deaths might be attributed to child abuse or outright murder was raised at both conferences, but there was simply no information available to draw any real conclusions as to the answers. A suggestion that SIDS was connected to apnea (babies stopping breathing for no reason) led to the adoption of huge numbers of apnea alarms being installed. These detectors are attached by small sensors to the baby’s body and are set to go off loudly if no breathing motion is detected. In the end, however, their widespread use served mainly to show that apnea is not the only or major cause of SIDS; there were too many cases where the alarm never went off. And studies showed that, like other social phenomena, SIDS is correlated with such factors as family background, poverty, mental illness, smoking, or drug use.
Improvements in baby care methods led to a significant drop in SIDS throughout the 1990s, particularly in families considered “low risk,” meaning stable families with good incomes and good physical and mental health. The improvement spurred further study, and during the early 1990s there occurred a kind of medical SIDS frenzy, with doctors publishing research based on as few as two cases, rising to stellar heights in their careers, and, even worse, encouraging parents who might be prone to Munchausen-type behavior to give way to it completely by calling for them to bring their babies repeatedly to the hospital for examination and care, exactly the kind of treatment that MSbP patients thrive on.
Then the bubble burst.
A team of suspicious law enforcement officials demanded and obtained the exhumation and autopsy of three siblings from New York State who had all supposedly died of SIDS. A detailed medical and legal investigation eventually proved that in fact they had all been suffocated by their father. The same team then investigated a family in which two infants who had died of SIDS had been the subject of a highly respected medical publication on SIDS and apnea. They discovered that three older siblings of these two babies had also died. Their mother eventually confessed to all the murders. This event and other similar ones were the flash points that drew together two strands that had been unconnected until then: SIDS (crib death) and Munchausen Syndrome by Proxy.
Until the mid-1990s, Munchausen Syndrome by Proxy had been studied in parents or caregivers who harmed children in order to gain attention and care. The children sometimes died, but this had not appeared as the goal of the caregivers’ actions. But then came the first diagnosis of Munchausen Syndrome by Proxy in a case of repeated SIDS.
ROY MEADOW’S intention, at first, was to join the swelling ranks of doctors concerned with finding causes and preventive remedies for SIDS, and to find features that could distinguish between natural SIDS and the death of a child caused by suffocation or other mistreatment. Since it is nearly impossible to detect signs of suffocation—the parents’ desperate vigorous attempts at resuscitation may cause the same slight bruises or cracked ribs as intentional abuse—the possibilities for detecting the difference seemed slim. Yet they were of paramount importance, both for those babies who suffered “near-miss” crib death and for the siblings of those whose abuse had gone undetected. Like many other doctors involved in the movement, Dr. Meadow wanted to find some signs that could help him tell one from the other. He devoted himself to this subject in the 1997 book he edited, The ABC of Child Abuse, and in a study titled “Unnatural Sudden Infant Death,” in which he surveyed eighty-one cases of sudden infant death, collected over an eighteen-year period, in families where the parents had actually been convicted of murder. He attempted to outline some general types of scenario to distinguish SIDS from murder. Unfortunately, the problem proved difficult; in half of the cases, autopsies showed physical signs of suffocation, but in the other half there were none.
It is a fact that some proportion of SIDS is unquestionably caused by parental abuse, but no one knows what that proportion is, and it is practically impossible to distinguish those cases with certainty. Until the 1990s the attitude of pediatricians toward this problem was to “let ill alone lest worse befall,” in the words of Dr. John Davies, who worried that innocent parents would be accused, families broken for no reason, and siblings sent into foster care.
But Roy Meadow was convinced that there were far more parents murdering their babies than anyone had ever realized—or at least admitted. He came to believe that Munchausen Syndrome by Proxy, hitherto regarded as a phenomenon leading mothers to harm their children, was actually claiming the lives of a much larger number of tiny victims than anybody realized. From that point on, his book, his study, and all the rest of his work became focused on developing a newly hawkish “interventionist strategy,” which meant making sure that mothers whose children died would be accused of having killed them if no other medical cause could be found. And his reputation as a specialist of the MSbP phenomenon lent tremendous weight to his words.
Partly because of that reputation and partly because of his vocal attitude toward child abuse, Roy Meadow’s career skyrocketed. He became president of the British Paediatric Association in 1994 and president of the Royal College of Paediatrics and Child Health in 1996. In the New Year honors list of 1997, Dr. Meadow was knighted for “services to paediatrics and to the Royal College of Paediatrics and Child Health.” His star was on the rise, and he became one of the most called-upon medical experts in trials of mothers in all of Great Britain.
At these trials, he would use the witness stand as a podium to promote his views, displaying a distinct talent for catchy phrases that the press loved to quote, such as “there is no evidence that cot deaths run in families, but there is plenty of evidence that child abuse does,” or “one cot death is a tragedy, two is suspicious, three is murder.” His views gained incredible notoriety, and on the strength of his highly respected word some 250 mothers were sent to prison.
UP ON the witness stand at Sally Clark’s trial, Meadow was eager to share his knowledge and experience, and the conclusions he drew from them, with the judge and jury. Statistical studies showed that “the chance of a cot death in a family of the social status of the Clark family is about 1 in 8,543,” he explained in his warm voice. “That means that the chance of two such deaths occurring in the same family is equal to the square of that number: one chance in about 73 million.”
Sally’s counsel begged to differ. Records from the CONI program, which followed babies born after a SIDS death in a family, showed that of five thousand babies monitored, eight had died. Surely that proved that the probability of such an event was much higher than 1 in 73 million, since the latter figure predicted that a double crib death would occur in England about once in a century. The CONI statistics showed that in reality this sad event actually occurs in England every couple of years. Indeed, the Clarks received many letters of support from families who had lost two, sometimes even three children, to SIDS.
Yes, but the CONI program data, explained Meadow, had not been collected with the kind of scientific precision and standards of a properly conducted study. The figures that he was using, by contrast, came from the CESDI report, which was more comprehensive than the CONI information, calculating the number of crib deaths in various sectors of the population.
The CESDI report, whose full title was “Confidential Enquiry into Stillbirths and Deaths in Infancy,” was a controlled study commissioned by the British Department of Health. In it the author, Peter Fleming, a professor at Bristol University, identified three major risk factors for crib death: a smoker in the family, an unemployed parent, and a mother under the age of twenty-six. The study provided probabilities for the occurrence of SIDS in the presence of one or more of these factors and in the absence of all three. In families where all three risk factors were present, the probability rose to 1 in 214; in families where all three factors were absent, it fell to 1 in 8,543, the figure cited by Meadow. The overall figure is a probability of 1 in 1,300. Thus, the figure of 1 in 73 million only concerned families of the Clarks’ habits and income; in the overall population Meadow would have expected the chance of a double crib death to be 1 in 1,300 squared, or about 1 in 1.5 million, fifty times more than the probability he was using for Sally. In other words, Meadow agreed that there could be a legitimate double crib death about once every couple of years in England, corresponding to observed fact. But these deaths would typically not occur among people like the Clarks; such a family, according to his reasoning, would suffer a crib death only about once in a century. It was just too unlikely an event: the Clarks did not have any of the three main risk factors for SIDS, so why should both of their babies die by pure chance?
As a matter of fact, the CESDI study makes it very clear that other family factors exist that may affect the probability of SIDS, but are not yet understood. Meadow’s essential error was to ignore this observation and to treat SIDS as a phenomenon that befalls babies as a consequence of completely random chance, like the lottery.
“So when Harry was born, the chance of his being a cot death was the same as Christopher’s? One in 8,543—like tossing a coin? It’s the same odds each time? Heads or tails?” questioned Sally’s lawyer.
“It’s the chance of backing the long outsider at the Grand National,” replied Meadow, calmly displaying a horrific lack of taste. “Let’s say it’s an 80 to 1 chance you back the winner last year and next year there’s another horse at 80 to 1 and you back it and it wins. To get odds of 73 million to 1 you have to back that 80 to 1 chance, four years running. It’s the same with these deaths.”
This response clearly indicates that Meadow viewed crib deaths as a random occurrence—in the face of the very CESDI study he was quoting, which warns that there may be unknown factors, even genetic ones, that increase the risk in certain families. The choice of the figure of 1 in 8,543 for the probability of a crib death occurring once in a family like Sally’s is correct, since the number is obtained by observation of millions of families. But Meadow’s calculation of the probability of two crib deaths by squaring that number relies on the totally unjustified assumption that crib death is a purely random event. If, in fact, there is a genetic trait that can cause crib death, then two crib deaths in a family may both be traceable to this trait and thus not be independent at all. Meadow’s calculation is an example of Math Error Number 1: multiplying non-independent probabilities.
So why did Roy Meadow treat crib death as a random occurrence? When you think about it, it really makes no sense to note that there are factors that increase the risk of crib death while at the same time considering each occurrence of it as being absolutely random. It has to be one or the other; it can’t be both. If it is random, it will strike independently of any risk factors. But the CESDI study clearly shows that that is not the case. If there are known risk factors, then there can be unknown ones as well; in fact there almost certainly are some above and beyond the three identified in the CESDI report, probably several.
Moreover, crib death is not a single phenomenon, but an umbrella term used to describe infant deaths that are not medically understood. These deaths, in fact, do have causes—it’s just that doctors have been unable to ascertain them. It sometimes happens that explanations arise later on, because of genetic features that continue to arise within the family or upon a more serious examination of the autopsy records. Once the cause of death is known and identified, the baby has no longer died of SIDS, and the statistics concerning SIDS are modified by the removal of the case from the databases. SIDS is not an absolute event that either has or has not occurred, nor is it a purely random event, so multiple occurrences cannot be assumed to be independent events. Unfortunately for the Clarks, however, Meadow’s figure was accepted without question by judge and jury.
And not only was it accepted, but also it was misconstrued. The second problem with a figure such as 1 in 73 million is that even if it were correct, it tends not to be understood correctly. The public, and no doubt many members of the jury, took it to be the probability that Sally Clark might be innocent—that there was, in fact, a chance of just 1 in 73 million that she might be innocent. In other words, the reasoning was as follows: “Such an event happened to Sally Clark, there’s a chance of just 1 in 73 million for that event to happen naturally; therefore it is practically certain that it did not happen naturally; Sally Clark must have made it happen.”
This logic, which is almost irresistible, is also wrong (another example appears in “the incredible coincidence” discussion of Math Error Number 7 in this book). The fallacy becomes immediately obvious in the analogous statement: “One million lottery tickets were sold and Mr. X won; there was only 1 chance in 1 million for that to happen naturally, so the probability is too low to believe that it happened naturally; therefore Mr. X must have cheated.” Of course, in lottery situations we know this is not true; someone always wins the lottery, and no one suspects the lucky person of having cheated.
The point is that double crib deaths, while extremely rare, do happen, and some unfortunate family somewhere will fall victim to it, just as somewhere there will be a fortunate Mr. X who wins the lottery. Once the event has already occurred, you cannot retroactively calculate the probability that it could have happened and then suspect that the likelihood is too small for it to have really happened. When it’s the lottery, no one ever has a doubt.
In addition to the possibility that Sally’s babies died by pure chance and the possibility that she murdered them, there was a third possibility, by far the most likely of the three: that they died of an actual medical cause that the doctors had been unable to determine. But the jury members were never told this. They were left to choose between “1 chance in 73 million that it happened by chance” and “otherwise she killed them.” How could they hesitate?
Sally Clark was convicted of murder by a 10–2 majority verdict on November 9, 1999, and given the mandatory sentence of life imprisonment. The press had a field day reviling her as a child murderer. On her arrival at Styal Prison she could hear the other prisoners, who had followed the news on television, screaming, “Here comes the murderer!” and, “Die, woman, die!” as they strained and clambered to get a better look at her.
Thanks to “1 in 73 million,” Sally Clark had suddenly become the most hated citizen of Great Britain. Nearly a year later, on October 2, 2000, the Court of Appeal upheld her conviction. They denied the influence of the statistic on the jury, writing, “The point on statistics was of minimal significance— a sideshow—and there is no possibility of the jury having been misled.”
A request to the House of Lords for leave to appeal again—Sally’s final chance for justice in Great Britain—was rejected. She faced life in prison, without even the hope of early release, which would have been possible only if she accepted to admit guilt and express remorse. But Sally was innocent. Not for freedom—not even for her life—would she say that she had killed her sons.
THE ONLY ray of hope in the months that followed was that the Family Court granted Steve Clark full custody of their remaining son, making it possible for Sally to see the child each week and even spend a full day with him once a month. Steve sold Hope Cottage, moved near where Sally was imprisoned, and devoted himself to continuing the struggle for her freedom while learning to be a single stay-at-home dad. Steve’s professional and family life had been shattered, and nothing remained to him but his little boy.
He and I become a team—he is my little mate, and we develop a strong bond of love; I get closer to him than most dads, but why did it have to be like this? We manage to muddle our way through together. Sometimes I sit outside his nursery all night, just in case he needs me . . . Then comes the morning I take him for his first day [at nursery school]. I cannot bear it. I cannot handle the thought of leaving him with strangers. But we walk there together, he holding my hand, sometimes quite tightly. Suddenly, much too soon, we are there. I don’t want him to see me crying. But I can’t help it. I kiss him goodbye and hand him over to a lovely lady, tears coursing down my face. I cry all the way back to the house; it feels strangely empty. What have I done? I sit there, desolate, terrified that something may happen to him.
Fortunately, Steve refused to give up. With the help of the lawyer who had worked on Sally’s case from the beginning, and of many other people who generously gave their time for free, he continued to chase up every avenue that might lead to anything—an appeal to the European Court of Human Rights, a submission to the Criminal Cases Review Commission, a public relations specialist to help the truth filter out to the public, and as a last resort, further analyses of the medical examinations performed on Christopher and Harry, the results of which were being kept under lock and key by the hospital where they died.
The medical results had not initially been at the top of Steve’s priorities. He was convinced that the experts had seen everything there was to see. Struggling with bills and a time-consuming new job, Steve had other things on his mind. However, as the case’s exposure grew, people appeared out of nowhere to help the cause. One of these volunteers was a lawyer who wanted to obtain the medical records from the hospital, convinced that Steve’s team needed them. Among other things, they wanted to get the original apnea alarm that had often rung when Harry was wearing it. They thought it possible that the alarm was not defective at all, and that in fact the child had undergone repeated episodes of abnormal apnea that had not been recognized by the health professionals checking on him.
Instead, after months of legal efforts, when the records were finally, reluctantly made available, the team found something else—something completely different, and shocking; something that had been overlooked by every single doctor who had had direct access to the records, meaning every single medical expert for the prosecution. Not by the defense, though. As a matter of fact, these documents had never been disclosed to the defense.
No fewer than eight different colonies of the lethal bacterium Staphylococcus aureus had been found in Harry’s body, some appearing with polymorphs, which are the cells that our bodies develop to fight off disease. They showed that the baby had been suffering from a serious bacterial infection when he died, one that even could have led to meningitis. Confronted with these records, a dozen new and independent medical experts wrote reports stating that Harry most certainly could have died, and very probably did die naturally, from a serious infection. His death never should have been considered an unexplained crib death.
At around the same time, Meadow’s mathematical assertions were put under scrutiny when on October 23, 2001, the Royal Statistical Society sent a public complaint to the Lord Chancellor, in which they exposed his errors and harshly expressed their gravity.
This approach is, in general, statistically invalid. It would only be valid if SIDS cases arose independently within families, an assumption that would need to be justified empirically. Not only was no such empirical justification provided in the case, but there are very strong a priori reasons for supposing that the assumption will be false. There may well be unknown genetic or environmental factors that predispose families to SIDS, so that a second case within the family becomes much more likely.
All of these facts were added to Sally’s file when it came up in front of the Criminal Cases Review Commission, and her conviction was quashed on January 29, 2003. Sally was finally free. But she had spent more than three years in prison, and in spite of the joy of being reunited with her husband and child, she found it terribly difficult to recover the habits of a normal life. Having been accused of murdering her children because she was obsessed with her career, she could not contemplate going back to work. Having been told that she killed Harry because he was messy and disruptive, she cringed when friends admired her tidiness. Everything she had been, everything she was proud of in her life, had been held up as a model of horror to the entire country. And on top of this, she had been deprived of the ability to make a single decision for herself throughout her years in prison.
Sally suffered from a recognized psychological phenomenon known as “enduring personality change after catastrophic experience.” In desperation, she sought consolation in alcohol, as she had for a short period after Christopher’s death. She died of acute alcohol intoxication in her home on March 16, 2007, just four years after her release. She was forty-two years old.
THE TESTIMONY of Roy Meadow, recognized expert on Munchausen Syndrome by Proxy, child abuse, and the evils of motherhood, sent dozens of mothers to prison. After Sally’s successful appeal, other cases were quickly forwarded on to the Criminal Cases Review Commission, and other mothers were exculpated and freed. One of them was Angela Cannings.
Angela had lost not two but three babies to inexplicable sudden death, the third literally days after Sally’s first conviction. Although there was a history of infant death in part of Angela’s family, which may have indicated an unknown genetic factor, she was accused of murder after the third occurrence and brought to trial. Sir Roy Meadow was the key expert witness for the prosecution. No one has described Meadow’s particular style on the stand as powerfully as Angela did in her book Against All Odds, which tells the story of her tragedy. Quoting some of his testimony, she writes:
I remember one exchange late in the day which made me shudder. Mr. Mansfield [Angela’s lawyer] yet again insisted that looking at the whole picture—me, our family, the lack of injuries on Jason and Matthew, the features consistent with cot death—it was a real possibility that my children could have died from natural, but as yet unknown, causes.
“I think the problem with that statement [is that] Mr. Mansfield is saying because the family is normal, child abuse doesn’t happen,” Professor Meadow replied. “It is absolutely right to say that child abuse and smothering are more common in certain families, but nevertheless, most abuse, most smothering happens in families who on ordinary meeting seem normal and caring and that is so, and most of the mothers who smother children, when you meet them, are normal. The second point is to start talking about the features of SIDS. SIDS means that you don’t know why the baby has died. It means that an unnatural cause such as smothering wasn’t found, and nor was a natural cause, so that in any group of SIDS babies there are some who have been smothered.”
I was trapped. If I appeared normal, I could be a child abuser; if my babies were thought to have died of cot death, I could have smothered them. There might not be any actual proof against me but Professor Meadow had created a world of smoke and mirrors from which I could not escape.
Like Sally, Angela was sentenced to life in prison. She immediately appealed. While she was waiting, she heard about the trial of Trupti Patel, another mother who had lost three babies to SIDS. Trupti’s trial took place six months after Sally’s release. Meadow testified against her, too, and listed no fewer than four different reasons proving that she must be guilty of murder. Fortunately for Trupti, however, the stinging judicial criticism of Meadow’s errors that had been published at the quashing of Sally’s guilty verdict had rippled out into public consciousness by then, and when other possible causes for the death of Trupti’s babies were discussed—a genetic defect in particular—the jury listened carefully and acquitted her. Following this, the Solicitor General of England and Wales effectively barred Sir Roy Meadow from testifying for the prosecution in any further trials. Angela Cannings’ conviction was overturned just months later, and following her release, cases of imprisoned mothers elsewhere were reviewed. But as was the case for Sally, it was too late for Angela to put the broken pieces of her family life back together. As she described movingly in her book, finding her husband sunk in depression and her one remaining daughter in a state of psychological disturbance, Angela struggled for many months before finally leaving her home to try to begin a new life.
In July 2005 the British General Medical Council (GMC) found that Sir Roy Meadow had been guilty of serious professional misconduct in his misuse of statistics at the trial of Sally Clark, and his name was struck from the medical register. The GMC’s decision was later overturned and Dr. Meadow was reinstated, but by that time he had retired.
Meadow always denied any wrongdoing, admitting only that what he had done was perhaps “insensitive.” But the GMC termed his actions “fundamentally unacceptable.” The panel stated that while Sir Roy Meadow was recognized as an eminent pediatrician, “he should not have strayed into areas that were not within his remit of expertise.” His calculation could be valid only if it were known that two crib deaths within a family must necessarily be independent of each other, but in fact there is no known medical justification for that assumption and many reasons to believe it false.
Meadow stood by his reasoning. But he regretted having used the example of betting at the Grand National to illustrate the probability. It was the only thing he regretted, apparently. None of the innocent mothers who spent years in prison because of him, none of the families whose lives were shattered, ever heard a word of apology.

MATH ERROR NUMBER 2 »
UNJUSTIFIED ESTIMATES
IT IS DIFFICULT TO OVERESTIMATE the extent to which we are bombarded with figures on a daily basis. Intended to inform us, to enlighten us, to help us, these figures also, far more frequently than one might like, mislead us. A shocking proportion of the numerical estimates we receive are simply wrong, whether by intention, by accident, or because of ignorance or typographical error. Worse, the effect of this kind of error is frequently minimized, as though the only important thing is having a number at all, one that can lend a scientific aura to whatever statement is being made.
A British report on the failings of the Labour government from February 2010 cited a figure of 54 percent for the proportion of girls in the ten most disadvantaged areas of England who became pregnant before the age of eighteen. When challenged by an alert reader who realized that this figure seemed unreasonably large, the Tories admitted that the correct estimate was actually 5.4 percent. The error would have been forgivable if the Tories had not felt it necessary to make the following public statement: “A decimal point was left out in a calculation. It makes no difference at all to the conclusions of a wide-ranging report which shows that Labour have consistently let down the poorest in Britain.”
This we’re giving you a number but who cares whether it’s right or wrong attitude ends up weakening our capacity for making our own assessments, because, after all, if it doesn’t matter, then why bother giving figures at all?
But it does matter. In the next case, not only were the statistical figures given in court multiplied together incorrectly as in Math Error Number 1, but also the figures themselves were inaccurate estimates thrown out to the jury by an enterprising prosecutor. Once caught, these errors eventually led to the overturning of a remarkable conviction—but not before the accused had already completed their terms in prison.
 
 
The Case of Janet Collins: Hairstyle Probability
Juanita Brooks crashed painfully to the ground, her cane underneath her. The groceries from her wicker shopping basket scattered over the pavement. Stunned and in pain, it took the elderly woman a moment to realize that she had been violently pushed from behind, and another to lift her head and scan the area for her attacker. What she saw was a young blonde woman tearing down the alley and rounding the corner at the far end. Dangling from her hand was Juanita’s purse.
John Bass, who lived on a street off the end of the alley, was outside watering his front lawn when he heard Juanita scream. As he looked up from his hose, he saw a young woman, blonde ponytail flying behind her, run out of the alley and jump into a bright yellow car that was waiting at the curb. The car revved up and took off, swinging widely around a parked car and passing within six feet of Bass. To his surprise, he noticed that the driver was a black man.
It was 1964. Interracial couples were very rare, and they were not treated with indifference. In public, in the street, they were noticed, singled out, and frowned upon.
The investigator assigned to the case was Officer Kinsey of the Los Angeles Police. Kinsey collected as many descriptive details from the two witnesses of the crime as he could. From Juanita he learned that the woman she had seen appeared to be generously built—Juanita estimated her weight at 145 pounds—with hair “between dark and light blonde.” She also described the woman’s clothing as “dark.” Bass agreed about the dark clothing and guessed that the woman he had seen was about five feet tall, but he described her build as “ordinary” and mentioned that her dark blonde hair was tied back in a ponytail, which Juanita could not remember. He also stated that the driver of the car wore a mustache and beard.
The police had no clues to the identity of the bag snatchers and no clear trail to follow. Juanita Brooks’ son, however, was enraged by what had happened to his mother: not only had she been attacked and robbed, but also she had sustained a dislocated shoulder from her fall. He was determined to find the attackers himself. Having come up with a simple plan, he visited every gas station in the neighborhood with a description of the pair until he hit on one whose personnel confirmed that indeed an interracial couple came there regularly to fill up the tank of their yellow Lincoln. Brooks took this information straight to the police, which explains how, four days after the robbery, Kinsey was ringing at the doorbell of the modest house inhabited by Malcolm and Janet Collins.
When the police officer chose to follow up the information that Juanita’s son brought him—when he agreed that the Collinses were suspects simply because they matched the description of the thieves—he could not have realized that he was engaging in an unorthodox identification procedure that would later result in a serious legal puzzle. He assumed he would probably find evidence of their crime easily enough; maybe he would even obtain a confession.
As Kinsey drew up in front of the Collins house, the first thing he saw was a yellow Lincoln parked in the street, and when Janet answered the door, he noted with satisfaction that she was wearing a ponytail. It was blonde, though he would have described it as light rather than dark, and Malcolm was not wearing a beard, but there were enough features in common with the thieves as described by Juanita and Bass for Kinsey to feel justified in asking the Collinses to accompany him to the police station. There he had them photographed, and interrogated them about their activities at the time of the robbery. Janet explained that Malcolm was unemployed, but that she had been at work at her job as a housemaid in San Pedro on the morning of the robbery starting at 8:50 a.m., and that her husband had come with the car to pick her up at 1:00 p.m. According to both of them, they had then driven to the home of a friend in Los Angeles and had spent the whole afternoon there. Officer Kinsey released them and had them driven home in a police car pending further investigation.
His next step was to show the photographs of Malcolm and Janet to the victim and to his only witness. The result, however, was disappointing. Juanita could not identify Janet at all, and Bass was able to say only that the ponytail of the woman he had seen running away “looked the same” as the one in the picture. However, Kinsey was not deterred. He was pretty certain that Malcolm Collins was a shady character. And he had a plan to prove it.
A DAY or two later, Officer Kinsey drove around the area where Malcolm and Janet lived until he saw them arrive home in their yellow Lincoln. He followed them, parked his car in a position from which he could survey the rear of the house, and put in a call for backup at the Collins home. Following his instructions, the additional officers rode in a marked police car and pulled up ostentatiously in front of the house. The car immediately disgorged numerous uniformed officers, who stormed up the front path and loudly rang the doorbell.
This tactic produced exactly the effect that the officer had hoped to achieve. From his position at the rear, Kinsey saw Malcolm go racing out of the back door, scurry into a neighbor’s garden, and enter the house. When Janet opened the front door, the other officers went straight into the Collins home, arrested her, and led her outside, where they pushed her into the police car. Then they went next door, entered the house, and began a room-to-room search for Malcolm, whom they discovered tightly squeezed inside a closet. The couple was taken back to the police station, and this time they were kept in custody and interrogated for more than forty-eight hours. Yet once more, in spite of their shocking treatment of the suspects, the police failed to obtain a confession or even a shred of solid evidence, and for a second time Malcolm and Janet were released with no charges.
Frustrated by the failure of his second premature attempt to extract a confession, Kinsey set to the tedious work of gathering evidence, questioning Janet’s employer, the friend whom the Collinses had visited on the day of the robbery, and several of their acquaintances and neighbors. He collected as much information as he could—concerning the Collinses’ alibi, their financial situation, their hair color and style, and the past and present state of Malcolm’s beard—and two weeks later he arrested Malcolm and Janet for the third time.
Although the facts that Kinsey collected through his investigation were actually rather imprecise and confusing, he decided that this time they were sufficient to justify the arrest, on the basis of two rather strong points against the couple. First, although Janet had claimed that her husband had picked her up from work at 1:00, her employer stated that the time had actually been about 11:30. True, 11:30 was the time at which Juanita said she had been robbed, which would have made it impossible for Janet to be the perpetrator. But neither Juanita nor Bass had been able to give the time of the robbery with any real precision, and the distance between Janet’s employer’s home and the robbery could have been covered in just a few minutes by car.
Second, on the day following the robbery, Malcolm had paid off two traffic fines totaling thirty-five dollars. The police found the receipts in his pocket. Asked separately about the funds used to pay the fines, Malcolm explained that he had used money he had won at a gambling hall, and Janet said he had paid them out of some of her savings. The trouble was that the stolen purse had contained a sum of money that Juanita estimated as between thirty-five and forty dollars.
To get an idea of what that sum represented in 1964, it is useful to have a few points of comparison. The average monthly rent in the United States that year was $115; a loaf of bread cost around $0.20. Janet Collins earned $12 a week for her part-time work as a housemaid. On the one hand, her $50 per month might seem hardly enough to survive on, but on the other, certain things cost unimaginably less than they do today. Janet and Malcolm had gotten married on June 2, two weeks before the date of the robbery, and had taken a honeymoon to Tijuana, Mexico. The trip cost Janet only “a part of that $12.”
Still, at Janet’s part-time salary, those traffic fines must have represented a heavy financial burden for the Collinses. At the same time, the money obtained from the bag snatching would have seemed like a near-miraculous piece of good fortune. Even if they had been so desperate that they had planned to snatch someone’s purse, they could hardly have imagined finding a sum as large as thirty-five dollars—exactly what they needed to pay their fines. Remember, that amount of money would have been nearly Janet’s monthly salary; not many people walked around carrying so much. The matching of the sums seemed almost too good to be true.
WHILE IN custody and awaiting the preliminary hearing, Janet grew afraid, and requested a private conversation with Officer Kinsey. During this conversation, Janet told Kinsey of her fear that because her husband had a previous criminal record, a new conviction would net him a longer prison term. She repeatedly expressed her anxiety on this subject, and finally she told Officer Kinsey that if either of them were to be convicted, then it should be her and her alone; she wanted to take all the blame. In excerpts from the conversation, which was recorded in its entirety and played back during the trial, she asks about this possibility again and again.
“If I told you that he didn’t know anything about it and I did it, would you cut him loose?”
“I just want him out, that’s all, because I ain’t never been in no trouble. I won’t have to do too much time, but he will.”
“What’s the most time I can do?”
“Would it be easier if I went ahead and said, if I was going to say anything, say it now instead of waiting till court time?”
At a certain point, Officer Kinsey summoned Malcolm to join in the conversation. Perhaps he hoped to extract some contradictions between their stories—for example, about exactly what money was used to pay the fines— and somehow parlay those contradictions into a confession. But that didn’t happen. Instead, like Janet, Malcolm seemed interested only in discussing strategy to obtain the least possible total punishment. “I’m leaving it up to her,” he can be heard saying at one point in the recording. And at another: “This is a little delicate on my behalf.”
The conversation ended when the couple finally decided that they needed more time to think things over. To Officer Kinsey the tone of the discussion and the concern of the couple with their possible prison sentences were signs of guilty behavior, and he described them as such during the subsequent trial, saying, “They seemed to be conscious of their guilt, and looking to find the best solution to get out of the situation.”
But just as Malcolm Collins’ fleeing the police to hide in a neighbor’s closet may not indicate actual guilt so much as a general fear of trouble with the police due to bitter past experience, so this conversation can be understood in quite a different manner. Married to a black man at a time of rampant racism, nineteen-year-old Janet must have repeatedly experienced the censure of society. Ignorant, working-class, and poor, she would not have been used to standing up for her rights. She probably felt that, guilty or innocent, there was essentially no chance at all that a trial would result in acquittal. Her marriage to an unemployed black man with a previous record fit into a perfect image of a couple of petty criminals, and jail time must have looked like a certain bet. Under those circumstances, Janet’s desire to shoulder the blame in order to save her husband from more serious trouble may seem indicative not so much of guilt as of love.
AS WAS revealed over the course of the couple’s joint seven-day trial, the prosecution’s entire case was built around the problem of identification. The defense stressed the impossibility of someone leaving work at 11:30 and committing a crime some streets away, also at 11:30. The prosecution responded by noting that none of the witnesses, neither Juanita, Bass, nor Janet’s employer, were certain of their times to within a few minutes. And as noted above, that was all it would have taken for the couple to drive to the scene of the robbery.
There was also the issue of Malcolm and Janet’s alibi. Unfortunately for them, although the friend whom they claimed to have visited in Los Angeles on the day of the robbery remembered their coming over to her place, she was not able to recall the precise time or even the precise date of their visit.
Still, both of these pieces of evidence were weak; they didn’t prove anything. What the prosecution wanted was to pinpoint Malcolm and Janet Collins as the robbers by identifying them through the physical evidence given in Bass’ description: the yellow car, which they undoubtedly did possess; Janet’s dark blonde hair, ponytail, and dark clothing; and Malcolm’s mustache and beard.
If those details had been more precise and corresponded more closely to the two defendants, they might well have been in serious trouble. But in fact, they were vague and did not quite fit. For one thing, Malcolm was not now wearing a beard. Bass nonetheless identified Malcolm at the trial as the man he had seen in the car. But the effect of his declaration was destroyed by the defense, who provided evidence proving that shortly before the trial Bass had failed to pick Malcolm out of a police lineup.
Asked whether he had worn a beard on June 18, the day of the robbery, Malcolm explained that although he did occasionally wear a beard, he had not been wearing one lately, having shaved it off a couple of weeks earlier for his June 2 wedding to Janet. The defense called a number of witnesses who were acquainted with Malcolm and confirmed his claim. However, the court clerk who took payment for Malcolm’s traffic fines on June 19 testified that he recalled him as having a beard on that day. In the end, this point simply could not be determined one way or the other.
Then there was the problem of Janet’s clothes and hair. Evidence was presented that on June 18 she had been wearing light-colored clothing, not dark. Furthermore, neither Juanita nor Bass was able to identify Janet in the courtroom. On top of that, while they both agreed that Janet’s hair seemed somewhat lighter in court than it had been on the day of the robbery, Janet’s employer testified that she thought that Janet’s hair had become darker since that day. The possibility that Janet had dyed, bleached, or otherwise altered her hair since June 18 was discussed in detail, but could not be resolved. Janet herself denied having done anything special to her hair.
Malcolm and Janet were both called to testify on their own behalf, and both denied any involvement in the crime. Malcolm told the jury about how he had picked up his wife at work and driven her to their friend’s home in Los Angeles, where they spent the afternoon. Janet confirmed this. Of her conversation alone with Officer Kinsey, she added on the stand that “inducements had been held out to her on condition that she confess her participation,” and she formally denied ever having made any confession or intending to do so.
There were no further witnesses, and therefore no further testimony was expected. It was obvious that the case against Malcolm and Janet was weak. But at the last minute, as a sudden move to bolster up the failing process of identification, the prosecutor presented a dramatic new approach.
RAY SINETAR, a thirty-year-old prosecutor with just two years of experience behind him, had been wondering how to explain to the jury what he saw intuitively: the Collinses had to be the thieves for the simple reason that the number of couples fitting their description was so small that, it seemed to him, they were virtually certain to be the only such couple in the neighborhood. It was frustrating to perceive this so clearly and yet not have the evidence to make it hold water in court. But Sinetar had a little knowledge of mathematical methods; his brother-in-law was Ed Thorp, a mathematician and blackjack genius from New Mexico who would testify in the role of expert witness two months later at the murder trial of Joe Sneed (see chapter 3). It struck Sinetar that maybe he could mathematically prove that the Collinses had to be the right couple, by calculating the probability that any given couple in the Los Angeles area could share their distinguishing features, vague as they were: mixed race, yellow car, mustache, beard, blonde ponytail.
Early in the morning of the second day of testimony, Sinetar dashed off a phone call to the local university, California State University at Long Beach, and left a message that he urgently needed a mathematician to come into court and testify. The man who answered the message was twenty-six-year-old probability theorist Daniel Martinez, who had come in to work that day to teach his class and thought it might be interesting to turn his knowledge into evidence in a court case. He later recalled, however, feeling a bit unsettled when the case began to unfold before him, wondering just what he had got himself into.
In court, Sinetar turned to the jury and explained to them that he was going to give a mathematical proof. He would show that if a person searched for couples matching the physical characteristics described by the witnesses to the crime—couple in car, black man, beard, mustache, white woman, blonde, ponytail, yellow car—the possibility of a precise match was so unlikely that if any such couple were actually to be found, the odds would be overwhelming that it must be the same couple as that seen by the witnesses.
Sinetar put Martinez on the stand and had him testify to the validity of the product rule, which, as we saw in the previous chapter, states that if two events are independent, then the probability that they both happen is obtained by multiplying the probabilities for each one happening on its own.
Next, Sinetar gave estimates for the separate probabilities associated with finding a person with each of the couple’s distinguishing characteristics, as follows:
•Black man with a beard: 1 out of 10
•Man with mustache: 1 out of 4
•White woman with blonde hair: 1 out of 3
•Woman with a ponytail: 1 out of 10
•Interracial couple in car: 1 out of 1,000
•Yellow car: 1 out of 10
Sources differ as to whether Sinetar gave Martinez the probability figures without mentioning the qualities they corresponded to, or whether he told Martinez that judging the validity of those probabilities was not his concern. In a telephone interview some forty years later, Sinetar recalled that he only gave the figures, but a quoted question and answer from the original testimony recorded in the state supreme court appeal judgment indicates that he said more:
Now, let me see if you can be of some help to us with independent factors, and you have some paper you may use. Your specialty does not equip you, I suppose, to give us some probability of such things as a yellow car as contrasted with any other kind of car, does it? . . . I appreciate the fact that you can’t assign a probability for a car being yellow as contrasted to some other car, can you?
Martinez’s recorded answer: “No, I couldn’t.”
In any case, what emerges clearly is that Martinez was asked to multiply the numbers together and was provided with paper and pencil for the purpose. He did so, obtaining the result 

 a probability of 1 in 12 million.
Having made this calculation, the mathematician was asked to stand down, and the prosecutor gave his interpretation of this result to the jury in an impassioned speech. He explained that this chance of 1 in 12 million represented the likelihood of a given pair of persons in Los Angeles fulfilling all of the criteria above—being seen together in a car, having a blonde ponytail, etc.—and that therefore, having found such a couple, one could be sure far beyond any reasonable doubt that this must be the couple in question. In fact, the prosecutor told the bemused jurors, this new type of mathematical proof was on the verge of replacing the traditional idea of proof beyond a reasonable doubt, a notion he described as “the most hackneyed, stereotyped, trite, misunderstood concept in criminal law.”
Recognizing that some people might be disturbed by the replacement of an actual search for solid proof of guilt by a purely theoretical and numerical operation, and that this might in fact even be a source of judicial error, he admitted that “on some rare occasion . . . an innocent person may be convicted.” But that can happen anyway, he said, and if it came to a choice between using the “new math” to convict the occasional innocent or using the old system and letting the guilty go free, then surely the new math was preferable, for otherwise, “Life would be intolerable . . . because there would be immunity for the Collinses, for people who choose not to be employed to go and push old ladies down and take their money and be immune, because how could we ever be sure they are the ones who did it?” Sinetar concluded his speech by noting that the estimates he had given were actually conservative, that the real values were probably even smaller, so that “in reality, the chances of anyone else besides these defendants being there . . . is something like one in a billion.”
It took the jury eight hours and five ballots to deliver a verdict of guilt. Surprisingly, a case of little importance in the annals of crime turned out to have tremendous significance in the annals of law. In a way, what the jury was doing that day was not determining whether the Collins couple was guilty or not. Rather, they were making a judgment about whether mathematical calculation could replace hard evidence. There was no serious evidence against the Collinses: nothing about their appearance could be identified clearly, their alibi was not firm but could not be proved false, and as for their poverty, miserable social situation, and fearful behavior around police, not only were these factors insufficient proofs of guilt, but the third one may well have been caused by the other two.
The jury found the Collinses guilty of second-degree robbery, and they were sentenced to prison terms. The public reactions to Sinetar’s legal exploit followed quickly. “Justice by Computer” and “Law of Probability Helps Convict Couple” were samples of the headlines that appeared soon after the trial. Attention started to build up around the event, and within a month a feature on the case ran in Time magazine. In its issue of January 8, 1965, under the heading “Trials: The Law of Probability,” Time told the nation:
A jury has convicted the [Collins] couple of second-degree robbery because Prosecutor Ray Sinetar, 30, cannily invoked a totally new test of circumstantial evidence—the laws of statistical probability.
Convicted by math, Malcolm Collins received a sentence of one year to life. Janet Collins got “not less than one year.”
JANET COLLINS did not appeal her sentence, preferring to see it through, stay under the radar, and keep out of the way of the law in future. But Malcolm, perhaps more rebellious by nature, and possibly encouraged by a lawyer who sensed an opportunity for legal innovation, did appeal. And when he lost, he appealed again, and the case went up to the supreme court of California. There, Sinetar’s technique met its match—in the person of twenty-five-year-old law clerk Laurence Tribe, who was assisting one of the court’s judges.
It so happened that Tribe had majored and excelled in mathematics at Harvard before turning to law school. Thus, in his memo for the judge, he was able to systematically call out all the errors that Sinetar had managed to make in the course of his misleadingly simple argument. Readers of the state supreme court’s judgment will find Tribe’s memo, unsigned, at the end, and any mathematician will recognize at once that it was written by an unusually knowledgeable hand. Tribe’s arguments are flawless and convincing.
The first two errors he raised are none other than Math Error Numbers 1 and 2. The prosecutor gave arbitrary values out of his own head for the probabilities of such features as cars being yellow—not to mention the absurd naming of a “probability” that a girl will be wearing a ponytail, given that hairstyle, unlike car color, can be altered instantaneously and at will. As for the assumption that the thieves were actually a married couple, it seemed to have no justification whatsoever; there was nothing to prove that the people in the yellow car at the scene of the robbery were married. In short, Sinetar’s assumptions, and his numbers, were based on no statistical research (or almost none—Sinetar does recall having asked the law office secretaries for their guesses before making his chart!) and certainly no hard evidence. Such estimations can be valuable in everyday life; the ability to make an educated guess is one of the weapons people can use to fight against the abuse of numbers in the public domain. But vague estimations have no place in a court of law—no person’s freedom should depend on them. As though to underline their inaccuracy, the prosecutor went so far as to tell the jury that he considered his estimates to be quite “conservative” and, as pointed out in the Time article, invited them to make up their own, suggesting that practically any numbers would do.
The supreme court judgment reads:
The prosecution produced no evidence whatsoever showing, or from which it could be in any way inferred, that only one out of every ten cars which might have been at the scene of the robbery was partly yellow, that only one out of every four men who might have been there wore a mustache, that only one out of every ten girls who might have been there wore a ponytail, or that any of the other individual probability factors listed were even roughly accurate.
The prosecutor’s next error was to ask his expert witness to apply the product rule to his probabilities, without verifying or allowing the witness to verify whether all the events in his list were independent. This was a serious mistake, since many of those events are actually not independent at all. The probability of a man having both a mustache and a beard is most certainly not equal to the probability of a man having a mustache multiplied by that of a man having a beard, given that beards not accompanied by mustaches are quite rare.
As a matter of fact, this flaw had not gone unnoticed. Rex deGeorge, the lawyer who defended Malcolm at his appeal, had already raised the same point, albeit unconvincingly. Who could take seriously his saying, “There is a dependency between Negro drivers and yellow cars; there are by far many more Negroes than Caucasians driving yellow cars,” or, “There is a dependency between blondes and intermarriage; blondes and redheads tend to be more adventuresome, more daring, and more likely to choose to be with a Negro,” or his claim that “there is a dependency between the way a woman would normally wear her hair and how she would fix it when she goes to carry out a robbery”?
DeGeorge’s appeal failed, but his main point is justified, and was made more rigorously by Tribe in the supreme court brief.
There was another glaring defect in the prosecution’s technique, namely an inadequate proof of the statistical independence of the six factors. No proof was presented that the characteristics selected were mutually independent, even though the witness himself acknowledged that such condition was essential to the proper application of the “product rule” or “multiplication rule.” . . . To the extent that the traits or characteristics were not mutually independent (e.g., Negroes with beards and men with mustaches obviously represent overlapping categories) the “product rule” would inevitably yield a wholly erroneous and exaggerated result even if all of the individual components had been determined with precision.
Other errors Tribe raised deal with more subtle difficulties. For example, he showed that even if one accepts that only one couple in 12 million shares the traits of the thieving couple, this figure cannot be confused with the probability that having found one such couple, it must be the right one. This is a different calculation and significantly more complex; we will face a very similar problem in the case of Diana Sylvester (see chapter 5). Indeed, Tribe calculated that the probability of another couple in the area existing with the same main identifying features as the Collinses (yellow car, blonde hair, etc.) was in excess of 40 percent.
Due to the misuse of mathematics and its excessive effect on the jury’s decision making, the original judgment was reversed; Malcolm’s conviction was quashed, and he was released to join his wife, who by that time had been out of jail for some three years already.
The bag snatching of which the Collinses were accused normally would have sunk without a ripple into the infinite sea of minor legal cases. But the novel use of mathematics in their trial shot it into the newspapers, and from there into the annals of legal history. Laurence Tribe went on to become a major name in American law, defending Al Gore against George Bush in front of the US Supreme Court after the 2000 presidential elections, teaching a series of brilliant students—including President Barack Obama, in whose administration Tribe later served—and, perhaps most importantly, writing a series of seminal papers in the early 1970s rejecting the use of mathematics at trial. It is practically impossible to overestimate the influence Tribe’s papers have had in the criminal justice system, bringing the field of research into the proper and correct use of mathematics at trial to a virtual halt for decades. It would take a new generation, and all the mathematical difficulties associated with the modern science of DNA analysis, to revive the urgency of that movement and bring it back to life.

MATH ERROR NUMBER 3 »
TRYING TO GET SOMETHING FROM NOTHING
SUPPOSE YOU ARE PROOFREADING a one-thousand-page manuscript, and your work is supposed to be good enough to overlook no more than a maximum of twenty errors throughout the book. You have read fifty pages attentively, and so far you have not found a single typo. What could you conclude about the number of errors that you are likely to find throughout the manuscript? There are zero in your sample: how many might there be in the book?
Would you feel inclined to assume that the part you read is representative of the whole and estimate the number of errors as being fewer than one per fifty pages, or fewer than twenty throughout the whole book? Would you snap the pages shut, go to your boss, and assure him that the job is done?
Or are you the kind of person who would think of the 101 reasons why mistakes might still occur in the rest of the book? After all, it could be that a whole group of them appear together a bit further along in the text. The author might have had a bad day or an inattentive moment. He might have written an entire chapter on a topic that happened to be the only word he didn’t know how to spell. Or maybe he typed the later text during a particularly bumpy train ride. If you’re the latter kind of person, you wouldn’t rest until you had thoroughly checked every single page; otherwise you’d never be certain that you had done a good job.
In fact, the best attitude depends on the exact work you are doing. If you are checking a product in which you feel certain that any errors will be distributed equally throughout—for example, an automatically produced product—you would probably be safe with the first method. But if you have no reason to believe that the errors will be spread out evenly, then you might easily miss something embarrassing. In the latter case, it’s difficult to draw any conclusion about the total number of errors in the whole book based on the zero in your sample. Guessing that the whole manuscript is perfect would be risky—and making such a guess in a court of law is outright wrong.
The prosecution in the next case we describe combined the previous two math errors, giving unjustified statistical estimates and multiplying them together for non-independent estimates, and to top it off, the most important of these estimates was made based on a finding of zero in the sample examined.
 
 
The Case of Joe Sneed: Absent from the Phone Book
The murder occurred on August 17, 1964, in the sweltering heat of a New Mexico high summer. Silver City, which had come into sudden existence as a tent city when a large silver mine was discovered there in 1870, had survived the plague of abandonment that turned so many of the nearby mining communities into ghost towns when the veins of ore ran dry. This was perhaps thanks to the splendid solitude of its situation in the midst of a southern desert paradise. Over the ensuing years, the town grew and developed into a ranching community, policed by sheriffs and, unofficially, by posses, and home to legendary criminal figures of the far West, such as Butch Cassidy and Billy the Kid.
The town was already blanketed by the cooling darkness of nighttime when Pauline Hicks, from the comfort of her home in the upper-middle-class section of Silver Heights, heard something that sounded like sharp shots ringing out into the shadows. Disturbed, she stepped out into her garden and walked over toward her neighbors’ house to take a quick look around. All seemed quiet, however, so Mrs. Hicks returned indoors and went to bed. “I thought nothing more about it,” she testified later.



Silver City Mines



Butch Cassidy



Billy the Kid
But the next morning, August 18, a young man came running to her house, knocking and pounding on the door in a state of fear and shock. “Help!” he shouted. “My parents have been murdered! They’ve been shot!”
Mrs. Hicks recognized twenty-year-old Joe Sneed, her neighbors’ son, although she had not seen him for some time. He had graduated from Silver City High School two years earlier, and had subsequently moved to California, where he had been living for about a year.
She and Joe called the police, who arrived almost at once and entered the house by the back door, which Joe had left open. They were shocked at what they found.
Ella Mae Sneed, Joe’s forty-eight-year-old mother, was lying in her bed, dead, her head resting on her pillow. She had been shot three times: in the left ear, in the left side, and in the back. It was obvious that she had been killed in her sleep.
Her husband, fifty-year-old Joe Alvie Sneed, was lying in his pajamas in a small entryway between the bedroom and the bathroom, with a bullet wound to the side and two in the back. But the possibility that Joe had been killed because he was up and out of bed—roused by a burglar, perhaps, or in the heat of a quarrel—was quickly discounted. Bloody tracks as well as the position of his wounds proved that he, like his wife, had been shot in bed, probably while asleep. The poor man had succeeded in staggering to the door of the bedroom before collapsing on the floor, dead.
There was not the slightest sign of a robbery. Not even a forced entry. The bullets came from a .22 caliber pistol, which was not found at the scene.
The police brought young Joe down to the station to ask him for details about his discovery. The questioning was cordial; some of the officers were Joe’s friends, and several had come to know him when he had worked in the streets of Silver City as a newspaper delivery boy a few years earlier. He told them that he had been returning to Silver City to visit his parents after his long absence. He had made the trip from California by car, and had spent the final night of his journey in a motel in Las Cruces, arriving at his parents’ home early in the morning to catch them at breakfast. Discovering the crime scene on entering, he had rushed immediately to the neighbors’ house for help without touching a single thing, he explained.
Asked if he was willing to take a lie detector test to check his story, he replied that he was. The test was administered at a specialized center in El Paso, and Joe’s answers and reactions were closely monitored, but he remained perfectly coherent and quite unflappable, and the test indicated that he was telling the truth.
As a double precaution, police also subjected him to a paraffin test, which examines the skin of the hands for microscopic particles that become embedded there when the hands have recently fired a gun. But Joe’s hands were absolutely clean. The police let him leave, and he went to stay with his grandparents in the nearby town of Central. On the following morning, August 19, a coroner’s jury returned a verdict of death by gunshot wounds at the hands of a person or persons unknown. “Mystery mounts in double slaying of a prominent Silver City couple found dead in the bedroom of their home,” reported the daily newspapers, “as lie detector and paraffin tests prove negative.”
Joe Alvie Sneed and his wife were prominent citizens of Silver City. The couple was responsible for the circulation section of the Silver City Daily Press. They had two married daughters who no longer lived at home; young Joe was their third child and only son. Described in the local newspapers as “an average American youth,” nothing emerged from his history in Silver City that might indicate any propensity to violent and shocking acts. Yet given that he was the discoverer of the bodies, the police were duty bound to treat him as a suspect. It seems, however, that in those first days they did not take this obligation as seriously as they might have; very probably they did not believe he was the murderer.
Unfortunately, this casual attitude led them to make a mistake—the first of a series—which nearly led to a grave judicial error.
ON THE day following the discovery of the bodies, Sergeant Richard Ingram of the Silver City police force called Joe’s grandparents in Central and asked them to bring Joe in to the Silver City police station for further questioning. The young man drove up by himself, using his grandfather’s car. Advised that he did not have to answer questions, he appeared surprised, saying that he really wanted to answer them, that he intended to cooperate with police and try to be useful, and that he absolutely wanted to know who had committed the crime. At some point he mentioned to the officers that he would like to get his own car back, since it had remained at his parents’ house when the police had driven him to the police station the day before. Sergeant Ingram, who was heading the investigative team, told Sneed that he would go fetch the car. He claimed that Joe responded by willingly handing over the keys.
The police fetched the car, but that was not all they did. They also searched inside—without a warrant, although they could have obtained one within the hour—and discovered something rather suspicious there that gave them something specific to look for as they gathered their evidence in Las Cruces. On the very next day, August 20, Joe Sneed was arrested for the murder of his parents. At the preliminary hearing, Sneed and his lawyer, J. Wayne Woodbury, contested the production of the documents found in the car on the grounds that the officers had obtained them by unlawful search and seizure. During the hearing, Sergeant Ingram was asked exactly what had given him the right to conduct such a search without obtaining a warrant. He claimed that he had asked permission from Joe himself, who had voluntarily given it.
INGRAM: Joe, the defendant, was worried about his car, and I told him that we would try to get it down to him as soon as we could . . . I went and asked Joe if we could have the keys to his car, that we wanted to search it and then we would bring it down to the City Hall.
Question: What did he say?
INGRAM: He handed me the keys.
Question: Was Mr. Sneed under arrest at that time?
INGRAM: No.
Question: For what purpose did you wish to question him at that time?
INGRAM: I had some questions I would like to ask him about his trips, et cetera.
Question: What prompted you to seek these questions, these answers from Mr. Sneed?
INGRAM: I was trying to find a clue.
Question: I see, in other words you were trying to find a clue against Mr. Sneed?
INGRAM: No, just a clue to shed a little light on the case . . . I didn’t interrogate him, I just asked him some questions.
Question: Make some distinction for me, it is yours, what’s the difference between asking questions and interrogating?
INGRAM: I wasn’t accusing him of anything.
Question: Was he not then under arrest?
INGRAM: No, sir.
Question: Nor was he a suspect? No more than anybody else might be?
INGRAM: I guess more so than a lot of people.
Question: More so than a lot of people?
INGRAM: Yes.
Question: But so far as you were concerned, this was a friendly assistance Joe was lending to the police department.
INGRAM: Yes.
“Unlawful search and seizure” is the act of conducting a search with neither the permission of the owner of the searched property nor a properly issued warrant. In his testimony, Ingram indicated that Joe Sneed had given an oral assent to the proposition of searching the car, but it sounds somewhat forced, given that Sneed was not a suspect at the time and probably would have reacted with surprise if asked specifically whether his car could be searched. Joe himself denied having been told any such thing, and he certainly never waived his constitutional rights against search and seizure in any formal manner, as would be necessary for a search without warrant to be conducted legally. He testified at the hearing that he had been unaware that the police, who were his friends and who had kindly offered to bring him his car, meant to use it to construct sufficient evidence against him to charge him with the crime—that, in short, he had been tricked.
In hindsight, it is surprising that Joe gave the police his keys at all. Perhaps he didn’t realize what it was that he had given them the chance to see. Two insignificant little bits of paper—he had possibly forgotten he even had them. And indeed, they didn’t mean much until the police followed up the trail they indicated.
One of them was a receipt from the Holiday Inn at Yuma, Arizona, dated August 12, five days before the murder. This wouldn’t have been unusual in itself, since Yuma was on the way from California to New Mexico. But the receipt was not made out in Joe Sneed’s name. The name on the receipt was “Robert Crosset.” The second slip was a receipt from a Surplus City store in Las Cruces, the town where Joe Sneed claimed to have spent the day and the night of August 17, when his parents were murdered. The date on the slip was August 17, and the nature of the purchase was not specified, but it gave the police the idea of inquiring at the store itself to try to discover what it had been.
When questioned about these papers by Captain Joe Barrios of the Silver City police, Sneed denied ever having used the name Robert Crosset. This raised the suspicions of the police even more. This suspicion connected with the use of a false name was what led directly to Sneed’s arrest. By that time, the whole of Silver City was in a state of feverish excitement over the murder of two upstanding citizens.
The first act of J. Wayne Woodbury, Sneed’s public defender, was to have his client file two motions to the district court of New Mexico. In the first motion Sneed requested a change of venue for the trial, on the grounds that the murder had “created a vast amount of publicity in the County of Grant, State of New Mexico, and much public excitement and local prejudice . . . together with misleading and erroneous stories carried by the Daily Press . . . [so] that a fair and impartial jury cannot be had.” The elder Sneeds had both worked for the Daily Press, the local paper, and naturally it was covering their murder in lurid detail. Given the circumstances, the trial was moved from Silver City to Las Cruces in Dona Ana County.
In his second motion, in what must have appeared something of a life-or-death gamble, Sneed requested the suppression from the trial of the two receipts found in his car, asserting that at no time did he ever “give any representative of the Silver City Police Department any permission whatever to search his automobile.” The motion to suppress evidence was accompanied by a superbly redacted brief citing a vast number of precedents in which the results of unlawful search and seizure were excluded from trial. The brief ends with a quotation from a celebrated judgment by the Supreme Court of the United States, a cry against the abuse by lawmakers and law enforcers of the very laws meant to protect citizens:
The criminal goes free, if he must, but it is the law that sets him free. Nothing can destroy a government more quickly than its failure to observe its own laws, or worse, its disregard of the character of its own existence. Our Government is the potent, the omnipresent teacher. For good or for ill, it teaches the whole people by its example. . . . If the Government becomes a lawbreaker, it breeds contempt for law; it invites every man to become a law unto himself; it invites anarchy.
In spite of these efforts, Sneed lost his bet, and his motion to suppress the evidence was rejected. It was ruled that “an analysis of the evidence discloses no case of mere acquiescence, nor of mere submission to a demand, or to a show of force. An analysis of the law and the facts shows that valid consent to a search can be had—that in such cases no arrest, no search warrant, is necessary—and that this is the case at bar.”
For E. C. (David) Serna, the district attorney prosecuting Sneed, it was particularly important to be able to present those two documents at the trial. This was because they tied in with a couple of further pieces of information that the police had been able to dig up once they had been furnished with the key name Robert Crosset. One of these was another record of a Robert Crosset, this time staying at a motel in Seaside, California, shortly before the sojourn in Yuma. The second and far more damning clue was that Robert Crosset was also the name of a person, described in the register as “a 5’9” male with brown eyes and hair,” who had signed the sales register in a Las Cruces pawnshop upon purchasing a .22 caliber pistol on that fatal August 17. The buyer had given as his address a post office box number in Las Cruces that was the same as the post office box number given by the Robert Crosset who had signed the hotel register at the Holiday Inn in Yuma. The only connection between this unknown Robert Crosset and Joe Sneed was that the receipt from Yuma had been found in Sneed’s car. But that one connection suddenly made the case look black, very black, against Joe Sneed.
THE TRIAL began on February 1, 1965. In the prosecution’s opening statement, they declared that they would prove the following facts:
•Sneed used the alias of Robert Crosset at two motels, in Seaside, California, and in Yuma, Arizona, and used the name again to buy a “cheap” .22 caliber pistol in a Las Cruces pawnshop.
•Sneed bought ammunition at a Las Cruces discount house, and a sales slip from the firm bearing the same date as the gun purchase was found in his car.
•Sneed’s parents were killed in their bed by a .22 caliber pistol.
•There were no signs of forcible entry into their home.
•Sneed had a key to his parents’ home.
•Sneed purchased a flashlight and gloves shortly before the slayings.
•Sneed’s car was not parked at a Las Cruces motel on the night of the slaying as Sneed had told officers that it was.



Joe Sneed, “average” youth
If the prosecution could have proven all of these points beyond a doubt, Sneed’s conviction would not have merited even a moment’s hesitation. The trouble, however, was that it was not as easy as they made it sound to justify their claims. As the twenty-three witnesses for the prosecution underwent cross-examination one by one, the testimony about whether Sneed’s car was or was not parked in Las Cruces on the night of the seventeenth turned out to be inconclusive—which was just as unfortunate for the defense as for the prosecution, since the whole defense strategy was based on establishing that Sneed had not left Las Cruces until the following morning. Similarly, the purchase of a flashlight and gloves was difficult to establish with certainty, as was the fact that the purchase Sneed actually made at Surplus City was ammunition, a fact that he denied.
The most difficult task of all for the prosecution was to demonstrate that Joe Sneed and Robert Crosset were one and the same individual. Certainly the hotel receipt from Yuma was found in Sneed’s car, but there could be any number of explanations for that; Crosset could have been a hitchhiker or a hired killer, or Sneed may simply have picked up the receipt from the check-in desk in the hotel or from the ground of the parking lot, thinking it was his. To identify Robert Crosset with Joe Sneed—to condemn him, in effect, for murder— required far more solid proof. There were only three possible ways to obtain such proof, because there were only three people who could provide positive identification of Sneed as Crosset: the motel receptionist in Seaside, the hotel receptionist in Yuma, and the pawnshop salesman who had sold the gun. But at this point in the trial the prosecutors found themselves in a bind, because as it happened, not one of the three was able to identify Joe Sneed for certain. The “average American youth” of average height, coloring, and features simply did not leave a strong impression in the memories of the people whose path he crossed.



Edward Thorp, blackjack genius
Sneed’s lawyer, Woodbury, put up a very simple defense; in substance, “We shall prove that this boy was not in Silver City the night of the murder.” One by one, he destabilized the witnesses and weakened the weight of their evidence against Sneed.
At this point, the outcome of the trial was unclear. If the prosecution could convince the jury that Sneed and Crosset were one and the same, conviction was obvious. If they could not do so beyond a reasonable doubt, acquittal was a distinct possibility.
It was for exactly this reason that the prosecution finally chose to make a rather risky move, in the hope of gaining an edge. They called an unexpected expert witness: Dr. Edward O. Thorp, a young mathematics professor at New Mexico State University in Las Cruces who had recently achieved fame through the immense success of his book Beat the Dealer, which introduced card-counting methods that enabled enterprising gamblers to beat the casinos at blackjack. A man with a taste for adventure* and something of a local star, Thorp and his testimony were awaited with excitement by judge, jury, and spectators alike.
Dr. Thorp was the brother-in-law of prosecutor Ray Sinetar, who just two months before the Sneed trial had obtained a striking conviction in the Collins case (see chapter 2) with his new “mathematical proof of guilt.” This was no coincidence: E. C. Serna of the prosecution had read the Times article about Ray Sinetar’s mathematical proof and, struck by the possibility of using the same kind of argument in his own case, had telephoned Sinetar to ask if by any chance he knew someone who could play the role of mathematical expert witness at the Sneed trial. Working as he did in Las Cruces, Sinetar’s brother-in-law Ed Thorp seemed like the perfect answer.
When Thorp received the unexpected phone call, he was intrigued, and agreed to have a talk with Serna for the purpose of learning more about the case, and seeing exactly what Serna wanted of him. Serna presented the case to Thorp in a way that made it look as though Sneed’s conviction was such a foregone conclusion that Thorp could hardly understand the need for a probabilistic argument. Indeed, comparing what Thorp remembers being told† with the evidence that was actually presented at the trial, it seems that Serna was taking some care to let the mathematician feel that he was only being asked to use probability to confirm a guilt that was already clearly indicated by the evidence. Serna told Thorp that there was a motive: Sneed believed that his parents’ interference had caused the breakup of a romantic relationship. He also told Thorp that it was known that Sneed had been in Yuma and in Seaside, whereas in reality this was not an established fact, but a deduction from the circumstance that Robert Crosset had been in those places, that the Robert Crosset receipt was in Sneed’s car, and that the police believed Sneed to be Crosset.
While these elements are certainly convincing, it is not at all clear that they constitute proof beyond a reasonable doubt, which is precisely the reason for which Serna wanted the mathematician’s testimony. Furthermore, the prosecutor told Thorp that Sneed had pointed out to police the exact place where he claimed that his car had been parked in a Las Cruces motel during the whole night of the murder, but that police had proven that Sneed’s statement was a lie, as that particular parking place was located in an area that had been reserved that night for a firemen’s convention. However, as mentioned above, the witnesses who testified about Sneed’s parking place at the trial did not succeed in actually providing any incontrovertible proof that Sneed’s car had or had not been there.
Finally, Serna explained to Thorp exactly what he wanted him to do: to ratify a probability calculation that he, Serna, meant to do in court, in imitation of what Sinetar had done in the Collins case. As Serna began to explain the arguments he proposed to use, Thorp perceived their defects and attempted to warn him, but Serna was clear about what he wanted to do. Convinced from all he had heard that Sneed’s guilt was certain, and “always amenable to an interesting experience,” Thorp agreed to play the game. In principle, he had nothing more to do than confirm the product rule on the stand, and multiply some probability figures together.
What Serna undertook to give the jury was a mathematical proof that the Robert Crosset of Yuma, Arizona (presumed but not proven to be Sneed himself), and the Robert Crosset who purchased a pistol at the Las Cruces pawnshop were one and the same person.
To begin with, he decided to calculate the probability that a random person might share a large number of traits with the Robert Crosset who had bought the gun. These traits included height, hair and eye color, post office box number, and of course the name itself.
The post office box number that had been given as an address in the pawnshop was the same as the one given in Yuma, and Serna observed that the chance of this happening purely by chance was 1 in 1,000.
The information about height and coloring obtained from the firearms sales register at the pawnshop was then presented in court. By law, when any weapon was sold, a description of the buyer had to be taken down, as well as the person’s name and address. Robert Crosset was listed as being about 5’9” with brown hair and brown eyes. To calculate the probability of a man having these features, Serna handed the pawnshop register over to Thorp on the witness stand and requested him to examine and count the heights of purchasers listed there. Out of 35 purchasers, Thorp counted 12 having a height between 5’8” and 5’10” and 12 who had brown hair and eyes, concluding that each of the two types occurred with a probability of 12/35.
Finally, in order to calculate the frequency of the name Robert Crosset, Serna had several telephone books from various communities in the area brought in, and even invited the defense to bring in their own telephone books, which they did. The trial proceedings then came to a standstill as the judge, the jury, Serna, Thorp, Woodbury, and even Joe Sneed himself all examined the phone books to see if they could find any Crossets. (Sneed’s apparent indifference to the situation as he coolly examined the phone books “as though it was a school exercise” did nothing to convince spectators of his innocence.)
From this counting, Serna estimated that about 1 in 30 men bore the first name of Robert. But the last name Crosset did not occur in any of the phone books examined in the courtroom that day. Estimating that the books contained a total of about 1,290,000 names in total, Serna guessed the frequency of the name of Crosset in the general population to be about 1 in a million.
He then asked Thorp on the stand about the use of the product rule in this situation. Thorp explained that, assuming that Serna’s probabilities were correct and that the events referred to were independent, the probability of them all occurring together would be their product, and he multiplied the numbers 1/30 (for the name Robert), 1/1,000,000 (for the name Crosset), 1/1,000 (for the post office box), 12/35 (for the height), and 12/35 (for the coloring). According to this calculation, the probability that a random person in the United States would have the same name, height, hair and eye coloring, and post office box as the man in the pawnshop came out to roughly 1 in 240 billion. “The significance of this figure,” Thorp is quoted as having stated on the stand, “is a chance of 240 billion to one that it was our suspect who was responsible for this series of numbers in the pawnshop, as opposed to some person coming in and accidentally implicating him. This is the application of this thing to criminalistics.”*
In cross-examination, Sneed’s lawyer, Woodbury, did put his finger on the problem of estimating the probability of an “extremely rare” event, if in a somewhat unexpected manner. “What is the probability of the waters of the Nile running red with blood?” he asked the surprised professor of mathematics. Suspecting that the lawyer was trying to lead him into rebutting a biblical fact in front of a jury from deeply religious Las Cruces, Thorp eluded the difficulty by responding: “Assuming that event occurred, it was only once in the known history of mankind, and a probability figure cannot be associated with it.”
The point Woodbury was trying to make is a very good one, but he probably did not have the mathematical savvy to demolish the numerical testimony by following it through, or by citing Math Error Numbers 1 and 2: the inaccuracy of the probability figures and the non-independence of the events they described. The jury may not have made the connection between the waters of the Nile and the name Crosset, or they may have trusted a mathematics professor to know his figures better than a Bible-quoting lawyer. In any case, the prosecution’s arguments convinced the ten-man, two-woman jury, who after a deliberation of seven and a half hours declared the defendant guilty of murder in the first degree, with a recommendation of life imprisonment.
Upon being asked if he had anything to say before the judgment and sentence of the court were passed upon him, Sneed stated that he was not guilty. Still claiming innocence, still denying that he had ever used the name Robert Crosset, Sneed was transported directly from the court to the New Mexico State Penitentiary in Santa Fe to begin serving his life sentence.
NO SOONER had Sneed settled into his new residence than he sat down with his lawyer and wrote down all the grounds on which he might appeal his conviction.“The defendant believes that the District Court made grave and reversible errors in the trial of this cause, which should be reviewed by the Supreme Court in the State of New Mexico,” Sneed and Woodbury wrote in filing a motion requesting a free transcript of the trial testimony, as the prisoner was “destitute and without funds.” The motion was granted, and by July the men were in possession of all the documents they needed to prepare a beautifully written, well-thought-out, impeccably argued appeal, which, although they did not know it at the time, would become a historic document.
They gave three grounds for appeal: unlawful search and seizure, improper comment to the jury concerning Sneed’s choice not to testify, and, most important by far, the erroneous use of mathematical probability to establish an otherwise unproven identification.
Basically, the mathematical part of the argument given by the prosecution comes down to the following: the probability of two completely different people giving the same name (Robert Crosset) and the same post office box number (210) and having the same height and hair and eye color, purely by chance, was computed as just 1 in 240 billion, therefore they must have been the same person, and from the evidence of the receipt in the car, that person must be Joe Sneed.
There are many shaky features in this approach. One of the weak points is the final deduction. It may not seem very useful to identify the two Robert Crossets with each other, when the identification of the Yuma Crosset with Sneed was not proven, nor was it even known that Sneed had been in Yuma at all. Although Serna had tried to imply that the presence of the receipt in Sneed’s car established his identification with the Yuma Crosset, neither he nor the defense ever proposed, for example, that it could have been placed there by someone framing Sneed. The presence of the receipt in the car made the identification of Crosset with Sneed appear very likely, but certainly not beyond a reasonable doubt.
Then, there are all the problems with the actual probability calculation itself. By estimating the frequency of this name in the general population, Serna appears to have been assuming that the name was a real rather than an invented one. But at the same time, Serna was trying to prove that Robert Crosset was Sneed, in which case the name Robert Crosset would have been invented, so that any calculation concerning the frequency of the name in the actual population would not be relevant; indeed, there is no reason to suppose that the frequency of an invented name, for example, John Doe, corresponds to the real frequency of John Does in the population.
And finally, the details of the calculation itself do not hold up. The probability of 1 in 1,000 that two people would randomly choose the same post office box number is valid only if all post offices have exactly 1,000 boxes. Actually, that probability diminishes when post offices are larger and have more boxes and increases when they are smaller.
Next, it is not reasonable to estimate the proportion of the male population of the United States measuring between 5’8” and 5’10”, or the proportion with brown hair or brown eyes, from one list of thirty-five gun purchasers in one pawnshop in one particular town, whose ethnic population distribution may be very different from that in other parts of the country. Such a small sample is almost certain to lead to very inaccurate estimations.
Then, it is not legitimate to multiply the probabilities of having the right height, hair color, and eye color. Indeed, height and coloring are certainly not independent features; in a city with a large Hispanic population, for instance, a shorter stature will often be associated with black hair and eyes.
Finally, by citing the arbitrary figure of 1 in a million for the estimated frequency of the name Crosset in the population of the southwestern United States, the prosecution missed the possibility that there could be a whole group of Crossets—say, belonging to one extended family—in one specific location for which they had not consulted the phone book. The absence of a name from a set of phone books actually gives very little information about its frequency in a region of the United States, because in trying to use phone books to estimate the frequency of the name occurring in the country, one is actually working under the unjustified assumption that the name is evenly distributed around the country.* One simply cannot draw any conclusion more precise than to note that the name is not very common. Zero cannot be given a positive measurement.
Then, the multiplication of the probability concerning the first name Robert with the estimated probability for the last name Crosset is also wrong, since again, these two events may not be independent. Indeed, there is no reason for the distribution of the first name Robert among all Crossets to be equal to that in the general population, since it often happens that in an extended family, the same first name occurs with much greater frequency due to family tradition.
In summary, the computation of a probability for two Robert Crossets with similar features not to be the same person is essentially meaningless in the context of Sneed’s trial. The number may sound convincing, but it simply does not correspond to any real measure of anything. Yet that calculation, that 1 in 240 billion figure, convinced a jury that Sneed was Crosset, and on the strength of this erroneously determined fact a man was condemned for murder. It was only on appeal that the prosecution’s reasoning was revealed to have caused more confusion than clarity.
On May 31, 1966, just over a year after the original sentence, the supreme court of New Mexico annulled the previous verdict and ordered a new trial for Sneed. The summary of the judgment shows that while the justices understood that there had been problems with the mathematical reasoning introduced in court with Thorp as expert witness, they were uncertain about the correct course of action.
[Thorp did not] state why a positive number was used in arriving at an estimate on the basis of the telephone books when the name Robert Crosset was not listed in those books. Since the name Robert Crosset did not appear, should any estimate, based on the telephone books, be used at all? Or should a zero be used as the estimate based on the telephone books?
Sneed’s retrial was to take place without any recourse to mathematics.
THE REST of the Sneed case is worth recounting because it shows just how difficult it was, in the absence of identifying information and without recourse to doubtful mathematical reasoning, for the prosecution to prove its case. Mathematics or no mathematics, the investigators were convinced that Sneed was guilty, and so for a second time the prosecution set out to see what evidence it could provide to convince the jury that Sneed should be identified with Robert Crosset; Sneed himself continued to deny having ever used the name. The new trial began on August 16, 1966.
The prosecution began by presenting the receipt from the Surplus City shop in Las Cruces that had been found in Sneed’s car. Although the nature of the purchase was not recorded on the receipt, they were able to confirm from the shop’s sales records that standard ammunition had been purchased in the shop on that day. They also presented the witnesses who declared that on the day of the murder Sneed’s car could not have been parked in the lot of the Las Cruces motel where he claimed to have spent the night, due to the firemen’s convention. The witnesses’ testimonies turned out to be rather shaky on cross-examination, since a person can and often does park his car in a reserved place, and it was impossible to actually prove that Sneed had not done so. At the same time, though, Sneed could not bring forward a single witness to support his alibi, nor did he give any explanation for the Crosset receipt in his car. In fact, the appeal trial had reached the exact same point where, in the original trial, E. C. Serna had decided to apply a probabilistic proof of identity. But now that avenue was no longer open. Another solution was needed, for the police investigators were certain that Sneed had killed his parents, and that an acquittal would simply let a cold-blooded murderer go free.
No one knows exactly what methods the prosecution used to get their main witnesses to change their statements, but when the clerks from the Yuma and Seaside hotels took the stand, their testimony was dramatically different from what it had been at the first trial. Clarke Wallace Fowler from the Holiday Inn in Yuma stated under oath that Joe Sneed was the man who had registered there on August 12, 1964. He claimed to recognize him and pointed his finger squarely at the suspect sitting in the courtroom. Marilyn Moore, the receptionist from the motel in Seaside, followed Fowler on the stand and did the same. On the basis of these identifications of Sneed with Robert Crosset, the prosecution rested its case.
But Sneed’s defense attorney was aware that the two clerks had not been able to identify Sneed at the first trial, and he had no intention of letting them get away with doing so now. Under cross-examination Fowler was forced to admit that he had been unable to identify Sneed at the preliminary hearing in 1964. “How is it that you failed to recognize him then, barely weeks after the murder, and yet now you are so certain?” asked Woodbury. Stammering, the witness replied that he would have been able to identify him the first time, except that he had been “too nervous.” Woodbury said he had no further questions. The power of Fowler’s testimony was shattered. Cross-examining Marilyn Moore, Woodbury asked her the same question: how could she be so sure that the young man on trial was the same one who had stayed at her little road motel two years earlier? “I know it was him,” she replied, “because he appeared neat and clean, and that is outstanding for our area.” The spectators laughed.
The case of Joe Sneed might have ended like that of Lizzie Borden, with an acquittal due to lack of evidence even though everything seemed to point toward guilt. But the prosecution had one more string to its bow: a last-minute witness whose testimony had nothing to do with “Robert Crosset” or Sneed’s trip from California to New Mexico, or even the murder of Joe and Ella Sneed. Instead it provided a window into the soul of the young man who denied the charges against him and sat, silent and inscrutable, at the defense table.
What the investigators discovered was that in spite of his young age, Joe Sneed had gotten married while in California, but the couple had divorced. According to information given by the prosecution to Edward Thorp outside of the courtroom, Sneed’s motive for the murder of his parents was their interference in his relationship with the woman, but no evidence of this had been presented at the first trial. The young woman was now remarried to someone else, but she agreed to testify as a witness at Sneed’s second trial. Her name was Kathy Storey, and the tale she told clinched the case for the prosecution as much as any identification ever could have done. The domestic violence she described soon made its way into the press: she vividly recounted how her husband had hit her in the head with a book and bitten her in the face, and how he had once thrown a fountain pen at her with such force that the point had remained embedded in the flesh of her leg. She also told a story of how he had once picked up the family dog and, before her horrified eyes, slammed the defenseless creature into the wall with all his strength.
Mrs. Storey was about to start speaking of things that Sneed had said to her during their short marriage—in particular about his parents—but Wayne Woodbury cut her short. Her testimony would be hearsay, he declared, and if she were allowed to give it, he would call a mistrial. The judge called a recess to think this over and consult the law, then agreed with Woodbury. He considered that Mrs. Storey’s testimony was sufficient as it stood.
Woodbury had spent the five days of the trial trying (relatively successfully) to destroy testimony showing that Joe Sneed was Robert Crosset, and (relatively unsuccessfully) to prove that Sneed had been at the motel in Las Cruces, with his car parked in the parking lot, throughout the evening of the murder. Kathy Storey’s testimony, coming as it did from such an unexpected angle, blew up his entire strategy. There wasn’t much to say in response.
Woodbury called a single defense witness to the stand, Sneed himself, and asked him a single question.
“Did you shoot your parents?”
“No, sir. I did not,” was the reply.
And Woodbury rested his case. There was nothing more to add, nothing else that he could do. As Grant County Assistant District Attorney William Martin explained, in asking for the death penalty during a one-and-a-half-hour summation, “The 23 prosecution witnesses have proved during this five-day trial that Sneed lied for his life.”
The eleven-man, one-woman jury went out at 6:10 p.m. and deliberated until 1:20 a.m. The verdict was guilty of murder in the first degree, with a recommendation of life imprisonment. Sneed was impassive as District Judge William Scoggin pronounced sentence. Asked by Scoggin if he had anything to say, Sneed answered, “Only what I said two years ago: I’m not guilty.”
Willie Silva, the Dona Ana County deputy sheriff who accompanied Sneed directly after the sentencing, reported to the newspapers that “he didn’t look disturbed at all. He didn’t say a thing. He was quiet all the time. Not a goodbye, or a hello: nothing.”
NO SOONER had Sneed been returned to his prison cell than he pleaded with his lawyer to lodge a second appeal and take the case all the way to the supreme court of New Mexico. He must have realized by then that without the two receipts found in his car during an unlawful search, there would have been virtually no evidence against him at all. Having the receipts suppressed was his only chance, but it was a significant one. Condemned to life in prison, Sneed was grasping at straws.
Ten days after the end of the second trial, his lawyer sent a letter to the judge, the tone of which speaks clearly enough of the utter hopelessness of the cause, and hints more than strongly that Sneed’s own defense attorney was convinced of his guilt.
Dear Judge Scoggins,
Joe E. Sneed[,] who was recently convicted of first degree murder in Dona Ana Criminal Action No. 11232, is insisting that I appeal his conviction to the Supreme Court. Inasmuch as I have gone this far with Mr. Sneed, I do not feel that I can, at this time, forsake him. However, I would like to be able to acquire actual expenses in connection with the appeal. Also, I am wondering whether it will be necessary to file additional pauper’s affidavits in order to obtain free process.
I will look forward to hearing from you in this regard.
With kind personal regards,
Sincerely yours,
J. Wayne Woodbury
On December 20, 1967, the supreme court of New Mexico affirmed the judgment and sentence, and Joe Sneed faded into history as another murderer, never fully explained, never fully understood. But the attempt to prove guilt by probability, and the state supreme court’s overturning of that attempt, reached legal tentacles into the future whose importance far outstripped the significance of the case itself.
 
*Such as, for example, donning a false beard and wraparound glasses to play blackjack in casinos where he was already known as the author of the book on how best to beat them. Thorp was well-known as a regular visitor in Las Vegas.
†Most of the information about E. Thorp’s experience recounted here comes from a personal conversation with him over the telephone on September 23, 2012.
*This direct quote comes from Judge Wood’s opinion at Sneed’s appeal trial. Thorp does not remember making such an explicit statement, and in particular finds it unlikely that he ever would have employed a word like “criminalistics.”
*For instance, the name Schneps is quite rare, and whenever two people of that name meet, if they are able to trace their ancestry back three or four generations, they generally find that they have common relations all coming from a single town in Galicia (now Poland).

MATH ERROR NUMBER 4 »
DOUBLE EXPERIMENT
AS THE PREVIOUS CHAPTERS have shown, probability is a delicate subject, because it can often run contrary to elementary intuition. We saw that even if the probability of an event occurring is correctly determined, it can be wrong to multiply it by itself if independence of the occurrences is not guaranteed. In this chapter we consider another common error concerning multiple occurrences.
Suppose you are running a test with a yes or no answer—for example a diagnostic test for an illness—and suppose that a positive result indicates that the illness is really present with a probability of 60%. You run the test and get a positive, meaning you can be 60% sure that what you are testing for is effectively present. Is it worth running the test again? If you get another positive, does it simply again indicate that you can be 60% sure that what you are testing for is present?
As it happens, there is a benefit to retesting: the combined effect of the two experiments makes a much stronger case than the results of each one separately. Let us show exactly how this works by using a simple example.
Suppose you are given a coin and told that it is of one of two types: either fair and balanced or weighted to come up heads 70% of the time. You are allowed one toss, and it falls on heads. Let us first investigate the probability that the coin is biased after this result.
To determine whether the coin is fair or weighted, we need to calculate the probability A of falling on heads if it is a fair coin, the probability B of falling on heads if it is a biased coin, and then multiply both A and B by a scaling factor that will bring the total probability to 1. (We know that the coin must be either fair or biased—there are no other possibilities.) The scaling factor will therefore be C = 1 / (A + B), with the final probability of the coin being fair equal to A × C, and biased equal to B × C.
In our example, the probability that the coin will fall on heads is A = .5 if it is fair, and B = .7 if it is biased. Thus C = 1 / (A + B) = 0.8333 . . . and the coin has a probability of being fair equal to A × C, roughly .416, or 42%. The probability of the coin being biased is B × C, which comes out to about .583, or roughly 58%. So, since the outcome of the single-toss experiment was heads, the conclusion that can be drawn from that outcome is that the coin is biased with a probability of 58%.
Now suppose you do the same experiment a second time. You toss the coin and it again falls on heads. By the previous calculation, you have again found that the coin is biased with a probability of 58%. But what happens when you combine the two results, considering them as one double-toss experiment whose outcome is two heads rather than as two separate, independent experiments?
The procedure to calculate the probability of the coin being fair or biased after this double experiment is exactly the same as before: first we calculate the probability A of the outcome for a fair coin, then the probability B of the outcome for a biased coin; we let C = 1 / (A + B) be the scaling constant as before, and A × C and B × C give us the final probabilities that the coin that twice came up heads was fair or biased, respectively.
Coin tosses are independent, so we can multiply their probabilities. Thus, the probability of two consecutive heads coming up with a fair coin is A = .5 × .5 = .25, and the probability of two heads with the biased coin is B = .7 × .7 = .49. We find C = 1 / (A + B) = 1.3513, so the probability that the coin is fair is now A × C = .337, or about 34%, whereas the probability that it is biased is B × C = .662, or about 66%. Thus, getting the same result twice under the same conditions has increased the reliability of the result from 58% to 66%!
In the case we examine now, the judge made the error of assuming that a new DNA test on a presumed murder weapon would provide no more information than the first one, and chose to reject a second test that might have proved decisive.
 
 
The Case of Meredith Kercher: The Test That Wasn’t Done
It was November 1, 2007. Meredith Kercher, a British student spending a year in the medieval Italian city of Perugia under the Erasmus program, spent a quiet afternoon having pizza with friends and watching a movie. She left her friends’ apartment a little before 9:00 p.m. and a few minutes later reached her home, a pretty cottage just outside the city walls, which she shared with two Italian girls and an American girl named Amanda Knox.
Around the same time, Raffaele Sollecito, a young Italian student living on a busy street a short distance away from the isolated little cottage where Meredith rented a room, used his computer for the last time that evening. One week earlier, he had met Meredith’s housemate Amanda at a classical concert, during which a string ensemble played Schubert’s Trout Quintet and tangos by Astor Piazzolla. The two of them had talked during intermission, spent the night together at Raffaele’s place afterward, and become practically inseparable from that point on. Raffaele was a shy student who had previously never had a girlfriend; he favored computer science, violent manga, and knives. Amanda, an outdoorsy type, didn’t seem to mind his introverted nature, appreciating her new lover’s devoted tenderness.



Meredith Kercher



Raffaele Sollecito
On the evening of November 1, Amanda Knox received a text message from her boss informing her that she didn’t need to come to work that night, because business was slow. Le Chic was a trendy pub in the center of Perugia run by Congolese musician Patrick Lumumba, and Amanda had found a job waitressing there a couple of nights a week. But according to the testimony she gave at her subsequent trial, when she found out that she didn’t need to go in to work, she spent the entire evening at Raffaele’s place, watching a film, eating dinner, smoking pot, making love—as she made sure to explain to an attentive jury—and sleeping.
On that same evening, Meredith was stabbed to death in the little hillside cottage where she and Amanda both lived. The results of the autopsy revealed that she had been attacked by more than one person. Indeed, the knife wounds she received to the neck were made not only from different angles—one from the right, one from the left—but also by different knives, according to the size of the wounds; a bloody print on her bedsheet showed where a knife had been laid down briefly on the bed. Innumerable bruises and contusions on her body showed that she had been gripped, restrained from defending herself, abused, and choked before finally being killed.
In her courtroom testimony Amanda described how she returned to her cottage the following morning to collect some clean clothes and take a shower, but noticing a few “strange things,” she became worried and went back to Raffaele’s place to tell him about them. She brought him over to the cottage and showed him the things that had unsettled her: some small traces of blood in one of the bathrooms, unflushed excrement in the other, and Meredith’s bedroom door locked. They explored the house together and discovered something worse: the window in the bedroom belonging to Filomena, one of the Italian girls, was smashed, and the room itself had been ransacked. Amanda called Filomena and told her to come home at once.
Filomena came, bringing several friends, and the police came as well— not the Carabinieri initially, but the Italian Postal Police, who had been independently investigating the discovery of Meredith’s two cell phones in a nearby garden, where they had been tossed and then found by an elderly woman who lived there. Filomena panicked at the sight of her ransacked room and Meredith’s locked door and insisted on having it broken down. Her friends kicked it in, and there lay Meredith’s body on the floor in a welter of dried blood, covered with the quilt from her own bed.
It is not clear just when Amanda and Raffaele stopped being witnesses in the eyes of the investigators and began to be considered as suspects. At any rate, it is certain that even from the start there were a number of little details that alerted police to something peculiar. The smashed windowpane and the raid on Filomena’s room looked fake: nothing was missing, and there were no footprints, trampled grass, marks on the wall, or shards of fallen glass on the ground below the broken window outside the house, nothing at all to confirm the hypothesis that someone had really made the difficult climb from the outside. The investigators reasoned that if anyone had staged a break-in, it had to have been someone eager to make the murder look like an outside job. But this would only be necessary if the person was actually an insider—even an inhabitant of the house.



The “house of horrors,” as the pretty cottage was called in the press
Worse, when questioned, Raffaele first stated that he and Amanda had been at a party with friends on the evening of November 1, but when said friends could not be produced, he then recalled that they had spent the evening at home.
The growing suspicions of the police may or may not have been reinforced by Amanda’s odd behavior in the days following the murder, during which she flirted with her boyfriend at the police station in front of Meredith’s grieving friends and responded to questions about the murder with such flippant remarks as “Shit happens” and “She fucking bled to death.” Indeed, later on much would be made of the idea that she was arrested because of her unbecoming behavior. But there was certainly more to it than that. The pair was questioned both together and separately multiple times over the following days, and late on the evening of November 5 Raffaele suddenly announced that he had told lies for Amanda and that while he had stayed at home surfing the Internet—a lie, as was subsequently shown by the records of his computer activity—Amanda had gone out alone. At least she might have. He couldn’t remember. He was too stoned.*
On hearing all of this, the police took Amanda, who had not been summoned to the police station that evening and was cheerfully doing homework and gymnastics in the hall, into a separate room and questioned her intensively. The focus of their questioning was precisely whether or not she had gone out on the evening of the murder. In her phone they found her text message to her boss, acknowledging his (deleted) message about not coming in that evening. She had written, “Ci vediamo piu tardi. Buona serata,” thinking this was the normal Italian for “see you later,” but in fact it means something closer to “see you later today” (or “see you tonight”); in other words, it indicates a planned meeting. The police seized on this message and insisted on knowing to whom it had been written. Amanda says they shouted at her and even cuffed her on the back of the head, though the police deny this.



Amanda Knox being brought to court
What happened next was a bombshell: Amanda broke down in tears, suddenly declaring that Patrick Lumumba was the murderer and that she had been in the cottage while he did it, cowering in the kitchen and covering her ears to block out the sound of Meredith’s screaming. She retracted this confession the next morning in a bizarre written statement in which she explained that the memories in her mind were “blurred flashes” and seemed less real than her memory of having been with Raffaele. Later she would claim that the story was all an illusion provoked by the intense pressure put on her by the police and their pressing suggestions that she had seen the murder and suppressed the memory. Nevertheless, her confession led to the arrest of Patrick Lumumba, Raffaele Sollecito, and Amanda herself, accused of being present at the scene. The police were also searching for a fourth man, whose yet unidentified footprints and DNA traces had been found in various places around the house, on Meredith’s clothing, and inside her body.
AFTER RAFFAELE’S arrest the police made a search of his apartment, and from his cutlery drawer they took a large kitchen knife. The investigator who collected it stated that it looked and smelled particularly clean and was lying on top of the other, ordinary table knives. This “very clean” knife was delivered to the laboratory of the Scientific Police of Rome for forensic analysis and handed over to their forensic geneticist, Dr. Patrizia Stefanoni.
According to her testimony, Dr. Stefanoni began by unpacking the knife from its wrappings and examining it under a strong light. She perceived a few streaks on the blade, perhaps indicative of vigorous scrubbing. She took swabs along these streaks, managed to obtain an infinitesimal quantity of biological material—human cells, in fact, but precious few of them—and proceeded to perform two analyses on it: one to determine whether or not the cells were blood cells, and the other to obtain a DNA identification. She also swabbed the handle of the knife.
The DNA on the handle turned out to be Amanda’s, but this was not considered incriminating, as she had used the knife while cooking at Raffaele’s house. The DNA on the blade, however, was a different story. The first test could not establish whether or not the cells were from blood. They were human cells, but they might have been from skin or tissue.
For the second test, Stefanoni’s machine was set up to work with a minimal quantity of biological material that was significantly greater than what she had at her disposal. At first this machine simply output “too low,” indicating that using the standard settings it was not able to analyze such a tiny quantity. Many forensic geneticists would have followed the accepted rules and stopped the analysis at this point. But Stefanoni elected to continue, modifying the settings and pushing the machine beyond the limits recommended in the manufacturer’s guidelines. By doing this she managed to obtain a DNA profile for the cells on the knife.
A DNA profile is given as a graph called an “electropherogram,” which shows a set of “genetic loci”: pairs of peaks situated at particular locations along a horizontal line. Every human being possesses millions of gene pairs, each of which has been given a name, but there are thirteen particular gene pairs that have been singled out by geneticists because the pairs differ quite significantly from person to person. The probability that two people (excluding identical twins) could have all of these thirteen peak pairs at the same locations in the electropherogram has been estimated at around 1 in 400 trillion, many times the population of the earth. To be certain that the graphs from two samples both come from the same person, every single peak must lie in the exact same position. If even one peak is clearly in a different location, then the two samples necessarily come from different people.
The figure below shows an electropherogram of Meredith Kercher’s DNA taken from a swab. The thirteen pairs of peaks are clearly visible along a horizontal axis (which has been broken into three lines to fit on the page). The vertical axis shows the heights of the peaks, which are measured in units called RFU (relative fluorescent units). When the DNA sample is sufficiently large (such as the one that produced the graph below), peak heights tend to reach as high as 1,000 or 2,000 RFU.
This electropherogram was created in the Scientific Police laboratory as a reference to determine whether other DNA samples from the crime scene came from Meredith. It is of good quality, with high, clearly defined peaks that cannot possibly be confused with the normal tiny peaks from background noise (sometimes called “stutter”) that appear all along the axis. If all DNA samples gave such clear results, DNA analysis would be a more precise science.



Meredith Kercher’s DNA
But the fact is that subtleties can be involved in DNA analysis, particularly in cases where the DNA sample is degraded, contains a mixture of DNA from more than one person, or is extremely small. The graph of a degraded sample may show only a few peak pairs out of the usual thirteen; a mixed sample will show too many peaks that are difficult to pair correctly. When the DNA sample is particularly small—such samples are called LCN, for “low copy number”—the heights of the peaks in the electropherogram are correspondingly much lower than the 1,000 or 2,000 RFU that will appear in a good sample such as the one above. Forensic geneticists are trained in methods to distinguish small true peaks from the occasional extra-large peak from background stutter in the output from LCN samples, but it can be difficult to do so with certainty, and experts may not always agree with each other in interpretation. One commonly used guideline is that any peak less than 50 RFU in height is subject to doubt.
In the case of the cells found on the knife seized in Raffaele’s flat, the problem was precisely this very small sample size, which Stefanoni attributed to the knife’s having been washed; indeed, the few cells that did remain were lodged inside a scratch in the metal. For this reason, Stefanoni was not able to apply the first most basic technique of DNA analysis—namely, dividing the sample into at least two smaller parts so as to compare the graphs from two independent runs through the machine. With two graphs, there is a very simple method for determining true peaks, which is to accept only those that appear in the exact same place in both graphs. This is considered valid even for small samples that produce low peaks, since there is virtually no probability that the random background noise would produce an unusually large peak twice in the same position. But Stefanoni feared that if she divided the already minuscule sample into two, she would obtain no results at all. She took the chance of using the entire sample on a single run.



The knife-blade DNA
The figure on the left shows the electropherogram from Stefanoni’s analysis of the DNA from the cells on the knife. All thirteen pairs of peaks are clearly visible, and the background noise is extremely low except for a few extra peaks that are about the same height as the visible pairs. They are all very low compared to the peaks from the abundant sample of Meredith’s DNA; the vertical axis of the graph shows that many of the peaks in the knife sample are less than 50 RFU, or below the accepted minimum. However, it is important to understand that that number serves as a guideline to distinguish low peaks from high stutter. In some cases, the stutter remains minimal and the profile appears clearly despite the relatively low peak heights. That is the case here.
Stefanoni proceeded to compare this output with the graph from the known sample of Meredith’s DNA, which we do below by superimposing them one on top of the other. The graphs have not been scaled for height, which is not connected to the identification of the individual. The only thing that counts for identification is the exact placement of the peaks along the axis. In these graphs, all the peak pairs in the two samples correspond perfectly, and Stefanoni logically concluded that the DNA on the knife blade also belonged to Meredith. To assume that this DNA is not Meredith’s would be tantamount to asserting that background noise randomly produced some unusually high peaks in the precise places where Meredith’s DNA peaks would normally be, a probability so low as to be negligible.



The two DNA samples: Meredith in thin, knife blade in thick
WHILE STEFANONI was performing her analyses in the lab, police investigators were making progress on the outside. On November 12 police found a witness—the only client at Le Chic that night—who asserted that Congolese pub owner Patrick Lumumba had spent the entire evening at his bar, providing him with an alibi. Patrick remained in prison while the police worked on confirmation.
On November 13 it emerged that police were still searching for the “fourth man,” the one whose DNA had been detected in the bathroom, on Meredith’s handbag, and on her body. This DNA had been analyzed and proved to belong to neither Amanda, nor Raffaele, nor Patrick.
On November 15 Dr. Stefanoni dropped her bombshell: the knife DNA was Meredith’s.
On November 16 it was leaked that the identity of the fourth man was known, but that he had fled from Perugia.
On November 18 it was revealed that the fourth man was African.
On November 19 the fourth man’s name emerged: Rudy Hermann Guede.
On November 20 Guede was arrested in Germany, where he was found train hopping without a ticket. On that same day, Lumumba was released.
On November 25 Guede, still held in Coblenz, made a kind of confession to the German police. He told a strange tale of having been in the middle of fooling around with Meredith when he suddenly had an urgent need to visit the toilet, during which time an Italian stranger came in and murdered the British girl. Hearing her scream, Guede said, he rushed out of the bathroom so quickly that he had no time to flush, and he attacked the murderer, who was wearing a swimming cap and brandishing a knife in his left hand. But Guede’s unfastened pants slid down to his ankles, causing him to fall over and giving the unidentified killer the chance to escape with a final shout of “Black man found, black man guilty!”
Guede was brought back to Italy on December 6 and promised that he would tell the full story the next day. After seven hours of interrogation, the same story stood, with the additional detail that there had been another person standing outside, who had fled together with the killer. Guede expressed both guilt and grief at having failed to save Meredith, who had been dying when he saw her. He told how he had fought with the killer and received some tiny cuts to the fingers, which still showed. He recounted how he had tried to staunch her bleeding wounds with towels from the bathroom (which were indeed found at the crime scene), and how he had written the letters “AF” on the wall in blood, thinking she had tried to pronounce this syllable with her dying breath (although no such letters were found). He had not called the police, he said, because he had no cell phone, and Meredith’s had been stolen by her killers. Afraid of being accused of the murder, Guede had run away.
It seemed that in Rudy Guede the police had found the murderer they sought. A high-school dropout with a miserable family background, he lied easily, couldn’t hold down a job, was well-known as a good source for students to get hold of a bit of hash, and had already been involved in a little petty burglary. He admitted to being in the house at the time of the crime. His traces were in the room and on Meredith. No one believed the story about the pair fooling around, as Meredith was a serious girl who had openly expressed her dislike of cheating and was seeing another boy at the time. Worse, it emerged that after leaving the grisly crime scene he had spent the rest of the night dancing at a local disco. And of course his fleeing the country didn’t help his image. It seemed as though the guilty party had been identified and would soon be brought to justice. Amanda, Raffaele, and their families should have been dizzy with relief.
Except for one problem: the evidence against them wouldn’t go away. Most incriminating was the DNA found on the knife from Raffaele’s apartment, which Meredith had never visited. This knife, appearing on a television report of the crime investigation, was brought to the attention of both Raffaele and Amanda in their prison cells.
Raffaele sank himself deeper into trouble by writing peculiar things in his diary. When Rudy Guede was arrested, for example, he wrote: “Today finally they have captured the real murderer of this incredible story. He’s a 22-year-old Ivory Coaster and they found him in Germany. Papa was happy and smiling, but I am still not 100% calm, because I’m afraid that he will invent strange things.” One really wonders what “strange things” he was expecting to hear from the mouth of that supposedly unknown stranger.
Even more oddly, when he learned that Meredith’s DNA had been found on his own kitchen knife, he wrote: “The fact that Meredith’s DNA is on the kitchen knife is because once while we were cooking together, I moved around holding the knife and pricked her hand. I apologized right away but she wasn’t hurt. So the real explanation of the kitchen knife is this.” It was easily proven that Meredith had never been to Raffaele’s place. Furthermore, her DNA was not on the tip of the knife, as would be expected from his story, but in a scratch on the flat of the blade. And he had never mentioned such an episode before during all the hours of interrogation; it came out only when police suddenly found a speck of Meredith’s blood there. The situation didn’t look good for Raffaele.*
In her own diary Amanda wrote that it was impossible that the DNA on the knife could be Meredith’s, since Meredith had never been at Raffaele’s house. She then slid into vague musings about whether it was possible that Raffaele had taken the knife and slipped out to murder Meredith, then returned and pressed it into Amanda’s hand while she slept in his bed.
Rudy or no Rudy, the knife began to look devastating for the lovebirds.
There was only one hope. Dr. Stefanoni had made use of exceptional methods to test the knife DNA. Because there were so few cells, she had not been able to divide the sample into two parts, so the test she had made on that sample could not be repeated. For the defense effort spearheaded by Amanda’s family, the best option now was to discredit the knife.
MERE WEEKS after the murder—in the very heat of the investigation— Amanda Knox’s parents, Curt Knox and Edda Mellas, hired the Seattle-based communication strategies firm of Gogerty and Marriott to orchestrate a public relations campaign of enormous dimensions. By January 2008 Curt and Edda were in Perugia with an ABC television crew, traveling by limousine, staying at high-end hotels, and, of course, visiting their daughter. And that was only the beginning. Over the course of the following months and years they participated in a seemingly endless series of publicity appearances, including television broadcasts with such celebrities as Oprah Winfrey and Matt Lauer and news coverage in Marie Claire, the New York Times, and innumerable other publications across two continents. A whole set of online blogs devoted to the case sprang up, all but a few devoted to discussions of Amanda’s innocence. Thousands of people rallied behind her parents’ efforts, and a Washington state senator went so far as to “convey her concerns to Secretary of State Hillary Clinton.”
The Knox/Mellas family based their argument for innocence on three pillars. First, Rudy Guede was fingered as the lone and single murderer. The campaign fought long and hard to prove that the break-in may not have been staged but was perfectly real, that someone could have climbed in through Filomena’s window even though it was jagged with smashed glass and high off the ground, and that a single attacker could have caused all the injuries inflicted on poor Meredith. Second, Amanda’s various missteps, her false accusation of Patrick Lumumba, and her shifting stories—she was not there, she was there, she was not there—were explained away as consequences of police pressure, coercion, and mistreatment during her interrogation.
Third, and most significantly, the scientific evidence against Amanda was discredited. Mixed drops of Meredith’s blood and Amanda’s DNA found around the cottage were said to be normal, as Amanda lived there and her DNA would have been all over the place, so Meredith’s blood may have simply fallen upon it. This argument was used even for the mixed trace found on the floor of Filomena’s ransacked room, even though it would have to mean that either Filomena’s whole floor was covered with Amanda’s DNA, or that Amanda had merely left a small trace here and there, but was remarkably unlucky when the murderer chose one of those precise spots to drop a bit of blood on. Another possibility raised was that Amanda’s DNA might have been tracked into the room later and deposited on the bloodstain by the white-suited police investigating the crime scene. All of these arguments and more were brought forward to provide possible explanations for the evidence.
But there remained the damning knife, the most dangerous piece of evidence against Amanda, and one that legitimately raised doubts in the minds of many who were following the case. If Meredith Kercher’s DNA was found on the blade of a large and murderous kitchen knife taken from the home of Amanda’s boyfriend, a place where Meredith had never set foot, then one may reasonably ask how it got there. Or, as the innocence campaign insisted, whether it was ever really there at all.
ON FEBRUARY 3, 2009, Amanda’s aunts Christina Hagge and Janet Huff appeared on CNN Headline News, where they were interviewed by star CNN anchor Jane Velez-Mitchell, famous for her irreverent comments on high-profile cases. From the transcript of that show, it is easy to perceive that Velez-Mitchell, while welcoming, is also challenging in her attitude and does not hesitate to ask pointed questions.
VELEZ-MITCHELL: If you’re saying that Amanda wasn’t involved, who is involved? This other man who was a native of the Ivory Coast? What happened?
HAGGE: Rudy Guede has been charged and sentenced to 30 years for participating in a crime. Amanda and Raffaele are completely innocent. They were home that evening together enjoying a very quiet evening, and they had nothing to do with this.
VELEZ-MITCHELL: But what about the knife? What about the knife?
HUFF: What about the knife? The knife has already been thrown out because A, it does not fit the size of the wounds that were made on Meredith and, B, yes Amanda’s DNA is on the handle, it’s a cooking knife that she’s used at Raffaele’s house, but the DNA that’s on the tip of that blade is a less than 1% match to Meredith. It could be more yours or mine than hers [emphasis added].
HAGGE: And the DNA is not on the tip of the blade. It is not blood DNA. It is—the DNA is on the back side of the blade.
VELEZ-MITCHELL: So what you’re saying is that she used a cooking knife and it was in the home of her then boyfriend. And the police went to that house and took the cooking knife and said that was the murder weapon, when it doesn’t match up and it wasn’t at the scene of the murder.
HUFF: That is what the prosecutor is alleging, yes.
“What a stupid prosecutor,” one might well think upon listening to this exchange. On the strength of this feeble scientific result—a trace of DNA on the blade that has less than a 1% chance of belonging to the victim—he actually has an innocent girl and her boyfriend arrested when the real culprit is already in jail? What a terrible judicial error!
Edda Mellas also appeared on The View, a show hosted by famed actress Whoopi Goldberg, legendary television anchor Barbara Walters, and a handful of other stars, and devoted to receiving the celebrities of the day. Edda’s visit immediately followed an interview with charming Indian actor Dev Patel, star of the hit film Slumdog Millionaire.
Sitting at the round table where the hosts receive their guests for animated discussion, Edda fielded questions about every aspect of the case, including the knife. Yes, it was found at Amanda’s boyfriend’s house, she explained. “There is a very poor chance that the DNA found on it actually belongs to the victim,” Edda stated.
On NBC’s Today Show with Matt Lauer, Amanda’s parents brought her younger sister Deanna along with them. Relaxing on the sofa in front of a coffee table decked with pink flowers, while Deanna expressed such sentiments as “They don’t really like her there because she’s a pretty girl” and Edda added that “Amanda just wants this to be over so she can be home,” it was Curt who undertook to point Matt Lauer’s attention to an image of the huge knife, explaining that “while Amanda’s DNA is prominent on the handle, the level of Meredith’s DNA found on the blade falls below even the level for a poor match [emphasis added].”
Millions of viewers were being told, repeatedly, that there was a 99% chance that the cells found on the knife blade were not Meredith’s.
IN ITALY, accused criminals may choose to undergo a fast-track trial rather than the detailed, full-length version. In return for saving the state the costs of a full trial, they may be given a sentence reduction. Rudy Guede chose the fast-track trial, and on October 28, 2008, he was convicted and sentenced to thirty years in jail for the murder of Meredith Kercher.* That same day, Amanda Knox and Raffaele Sollecito were ordered to stand trial together; they chose the standard-length trial, which in Italy can last a year or more. Their trial began on January 16, 2009.
As might be expected, the knife played a key role during the trial, and the cool, dark-haired Dr. Stefanoni underwent a grueling session of questioning and cross-questioning that lasted for two full days. One of the first questions Stefanoni faced was whether the DNA that produced the famous result so similar to Meredith’s might not have come from the knife at all, but from some molecule of Meredith’s samples left in the machine from a previous test or floating in the air of the laboratory—in other words, whether it might not have been a result of contamination. But Stefanoni’s testimony in court on this point was absolutely firm. The judges’ report states that Stefanoni
excluded the possibility that in the machine used for the analyses of the various traces, any secondary deposits might form from which it would be possible to transfer DNA onto other traces. With respect to this, she stated that the machine is equipped with a security system that prevents such an occurrence. With respect to laboratory contamination, she stated that . . . she was not in possession of any data referring to such contamination, and emphasized that if all the procedures associated with good laboratory procedure are applied, the possibility of such contamination is excluded.
The second and more difficult question was whether the avant-garde methods Stefanoni used, such as modifying the machine’s sensitivity to test an LCN sample without dividing it into more than one part, should be permitted as evidence at all in a court of law, given that they have not yet been subject to rigorous international scientific testing. Here are the words with which Dr. Stefanoni defended the reliability of her results.
If an analysis is performed following all the parameters of reliability and proper laboratory procedure, with the due positive and negative controls and the due precautions of wearing the single-use gloves and everything else which is indicated in proper laboratory procedure, then I can be tranquilly certain of getting a result, even with a very tiny quantity of DNA. Therefore I can use the DNA for a single analysis even without being able to repeat that analysis, even if I wanted to. And that analysis is absolutely valid; it has no reason to be put in doubt, as long as the data is absolutely readable and interpretable.
The final question raised by the defense was whether it was possible that the electropherograms showing Meredith’s DNA and the one showing the DNA from the knife did not actually coincide. In her testimony, the experienced geneticist simply responded that “comparing the two electropherograms, I saw nothing different, and nothing additional, which could have led me to think that the profile did not belong to the victim but to some other person, known or unknown, but another individual.” What Stefanoni saw is the same thing that anyone can see by looking at the graph obtained by superimposing the DNA electropherogram of the knife DNA on top of Meredith’s DNA: they are identical.
The court accepted Stefanoni’s claim that the DNA on the knife belonged to Meredith and concluded on this basis that the knife found in Raffaele’s house, with Amanda’s DNA on the handle and Meredith’s DNA on the blade, was the murder weapon responsible for inflicting the massive lethal wound to Meredith’s neck. Together with the scattered pieces of evidence that fit together to make a bigger picture, they concluded that Amanda and Raffaele had been present at the cottage on that fateful night, and had joined Rudy Guede in an aggressive attack on Meredith that turned fatal.
On December 4, 2009, almost a year after the start of their trial, Raffaele Sollecito and Amanda Knox were convicted of murder. Raffaele was sentenced to twenty-five years in jail, and Amanda, because she had accused an innocent man of murder, to twenty-six.
AMANDA’S AND Raffaele’s lawyers immediately lodged an appeal. There were some grounds: by some unfortunate coincidence it seemed as though each and every piece of evidence used to convict the pair was flawed in some way or another. A bloody footprint on the bathmat seemed to fit Raffaele’s foot, but the identification could not be certain. His DNA was found on the ripped-off clasp of Meredith’s bra, but that clasp had been forgotten in the murder room during the first forensic inspection. Between then and the time it was collected from the floor forty-six days later, objects had been carried in and out of the room, bringing a possibility of contamination from the forensic technicians’ shoe covers every time. A witness who claimed he saw the pair talking animatedly in a little square overlooking the cottage gate the evening of the murder said it was the night of Halloween instead of November 1. Another claimed, a year after the murder, that he had seen Amanda in his little grocery store at eight o’clock in the morning on November 2, but it turned out that he had failed to identify her when the police showed him photos of her in the days following the murder. Two witnesses, in addition to Rudy Guede, told of hearing a terrible scream from the cottage on the night of the murder, but none of them could really say what time they had heard it.* A broken-down car had been parked in front of the gate leading to the cottage from 10:30 p.m. to about 11:30 p.m., during which time a tow truck had come to make repairs, yet none of the people involved had seen a light or heard any sound from the cottage or spotted anyone going in or out.
In the end, some of the most damning evidence against the couple came from their own fabrications and contradictions: Amanda’s accusation of the innocent Lumumba; her claim, later retracted, that she had been in the house when Meredith was murdered; Raffaele’s statement, also later retracted, that Amanda had left his house and gone out alone that evening. Then there was their claim that they had slept straight through the night until 10:00 a.m., when in fact Raffaele’s father had called him at 9:30 in the morning, and worse, Raffaele’s computer showed continuous use setting up a playlist and listening to music from 5:30 to 6:10 a.m. Also, a text message from his father late in the evening showed up on his phone after 6:00 the next morning, indicating that he had turned his phone on at that time as well.†
But Amanda’s and Raffaele’s lawyers repeated untiringly that none of these discrepancies provided any proof of murder, and they left no stone unturned in their effort to discredit each piece of evidence one by one. It began to seem as though the outcome of the appeal trial hung on a single thread: the DNA, both Meredith’s on the knife and Raffaele’s on the bra clasp. Drowning in the conflicting and strongly expressed opinions of the expert witnesses who had been hired by both sides in the first trial, the appeal judge, Claudio Pratillo Hellmann, decided to call on a team of independent experts, university forensic geneticists unconnected to the case, to make a final judgment on the quality and reliability of Stefanoni’s work. They chose Professor Carla Vecchiotti and Dr. Stefano Conti, both of Rome’s highly reputed La Sapienza University. Conti and Vecchiotti studied the knife and bra clasp in their lab; they also examined all of the records from Stefanoni’s lab pertaining to the analysis of the two items. They submitted a report on their analysis to the court at the end of June 2011.
The day the experts’ report came out was the day that the trial completely changed direction. The experts lambasted the on-site forensic work. They showed a film of the white-garbed technicians lifting samples of blood and hair from the crime scene, focusing on smudges of dirt on the tips of the single-use latex gloves and on the handing of evidence back and forth before bagging it. As far as Raffaele’s DNA on the bra clasp was concerned, they deemed it unreliable as evidence because of the possibility that his DNA could have been tracked in by the dirty feet seen on the video going in and out of the room, despite protocol saying that shoe covers had to be changed every time. Although none of Raffaele’s DNA was found anywhere in the house except on a single cigarette stub in an ashtray, making it difficult to see where it could have been tracked in from, the two experts’ searing criticism of inspection techniques raised some doubt about the validity of the evidence. Furthermore, they pointed to the electropherogram of the DNA from the bra clasp, which, while it contained a clear profile of Raffaele, also contained a rather large number of peaks that seemed too significant to be mere background noise, indicating, rather, some contamination by further unidentified contributors to the sample. Despite the commonly accepted guidelines for interpreting such peaks, Stefanoni had chosen to consider these extra peaks as background noise, stating that she saw only Meredith’s and Raffaele’s genetic profiles on the bra clasp. Her conclusion was now rejected outright by the experts, who did not pause to explain why, apart from Meredith’s, a more significant quantity of Raffaele’s DNA was present than anyone else’s. They deemed the bra clasp evidence unreliable.
The knife posed a subtler problem. To start with, Conti and Vecchiotti attempted to make a new test, but they found that the quantity of material remaining on the knife was so small as to consist of only a couple of individual cells, if any. At this point they could have done some tests to quantify it precisely, but they declined to do this on the grounds that even if some cells were there the sample would be even smaller than the one Stefanoni had worked with. If LCN results were deemed unreliable by the scientific community and thus unfit for use in court, then any new results would be so as well, in which case testing the new sample would be useless.
Although they were just as scathing about the collection procedures used during the forensic inspection of Raffaele’s house, including the manner in which the knife was found, collected, bagged, and transferred to Stefanoni’s lab, the experts were unable to explain how, of all the possible traces of DNA that might have contaminated the knife during this process—DNA from the handlers, from other objects in Raffaele’s house, or from lab technicians—of all people, it was the DNA of Meredith, who had never been near either Raffaele’s house or the lab, that landed there. It was all very well claiming contamination, but nothing from the collection procedure—from kitchen drawer, to lab, to swabbing, to DNA testing machine—could be blamed for the presence of Meredith’s DNA.
The experts, however, did raise one point in the procedure where it seemed as though there was a real chance of contamination. When a very small sample is run through a machine where good-quality samples from the same person have been run previously, it is possible for the good-quality sample to “rub off” on the tiny one, thus contaminating it. Stefanoni had testified that the knife sample had been run “somewhere in the middle of a series of 50 or 60 samples of Meredith’s DNA.” During their court testimony on July 25, 2011, Conti and Vecchiotti stressed this point. Stefanoni, they said, should have carried her LCN sample to another lab for testing so as to avoid this problem. Not having done so left her results open to question.
Five days later, on July 30, the prosecution had their chance to interrogate the experts in court. They had brought in a record of all the tests done in the laboratory in the days preceding the knife DNA testing.
“Do you know when the last sample of Meredith’s DNA was tested in the lab, prior to the knife DNA testing?” the prosecutor asked the experts. No, they responded. They had studied only the reports of the knife testing, not testing of other samples. They didn’t know. It turns out that it had been six days earlier. “The machine was used and flushed out repeatedly in between the previous sample from Meredith and the knife sample. Is it still possible that a sample from her DNA contaminated the one from the knife?” “No,” the experts admitted. A six-day delay was too long for that type of contamination to have occurred.
As a last resort, Conti and Vecchiotti held fast to their statement that the sample was too small for the results of the tests to be considered reliable. To support their position, they cited a number of scientific publications warning against the use of LCN DNA samples in court for the purposes of conviction. They did not make any assessment of the reliability of the result in the particular case of the knife electropherogram despite the low level of background noise that left the genetic profile clearly visible.
The prosecution submitted a formal request for the new, tiny sample swabbed from the knife by Conti and Vecchiotti to be submitted for analysis. In court on September 5 and supported by expert prosecution witness Giuseppe Novelli, Stefanoni explained that newer generations of DNA analysis kits existed in 2011 that had not been available in 2007, and these new kits could give results on samples as small as a couple of cells. She wanted a new analysis performed to confirm that her previous work was correct. The prosecution agreed and asked the judge to order the new tests.
The request was rejected by Judge Hellmann on September 7. On the day that this decision was announced, even Barbie Nadeau, the author of Angel Face: The True Story of a Student Killer, and one of the most unambiguously “guilter” journalists following the case, tweeted directly from the courtroom: “Looks like Knox will walk.” Indeed, it was difficult to interpret the judge’s decision any other way.
Nadeau was not wrong. On October 3 the jury deliberated for ten hours, but seemed pleased and full of smiles when they finally returned, and the judge read out the decision that overturned the verdict of the first trial, declaring that Amanda and Raffaele had not committed the crime of which they were accused and setting them free.* Their verdict was in flat contradiction with the Italian supreme court verdict decreeing that Rudy Guede had not acted alone, and with autopsy reports that clearly indicated that Meredith had been attacked by more than one person. But above all, the verdict was in contradiction with the DNA found on the knife.
How did the appeal court justify rejecting the knife DNA and refusing the prosecution’s request for a retest using new technology? In some countries we would never know the answer to that question, but in Italy judges are required to produce a document called the “motivations” for the sentencing, which explains the reasons for their decisions in detail. Here is the passage in which Judge Hellmann justified his choice concerning the knife:
We deduce that for our purposes, the result obtained by the Scientific Police cannot be accepted as reliable, since it is the product of a procedure which did not follow the techniques indicated by the International Scientific Community, or in any case its reliability must be seriously weakened, so much so as to make it necessary to find confirmation in other elements independent of the scientific analysis.
This also explains why the expert team did not proceed farther in analyzing the sample that it collected from the blade of the knife: the quantity was found to be again LCN, and altogether insufficient to make two separate tests* possible, so that if they had proceeded further, the court-appointed experts would have committed the same error as the Scientific Police. And on the other hand, it seems clear from the ideas explained above that because the necessity of dividing the sample into two or more parts holds for every single trace, its aim being to guarantee the reliability of the result of the analysis of that trace, it is not by analyzing two different traces that are both LCN, without treating either of them with the proper procedure to guarantee the result, that one can think to make up for the lack of repetition in the procedure for each single trace: the sum of the two results, both unreliable due to not having been obtained by a correct scientific procedure, cannot give a reliable result.
Here, Hellmann is making a statement about experiments whose outcomes are reliable with a particular percentage of certainty. Let us say, for example, that we run an experiment whose result has an X% chance of being correct. We then run the experiment independently a second time and obtain roughly the same result, again with an X% chance of being correct. What Hellmann is saying is that the fact of having run the experiment independently two times and obtained the same result twice does not increase the reliability of the result. “The sum of the two results, both unreliable . . . cannot give a reliable result.” This sentence shows a complete misunderstanding of the probabilistic result of considering two separate results from two performances of the same test. It is precisely the situation explained in the introduction to this chapter with the weighted coin.
To show how wrong Hellmann’s reasoning is, here is another example, this time with an initial probability of correctness of approximately 80 or 90%. In fact, it is difficult to give any precise assessment of the probability that the knife electropherogram represents Meredith’s DNA. Visually, it seems quite certain that it does. But the advantage of an estimate of 80–90% is that such a probability is relatively convincing, but certainly not beyond a reasonable doubt. Let us now consider what can be deduced, mathematically, if you do two tests and obtain similar results.
The new example is similar to the one in the introduction: you are given a coin that is either fair or biased to fall on heads 70% of the time, and after a certain number of tosses you must decide whether or not the coin is biased. Now, though, let us suppose that a test consists not of a single coin toss, but of ten.
You do a first test and obtain 9 heads and 1 tail. Knowing that your coin is either fair or biased, the probability that the coin is fair given this outcome is about 8%, or that it is biased, about 92%. Pretty convincing, but not enough to convict your coin of being biased beyond a reasonable doubt.
You do a second test, and this time you throw 8 heads and 2 tails. Now the probability for a fair coin is about 16%, for a biased coin about 84%. So the naïve thought might be that you haven’t gained any certainty from this second test; if anything, the 92% certainty that you had before has now been diminished a little. This is obviously the line of reasoning going on in Hellmann’s mind when he wrote the passage above.
But if you think about it differently, what you’ve really done is throw the coin 20 times and get 17 heads and 3 tails. Using the exact same probability calculation as in each separate case—the one explained in the introduction—now yields a probability of 98.5% that the coin is biased! There is no legal set numerical threshold for reasonable doubt, of course, but 98.5% is a lot closer to that elusive notion than 92% or 84%. Thus, running a test that is only moderately reliable twice and getting the same result may indeed, in total, yield a very reliable result.
THE APPEAL trial verdict is presently being appealed to the Italian supreme court, which has the right to either confirm the appeal verdict or cancel it and order a new appeal, during which the knife DNA might or might not be retested. What will happen, only the future can tell.
In the meantime Raffaele and Amanda have returned home, one to Bari, Italy, the other to Seattle, and both have undertaken to write books chronicling their experiences and proclaiming their innocence. Whoever killed poor Meredith will probably never tell the complete story. What we do know is that by using flawed scientific reasoning to reject a technically possible retest of the knife DNA, Judge Hellmann missed a major opportunity to get at the truth.
 
*The final version of events presented in court by Raffaele’s lawyers (he himself did not testify), and in his recently published book, Honor Bound, is that they remained together at home throughout the evening. But it contrasts not only with his declarations to police in the days following the murder, in which he said that she had gone out alone, but also with his written statements in his diary from prison, in which he said: “I remember that . . . Amanda had to go to the pub where she usually works, but I do not remember how long she was gone. I remember that she subsequently told me that the pub was closed (I have serious doubts regarding the fact that she went out). I am straining myself to remember other details but they are all confused.” Finally, cell phone ping analysis indicates that Amanda was in Raffaele’s apartment when the text message from Patrick arrived in her phone at 8:18 p.m., but a few streets away when she actually answered it, which did not happen until 8:35 p.m., almost twenty minutes later.
*In his book, Honor Bound, Raffaele explains his explanation thus: “How did Meredith’s DNA end up on my knife when she’d never visited my house? I was feeling so panicky I imagined for a moment that I had used the knife to cook lunch at via della Pergola [Meredith’s home] and accidentally jabbed Meredith in the hand. Something like that had in fact happened in the week before the murder. My hand slipped and the knife I was using made contact with her skin for the briefest of moments. Meredith was not hurt, I apologized, and that was that. But of course I wasn’t using my own knife at the time. There was no possible connection.”
*Later reduced to sixteen years on appeal.
*In a Skype call with a friend before his arrest, Rudy Guede mentions this terrible scream and his certainty that people outside the house must have heard it, and he places it at 9:20 or 9:30 p.m. But since he also claims that Meredith returned home at 8:20 or 8:30 p.m., his timing cannot be considered reliable.
†In his book, Raffaele explains that he “had been up several times in the night—listening to music, answering e-mail, making love,” but no e-mail message he wrote to anyone that night has been found.
*Amanda was essentially sentenced to time served for her unwarranted accusation of Patrick Lumumba.
*By this phrase the judge is referring to the standard process of performing two separate tests on the new sample by dividing it into two parts.

MATH ERROR NUMBER 5 »
THE BIRTHDAY PROBLEM
THE BIRTHDAY PROBLEM is a classical probability puzzle that asks the following question: how many people do you have to put in a room for there to be a 50-50 chance that two of them share the same birthday?
Before reading ahead, try to guess the answer. Most people will correctly intuit that if 2 randomly selected people are in a room, the chance that they happen to share the same birthday is 1 in 365 (discounting February 29 births!). But if 3 people are in a room, the chances of any shared birthdays increase to about 3 in 365. With 4 people in the room, the chances move up to about 6 in 365, and with 10 people, they increase to a surprising 52 in 365, or over 14%. At 23 people in a room, the chance that at least two of them share a birthday is very close to 50%.*
This final result seems very counterintuitive to most people, who tend to guess that to get a 50% chance of a shared birthday, you would need about 183 people, or roughly half of 365. At just 23 people in a room, most people tend to think it is far more likely that they will all have different birthdays— yet this is not the case.
The funny thing is, people often offer the same answer for a quite different question, which has to do with specifying a particular date: how many people do you need to put in a room for there to be a 50-50 chance that one of them has a birthday on January 1?
The answer to this question is not 183 either, but 253. The reason is that as you keep adding people to the room, the probability that two or more of them share birthdays increases. Given that 364/365 is the chance of one person having a birthday not on January 1, (364/365)n is the chance of n people not having that birthday. Since we want that chance to be less than 50%, we look for the smallest n such that (364/365)n is less than 1/2, which is 253.
The unexpectedly large difference (23 people versus 253 people) between the answers to two similar-sounding questions is a trap that one can fall into quite easily, as the following case illustrates.
 
 
The Case of Diana Sylvester: Cold Hit Analysis
In the early morning of December 22, 1972,* twenty-one-year-old nurse Diana Sylvester walked the few blocks home from her night shift at the San Francisco Medical Center of the University of California, reaching her Sunset District apartment at around 8:00 a.m. Her roommate, Patricia Walsh, also a nurse at UCSF, worked day shifts starting at 7:00 a.m.; when Diana got home that morning, Patricia had already left. What happened next has never been fully elucidated.
Shortly after 8:00 a.m., Diana’s landlady, Helen Nigodoff, who lived in the apartment below, heard loud noises coming from upstairs. The thumps and screams went on for a good twenty minutes before she finally decided that she had better see what was going on. It wasn’t the first time there had been disturbances in Diana and Patricia’s apartment; they had many friends, male and female, and Helen had gone up to complain about the noise three weeks earlier. But on this morning something didn’t sound right.
Helen rang the downstairs doorbell to Diana’s apartment, but since the door was already open, she didn’t wait but hurried up the flight of stairs toward the apartment’s main entrance. A man standing in the doorway startled her. Helen asked what was going on. “Go away, we’re making love,” he snarled aggressively, and she quickly turned back down the stairs. From the safety of her own place, she called the police and told them that something violent and frightening was going on upstairs. She managed to get a good look at the stranger as he ran down the stairs and out of the building.



Diana Sylvester
Minutes later the police arrived and rushed up the stairs to Diana’s apartment, where the door was still wide open with no signs of having been forced. There they were met with a tragic sight. Under a brightly lit Christmas tree with gaily wrapped gifts heaped underneath it, Officer John Forbes and his colleague Inspector Kenneth Manley found Diana’s naked body. Her clothes were in a pile next to her, and she had two bleeding wounds in her chest. As the postmortem revealed, the killer had forced her to perform oral sex on him, strangled her, and then stabbed her twice in the heart.
FINGERPRINTS IN the room and sperm samples taken from the victim’s body were stored by the police, but DNA analysis did not yet exist. The only clue to the identity of Diana’s killer was a statement given by Helen Nigodoff, who described the man she had seen as “white, medium height, heavy-set, chubby, curly brown hair, beard, mustache, with a clean-cut appearance.”
As in the Janet Collins case (see chapter 2), the police were reduced to searching the neighborhood for individuals who fit such a description. They managed to find one quickly. His name was Robert Baker, and he was a thirty-two-year-old street artist who lived in his Volkswagen van. He had escaped from a mental institution a month earlier. He was the primary suspect in a rape that had occurred two weeks before Diana’s murder, merely four blocks away from her house; that victim had actually identified him. She hadn’t been killed, but Baker had threatened her, saying, “I can rape you now or after you’re dead.” Also, as in Diana’s case, the front door to the victim’s flat hadn’t been forced; he had persuaded her to open the door to him on some pretext. Police records also show that four days after Diana’s murder Baker had harassed a young girl and her nanny, following them to their home a few doors down the street from Diana.
In their search for a possible link between Robert Baker and Diana Sylvester, the police hit on another clue. A week after the murder, Charlene Nolan, another nurse at UCSF and friend of Diana’s, told the police that on her way home on the morning she died, Diana had planned to stop and buy a candle from a street artist at Millberry Union Plaza. Patricia, Diana’s roommate, confirmed that there was indeed a new candle in the flat. Charlene knew the street artist; his description did not correspond to the man seen by Helen Nigodoff, but on the other hand, the police discovered that Robert Baker had been selling drawings not far from where Diana bought her candle, and could easily have seen her and followed her home.
When they searched Baker’s van, police found mail stolen from Sunset District mailboxes and a parking ticket with drops of blood on it. The blood type was O, the same as Diana’s, but because it is also the most common blood type, the finding could not be considered conclusive. Given the limits of forensic science at the time, no further information could be extracted from the ticket. Unfortunately, it was later mislaid or destroyed.
On January 11, the police organized an identification lineup that included Robert Baker. Although records do not state precisely which witnesses were asked to take part in the identification process, it can be inferred that Helen Nigodoff was one of them. She must have failed to pick Robert Baker out of the lineup, though, because the case came to a close for lack of evidence, and Baker was never charged for Diana’s murder. He died in 1978, and Diana’s case files sat, among all the other unsolved “cold case” files, gathering dust for more than thirty years.
IN 2003 the San Francisco Police Department received a grant to use new DNA technologies on a set of old, unsolved cases in which usable DNA evidence had been successfully preserved. The new method consisted of taking a DNA sample from a piece of evidence shut away in the cold case files and running it through a large database containing the DNA of thousands of known California criminals in order to search for a match.
Although it was over thirty years old, Diana’s case file contained a slide with a swab of sperm taken from Diana’s dead body. For this reason it was chosen as one of the cold cases to be reexamined. Unfortunately the sperm sample was extremely degraded, so that only a part of the DNA could be read; out of the thirteen genetic pairs (called genetic loci; see the explanation of DNA analysis in chapter 4) that form a complete DNA identification profile, only five pairs and partial indications of two or three more were visible on the electropherogram from the sample.
In DNA analysis, if two graphs show peaks located in distinctly different places, this absolutely precludes a match. But what often happens in the case of degraded DNA samples is that a graph showing only a few clear peaks is matched to a complete sample, and no differences are visible. In other words, every peak present in the degraded sample exactly matches a peak in the complete sample, but it is impossible to know if the missing peaks from the degraded sample would correspond or not. Still, the investigators took the partial DNA profile of Diana’s attacker and ran it through the system. They came up with exactly one candidate for a possible match: one person in the whole criminal database whose DNA graph showed peaks in the exact same positions as those of Diana’s murderer.
The match was John Puckett, a seventy-two-year-old man from the Bay Area. The reason his DNA profile was in the database was because some quarter of a century earlier he had been convicted on three counts of rape. These all occurred in 1977, and his method of operation had been quite similar in all three cases: he would approach women, pretending to be a police officer, threaten them with an ice pick or a knife, and force them to drive to an isolated area in Marin. There, as two of the women testified at his trial, he raped them; the third was compelled to perform oral sex. Puckett was convicted and sent to prison until 1985. After his release, apart from a misdemeanor battery charge in 1988, for which he was charged but not convicted, his record stayed clean. In 2003 he was living with his wife in a mobile home and was now an elderly, ill man in a wheelchair.
On October 12, 2003, San Francisco Police Department homicide inspectors Joseph Toomey and Holly Pera knocked on the door of Puckett’s home. He answered the door, clutching a urine bag in his hand—he had difficulty walking, having recently undergone triple-bypass surgery. The inspectors interrogated Puckett for over an hour. Puckett denied having ever met Diana, having had sex with her, or having been inside her house. He offered to provide Toomey with a fresh DNA sample; the offer was accepted and confirmed the match with the cold case sperm sample. At the time of the murder thirty-three years earlier, no one had connected John Puckett with the crime, and he had never been a suspect.
On the evidence of the DNA match, together with the corroborating facts that he had lived in the area at the time of Diana Sylvester’s killing and that he was old enough to have been able to commit it in 1972—but with no direct evidence of his involvement—Puckett was arrested and charged with murder. According to the officers who arrested him, he behaved “like a gentleman” when they took him away. He turned to his wife and said, simply, “I guess I won’t be seeing you anymore.”
Toomey interviewed Puckett again and searched his home for old pictures. One picture dated back to Christmas 1972, three days after Diana’s murder. The picture showed that at that time, Puckett was curly-headed, had a great deal of facial hair, and was significantly overweight. The similarity to Helen Nigodoff’s description (“white, medium height, heavy-set, chubby, curly brown hair, beard, mustache”) was plain. But Puckett continued to deny knowing anything about the crime.
AS WE saw in the Amanda Knox case (see chapter 4), difficulties with identifying DNA can arise when the samples are too small, when they are mixed samples from more than one person, or when they are degraded. When a degraded sample shows only a few clear peaks rather than the full set of 13 genetic pairs (loci) ordinarily used by forensic biologists, even a good match of the peaks that are present with the DNA of a given individual cannot be considered complete identification. Indeed, it is common for different members of the same family—and even perfect strangers—to share a few peaks. The California state law usually requires a minimum of 7 loci to even consider running a degraded sample through its database of offenders.
By studying large DNA databases, the FBI has calculated something called the random match probability (RMP), which measures the likelihood that two unrelated people have any given number of matching loci. For example, the probability of two strangers sharing 13 identical loci is given as about 1 in 400 trillion. Since the population of the world is only about 6 billion, it is considered a certainty that if two samples match at 13 loci, they must belong to the same person.
Each gene locus of the 13 pairs usually considered has a fixed probability called the random match probability—which has been measured precisely— of occurring in a specific position for any given individual. The RMP values differ somewhat from gene to gene, but the average is roughly about 1 in 13. In other words, any given configuration for 1 of the 13 genetic loci used for identification will be held by roughly 1 out of 13 people, or about 7.5% of the population.
Given the fact that the 13 gene loci are known to be statistically independent from one another, it is correct to multiply these probabilities together to estimate the proportion of people who will share several identical gene loci. For instance, the proportion of people having 2 given gene loci will be about (0.075)2, meaning about 1 in 177 people; the proportion of people having 3 specified loci is about (0.075)3, meaning 1 in about 2,370 people, and so on. For greater numbers of specified loci, the proportions become very small: 1 in 177 billion for 10, 1 in 2 trillion for 11, and 1 in 31 trillion for 12.
The RMP values for each gene pair calculated by the FBI are more sophisticated than this figure of 7.5% and therefore generate more precise probabilities, but the overall numbers are actually quite close to the estimates given here. For 9 loci, for example, the RMP is given as 1 in about 13 billion. This means that given a specific set of 9 pairs, we can expect to find about 1 person in 13 billion who will have those 9 pairs in exactly the specified locations. This published figure of 1/13,000,000,000 is very close to our estimation of (0.075)9.
These numbers are the product of well-documented science and were deemed indisputable—until one person began to question their correctness. When the task of participating in Puckett’s defense fell to Bicka Barlow, an attorney with a background in forensic genetics who worked for the San Francisco Public Defender’s Office, she sat up and took notice. Bicka had been worried for quite some time about how DNA evidence and the FBI’s RMP were being used to search databases for cold hits. She believed that this method was leading to the arrest of innocent people due to miscalculation of probabilities. When Puckett’s case landed on her desk, she saw an opportunity to investigate the problem in depth.
Bicka had been particularly struck by the research of an Arizona state employee named Kathryn Troyer who had carried out a major statistical study in 2001. Troyer ran a series of tests on a DNA database containing over 10,000 profiles. Given the 1 in 13 billion statistic, one might not expect to see any matches at 9 places in such a small sample. Yet Troyer did find one such pair of individuals in the database: two unrelated individuals who shared 9 identical genetic loci.
One example may not prove much, but as the years passed and the database increased, Troyer kept performing her tests again and again. In 2005, using over 65,000 profiles, she found 122 pairs with 9 matching loci and 20 pairs with 10 matching loci. This appeared to show that in spite of minuscule probabilities of such matches occurring in the general population, they actually do occur and not that infrequently.
In preparing John Puckett’s defense, Bicka pounced on the results of Troyer’s study. In her view these results could only mean one thing: the FBI’s RMP statistics must be wrong. If as many as 122 pairs could match at 9 loci in a sample of just 65,000 people, then what could that 1 in 13 billion statistic mean? “[So many] matching pairs at 9 loci is an incredible fact. . . . The State has information that they’re not providing to the defense that says that, in fact, their statistical analysis is wrong and it could be wrong by orders of magnitude. . . . I could have gotten a statistician to calculate a probability . . . it’s almost—it’s improbable.”
What Bicka Barlow was expressing was an intuition that while the RMP figures of 1 in 13 billion give the impression that 9-locus matches are incredibly rare, database experiments show that actually they are fairly common, and these two facts appear to contradict each other. In the appellant’s brief (the legal document preparing Puckett’s appeal), this seeming contradiction is noted more bluntly as one of the major grounds for appeal: “The trial court erroneously prevented appellant from challenging the prosecution’s statistical analysis by presenting evidence of matching pair studies to demonstrate that the probability of obtaining a false match was much higher than the Random Match Probability would suggest.”
Should we have “serious concerns as to the inculpatory force of the RMP statistics” as the appellant’s brief suggests? Are they reliable enough to provide evidence against anyone at all? How many innocent people have already been locked away behind bars by those frighteningly tiny probabilities?
THE ANSWER lies in a simple statistical calculation, correctly identified in the respondent’s brief (response by the State of California to the appeal) as nothing other than the famous “birthday problem.”
As a general matter, the Arizona results are merely an illustration of a well-known but seemingly paradoxical mathematical concept known as the “birthday problem.” The birthday problem asks, “What is the minimum number of people in a room for the odds to be better than 50% that at least two will share the same birthday, no matter what day it is?” This question assumes that the rarity of any particular birthday is 1 in 365 (i.e. its random match probability). The correct answer, although belying common sense, is a mere 23 people. In other words, pairs of relatively rare events are expected in relatively small databases, as long as one is not looking for a specific target event. The solution is based upon the fact that with only 23 people, 253 separate pairwise comparisons can be performed, making it likely that some birthdays will occur twice. A key point is that the question does not ask how many people would have to be in a room to expect to find a particular birthday represented (e.g. January 1). The rarity of any given, predetermined, event (e.g. a January 1 birthday, or a target DNA profile in the DNA database context) remains unchanged.
The respondent’s brief quotes Bicka’s remarks on the Arizona data during the trial: “If you are going to find two people that match at 9 loci in a database of 10,000, that says a lot about whether or not somebody else out there shares Mr. Puckett’s profile, and it flies in the face of the common sense understanding of what that random match probability means!” They correctly identify this remark as a typical birthday problem fallacy, confusing the possibility of a match between any two people in the database, which is reasonably large, and the possibility of a match with one particular DNA sample given beforehand, which is minuscule!
In their words: “Were the issue framed instead in terms of the birthday problem, defense counsel’s argument would seem to be that observing one or more pairs of birthdays when comparing everyone in a relatively small room says a lot about whether or not somebody else out there shares, for example, a March 5 target birthday.* This, of course, is false.”
The application of this reasoning to the problem of whether or not the Arizona database results contradict the FBI’s random match probability is not calculated explicitly, although the respondent’s brief expresses the right idea. The question we need to answer is the following: Given the FBI’s random match probability statistics, how many 9- (or 10-, 11-, 12-) locus matches would we expect to find, on average, in a database of 65,000 profiles?
What people forget when they see the “1 in 13 billion” figure is that what is being measured is not a number of individuals, but a number of pairs of matching individuals—and that in any population, the number of pairs is far higher than the number of individuals.
In a population of N people, there are N × (N – 1) / 2 pairs of people. When searching for a 9-locus match, every individual is tested against every other. Furthermore, there are 715 different ways to choose 9 loci out of the 13 usually considered by forensic geneticists, so that “a match at 9 loci” can mean a match at any one of these 715 choices of 9 loci.
In table 5.1, we consider the databases of sizes 10,000, 60,000, and 65,000 that Troyer studied. The number of tests for matches performed in each case is given by 715 × N × (N – 1) / 2, where N is the size of the database; indeed, each of the N × (N – 1) / 2 pairs of individuals is tested for a match at each of the 715 different choices of 9 loci among the 13. The number of matches predicted by the RMP is obtained by multiplying this total by the FBI’s predicted frequency of 1 in 13 billion. The final column shows the number of 9-locus pair matches that Troyer actually found.



From this table it appears clearly that the expected answers are close to the actual answers that Troyer found. There is, in fact, no contradiction with the 1 in 13 billion random match probability. There is only the “surprise” of realizing that the 1 in 13 billion figure refers to 1 in 13 billion pairs, and that the number of pairs is large for even quite a small population; indeed, there are already over 35 billion pairs in the smallest population of 10,000 individuals. This is exactly the principle behind the birthday problem: there are 253 pairs of people in a group of 23 people, and thus the chance of finding a common birthday is quite large—as we saw, greater than one in two.
What Bicka Barlow and Puckett’s defense team tried to argue is that the Arizona data shows that there are really a great many matches out there, many more than the RMP figures might lead one to believe. What they are ignoring is that these surprising numbers of matches occur when you search among all the pairs in a population for any possible match of any set of genetic loci whatsoever. This is entirely different from a cold-hit database trawl, in which one DNA sample is given at the start and you search through the database to find the same one. In this situation the probability of finding a match will be much lower, as is the case with the two different birthday problems explained above.
In conclusion, there is no contradiction at all between the Arizona database findings and the RMP statistics provided by the government. The suspicions raised by the defense here were unjustified and based on an intuition that, although natural and widespread, is faulty.
A SECOND, more complex problem emerged during the preparation of Puckett’s trial. The RMP for a match at the five and a half genetic loci visible in the sample from Diana’s murderer was calculated as 1 in 1.1 million. The defense challenged this figure by a second argument, this time not so much a challenge to the figure itself but to its meaning. The gist of the argument is this: the figure signifies that if you pick someone off the street, there’s 1 chance in 1.1 million that he or she will share the same five and a half genetic loci as Diana’s killer. If you search through a large database, this comes down to picking that many people and doing the comparison with each of them, so the chance of finding a “random match”—that is, an individual with the same genetic loci but who is not the source of the original DNA sample—is multiplied by the number of people in the database. In the case of the Puckett cold hit, the database consisted of 338,000 registered sex offenders from California.
A comparable example is the following. Consider a lottery with 1.1 million tickets. If you buy 1 lottery ticket, the probability that the winning number is on your ticket will be 1 in 1.1 million. But if you buy 2 tickets, your chance of winning will double, and if you buy 10 tickets, you’re multiplying your chance of success by 10. Thus in this lottery, buying 10 tickets would increase your chances to 10 in 1.1 million, or 1 in 110,000. If you buy 100 tickets, your chance of winning goes up to 1 in 11,000, and if you buy 1,000 tickets, your chance is now 1 in 1,100. What if you go so far as to buy 338,000 tickets? Then your chance of winning would be 338,000 in 1,100,000, which is equal to 338 in 1,100, or just a little under 1 in 3.
Now think of the criminal’s DNA sample as the winning number, and a random person from the population as a ticket that has a chance of 1 in 1.1 million of matching. The idea is that if instead of picking 1 random person, you pick 338,000 people, as in the lottery, your chance of finding a match would be just a little under 1 in 3.
Thus while the prosecution seemed to say that there was 1 chance in 1.1 million that Puckett could be someone other than the source of the DNA found on Diana’s body, the defense countered that since he was found by a database search of over 338,000 people, there was really about 1 chance in 3 that Puckett could be merely a “random match,” and thus innocent.
It’s very different to say that some event—Puckett being innocent and merely a random match to the criminal—has 1 chance in 1.1 million of occurring, or 1 chance in 3. In computing the latter probability, Bicka Barlow thought she had the means to make the Puckett trial into a showcase for her theory that cold hits carry a tremendous risk of sending innocent people to jail. In her opinion she had never seen a weaker case against a defendant in a murder trial; apart from the DNA there was no evidence whatsoever against the defendant other than a rough similarity with a thirty-year-old eyewitness description. Bicka was a fighter: her mother was a Holocaust survivor, and Bicka had spent part of her childhood attending the peace rallies that took place around Berkeley, perched on her father’s shoulders. Now she thought she had a prime case for victory in the battle against the conviction of innocent people by cold hits. But things didn’t work out quite as planned.
BEFORE THE trial even started, the judge decided that it would be too confusing to present the different and seemingly contradictory mathematical arguments in court. Not only did he exclude the use of the 1 in 3 probability figure, but he also ruled that the jury could not be informed that Puckett had been identified as a result of a cold hit from a DNA database. “I’m not inclined to change my opinion regarding what’s in and what is out, and so the database search for matches and partial matches, that experimental exercise or line of research, that is out,” he pronounced at the preliminary hearing.
Because of the judge’s decision, none of this information—which formed the backbone of the case that Bicka was preparing—was ever presented in court. One juror even sent a note to the judge asking just how Puckett had been identified as a suspect. He was told that the information wasn’t relevant. “I am instructing you not to guess,” the judge wrote in his response.
Instead the jury heard about the evidence collected from the crime scene, about Helen Nigodoff’s testimony, and about Puckett’s past convictions for assault and rape. They were told how when interrogated about Diana’s murder the defendant had responded, “I don’t remember this at all,” and how he had said the same thing nearly thirty years earlier when faced with the evidence of his other crimes. They learned that he had told the women he attacked that he wanted to “make love”—the same phrase the murderer used when he growled to Helen Nigodoff, “Go away, we’re making love.” They heard each of Puckett’s three earlier victims describe what he had done to her, and how his weapon had left scratches on her neck similar to those found on Diana’s dead body. And of course the jury heard about the random match probability of 1 in 1.1 million that Puckett and Diana’s murderer could share five and a half genetic loci by chance.
Deliberations began on February 14, 2008. It took nearly twenty hours, spread over several days, for the jury to reach a decision. During this time the jurors contacted the judge with a note: “We know that cold DNA cases were evaluated at some point. Given that the defendant had not yet provided his oral swab, how was he identified as a person of interest?” It seemed clear that the question could not be erased from the jury’s minds, and the court finally decided to stipulate that Puckett had been found as the result of a cold hit—only to be foiled by the defense, who protested that such important information should not be revealed to the jury without a complete explanation of its significance. The defense believed that without the proper explanations, the aura of scientific prestige surrounding the term “cold hit” would work against the defendant. Once again, the jury was told that the question was irrelevant and that they should refrain from guessing.
After these lengthy deliberations, they finally reached a verdict and declared John Puckett guilty of first-degree murder. On April 9, he was sentenced to life imprisonment. Declaring his innocence, he appealed the verdict the same day.
NATURALLY, THE main ground of appeal was the exclusion from the trial of any mention of the 1 in 3 chance of the match to Puckett having occurred purely by chance, calculated by Bicka Barlow. From the appellant’s brief:
What the jury did not know, and what the trial court believed the jury did not need to know, was that the real chance of a coincidental match in this case was 1 in 3. This number would have placed the prosecution’s case in an entirely different light. Absent statistical evidence to the contrary, the prosecutor was free to mislead the jury into believing that the odds that appellant just happened to have the same genetic profile as the perpetrator were much rarer: “The coincidences that the defense are going to have you believe in this case are beyond imagination, are beyond reasonable. In order to acquit this man, in order to find him not guilty, you’re going to have to look at all of the circumstances of this case, and say ‘You know what, he could have been the one in a million.’”
In the respondent’s brief to the appeal, the 1 in 3 figure looms large as well, but for the opposite reason. The respondent’s brief argued against the validity of the 1 in 3 figure, and the high chances of a jury’s accepting it as the probability that Puckett might be innocent of Diana’s murder. The brief explains that this understanding is wrong: “The 1 in 3 figure . . . does not come remotely close to conveying the probability that an innocent yet plausible suspect was coincidentally identified in the database search—the only probative question from the jury’s perspective.”
The basic argument given by the prosecution is that once the match was found, the fact that it corresponded, like the actual murderer, to a heavy-set white California sex offender old enough to have murdered someone in 1972 made it extremely likely that this was not merely a random match to a different person, but the right match.
In this case, the jury had to determine whether appellant was the perpetrator, or an innocent person who (1) coincidentally shared the perpetrator’s DNA profile, (2) coincidentally matched the perpetrator’s description, (3) coincidentally lived in and around San Francisco at the time of the crime, and (4) coincidentally committed a number of other violent sex crimes with factual similarities to the assault on Ms. Sylvester. To that end, the jury would have found evidence that the DNA database search produced a “hit” to a plausible but innocent suspect probative. But the “1 in 3” database match probability statistic would not have provided that evidence. It was not, therefore, relevant.
SO WHICH is it? A chance of 1 in 1.1 million of finding a purely coincidental match to a person other than the criminal, or a chance of 1 in 3? The key is to explain the meaning of these figures. Both of them make sense, but neither of them actually gives an estimation of the probability that Puckett is innocent of the crime; they are measuring something different.
The main thing to understand with the 1 in 1.1 million probability is that it has absolutely nothing to do with the chance that Puckett might be innocent. It is simply the probability that a random person has the same DNA as the criminal. Given the US population of about 310 million, this means that one can expect around 300 people around the country to share the same DNA configuration as the sperm sample taken from Diana’s body. A priori, then, using no other information about Puckett than his DNA sample, we can deduce that he belongs to a group of about 300 people, each of whom might be the criminal; thus the 1 in 1.1 million statistic translates into a chance of 299 in 300 that Puckett might be innocent. In terms of the measure of innocence, this is the only information yielded by the DNA statistics, and it is strongly in favor of innocence. The 1 in 1.1 million statistic should not be used alone and out of context, and certainly not as the chance of innocence, although this mistaken impression may have been given to the jury at Puckett’s first trial.
As for the 1 in 3 figure, what does it really measure? When calculating that the chance of 1 in 1.1 million of a person’s DNA matching the criminal’s must be multiplied by 338,000, the size of the database, for a total of 338,000/1,100,000, which is very close to 1 in 3, this calculation is merely finding the probability that there will be a match in the database to the criminal’s DNA sample—independently of whether the match really is the criminal or not. Yes, there is a chance of about 1 in 3 of finding a match in the database. But what about the next step? There was only a 1 in 3 chance of finding one, fine; but now one such match has actually been found, and the main question becomes, what is the probability that it is actually the right match—to the criminal—as opposed to a purely coincidental match to an innocent man? The answer to this question would indicate the chance of Puckett’s guilt or innocence, but this issue is entirely ignored by the 1 in 3 calculation. Like the 1 in 1.1 million, the 1 in 3 probability has a perfectly legitimate meaning—but it is certainly not the chance of Puckett’s innocence.
IN HIS article “Rounding up the usual suspects: a legal and logical analysis of DNA database trawling cases,” legal scholar David Kaye points out another problem with the 1 in 3 figure. He argues that the presence in the database of a large number of profiles belonging to people either too young to be Diana’s murderer or of the wrong ethnic group skews the calculation, since these profiles have no bearing on a search for the murderer. Kaye suggests paring down any database before beginning a trawl, and considering separately the profiles of the plausible suspects, those not excluded from suspicion for obvious reasons such as age. If the plausible suspects form, say, 5% or 10% of the database, and the cold hit found in the database is actually a plausible suspect, Kaye suggests, this fact considerably increases the probability that the hit is the right person rather than a purely coincidental match. This reasoning is close to the prosecution’s remarks above that argue that the traits shared by Puckett and the murderer (age, race, etc.)—precisely those traits that make him a plausible suspect—should play a role in determining the probability of his guilt or innocence.
If 1 in 1.1 million and 1 in 3 have nothing to do with the probability of Puckett’s innocence, then what is that probability? How can we turn the arguments above into a numerical estimation? The purpose of this exercise is not to give an actual mathematical proof; that would be impossible. But a correctly performed estimation is a powerful tool for grasping the nature of a situation. Even though our calculation is approximate, it gives a good idea of the numerical chance of innocence that remains after considering the traits that identify Puckett as a plausible suspect.
We will take the following approach. If Puckett is innocent, then two different people had the same DNA configuration: Puckett and the criminal. Using the reasoning concerning the 1 in 1.1 million figure above, we know that we can expect to find about 300 such people in the United States. These people are expected to be randomly distributed around the country, both by age and geography. Yet Puckett and the criminal share other important traits. They are both white, they were both in California, they are both male sex offenders in the real sense of the word (independently of having ever been caught, registered, or convicted), and they are both over sixty-five, which seems a reasonable minimum age for a person who committed murder in 1972.
To estimate the probability that a random individual in the United States belongs to the group of people sharing these traits with Puckett and the criminal, we begin with the probability of sharing DNA, which is 1 in 1.1 million, equivalent to a probability of about 0.0000009. White people constitute about 72% of the population in the United States, so a person is white with a probability of 0.72. The state of California represents about 12% of the population of the United States, so one is Californian with a probability of 0.12.
The number of registered sex offenders is about 400,000, but it is estimated that the true number is about double that, so let’s say 800,000 people. Of these, an estimated 96% are men, which brings us to about 768,000; thus, we estimate the probability of being a male sex offender in the United States as 768,000 in 310 million, or about 0.00247. Considering that people who have been sex offenders at any time in their lives form a group ranging roughly from ages twenty to eighty, those who are over sixty-five would account for a quarter, or 0.25 of this group, so the probability of being a male sex offender over sixty-five is about 0.00247 × 0.25 = 0.0006175.
We now have the following table of probabilities:
Probability that a random individual in the United States:
Has the right DNA type:
0.0000009
Is white:
0.72
Is from/in California:
0.12
Is a male sex offender over 65:
0.0006175
The probability of having all of these features, considered as independent of each other, is thus about 0.000000000048. Since the population of the United States is about 310 million, this means the probability that there exists some person in America having all these traits is equal to 310 million times 0.000000000048, or 0.01488, which is roughly equivalent to a chance of 1 in 70.*
At any rate, even though we now know that there is only about 1 chance in 70 that someone exists with all the above traits, we also know that one such person actually did or does exist—namely, Diana’s murderer. So the question becomes: what is the probability that a second such person could also exist? Indeed, if Puckett is innocent, he would be the second person— therefore this probability is really an estimation of his innocence.†
There is a precise theorem that can be applied to solve this problem: knowing that one person belongs to a particular group, what is the probability that a second person also belongs to the same group? Known as Bayes’ theorem, it is used quite frequently in legal situations. According to Bayes’ theorem, given two events, A and B, the formula for the probability of A knowing B is given by: prob(A given B) = prob(B given A) × prob(A) / prob(B). Here, A is the event “two people belong to the group,” and B is the event “one person belongs to the group.” Our question can be rephrased in mathematical language as: knowing B, what is the probability of A? We know that the probability of B is 1/70, and the probability of A is thus (1/70)2 = 1/4,900. As for the probability of B given A, that is equal to 1 (in other words, certainty), since if A is true (two people belong to the group), then B is certainly true (one person belongs to the group). So prob(B given A) = 1; prob(A) = 1/4,900; and prob(B) = 1/70; thus Bayes’ theorem tells us that prob(A given B) is equal to 1/70. In other words, in this situation the probability of a second person belonging to the group, knowing that one person already belongs, is exactly equal to the probability that one person belongs.
From these considerations, we conclude that there is at most a chance of about 1 in 70 that John Puckett could be a different person from the one who left the sperm sample at the murder scene. Unlike the figures discussed by the defense and the prosecution, this is a legitimate estimation, albeit an approximate one, of the chance of Puckett’s innocence.
John Puckett may be guilty or he may not; this book is not a tribunal. What is certain is that he must not be either convicted or acquitted based on a calculation of something quite different from the probability of his innocence. If mathematics is to play a role in his trial, it should—it must—be correct mathematics. Anything else is a travesty of justice.
 
*To calculate this, it is easiest to compute the opposite probability: that everyone in the room has a different birthday. For 2 people in the room, it is 364/365, as person 2 has 364 “free days” for his birthday (the ones that are not person 1’s birthday). For 3 people, this number has to be multiplied by 363/365, as person 3 now has 363 free days, and for 4 people, the number has to be multiplied by 362/365. Continuing this calculation on an ordinary calculator leads to the probability of just slightly under ½ for 23 people all having different birthdays, meaning just slightly over ½ for two or more of them to share.
*The date of Leila’s birthday—viz. the birthday coincidence problem.
*This date, explicitly given as an example in the brief, just happens to be Coralie’s birthday; like the coincidence of the date of the murder being Leila’s birthday, this illustrates the fact that birthday matches—like DNA matches—occur more frequently than one might intuitively suppose.
*It should be noted that we have treated race and being a male sex offender over sixty-five as independent here. With accurate statistics we may find that the proportion of whites among male sex offenders of any age is smaller than the proportion of whites in the general population, in which case the product 0.72 × 0.0006175 would have to be replaced by a smaller figure, which would have the effect of decreasing the 1 in 70 probability.
†It is actually slightly larger than the probability of his innocence, since it ignores the tiny possibility that two different people could belong to the group and yet Puckett be the murderer rather than the second person.

MATH ERROR NUMBER 6 »
SIMPSON’S PARADOX
The average SAT verbal test score in 2002 was precisely the same as it was in 1981. Yet each of the six major ethnic categories used by the College Board shows an increase in scores over that period of time: whites, 8 points; blacks, 19; Asians 27; Puerto Ricans 18; and American Indians, 8. How can it be, then, that all groups that make up the national average have gained but the national average score has not budged in 21 years?*
THIS PUZZLING FACT is a classic example of the phenomenon known as Simpson’s Paradox: over the last twenty years, the average score of every ethnic group of students on a standardized test administered every year has gone up—yet the overall average is identical to what it used to be. Table 6.1 shows the average test scores of each group in 1981 and in 2002, with the overall averages at the end. Every group has improved, yet the overall score is identical. How can that be?
The secret lies in the important role played by a factor not displayed in table 6.1. In the present case, that factor is the large-scale changes that occurred within the populations of the different ethnic groups with respect to one another. In particular, as table 6.2 shows, the size of all the minority groups increased significantly in proportion to the white population. This table shows the ethnic makeup of the test-taking populations in the two years under comparison.






What table 6.2 reveals is that while the white group has the highest average score on the test in both 1981 and 2002, in 2002 whites count for much less overall in the calculation of the average score. The lower scores of the other groups bring the average down, even while the increase in the average score of each group brings the average up. The overall result is: no change whatsoever.
Because of these invisible factors, Simpson’s Paradox can easily be manipulated to deceive. As an employee of a major gas company told a mathematician friend of ours, “I had to present the economic results of the company over the last year, so I asked them whether they wanted a presentation that makes it look like we earned money, or one that makes it look like we lost money.”
Simpson’s Paradox never fails to astonish whenever it shows up in reallife situations, and it serves as a constant reminder that conclusions drawn from statistics are a lot less clear-cut than we think.
 
 
The Berkeley Sex Bias Case: Discrimination Detection
It is one of the most prestigious universities on the planet. The Academic Ranking of World Universities has rated it third-best school in the world for years, squeezed in among Harvard, Stanford, and Britain’s Cambridge. Students dream of admittance; more than half of the applicants—not to mention the successful ones—have perfect grades in high school and stellar results on their standardized tests. The campus crawls with vigorous young people intent on success. And to top it off, the university is located in the historic town of Berkeley, the “third most politically liberal city in the United States,” one of the birthplaces of the 1960s hippie movement, and among the best places in America to sip a mocha latte while stretching one’s legs at an outdoor café. Lush gardens surround the elegant campus buildings, and long palm fronds wave overhead against a shimmering, flawlessly blue sky; to many, the University of California at Berkeley may seem like the Promised Land.



The University of California at Berkeley
But Berkeley is by no means a flawless institution. It has undergone periods of public criticism, and its high profile has ensured that the university has been widely covered in the press and deeply investigated within the school itself. One of the recurring problems the university has faced is allegations of sex bias: giving unfair advantage to men over women, both in student admittance and in faculty hiring.
JENNY HARRISON probably knows more about the consequences of this type of allegation than any other person alive. In 1975 she earned a PhD in mathematics from the United Kingdom’s University of Warwick. The research she published there was recognized by fellow mathematicians as being brilliant and quickly secured her prestigious postdoctoral positions at Princeton and then Berkeley, where she took up a tenure-track position in 1978. At that point in the young woman’s career, everything looked ripe with promise.
Jenny continued with her research at Berkeley, but she encountered a few problems along the way—her work was difficult to understand and aroused disagreement among her colleagues as to its correctness and its value. These disputes were eventually resolved sufficiently for her to publish a paper in 1986, eight years into her position. That was the same year when her case came up for a tenure decision by the department. Jenny felt confident going into the tenure review: her work was now going well, and several of her colleagues had already received tenure since she had first arrived there.
But she was in for a shock. The mathematics department, citing the standard of her work as not high enough for a permanent professor, denied her tenure. It was the first time in twenty years that the math department at the university had not granted tenure to one of its own.
JENNY HARRISON was immediately suspicious. She knew the other assistant professors who had been granted tenure since she had been at Berkeley, and she didn’t consider their work to be markedly superior to hers. Jenny became convinced that there was another cause—namely, that some influential members of the department objected to her because she was a woman. Indeed, a quick look at the department lent some weight to her claim. The tenured faculty in mathematics numbered only a single woman among its sixty-odd members.
With the support of a few department members who agreed with her, Jenny filed a complaint with the Privilege and Tenure Committee, a campus-wide group of professors who reviewed grievances regarding tenure cases. She alleged that her file had been unfairly judged and that the unfairness was due to gender bias. The committee looked into the situation and ultimately ruled against her. But Jenny felt she had not been given a fair chance to present her case. She had been denied access to the documents she would have needed to prove her point—most importantly, the files of other recently tenured department members. Even her own file had been partially withheld. In contrast, the university’s staff had had complete access to everything. It was simply not a level playing field.
So Jenny went to court. She filed a lawsuit against the University of California at Berkeley for gender discrimination. With this act, closely guarded secrets of the legendary mathematics department began trickling out into the open. One after another, professors involved in the dispute were questioned by lawyers. Hours and hours of such questioning produced hundreds of pages of documents, and details began to emerge.
One of the most commonly cited arguments against giving Jenny tenure was that there were other mathematicians “out there”—stars, Fields Medalists, etc.—whose work was more brilliant, more exciting, or more revolutionary than hers, and who could be offered tenured positions instead of her. Jenny countered that this wasn’t valid reasoning; otherwise it should be applied to every member of the department who came up for tenure, in which case almost no one would receive it. After all, there is practically always someone more brilliant out there. Being measured directly against the world’s very greatest mathematicians, she claimed, was a process that had been applied to her alone: the only woman candidate. The proper assessment would have been to compare her with other assistant professors of mathematics at Berkeley who had come up for tenure and to whom it had been granted. (It is notable, and may perhaps also be a sign of sex discrimination, that the only other female faculty member at Berkeley, who had been granted tenure in 1975, was considered significantly above this group in excellence.)
Between 1978, when Jenny first took up her position, and 1988, when the Privilege and Tenure Committee reviewed and rejected her grievance, there had been no fewer than eight other applications for tenure in the mathematics department, all of them successful. At first Jenny had not been allowed to see these other applicant files in order to publicly compare them with her own, but once the lawsuit was initiated, she was able to obtain a court order obliging the university to deliver them to her. Of course, no two mathematicians will ever agree completely about exactly whose work is more interesting or better than whose; to some extent it is a subjective matter. But according to at least some of her colleagues, the files indicated that Jenny sat squarely in the middle of the overall group; there was nothing in her file that made it significantly worse than those of the other tenure applicants. The comparison lent weight to her charge of gender discrimination.
Jenny also found more tangible traces of discrimination. She discovered, for example, that in sending out a letter requesting an opinion on her suitability for tenure, the department chairman had thought fit to add that the evaluator should keep in mind that Berkeley aspired to be “the top mathematical center in the world.” This phrase was used in soliciting opinions about Jenny, but it had not been used in the solicitation letters concerning any of the other candidates.
Rather than go to trial, the university finally agreed to a settlement with Jenny: a committee of reviewers from outside the university would be called in to judge the situation. As weeks dragged into months and months into years, however, one decision was made that worked in Jenny’s favor: the outside committee decided that it would consider not only her work from 1978 to her tenure rejection in 1986 but her subsequent work as well, and they would use it all as a basis to judge whether she was good enough to take her place among the other tenured professors at Berkeley. During the seven-year battle, Jenny bore and raised a child, overcame a bout of throat cancer, and produced enough new research so that when the decision finally came in 1993 it was in her favor. Jenny Harrison was awarded a financial payment (amount undisclosed), and above all she was finally appointed to a tenured position at Berkeley. The numbers have increased a bit since then; today, Harrison is one of four female full professors in the Berkeley math department, alongside about fifty men.
The final settlement was not to everyone’s liking. Loudest in their disapproval were the professors who had been accused of sex bias in denying Jenny tenure. Needless to say, no single individual ever admitted anything of the kind. It is a difficult accusation to prove—after all, who can penetrate into the mind of another and know what he or she is thinking? There were professors in the department who scoffed at the idea of sexism playing any role in their vote, and there were others who were more reflective on the matter. In the case of a male candidate, observed one of the latter, “there’s hardly ever an important split in the department,” but “if a woman is perceived as being ‘not world class,’” then “all these doubts come out” and she is treated differently from men with similar qualifications.



Jenny Harrison, professor of mathematics at Berkeley
But even if Jenny successfully proved that she had been treated differently from the other candidates, how could she possibly show that that difference was due to sex discrimination? After all, there could be any number of other factors at play that no one wanted to mention: incompatibilities, rivalries, jealousies, and just plain mathematical judgments, which must always contain an element of subjectivism. If no one ever admits to negative feelings about women, whether as mathematicians, colleagues, professors, students, or in general, then how can anyone ever hope to actually prove that those feelings exist?
The only way to prove or disprove such a claim, in fact, is to leave the individual case aside and focus on trends. If one can point to the existence of a regular, repeated pattern of behavior, then one may begin to gather elements of actual proof.
DURING THE course of the Jenny Harrison tenure battle, faculty members, both men and women, publicly opined on the matter. Professor Lenore Blum, who was not a faculty member at Berkeley but held the position of deputy director of the Mathematical Sciences Research Institute, the MSRI, located just up the hill from the university campus, stated quite emphatically that problems did exist. “Blanket denials that [the department] ever behaved badly towards women—or categorical statements that its actions have been exemplary—are just not true, nor are they widely believed outside Berkeley,” she said. And she went on to describe the university’s reaction to the pressure exercised on all American public institutions in the 1970s to make a special effort to recruit both women and minorities. Obeying the letter, if not the spirit, of the affirmative action trend, Berkeley issued an invitation for women and minorities to apply for two tenure-track positions that had opened in the department. But behind the scenes, “the Department had already offered the positions to two men,” claimed Blum. “This charade was clearly unfair to the women and minorities who applied in good faith and were subsequently subjected to an evaluation which necessarily had to unearth flaws in their records.” In other words, in order to reject all the candidates who had been so warmly invited to apply, the hiring committee had to search out bad things to say about them in order to explain the rejection. This didn’t exactly cast the university in the best light.
And Berkeley’s record with actual hiring is certainly no proof that sex discrimination did not exist. When Marina Ratner—the only female tenured faculty member in the department during the Harrison case—was first hired, a letter was printed in the campus newspaper written by a department member who stated that although Ratner was “well-qualified,” there were “several men who were better.” This attack seems gratuitous, coming as it did after the department had already voted to offer the woman a position. The goal appears to have been purely to denigrate her, with no practical purpose in mind. Of course, as above, it is open to doubt whether this sentiment was or was not driven by sexism; the author of the letter might have written exactly the same letter for a newly hired male with the same qualifications. Whatever the case, his assessment of Ratner was simply wrong. She went on to become one of Berkeley’s most famous mathematicians, proving astonishing theorems, winning major prizes, and being elected to the National Academy of Sciences. But Ratner herself does not view the letter as being motivated by sexism, adding that although she believes sexism does exist in the mathematical community, “it is mostly subconscious.”
This is possible, even probable. The men who examine the women’s applications and find things to denigrate, criticize, and belittle are probably not consciously aware of any motivation for doing so other than a lofty desire to make a correct judgment. They are undoubtedly acting in good faith, if not always with elegance. Certainly in Jenny Harrison’s case, the outside review committee who eventually recommended her appointment with tenure compared her file with those of the other tenured professors and found no significant difference in level. But that was several years after the first tenure review, and she had much more published work the second time around. Some in the department assert that her rejection in 1986 was a judgment based purely on mathematical considerations, while others claim that her mathematical level was already sufficient at that time and there were other causes. The conclusion is that in an individual case, it is virtually impossible to ascertain the precise causes of an event such as tenure rejection, and the precise role that sex discrimination might have played. The existence of sex discrimination cannot be detected by staring into the minds of individuals. It is necessary to step away from the personal stories, and consider the larger trends.
IT SO happened that shortly before Jenny Harrison first arrived at Berkeley, the university had been sued for bias against female applicants to graduate school. Indeed, a simple examination of the overall data showed that of the nearly 13,000 applications for doctoral spots at the university—broken down into about 8,500 men and 4,500 women—fully 44% of the men had been accepted, and only 35% of the women. The numbers are given in table 6.3.



If not sex bias—if all judgments about whom to accept had been made with total objectivity on the basis of the quality of the applicants—then one might conclude that the men sent in higher-quality applications than the women, or perhaps that men are better students in general. But all data strongly belie this assumption; women generally outperform men at the undergraduate level in the United States, so if anything their applications would have been stronger than the men’s. Why, then, were so few of them, relative to the male candidates, considered worthy of acceptance to the ivory tower?
When these results were published, it seemed to many that here, finally, was clear proof of the existence of sex discrimination at Berkeley.
TABLE 6.3 represents admissions only from the academic year 1973–1974. Before launching accusations, it is important to determine whether these numbers could represent a normal statistical fluctuation, something that might happen quite naturally once or twice over a significant period of time.
To make such a determination, we must calculate the chance of such numbers—44% versus 35%—happening naturally, under the assumption that there is no sex bias or inherent inequality in the applications, so that women and men have the same a priori chances of getting in. If this chance turns out to be, say, 1 in 20, we could conclude that once every twenty years or so the admissions figures can be expected to look like this, and so it may not really be a suspicious circumstance indicating the existence of bias.
The total number of applicants is 12,763, and the total number of admissions is 5,232, which is 41%. So under the hypothesis of complete equality, one would expect 41% of men and 41% of women to be admitted, or 3,461 men and 1,771 women.



From the figures in table 6.4 we see that in reality Berkeley accepted 277 more men and 277 fewer women than expected. The number that gives the probability of such a skewed result happening naturally in a pool where everyone has equal chances is called the p-value.* Under the assumption that men and women candidates are of equal level and stand an equal chance of being accepted, the p-value measures the probability that this particular distribution would occur over many (theoretical) years of admissions.
For a simple explanation of the meaning of the p-value, suppose you have a vat containing 8,442 black marbles and 4,321 white marbles (the number of male and female candidates), and without looking at their colors, you randomly select 3,738 + 1,494 = 5,232 marbles (the number of accepted students). The p-value is the probability that you will select at least 3,738 black marbles and at most 1,494 white ones. It is easy to run a simulation of the experiment millions of times on a computer, and there is also a theoretical formula for the p-value. Once calculated, it turns out that the p-value in the Berkeley case is extremely tiny, equal to 0.0000000057, or about 6 chances in a billion.
Generally, when the p-value for an occurrence is under 1 in 1,000, it is accepted that there is legitimate cause to ask whether the hypothesis of pure chance may be wrong and to investigate whether there is another cause. One has to leave room for the surprise factor, though, because very unlikely events (sometimes called “black swans”) do constantly occur in the world. The bottom line is that unlikeliness and rarity are legitimate grounds for suspicion but are not sufficient to draw any conclusions. All that can be said is that there are grounds for further analysis. And that, rightly, is the view that the University of California at Berkeley decided to adopt.
THE UNIVERSITY called together a committee of three to perform the investigation: a professor of statistics; a professor of anthropology, who was also dean of graduate studies; and one member of the data processing staff of the graduate division. The three committee members began by deciding that since admissions at Berkeley are decided department by department, independently of each other, it was possible that the cause of the inequality was due to a lack of evenhandedness in just a few departments rather than a single cause across all departments. Therefore, the committee requested a breakdown of admissions data by department, and began their review of the situation by exonerating those departments that either had not received any applications from women at all or had accepted all students who applied.
After this exercise, eighty-five departments remained under scrutiny. The committee examined their admissions statistics one by one, and in each case the p-value was calculated as above to see whether the fluctuations that occurred in the percentages of men and women being accepted were really out of line with numbers that might occur with a reasonable frequency in the absence of any bias. Most of the departments showed no unexpected gap in the percentages of men and women accepted from the applicant pool. In the end, the committee narrowed the departments under question to six. These were six large departments, each of them with numerous applicants. The admissions data of these six departments lumped together are given in table 6.5.



It would seem that the culprits had been correctly identified—nearly half the men had been accepted, and less than one-third of the women! The ratios were even worse than the 44% versus 35% of the university overall. Clearly, it would seem, these departments housed the university’s most misogynous minds, shunting Jill’s application into the wastebasket while placing Jack’s in the acceptance pile.
The investigators went further, deeming that the worst of the offenders should be identified, the finger correctly pointed, and the situation rectified. To this end, they made a table listing the acceptance figures for the six departments separately (table 6.6).



But to their surprise, this more detailed table didn’t give any indication of bias against women at all! Out of the six departments, four of them (A, B, D, and F) actually accepted higher proportions of women than of men, with department A even showing a marked preference for the female candidates, accepting 82% of all female applicants compared to only 62% of the males.
The remaining two departments, C and E, showed only a tiny edge for the male candidates: 37% of males versus 34% of females for department C, and 28% versus 24% for department E. Certainly nothing to raise an eyebrow at. Where did that elusive sex bias go? It seems to have melted away, and we are left with a paradox. No single department shows marked bias toward male candidates, with most actually giving an advantage to females. Yet the overall totals reveal that a far lower percentage of women than of men are accepted. How can that be?
THIS PROBLEM, which commonly occurs in statistics, is known as Simpson’s Paradox, and it arises through the act of forgetting, or ignoring, an important piece of relevant data. Here that piece of information is the following: what proportion of women and what proportion of men actually apply to the departments with the lowest (or highest) acceptance rates?
To show how tricky Simpson’s Paradox can be in real-life situations, let’s drastically simplify the problem and suppose that there are only two departments in the university, A and B. Suppose there were 1,000 candidates in all, 600 men and 400 women, and suppose that both departments actually have quite a strong bias in favor of the female candidates. But suppose also that acceptance rates at B are overall much lower than those at A—and that most of the women apply to B! Then we might have a table like table 6.7 on the next page.
This simplified situation reveals in a nutshell what was happening at Berkeley. Far from showing bias against women, department A accepts 90% of women compared to only 80% of men, and department B accepts 30% of women compared to only 20% of men. Yet the total acceptance rates show that 70% of men are accepted compared to only 45% of women!
It’s enough to make anyone suspicious, and yet the problem doesn’t even exist. Or at least there is a problem, but it is absolutely not about sex bias in the admissions process.
IN THE END, the skewed admissions data at Berkeley didn’t reveal any sex discrimination in the admissions process, but it did reveal another factor, something that was already well-known. So well-known, in fact, that it didn’t occur to anyone that it was actually causing the problem in acceptance figures namely, the fact that very few women apply to the Berkeley mathematics and engineering departments. Few apply, and even fewer are accepted, whether as students or as faculty. The two separate problems—the department’s record in rejecting women and the lack of women applicants—are actually closely related.



Why do so few girls choose to study math and engineering? That question has occupied many a student of society, and many different factors have been blamed, ranging from the psychology of the individual, to deeply rooted social attitudes, to differences of physiology and child-rearing methods. While no satisfactory answer has ever been given, it is generally accepted that one of the factors that discourage young women from studying mathematics is the perception of the subject as being male-dominated and competitive. This is a vicious circle, since the lack of women within mathematics departments really does perpetuate the male domination of the subject, making it a hard-to-breach fortress for female candidates. That fortress was precisely what Jenny Harrison had to face and vanquish. As it turned out, the whole question of sex discrimination at Berkeley was really a reflection of a much wider problem—the problem of gender and mathematics.
 
*From EDDRA, the Education Disinformation Detection and Reporting Agency.
*This p-value will play an important role in the Lucia de Berk case (see chapter 7).

MATH ERROR NUMBER 7 »
THE INCREDIBLE COINCIDENCE
SUPPOSE YOU BUY a lottery ticket. You wake up the next morning and are shocked to find out that you have the winning number. Certainly that is an event with a very low probability; yet at the same time, someone is certain to win the lottery, so that “coincidence” is sure to occur somewhere, for someone. The only difference between you and that other someone lies in your point of view. Statistically speaking, the two events—“I win” and “He wins”—are equally probable at the start.
On the one hand, we all know that for each lottery, some John Doe will win. But at the same time, when John Doe does win (especially if he happens to be you), you realize that the probability of that happening was extremely tiny. This may sound like a contradiction, but of course it isn’t. It’s merely an illusion arising from the fact that until John Doe won, you made no specific prediction concerning him, whereas when you bought your own ticket, you probably thought something along the lines of “I have one chance in a million of hitting the jackpot.”
Because of this, it can be misleading to retroactively calculate the probability of an event that has already occurred. If after performing such a calculation you find the probability of the event’s occurring to be extremely small, you might become suspicious and wonder if whatever it is that you observed happened as a result of scheming rather than chance.
In the event of a crime, such calculations can become slippery—one must take enormous care. While it might be legitimate to have suspicions, they might be the result of this kind of retroactive thinking—and when the police act on a suspicion, lives can be destroyed.
 
 
The Case of Lucia de Berk: Carer or Killer?
On the morning of September 4, 2001, at Juliana Children’s Hospital in The Hague, a baby died unexpectedly. Little Amber was almost six months old and had struggled since birth with a complicated condition involving anomalies of the heart, brain, lungs, and intestine. She was not able to eat on her own and had to be fed artificially. On July 25, she had had a heart operation that seemed to help, but after a month of improvement, Amber suddenly needed extra supplies of oxygen and diuretics on August 28, and her condition worsened. By September 3, Amber was suffering from vomiting and diarrhea and appeared to be in pain.
Two nurses were in charge of Amber’s care. One of them was Lucia de Berk, a forty-year-old licensed pediatric nurse from The Hague. At around 11:00 p.m. on September 3, Lucia decided to connect Amber to a monitor to keep close track of her heart rate and breathing difficulties. She also called for doctors to come and examine the baby, who seemed to be growing steadily worse. Amber was wheeled to the examining room, and two pediatricians examined her; the time of the examination was recorded as 1:00 a.m. on September 4. They put her on a drip and diagnosed her with enteritis, an inflammation of the small intestine, but they did not judge the child to be dangerously ill. After the examination, they sent Amber back to her room, where she was reconnected to her monitor by finger cuff.
At 2:46 a.m., little Amber went into crisis. To the horror of the two nurses in the room, the baby’s breathing frequency dropped suddenly and drastically, followed by a slowing of her heartbeat. Her face turned gray. They called for a doctor at once, and he immediately summoned the resuscitation team, but it was impossible to save the dying child. They spent forty-five minutes trying to revive her, but she was declared dead at 3:35 a.m. Her heart had actually stopped beating sometime earlier.
The doctors familiar with Amber’s situation did not find her death suspicious; they knew how ill she had been. But the doctors who were present that night were not the ones involved in her regular treatment. Nevertheless, they signed a declaration of natural death.
By the next afternoon, however, that declaration had been officially retracted by the hospital.
ON THE day after the death, a nurse at the hospital heard about the incident and went to talk to her superior. As she explained it, she was “worried that, during her 2 years at Juliana Children’s Hospital, Lucia had been present at five resuscitations.” It seemed to the nurse that this was a large number compared to the experiences of other nurses. Her superior agreed, and a rumor began to make the rounds: a list of the five resuscitations where Lucia de Berk had been present was soon circulating around the pediatric ward. Looking at it, the other nurses had to agree that it seemed to be too many to be attributable to simple coincidence. Worse, Lucia had been present at five patient deaths.
The categorization of Amber’s death was changed to “unnatural,” and after what must have been a heart-wrenching conference, the situation was brought to the attention of the general director of the hospital, Paul Smits. Smits was the director of two hospitals in The Hague: the Red Cross Hospital and Juliana Children’s Hospital. He had some expertise in making Microsoft Excel spreadsheets, and together with the chief pediatrician he proceeded to do a little computation of his own. Putting together all the information the nurses had brought him, he felt he ought to calculate an actual figure for the probability of Lucia being present at so many resuscitations and deaths. What he found disturbed him deeply. Even if his calculation was not exact, it seemed to him, as it had to the nurses, to indicate that “Lucia was involved in an extremely unlikely, high number of incidents.”
On the morning of September 5, the day after Amber’s death, the five other deaths at which Lucia had been present were all reclassified as “unnatural”; they had all been declared natural when they occurred. To collect the largest amount of data possible, Mr. Smits contacted his other hospital as well as the Leyenburg Hospital, where Lucia had previously worked, and asked for the list of deaths at which she had been present. When the lists arrived, they seemed to bear out his fears. The doctors, who were now very concerned, pushed him to take the affair as seriously as possible. Mr. Smits called the police and Lucia de Berk was formally accused of thirteen murders and four attempted murders.
A DIRECTOR of two hospitals beset with financial and organizational difficulties, Paul Smits attacked the problem as he did the innumerable problems that faced him each and every day: with authoritarian vigor. It was clearly a situation in which action had to be taken swiftly and efficiently. That meant not only removing Lucia as quickly as possible from the active nursing staff or handing the case over to the police, but also informing the media of what had occurred.
Smits took all the information from the three hospitals and turned it over to the police. He claimed that he did not give them his calculations or their results; those numbers simply influenced his decision to call them in. However, it is clear from records of the police interrogations of nurses in those first days that they were already working on probability figures.
Next, the board of directors of the hospital contacted the Netherlands’ most sensational newspaper, De Telegraaf. The article that soon appeared in De Telegraaf did not name Lucia, but it told the terrifying story of a nurse in two hospitals who had been involved in the killings of large numbers of patients. The newspaper transmitted the director’s sincere apologies, his sympathy with the families of the victims, and his desire to get to the bottom of each and every incident and to make sure that punishment was meted out where it was due. The article treated the deaths as murders, although they all had been declared natural deaths until it had been noticed that they happened on Lucia’s watch. To top it all off, the paper hinted that more murders would probably be surfacing soon as the investigation continued. Within a single day, that publication turned Lucia de Berk into the most horrific serial killer the Netherlands had ever seen.
Other papers picked up the story. Lucia was compared to Beverley Allitt, baptized “The Angel of Death” (see chapter 1); this epithet was even used in court. The probability figures that the police had already considered leaked to the papers, with figures such as “a single chance in seven billion” bandied about—a devastating number, given that there are only six billion people in the world. It goes without saying that no mathematical justification of that number was ever included in the articles where it appeared. By unstated consensus, numbers in newspapers carry their own justification, or at least their own prestige, along with them.



Lucia de Berk
It was not enough for Lucia to be banned from her job and her livelihood, and to be under suspicion of unspeakable crimes. She was painted as the most vicious creature that the public imagination could conceive of—a slaughterer of babies and elderly people, a destroyer of the weak, a vile monster. She had no way to defend herself other than to repeatedly declare her innocence.
On December 13, 2001, Lucia de Berk was arrested and charged with thirteen murders and four attempted murders. Even though it cannot have come as a surprise, she was stunned, stating that she had no knowledge of any of the acts attributed to her. She was remanded in custody while awaiting trial.
LUCIA’S FIRST trial began several months after her arrest. It emerged almost immediately that there were a few peculiarities about the accusations leveled against her. To start with, it was soon proven by her lawyers that there were two deaths on the list contained in the accusation at which Lucia had not been present at all. Either she had signed out and left the hospital before they occurred, or she had been out sick at a time that normally would have been her shift. There was also a case or two in which the death was so obviously expected and natural that they could not reasonably form the basis of any accusation of wrongdoing. Those cases, however, were quietly dropped from the trial. No one tried to calculate the differences they made to the damning “probabilities.”
Next, it was set forth by Lucia’s lawyers that not a single one of the deaths, or even the nonfatal incidents included in the list of accusations, had been observed to be in any way unnatural when it occurred. They emphasized the peculiarity of the situation: until the day when someone noticed that Lucia was present at a surprisingly large number of these events, there had been no grounds for suspicion of anything, of any kind, at all. In response, the prosecution argued that Lucia must have covered her tracks extremely well.
Finally, and this was perhaps the most difficult point, even once the deaths had been accepted as murders, there was no medical evidence to justify that claim. No traces of poison or violence could be found in or on the bodies that had been exhumed for the purpose,* and the medical witnesses called to the stand found it hard to show why they believed the deaths were due to murder at all. It was not as though such a situation was legally unknown—it had already occurred for the mothers accused of crib death, for example—but it was still uncomfortable. The prosecution made an extra effort to locate evidence of murder, sending for repeated medical analysis every bit of the physical remains of the long-dead victims that they could lay hands on.
In the case of little Amber, a jar in the hospital storehouse contained gauzes soaked with diluted bloody fluid from her body taken at the time of her autopsy. Laboratory tests run on this fluid produced evidence of a small but lethal concentration of a drug called digoxin. The doctors claimed there should have been no trace of digoxin in Amber’s body, because even though she had been given the drug during the first four months of her short life, the treatment had been stopped two months before her death and all traces would have been expelled by then.
Evidence was presented at the trial that Lucia had a key to the hospital cupboard where the digoxin was kept. In the absence of any further confirmation of the poisoning, another suspicious fact was revealed. Hospital records showed that about an hour and a half before Amber died—about the time lapse it would take for a digoxin injection to kill her—the baby had been disconnected from her monitor for a period of about twenty minutes. These two facts—the key and the disconnection—were cited as Lucia’s means and opportunity to murder Amber.
The prosecution managed to unearth some evidence indicating a possibility of poisoning in a second case: that of a boy named Achmad, a very sick child who had died at Juliana Children’s Hospital several months before Amber. On January 25, 2001, Achmad had gone into a coma from an overdose of chloral hydrate. The medicine had been prescribed by the neurologist for him in rather large quantities in case of restlessness, but once Lucia had been accused of murder, it became easy to conclude that she had deliberately administered an overdose. Thus means and opportunity were once again present. Achmad’s coma was one of the nonfatal incidents of which Lucia was accused. His death a month later, due to an error in his medicine, was one of the accusations of murder.
Achmad underwent a gastroscopy, for which he was given anesthesia on the morning of February 23. That same evening, he was prescribed two sedatives: dipiperon and oxazepam. The doctor who prescribed these had not intended him to receive a large dose of chloral hydrate as well, but as no one removed it from the ward dossier, it was given to him in addition to the other medicines. Although Lucia had already left for the night when the poor child succumbed to the combined effects of serious illness, the shock of operation, and the effects of overmedication, it was assumed that she had administered the medicine before leaving. After consultation with the coroner, Achmad’s death was declared natural. But in hindsight, it seemed only too easy to assume that Lucia had deliberately increased the dose of chloral hydrate—already large for his size, age, and condition—to an overdose inducing death.
Of all the other murders attributed to Lucia, not a single one could be attributed specifically to any drug. Thus, the cases of Amber and Achmad became known as locomotive cases, meaning that if it could be proven that Lucia had committed these two murders, then it could be inferred that she must also have committed the others, dragged along behind the locomotives like the wagons of a train. This is known as juridical chain evidence.
The theory, such as it was, made at least some sense, but there was a disturbing lack of medical proof. Investigators began to hunt for other types of evidence, clues that could reveal what was behind Lucia’s behavior. For this purpose, they seized her private diary and found a suspicious and frightening entry for November 27, 1997. There, Lucia had written: “Today, I gave in to my compulsion.”
It so happened that November 27, 1997, coincided with the death of a Mrs. Zonneveld, an elderly patient of Lucia’s in the terminal stage of cancer. The prosecution called Mrs. Zonneveld’s surgeon as a witness. Of course he had certified the woman’s death as natural when it occurred, but after the trial, he stated in a letter to the court that he had been rather surprised when she died, as he had expected her to live a few days longer.
When interrogated about her “compulsion,” Lucia explained that she was referring to her addiction to reading tarot cards for her friends and family, as well as for her patients—a practice strongly frowned upon in hospitals. Lucia owned a pack of tarot cards, which she kept carefully wrapped in a traditional wooden box, and her psychologist stated that her tendency to resort to the cards for insight, and to yield to that tendency as a compulsion, corresponded to her personality. But the idea was laughed out of court. It was all too trivial. It was so much more meaningful to assume that Lucia had yielded to an unspeakable compulsion to murder her dying patients.
Digging for dirt into her past, the investigators discovered a brief involvement in prostitution at the age of seventeen, when Lucia had been living in Canada. They also learned that once in the Netherlands, she had falsified a Canadian school diploma in order to enter nursing school. She had no morals, it was concluded; she was a liar and a cheat. Little by little a picture of a murderer was building up. It hung together—yet almost none of it constituted real proof.
The real clinching factor, the one that had convinced the hospital’s director in the first place, was not Amber’s death, or Achmad’s, or even the completely unexpected resuscitation of a little boy named Achraf on September 1,* which was later recognized by many as the first real moment when they realized that something seemed to be wrong with Lucia. Nor was it a matter of diary entries or youthful misbehavior. Instead, it was the statistical analysis that finally persuaded Smits: the table that he and the doctors had made showing the proportion of deaths and dangerous incidents that had occurred during Lucia’s shifts.
As the trial developed, this table became the most damning item: the one thing people could not dismiss by saying it was either irrelevant, unimportant, or not proven. But to make proper use of the table, it was not enough to show the raw numbers to the jury, or to give them the intuitive calculations that Smits had made with the help of the doctors now pushing for Lucia’s arrest. The conclusions of a professional statistician were required. To calculate the real probability that the numbers in the tables could indicate murder was a task that should have been entrusted to an expert.
IT WAS unfortunate, then, that the main expert witness the court chose to call to analyze the table of numbers was actually a law professor with an undergraduate degree in statistics. The Netherlands is home to any number of internationally renowned professors in mathematical statistics, but the expert called to the trial was Henk Elffers, a professor of law and psychology specializing in the psychology of compliance and spatial crime analysis. Elffers used the knowledge he had gained as a young student to attack the particularly difficult problem of decoding the meaning of the information contained in Smits’ murder table. He took the table of deaths and serious incidents given to him by the hospital doctors, used it to make his computation, and gave the result to the court. Elffers’ conclusion: there was one chance in 342 million that Lucia could coincidentally have been present at so many natural deaths.
Although neither the table nor the computation was fully correct, as we shall see, nevertheless, when one considers the evidence, it is not hard to understand why Paul Smits became suspicious and why Henk Elffers believed it indicated guilt with virtual certainty. During the nine months that Lucia worked at Juliana Children’s Hospital, 1,029 different nursing shifts had taken place, and she was present on 142 of them. Eight of the incidents during Lucia’s shifts that the hospital had reclassified as “unnatural” occurred during this nine-month period. The data collected by the doctors and nurses at the Juliana hospital is given in table 7.1.



Admittedly, the numbers are striking, even worrisome. There is no doubt that Lucia was present at far more near-lethal incidents than one might expect of a random distribution of nursing shifts.
Fortunately, statistical analysis exists in order to give a precise mathematical estimate of the likelihood that such a thing might happen naturally. Certainly the incidence of so many deaths occurring during Lucia’s shifts does not seem likely, but it is not enough to simply say so. One has to do the mathematical calculation in order to decide whether it is so unlikely as to virtually rule out its happening by coincidence, or whether it is simply at the margin of reasonable probability—a combination of events that, although rare, can still be expected to occur now and then in every country.
Indeed, if we imagine making a list of all the thousands of nurses in a country, together with the number of deaths at which each one was present, then there will be at least one unfortunate nurse who will find herself at the extreme end of that list, with an unusually large number of deaths compared to the others. But surely we are not going to arrest her! The purpose of the calculation is to quantify the difference between a nurse’s being in this position—at the extreme end of a natural curve—and her being far beyond the edge of the natural curve, a likely murderer.
To make sense of the computation, however, requires an experienced and careful statistician, which Henk Elffers was not. What Elffers did was to apply a standard statistical test called “Fisher’s exact test” on the figures presented in table 7.1. This test yields the p-value, a number between 0 and 1 that tells you the probability that a set of numbers has of being an absolutely random distribution with no outside influence. For instance, a p-value of 0.05 or greater means the situation lies within the range of events that occur more than 95 percent of the time. If the p-value is less than 0.05, this means the event one is considering lies in the marginal set of events that occur less than 5 percent of the time. A p-value of 0.01 means the combination of events being considered occurs about 1 time in 100. As we already saw in the p-value discussion in the Berkeley admissions case (see chapter 6), a p-value of under 0.001, less than 1 in 1,000, is accepted as small enough to raise suspicions about the naturalness of the event under consideration, but not sufficient to conclude that there is definitely something wrong.
When Elffers performed Fisher’s test on Lucia’s table for the Juliana Children’s Hospital, it yielded a tiny p-value of 0.000000110572, or less than 1 in 9,000,000. This p-value of 0.000000110572 would indicate that the table of shifts and deaths concerning Lucia’s work at Juliana Children’s Hospital corresponds to a combination of events that would occur only once in about 9,000,000 cases of a nurse working at a hospital over a nine-month period. Since there were 27 nurses at the hospital, Elffers multiplied this p-value by 27 to obtain the chance that such a combination could occur within the hospital, obtaining a result of 0.0000029854, about 1 in 350,000. Definitely an event rare enough to provoke worry in a country that contains only about 250,000 nurses in total.
Elffers’ next step was to apply the same test on the data for the two wards at the Red Cross Hospital where Lucia had also worked. There, he used the following tables. For the first table (table 7.2a), which showed that Lucia had worked roughly a quarter of all shifts and been present at roughly a quarter of all incidents, he calculated a p-value of 0.07155922, so about 1 in 14, making this table appear well within the bounds of normalcy.
The second table (table 7.2b) shows that during the nine-month period under investigation, 5 patients died, and 366 nursing shifts were worked. During that period Lucia worked just a single shift, and during that one shift a patient died. No special probability test is necessary to see that under the assumption that shifts and deaths were randomly distributed, the probability of this happening is about 5/366, 0.0136, or about 1 in 73.
When the three p-values of 0.0000029854, 0.071559, and 0.0136 are multiplied together, the product is close to 1 in 342 million. In a letter to the Guardian of April 10, 2010, Henk Elffers denies having multiplied the values together in this manner. However, a memo authored by him and dated May 29, 2002, gives the above calculation in detail. Furthermore, the argument Elffers gave in court indicated that this multiplication should be carried out; indeed, it was performed by the prosecution and quoted to the judge, and it was cited in every European newspaper covering the case. The figure was interpreted to mean that there was a single chance in 342 million that such a distribution of deaths and shifts could occur naturally. Since 342 million is many times the number of nurses on the planet, that meant that this distribution was not likely ever to occur naturally at all. But it had occurred—therefore, the conclusion that Elffers drew was that it simply could not have been natural.



Elffers explained to the court that conceivably other, non-malicious factors might have caused the strangely skewed results. He suggested five possibilities: (1) perhaps Lucia was a particularly incapable nurse; (2) perhaps she was systematically assigned to the patients with the worst health; (3) perhaps she was given or chose special shifts with respect to those of her colleagues, for example the night shifts, during which the majority of patients die; (4) perhaps there was some other person who was also present at every single one of the suspicious incidents; and finally, (5) perhaps someone was trying to frame Lucia.
But Lucia rejected all of these suggestions in her testimony. Without meaning to incriminate herself, but simply telling the truth, she testified that she was a good nurse and that difficult shifts and patients were shared equally among all the nurses. No one else had been present at all the deaths. She did not think anyone was trying to frame her. She believed that what had happened was simply a matter of chance, in spite of the numbers. But her belief was contested by expert witness Elffers. Turning to the judge, he stated: “Your honor, it was not chance. The rest is up to you.”
During the trial, Lucia de Berk was treated by the press like a monster. Her denial of all wrongdoing and her refusal to confess made her seem even guiltier, and she became a focal point of loathing for an entire country. The revelation that she had worked as a call girl in Canada for a couple of years was just more grist for the media mill. She was accused of all kinds of things, from arson, to stealing books from the hospital library, to selecting mainly Arab children as her victims in the belief that the Islamic parents would object to autopsies. Even the drawings of court proceedings published in the newspapers showed a witch-like figure with no resemblance to the real woman.



Newspaper sketch of Lucia in court
On March 24, 2003, the court in The Hague sentenced Lucia to life imprisonment for four murders and three attempted murders. Her defense team had succeeded in having the original list of accusations reduced from seventeen to seven—they had actually shown that she had not even been present for several of them. But it wasn’t good enough.
LUCIA APPEALED the verdict, and the case was retried at the High Court of the Hague in June 2004. The prosecution amassed a string of new evidence on the various cases, providing what was considered to be incontrovertible proof of the murders of Amber and Achmad. They also presented, with great fanfare, the testimony of a fellow detainee of Lucia’s who asserted that one day during exercises in the prison yard, he had heard her say that she had “released these 13 people from their suffering.” Interrogated in the courtroom, however, the man admitted that he had invented the entire story.
On June 18, 2004, Lucia was now found guilty of seven murders and three attempted murders—four new murders had been attributed to her on appeal, while only three of the four original murders for which she had been convicted in the first degree were among the new seven. Indeed, Lucia’s defense had succeeded in finding information proving that in the original list there was yet another case at which Lucia had not actually even been at the hospital, but was absent on holiday leave. After this discovery, that particular death quietly disappeared from the list; no one asked any longer whether it had been natural or unnatural. But neither did anyone recalculate the p-values of the updated tables.
The set of deaths that were qualified as murders kept changing according to whether or not Lucia was known to have been present. This already should have been a red flag: it wasn’t merely a matter of who had murdered the patients at this point, but whether they had been murdered at all. In essence, if Lucia had not been on shift, deaths were considered natural, but if she had been present, they were murders—the status of each death seemed to hinge on whether or not Lucia had been present. The whole affair was turning into quicksand.
In its judgment the court explained that it was considering only the cases of Amber and Achmad as murders that absolutely could be proven by medical evidence. But it relied on the “chain-link” hypothesis: if two cases were murders, then the others must be as well. As for the statistics, the court stated firmly that despite appearances, “a statistical probability calculation played no part in the conviction.” The evidence they considered, they insisted, was entirely medical. And they had any number of medical doctors on the stand, explaining exactly why they believed that the deaths were unnatural—explanations all the more necessary for those doctors who had originally certified the deaths as natural. They changed their minds, and in the end their statements convinced the court.
On appeal Lucia was given one of the harshest possible sentences in the Netherlands: life imprisonment together with coerced psychiatric treatment, in spite of the fact that the psychiatrist who had followed her for six months during her imprisonment found no evidence of mental illness at all.
Three days after the judgment, a new report on the contents of the swabs containing Amber’s diluted blood arrived from a laboratory in Strasbourg with state-of-the-art techniques for detecting proportions of digoxin. Since the trial was over, the report was shelved, but it was taken out and submitted as new evidence when, Lucia having appealed again, the case came before the supreme court of the Netherlands. The document was not examined by the court, however, which ruled on March 14, 2006, that life imprisonment and coerced psychiatric treatment could not be combined. The case went back to the Amsterdam court of appeals to be judged again on the basis of the same facts as before. The court upheld the guilty verdict for the seven murders and three attempts.
After hearing this verdict destroy her last chance at freedom, Lucia suffered a stroke. She lay paralyzed in her cell for ten hours before finally being transported to the penitentiary hospital; having never seen her ill previously, the prison guards and nurses believed she was putting on a hysterical act. After this lengthy delay in treatment, Lucia lost the power of speech and all motion on the right side of her body. There was nowhere left for her case to go; she had no more hope.
LUCIA DE BERK would likely have spent the rest of her life in prison if it had not been for a group of siblings who became deeply involved in her case. Geriatrician Metta Derksen de Noo was the sister-in-law of Arda Derksen, the chief pediatrician at Juliana Children’s Hospital who had made the first list of suspicious incidents at which Lucia had been present for the hospital’s director, the list that he took directly to the prosecutor. Arda had subsequently overseen the internal hospital investigation that preceded the report of murders and attempted murders to the police. Like Paul Smits, she also tried to work out the statistical probability of the deaths during Lucia’s shifts having occurred by pure chance; she was aided in this endeavor by a theoretical computer scientist from Amsterdam, who was also a member of her family. Later, Arda was also helpful to the prosecutor. She had been suspicious of Lucia even before Amber’s death, due to the “unexpected” resuscitation of one of her own patients. Once the hospital was full of gossip about Lucia, Arda’s suspicions had become stronger than ever.
Yet during Lucia’s trial, Arda suffered from some health problems that made her unable to testify. Her behavior increased the suspicions of her husband’s sister, Metta de Noo, that something might be wrong with the case to which Arda was devoting so much attention.
In the winter of 2004, after Lucia’s first conviction but before her appeal, Metta began to investigate all of the medical records of the case—all the records concerning the supposed deaths of patients at Lucia’s hands and the transcripts from her trial. She was shocked to realize that many of the medical diagnoses she was seeing appeared unconvincing, even insincere; in fact, she could not point to one solid piece of evidence that indicated murder at all. Disturbed by Arda’s problems and upset by these circumstances, Metta intensified her investigations, wrote innumerable letters, and repeatedly visited lawyers and doctors about the case—with no results. In November 2005, she began consulting with Lucia’s lawyer, and later she became personally acquainted with Lucia in prison, created a website devoted to the case, founded the Committee for Lucia de B. in her support, and got her own husband, her mother, and two of her brothers involved in Lucia’s defense.
Although Metta found little support during the first year or two of her efforts, she gained a powerful ally when she finally persuaded her brother Ton to champion the cause. Ton Derksen, a professor at the Faculty of Philosophy of the Radboud University in Nijmegen, was able to get the ear of authorities such as the public prosecutor, who had remained deaf to Metta’s demands. The detailed investigation that Metta had started into all of the medical, personal, and statistical evidence culminated in a remarkable book authored by her brother Ton, Lucia de B.: Reconstruction of a Judicial Error, as well as more recent books by both Metta and Lucia herself.
Although none of these books have yet been translated into English, a translation of part of Ton’s book can be found on the Internet; it contains a full-fledged crime investigation performed in extreme detail. Much of the work it contains calls the skill of Lucia’s lawyers into question as, even while working for her in good faith, they missed several important pieces of information, and like the prosecution, they relied on mathematical expert witnesses who were not professional statisticians and thus not fully equipped to refute the testimony of Elffers and his colleagues.
In his book, Derksen examines the case of Amber, the main locomotive case used to convict Lucia, and shows that the proof of her murder reconstructed by the court included two major factual errors. The first concerned the time at which the court concluded that Lucia had administered the drug to the baby. On September 3, Amber had appeared unwell to the nurse, as she was needing increasing levels of oxygen to help her breathe. At 11:00 that night, Lucia had connected Amber by finger cuff to a monitor to help follow her oxygen saturation levels, and at a time that she recalled as being “about 1:00 a.m.,” she called for a pediatrician to come and examine the sick child. So Amber was disconnected from her monitor and wheeled into a special room. Two doctors examined Amber at a time noted in the register as 1:00 a.m. According to their testimony, the examination lasted “about 20 minutes,” after which they concluded that the child was not seriously ill and sent her back to her room, where she was reconnected once again to the monitor. The graph from the monitor does indeed indicate an interruption at around 1:00 a.m., but it is a short one, corresponding to a period of five to ten minutes rather than the twenty to twenty-five minutes it would have taken for Amber to be examined, counting the transport from her room to the examination room and back.
Amber’s crisis began at 2:46 a.m. with two nurses in the room. The resuscitation team was summoned and did all they could, but she died a short time later.
A person dies sixty to ninety minutes after an overdose of digoxin, so the court considered the printout from Amber’s monitor from 1:15 a.m. to 2:45 a.m., and they found a lengthy interruption of monitor activity lasting from about 1:20 a.m. to 1:48 a.m. This, the court judged, must correspond to the murder time: Lucia must have turned off the monitor and introduced the poison into the intravenous tube that had been placed on the baby at her examination. Her conviction for Amber’s murder was based on this conclusion together with the presence of traces of digoxin found in the child’s body.
But Derksen points out that the medical examination could not have taken place at 1:00. The interruption was too short: there simply would not have been enough time. He attributes the brief interruption to the fact that the nurse was probably cleaning or changing Amber, who was suffering from acute digestive difficulties. A careful inspection of the monitor graph indicates that only the interruption from 1:20 to 1:48 is long enough to correspond to the doctor’s examination: Derksen concludes that this examination must have begun around 1:20 rather than the imprecise 1:00 noted down in the register. There was nothing unusual in this; indeed, Derksen also observed that every one of the times noted in the register was either on the hour or on the half hour; it was not usual to write down the exact time to the minute. The doctor’s estimation of the hour of their examination was simply off; it must have taken place at 1:20 rather than 1:00 a.m.
This, together with the known delay in effect of digoxin, would imply that Lucia must have poisoned the baby during the medical examination. She could not have done it later, since the monitor graph shows continuous activity from 1:48 until the end of Amber’s life. Nor could she have done it before, as death would then have occurred earlier than it did. As Derksen pointed out, it is virtually impossible to pinpoint a time when the murder could have actually taken place.
The second major error in the court’s proof of Amber’s murder was the medical evidence of digoxin poisoning. To show that no such poisoning had occurred, Derksen used the report from the Strasbourg laboratory that had been rejected by the supreme court.
The difficulty with measuring digoxin concentrations is the presence of DLIS, Digoxin Like Immunoreactive Substances, which can occur naturally in the body, in particular in the bodies of infants. The two medical tests whose results were used by the court were not able to distinguish between digoxin and DLIS; they detected concentrations of 22 and 25 milligrams per liter of digoxin in Amber’s blood, contrasting with an expected level of 1–2 milligrams per liter. However, digoxin concentration increases after death—almost any concentration will increase with evaporation of liquid—and it is considered that a finding of 1–7 milligrams per liter indicates an absence of any poisoning.
This very concentration, 7 milligrams per liter, was exactly the result found by the Strasbourg laboratory, which used the only known method capable of distinguishing between digoxin and DLIS. This information had been ignored by the Dutch supreme court, along with several other medical findings from Amber’s autopsy, such as non-contraction of the heart, which indicated that she had not died from digoxin poisoning at all.
Amber’s short life was tragic enough. But she was not murdered.
WITH THE main locomotive case destroyed, the case for the other murders was greatly weakened. Yet a major question remained: why was Lucia present at such an unrealistically large number of deaths? The result of Elffers’ calculation shows that it is virtually unthinkable that such an event could happen by chance, as Lucia claimed. Smits’ calculation, confirmed by Elffers’ p-value, was the basis of the original suspicions against her. How could it be explained?
Fortunately for Lucia, a battery of professional statisticians—including Professors Richard Gill and Peter Grunwald of Leiden University—joined Metta de Noo and Ton Derksen in their battle for the rectification of injustice. On closer examination, these professors concluded that the statistical analysis methods used by Henk Elffers, although convincing at first sight, were in fact inaccurate and not correctly applied to the case. One of the most glaring errors is the multiplication of the p-values (which Elffers denies having done, but the result of which reached both the court and the newspapers).
Although p-values can be multiplied under certain circumstances, such as the total independence of the events whose p-values are being measured, they cannot and should not be multiplied as a general rule. A simple example illustrates why multiplying p-values can give a drastically wrong result.
Imagine a situation similar to Lucia’s, but simplified. Suppose that nurse N, while not a bad nurse, is a little more careless or perhaps less trained than most other nurses and makes occasional mistakes in her treatment of patients. Every nurse probably makes such mistakes from time to time, and the large majority of these are not harmful. There are about 250,000 nurses in the Netherlands; let’s suppose that without doing anything drastically bad, nurse N sits squarely in the middle of the group of 1,000 nurses who make the most errors. If you make a table containing all the errors made by N in the hospital where she works, you will find a p-value of 1/250, meaning that N belongs to the group of 1,000 nurses who make the most errors among the 250,000. Since this p-value is greater than 1/1,000, it is above the level accepted as giving rise to legitimate suspicion.
Now suppose that nurse N works in two hospitals. Given the kind of nurse she is, if two separate p-values are calculated in the two hospitals, both will probably be close to 1/250, and both will point to the same fact: that nurse N has some problems with accuracy. But what happens if you multiply them? Suddenly you get a p-value of 1/62,500, meaning that N must be one of the very worst nurses in the country, with a p-value that may legitimately arouse suspicion as to her acts.
Yet clearly the fact of working in two different hospitals should not change anything in the calculation of nurse N’s p-value, since obviously she is the same nurse in both hospitals. The reason for the error is that her relatively poor performances in the two hospitals do not constitute independent events, since both stem from the same underlying cause, which may be inattentiveness or poor training. This is why it is wrong to multiply the p-values: in this case, that operation does not reflect reality.
Lucia denied that she was in any way the cause of any of the lethal or near-lethal events at which she had been present. She attributed the number of deaths in her presence to absolute random chance, and if she was right, then multiplying the p-values would not have been an error. So one may ask whether she, like nurse N, may have been a nurse whose performance was within the bounds of normality but still under average—in which case the p-values should not have been multiplied, and thus the statistic most indicative of her guilt would be invalid—or whether she was in fact right, and the defect in Henk Elffers’ calculation was something different.
Over the course of his investigation, Ton Derksen made an interesting discovery: there was, indeed, another serious flaw in the calculation made in court. It wasn’t in multiplying the p-values, it wasn’t even in any of the mathematical operations; it was something more fundamental: the compilation of the actual tables. Elffers appears never to have double-checked them, but Derksen dug into the actual making of these tables.
The hospital claimed to have first made a list of suspicious incidents and then proceeded to check whether Lucia had been present—only to find that she had been there for all of them! This sounds like a simple procedure with a damning result, but it is in fact misleading. The ambiguity lies in how the incidents were classed as “suspicious.” Since no one had suspected anything when each incident occurred, they were termed “suspicious” only in hindsight. But a list of some nine or ten incidents at which Lucia had been present was circulated on the day following Amber’s death, so—as Derksen asked—how is it possible to believe that the list of “suspicious” incidents was made without any knowledge of her presence?
The real question is whether there were any suspicious incidents that occurred when Lucia was not present, incidents that, like those on the list, were not considered suspicious at the time but had similar features. If there were any such incidents that had not been included in the original list, this could change the table and have a considerable effect on the p-value.
It was not an easy question to answer, since none of the events had been found suspicious at the time, but as Derksen searched through the hospital records, he did find a few striking things. Consider, for example, the case of the child Kemal, who underwent three resuscitations and a coma from an overdose of chloral hydrate. Two of the resuscitations found their way onto Smits’ famous list, whereas the third was left out. Why was this? Derksen could find no differences in the circumstances surrounding the three resuscitations, except for one: Lucia was not present at the third one, and that one was absent from the list. As for Kemal’s coma, it was closely related in type and in cause to Achmad’s coma, which was also the result of an overdose of chloral hydrate. But Kemal’s coma was not classified as suspicious. That is, Lucia had not been there. Derksen went on to discover two further incidents that were exactly as suspicious as those on the list but had taken place in Lucia’s absence.






Recall the table compiled by the investigators at Juliana Children’s Hospital and presented at her first trial (table 7.3 above). We can correct this data by removing the two incidents that were discovered to have occurred outside her shifts and subsequently removed from consideration at her trial, and then adding the two incidents above concerning Kemal as well as two others discovered by Derksen. The new table looks like table 7.4.
Applying the same method as before (Fisher’s test) to table 7.4 yields a p-value of about 1 in 1,230. This is a far cry from the p-value of 1 in 9,000,000 corresponding to the first table! A figure of 1 in 1,230 is, as we have said, sufficiently small to arouse some suspicion, but here, given the number of nurses in the Netherlands, it is really not so unusual. It simply means that out of some 250,000 nurses, one could expect a couple of hundred to be involved in a set of circumstances similar to those of Lucia. And indeed other nurses did come forward with their own stories: a letter to the newspaper written by a nurse in support of Lucia’s situation mentioned that during her student years she herself was present at thirty deaths, whereas a fellow student of hers was not present at any.
ON THE basis of his discoveries, Ton Derksen submitted a request to a committee, the Buruma Committee, to decide whether Lucia’s case should be referred to a special body called the Committee for the Evaluation of Closed Criminal Cases. No defendant is allowed to submit such a request; it must emanate from someone external to the case.
The Buruma Committee recommended further investigation, and by October 2006 a panel of three was appointed to conduct research into the situation from scratch. Above all, they were asked to focus on certain aspects of the case—namely, to determine:
•Whether the statistical evidence was supported and complete.
•Whether the question of digoxin poisoning had been fully resolved.
•Whether the only unexplained deaths at the hospital were truly all under Lucia’s supervision, or whether other deaths had been put aside on the basis that they did not involve her.
The Grimbergen Report, named for one of its authors, was released in October 2007 after ten months of work. It contains a sort of apology for the length of time it took to put it together; the three researchers had wanted to do the best possible job, but at the same time they were well aware that Lucia was spending those months in jail in a state of increasingly poor health.
In the report, they note some of the major errors in the initial investigation: the fact that after Amber’s death, Lucia was considered a suspect—the only suspect—almost immediately, and the fact that this led to a conscious choice on the part of the investigators to focus the investigation on the ward where she worked during the period she worked there. In fact, Lucia had been suspected of wrongdoing even before the death of Amber. She was aware of this suspicion and had wondered whether perhaps Amber had been entrusted to her care as some kind of test. This focus on Lucia’s guilt led the police to miss or not take account of simple observations of major importance. For example, in the ward of Juliana Children’s Hospital where Lucia worked, during the period she worked there, there were six patient deaths, whereas in the period of equal length before she arrived, there had been seven! Accusing Lucia was tantamount to assuming that the number of deaths had actually dropped once an active serial killer arrived on the scene. It was such a simple remark, yet it had had no influence at her trial.*
The report also investigated the additional resuscitation incidents at the hospital that Ton Derksen had unearthed, as well as the Strasbourg report about the measurement of digoxin in Amber’s blood. The researchers concluded that not only had the prosecution seriously erred in concluding that the child had been poisoned, but that the defense, too, had erred in accepting that conclusion. The report stated that there seemed to be no indication at all that Amber had died from digoxin poisoning. One of the world experts on digoxin, Professor Gideon Koren from the University of Toronto, wrote a letter after having examined the evidence in detail, and his conclusion speaks for the report: “I’m of the opinion that every attempt to interpret the post mortem level as proof of poisoning (inadvertently or on purpose) is incorrect and, in all honesty, quite shocking. The idea that a professional in health care could be imprisoned because of such an incorrect interpretation would be absolutely unacceptable.”
The Grimbergen Report recommended that public prosecutors initiate a request for judicial review of Lucia’s case. A petition was immediately handed to the Dutch minister of justice asking for Lucia’s detention to be temporarily suspended during the revision of the case, but this request was refused. The petition appeared the following day as a full-page newspaper advertisement.



Lucia de Berk, a free woman
On January 5, 2008, a “Light for Lucia” torch procession was held at the prison where she was incarcerated, and a month later a new play called Lucy, a Monster Trial premiered in Amsterdam. The supertanker of media coverage and public opinion was slowly, hulkingly, beginning to turn around.
Lucia appealed the decision to refuse her liberty, and on April 2, 2008, the minister of justice granted her a temporary suspension of sentence for three months, on the basis that the proof of Amber’s murder had melted into thin air. Although still partially paralyzed by her stroke, Lucia was able to walk out of Nieuwersluis prison. It was her first day of freedom in more than six years.
Events followed with the excruciating slowness typical of the workings of justice, but each successive step led closer to the final truth. In June, the Dutch supreme court was officially requested to reopen the case; in October, it accepted and began by ordering a set of entirely fresh medical investigations, not for Amber but for other cases—in particular, Achmad, the other “locomotive,” and Achraf, the child whose sudden need for resuscitation had been so unexpected. Fourteen months later, in December 2009, the court accepted the testimony of the new medical witnesses to the effect that the deaths now appeared to be entirely natural. The trial was adjourned a final time, to March 17, 2010, the day that Lucia herself was interrogated for the last time. At the close of the trial, the public prosecution itself, in what must surely be a historic gesture, requested the court to acquit her.
On April 14, 2010, the court delivered its final verdict of not guilty. In doing so, it reversed a miscarriage of justice that devastated lives and reputations from that of the justice system of the Netherlands, in the eyes of the people and the international community, to that of a humble woman who had only ever wanted to be a nurse, and who had been a good and cherished one until her world came crashing down around her.
 
*It was said by many that Lucia had purposely chosen Islamic patients as her victims knowing that the parents would not accept autopsy or exhumation of the bodies. After two years, however, many of these families ended up legally obliged to accept them in spite of their religious beliefs.
*One-and-a-half-year-old Achraf had been admitted to the hospital as a “social case”; his mother was worried about his apnea, but he was not perceived as seriously ill. No one realized for some time that the child was suffering from a severe hereditary illness, Freeman Sheldon syndrome, with abnormalities of the heart and lungs. The necessity for his resuscitation took doctors by surprise and was an important catalyst in starting the accusations against Lucia.
*The report also showed that Arda Derksen, chief pediatrician at Juliana Children’s Hospital, was the contact person at the hospital for the investigation by the public prosecutor. The medical records were all confidential, but she communicated their contents to the prosecution via summaries.

MATH ERROR NUMBER 8 »
UNDERESTIMATION
An ancient Indian legend tells the story of a dravida vellalar who invented the game of chess. The sultan was so delighted by the game that he offered the inventor any gift he might wish. The vellalar asked to receive grains of wheat, counted using the 64 squares of the chess board, by placing one grain on the first square, two grains on the second square, four grains on the third square, eight grains on the fourth square, and so on, doubling the number of grains for each square. The sultan, slightly offended at the measly nature of the gift, accepted, and ordered his treasurer to count and hand over the wheat.
Several days passed and no wheat was forthcoming, so the sultan called for his treasurer and asked what the problem was. The treasurer told him that the amount of wheat required would form a heap incomparably greater than the highest mountain on Earth.
Vexed, the sultan called for the inventor and told him that his wheat was ready, and he should go and count every single grain before taking it away.
THE REASON FOR the sultan’s error in this story is a widespread lack of intuition concerning the speed of exponential growth. The rational, commonsense part of our brains is accustomed to observing a small portion of something and then extending that image to form a mental picture of the whole. In the case of the chessboard, the sultan probably thought something like: 1 grain, 2 grains, 4 grains, 8 grains, 16 grains, 32 grains, 64 grains, 128 grains, 256 grains . . . Why, this poor beggar will barely get enough for one dinner!
Our daily habits of working with relatively small amounts, small distances, and small sizes create a sort of mental block against gigantic numbers. Our lack of experience prevents us from having the kind of realistic, familiar understanding of their meaning that we have for the numbers that measure quantities we frequently encounter. We build our mental pictures around what we are used to, and this can lead to great surprises when dealing with things or quantities that are extremely large.
Here is another example of this sort of error: a problem whose answer astonishes even professional mathematicians.
Assume that the world is a perfect sphere and wrap a wire tightly around the equator. Now take a second wire that is exactly one meter longer than the first one, and wrap that around the equator as well. Because this wire is longer, it will be slightly loose, a bit up off the ground all the way around. But how high will it actually be? Can you slip a razor blade underneath?
Before calculating anything or looking at the answer below, make a picture of this situation in your head. You’re standing on the ground, and the first wire is tightly running along the equator at your feet. The longer wire, with a meter added in, runs along the equator too, but just a little bit off the ground, since it’s just a bit longer. Mentally look at your feet. See the wire near your toes? How loose is it now? How high off the ground? How much difference did one little meter make compared to the whole equator of the earth?
Here’s the answer: the second wire is almost 16 centimeters off the ground, all the way around the earth. Not only razor blades, but a row of rabbits, can fit underneath it from Ecuador to Malaysia and back around the other way.*
This answer is incredible to our minds; it seems to us that one meter is so tiny compared to the circumference of the earth that it should make essentially no difference at all to the height of the wire. In fact, we are seriously underestimating the true “looseness” that occurs. The reason for this is that the circumference of the world is too large for us to intuit and to compare correctly with a small dimension like a meter. We think of 16 centimeters as being “much too big,” although in fact it is minuscule compared to the earth’s radius.
Getting back to the chessboard story above, let’s take a look at the numbers. After the sultan has finished counting off the grains corresponding to half the chessboard, 32 squares, he is already up to 4,294,967,295 grains of wheat, weighing maybe 100,000 kilograms. That much wheat can fill up enough boxes to stock the shelves of a thousand supermarkets, and it is certainly already well over what the sultan had thought he was bargaining for. After 64 squares, there would be 18,446,744,073,709,551,616 grains, nearly 500 billion metric tons, which is comparable to the mass of a large mountain.
The important point here is to recognize an exponential growth pattern, or any growth pattern that doubles (or triples or whatever) at regular intervals. Such a growth pattern starts out relatively slowly, and then accelerates with frightening speed. For instance, be wary of participating in e-mail chain letters in which you are incited to send ten copies to your friends on pain of some curse falling on your head. If everyone who received the letter followed the instruction, the letter would end up spamming more than the population of the world in ten reiterations, clogging the world’s bandwidth with unspeakable amounts of virtual clutter.
The case we are about to describe is a story of people who got fooled because they did not realize the implications of the incredible rapidity of exponential growth.
 
 
The Case of Charles Ponzi: American Dream, American Scheme
It was in the cold month of November 1903 that twenty-one-year-old Carlo Ponzi arrived in Boston, Massachusetts. He had sailed from Italy, which was nothing unusual, for Italy at the turn of the century was one of the most massive sources of emigration to the New World, whether to Canada, the United States, or South America. The only thing that differentiated Ponzi from the majority of the other immigrants was the fact that he had a university degree, from the University of Rome, La Sapienza. However, not unlike many university students today, Carlo had discovered soon after graduating that a degree earned by dint of assiduous frequentation of bars and gambling halls did not easily lead to a situation of gainful employment. Not that a situation of mere gainful employment held much charm for Carlo. He was a man of ambition, and a mere salary did not attract him. If he left for America, it was because he meant to realize the American dream.
He brought a little money with him but was fond of telling the story of how he gambled it all away on board, so that on disembarking, he had only $2.50 in his pocket—“but $1,000,000 in hopes!” One of his first acts upon settling in the United States was to change his name from Carlo to Charles; he then set about looking for a job. But the reality of his situation soon hit: penniless and speaking broken English, Ponzi could find no other work than waiting on tables and washing dishes. A first, cheap attempt to earn extra money by shortchanging customers got him fired.
In the year 1907, the United States went through a sudden economic crash known as the “panic of 1907” (the same crisis during which Wall Street financier Hetty Green, whose story is told in the following chapter, loaned more than a million dollars to the city of New York). The New York Stock Exchange fell 50 percent from its peak the year before, and the images that we associate with the 1929 depression—financial institutions falling into bankruptcy like dominos, crowds of people assailing the banks in a desperate bid to get their money out—were familiar sights in 1907.
The crisis of 1907 was finally stabilized thanks to the intervention of a single figure: J. P. Morgan. Considered a hero at the time, Morgan later came under heavy criticism for his excessive role in the financial life of the United States. A committee was formed to investigate his “money trust,” and Morgan was called in for questioning. The resulting dialogue went down in the annals of financial history:
COMMITTEE QUESTIONER: Is not commercial credit based primarily on money or property?
J. P. MORGAN: No, sir. The first thing is character.
COMMITTEE QUESTIONER: Before money or property?
J. P. MORGAN: Before money or anything else. Money cannot buy it . . . a man I do not trust could not get money from me on all the bonds in Christendom.
Charles Ponzi might have been listening in, so well did he learn the lesson imparted by Morgan.
THE FINANCIAL situation in the United States in 1907 made it impossible for Ponzi to find work, and he decided to venture north to Canada. He landed in Montreal, where he contacted an Italian immigrant, Luigi Zarossi, who ran a successful cigar business on the rue Saint-Jacques. Introducing himself as Carlo Bianchi from a nonexistent (but wealthy) Italian family, Ponzi was befriended by Zarossi, who offered him a low-level job as assistant bank teller at Banca Zarossi, the bank he had founded to service the growing ranks of Italian immigrants who were arriving in the city.
Thanks to some impressive real estate deals, Banca Zarossi was able to offer its clients 6 percent interest, more than double the going rate at the time. Ponzi developed a close friendship with Zarossi and his family, and rose to the position of bank manager. It was there that he learned his first major lesson in finance. The bank was growing so rapidly that Zarossi’s real estate holdings were not sufficient to pay out the 6 percent interest rate, and Ponzi discovered that Zarossi was using the money from new clients to pay it out instead. This meant that in case of a rush on the bank, Zarossi would be unable to refund money to his clients. When rumors about the situation began to spread and it became clear that Banca Zarossi was on the point of collapse, Zarossi stole all the remaining money and fled to Mexico, leaving his wife and children behind.
Ponzi moved in with Zarossi’s abandoned family and made a sincere attempt to help them, but between their complete lack of money and the anger of the cheated clients, the situation was catastrophic. He went for help to the offices of a business called Canadian Warehousing, which had been one of Banca Zarossi’s clients, but found no one there. Seeing a checkbook behind the desk, Ponzi seized the opportunity to write himself a check for the authentic-sounding if large sum of $423.58 (about $10,000 in today’s dollars). He signed the check with the name of one of the directors of the company and cashed it.
Unfortunately, however, although Ponzi had not been charged with any crime in the collapse of Banca Zarossi, his doubtful position and penniless situation were well-known to Ponzi’s neighbors, who alerted police when they saw him suddenly spending large amounts of money in the days that followed. He didn’t try to hide it: as the police officers walked toward him, Ponzi famously held out his wrists and simply said, “I’m guilty.” He was sentenced to a three-year prison term at Montreal’s St.-Vincent-de-Paul Penitentiary. Released after twenty months for good behavior, Ponzi decided to return to the United States and “start afresh.”
IF “STARTING AFRESH” meant seeking more opportunities to get rich quick, then it can be said that Ponzi made great efforts. Ten days after his arrival in the United States on July 30, 1910, he was arrested again, this time for participating in a plan to smuggle illegal Italian immigrants over the border. During the two years that he now spent in prison in Atlanta—probably a welcome change from Montreal, particularly in the wintertime—Ponzi, like others before and after, learned a remarkable amount about the art of criminal technique. He became friends with Ignazio Saietta, a Sicilian mafia mobster jailed for counterfeiting money (after dozens of murders), and Charles Morse, a powerful New York businessman, whose efforts to corner the stock of the United Copper Company had been one of the major causes of the economic panic of 1907. Morse was used to a life of wealth and ease; he knew his way around money, and on top of that he succeeded in fooling a panel of army doctors into declaring that he was so ill that if he did not immediately receive a presidential pardon to allow him to go abroad for treatment, he would die. But Ponzi knew the truth: Morse had ingested a drink of soapsuds before the doctors examined him. Soap is toxic and will produce symptoms of poisoning, but the toxins are generally reasonably harmless and soon pass out of the system. Morse left prison and took himself off to a German spa for “treatment.” He left behind him a friend with a head full of new and interesting ideas.
Once out of prison, Ponzi moved slowly back north, following the jobs that he could find. He eventually landed a clerking position in Boston, and that is where he met and courted a charming petite Italian-American woman from a modest background, Rose Gnecco. Ponzi was now nearly thirty-five, and Rose was impressed by his sophistication and experience. Not that he told her the truth about his past—that was not one of his most noticeable habits—but Ponzi’s mother, having learned of her son’s relationship and feeling that the young girl ought to be warned, took it upon herself to write Rose a letter describing the main points of her son’s hitherto unimpressive career. Rose did not care, or if she did, she did not change her plans, and the couple married in February 1918.
After his marriage, Ponzi’s first job was to run his father-in-law’s grocery shop, but this did not last long, although it was no fault of his: the business had already been on the brink of failure. Anyway, groceries were not his style; Ponzi wanted to make money fast, and he decided to start his own business. After some thought, he came up with the idea of an international trade journal, with profits to be made through advertising. Alas, his bank, the Hanover Trust Company, to which he applied for a two-thousand-dollar loan to cover his starting costs, rejected his application (with some prescience, it would seem), and the proposed journal, which had already been announced in various venues, came to nothing.
WHILE PONDERING his next move, Ponzi received a letter from a business correspondent in Spain who wanted to learn more about the nonexistent but much advertised journal. In order to facilitate a response, the Spanish businessman had included an international reply coupon (IRC) in his letter. The sight of it caused a stir in Ponzi’s mind. This coupon was a way for the Spaniard to pay for Ponzi’s return postage even though, being in Spain, he could not actually purchase an American stamp. It was an international system organized by treaty; the coupon could be bought for a few centavos in a Spanish post office and redeemed against a five-cent US postal stamp. The thing was, as Ponzi noticed, the Spanish purchase price was fixed, while the value of the Spanish currency against the dollar, like that of all other European countries, had fallen sharply in the aftermath of World War I. Ponzi saw an opportunity for what is known as arbitrage, taking advantage of a situation where the buying and selling prices of the same item are different for whatever reason.
Ponzi reasoned that the same opportunity would work in Italy, where he could obtain the help of members of his family. Converting $1.00 to Italian lire at the going rate of exchange would suffice for his family to purchase sixty-six IRCs* and send them over to Ponzi in large packages, where he would use them to buy five-cent stamps. In this way, he calculated, $1.00 would yield $3.30. Even subtracting commissions to family members and the cost of transporting the packages, it was still a tremendous profit!
Ponzi set up a company, the Old Colony Foreign Exchange Company, with offices on School Street in Boston. Its stated purpose was to organize the purchase and delivery of thousands of IRCs in Europe and exchange them for American stamps. The plan seemed flawless; the only trouble was capital. So he set out to find investors. And that is when Ponzi discovered his true talent, the one that would earn him millions.
IN ORDER to convince investors to put money in your company, you need three things: a convincing plan, a promising payoff, and above all—if one heeds the luminous words of J. P. Morgan quoted earlier—a personality that inspires trust. Charles Ponzi, perhaps one of the least trustworthy people the human race has ever produced, was able to inspire trust. His plan was infallible and legal. The promise he offered his first investors was unheard of: 50 percent interest in forty-five days, or 100 percent in ninety days. In effect, he was promising to double investments every ninety days. As for the trust, well, it seems that Ponzi could convince anyone of anything. After the first few investors got their money back with the promised profits, Ponzi’s doorbell never stopped ringing.



Charles Ponzi at the height of his success
By April 1920, only three months into his scheme, Ponzi and his wife were living the kind of life they had only dreamed of. He bought expensive jewels for her, gold-topped canes for himself, and two cars. And his fortune kept growing. In May, he purchased a luxurious mansion in the bankers’ part of the historic town of Lexington, near Boston, and a custom-built, chauffeur-driven limousine.
And still the investors continued to fork over their money. What they didn’t know, what nobody knew except Ponzi, is that he had stopped even thinking about buying IRCs. At the beginning, to be sure, he had had his family buying them in Italy and sending them to him in packets. But he found that redeeming huge numbers of IRCs in local post offices was difficult. The postal agents became suspicious of him and refused to give him the cash he demanded. Soon he was visited by government agents who informed him that any attempt to speculate on government-issued IRCs would be illegal. That was the end of that idea, although he never mentioned this incident to the investors.
By June, he had realized another of his dreams: vengeance. By buying a massive number of shares, he took control of the Hanover Trust Company, the very bank that had refused him a modest loan for his trade journal project the previous year. Never one to give up, Ponzi continued to pay interest to his investors with the huge flow of incoming money from new investors, all while telling himself that this reshuffling of money was merely a temporary ploy to tide himself over while he set up some serious investments. The new bank fell under the latter category; he also bought a meatpacking plant and real estate. But none of these ventures was anywhere near profitable enough to provide him with an interest rate of 100 percent every ninety days. So Ponzi kept on being Ponzi, handing money from new investors to pay the interest to the old ones. And that new money kept on rolling in.
By July, the scenes that met his eye as he pulled up at the office in his limousine each morning defied the imagination. He described them later in his autobiography:
A huge line of investors, four abreast, stretched from the City Hall Annex, through City Hall Avenue and School Street, to the entrance of the Niles Building, up stairways, along the corridors . . . all the way to my office! . . .
Hope and greed could be read in everybody’s countenance. Guessed from the wads of money nervously clutched and waved by thousands of outstretched fists! Madness, money madness, the worst kind of madness, was reflected in everybody’s eyes! . . .
To the crowd there assembled, I was the realization of their dreams. . . . The “wizard” who could turn a pauper into a millionaire overnight!
If Ponzi managed to remain beloved even while the millions were coming in, it is because he always remained the modest and simple man he had been from the start: the true embodiment of a rags-to-riches fairy tale. At the peak of his triumph, in an interview with the New York Times, he described his story in the following terms.
As I say, I landed in this country with $2.50 in cash and $1,000,000 in hopes, and those hopes never left me. I was always dreaming of the day I would get enough money on which I could make more money, because it is a cinch no man is going to make money unless he has got money to start on.
I saved a bit of money from the odd jobs and had the time of my life for a couple of weeks. Then my cash was gone. So into the big town of New York I went to find a job. Up at one of the big hotels they needed some waiters, and they even furnished me with the tuxedo service coat. Yep, I’ve carried tons of food on the old waiter, and with the small salary and tips I made enough to live. I went from one waiting job to another, worked in various hotels, small restaurants, and did my dish washing stunt from necessity at times. I got tired of New York and began to travel, getting jobs all along the way.
It was small jobs, and small jobs, up to the year 1917, when I headed for Boston. Once more, saw an advertisement in a Boston newspaper, answered it, and took a job with J. R. Poole, the merchandise broker. My salary was $25 a week.
And then I found my inspiration. She was Rose Gnecco, daughter of a wholesale fruit merchant of Boston, and the fairest and most wonderful woman in the world. All I have done is because of Rose. She is not only my right arm, but my heart as well. We were married in February 1918.
—New York Times, July 29, 1920
He comes across as a charming fellow, humorous, down-to-earth, friendly, and familiar with the struggles and difficulties of ordinary people. Of course, the reality differs significantly from the tale he told, but no one knew that. They wanted the American Dream, and Ponzi gave it to them. With his popularity and style, no one resented Ponzi’s twelve-room mansion, his heated swimming pool, his limousine, his wife’s diamonds. He truly made people feel that he deserved it all, and more—that they, too, could reach those heights of wealth if they just followed his Pied Piper call.
SUPPOSE NOW that you were an investor, wondering whether to invest in Ponzi’s scheme. Back then our advice to you might have been: get in it as early as you can—wait just long enough to see if the very first wave of investors makes their promised profit. Get in early, and get out early. Take your earnings and run. In the twenty-first century, though, our advice would be more along the lines of: don’t touch it with a ten-foot pole. Nowadays even successful investors in a Ponzi scheme are liable to lose more money than they earned, once the lawsuits start raining down. Why? Because any simplified model of Ponzi’s scheme (more scam than scheme) shows that it is going to blow up, and pretty quickly. In 1920 no one should have been taken in; yet in 2010, people were still duped by such ploys, because the power of the dream is so strong. Only now, everyone suffers the consequences.
The first piece of advice we would give to someone considering an investment that promises astonishingly high rates of interest is to do a little calculation before making any decisions at all.
1) Money-Based Model
To make a simplified model of Ponzi’s scheme, we will assume that every investor puts in $1,000, and that all of these investors ask for their interest and capital back at the end of the ninety-day period. In reality, many investors actually left their capital with Ponzi for a new round, so that he did not need as many new investors for each session; in this sense, Ponzi’s scheme could last longer than our theoretical model. On the other hand, we also assume that Ponzi is not making any personal profit from the scheme but keeping all the invested money rolling among investors, whereas in reality, Ponzi was skimming off a portion of the incoming money for his personal use, which would cause his scheme to collapse sooner than our model. We consider that these two simplifying assumptions roughly cancel each other out.
The scheme is working as long as Ponzi has enough money at his disposal from new investors to pay back interest and capital punctually to all the earlier ones. The scheme collapses when he no longer has enough money to do that. The goal is to double everyone’s money every ninety days.
We’ll suppose that Ponzi started with 100 investors each putting in $1,000 for a total investment of $100,000. (In reality, it took Ponzi a few weeks to reach this point.) Ninety days later, he owes these investors $100,000 in interest as well as their capital back; he needs to find 200 new investors to put in $200,000 within the first ninety-day period, which he can pay out to the original investors at the end of the period. This accomplished, he now needs to double the $200,000 in order to be able to pay the 200 new investors back their money and interest at the end of the second ninety-day period. Thus, he must find 400 investors during the third ninety-day period to pay the 200 back, 800 in the fourth ninety-day period to pay the 400 back, and so on, with the number of new investors needed doubling every period. The moment he can’t find enough new investors to enable him to pay back the previous ones, people will get scared; investors will start demanding their capital back, but new investors will not be forthcoming to provide the necessary funds, resulting in the collapse of the scheme.



At this rate, how long can Ponzi be expected to continue? Table 8.1 shows his projected schedule of reimbursements at the end of each period, together with the number of new investors he’ll need to find during that period and the total number of investors he will have had up to that point.
At the end of a year and three months, he would need to be prepared to pay out $3,200,000; at the end of a year and a half, $6,400,000; after a year and nine months, $12,800,000; and after two years, $25,600,000. Continuing to double every ninety days, we find that after a third year he would need to be prepared to pay out $409,600,000, and after four years, $6,553,600,000.
Given that 1 billion dollars is the total sum of money that John D. Rockefeller (1839–1937), the richest man in American history, amassed over his entire lifetime (the equivalent today is about 200 billion dollars), it is unthinkable that Ponzi could obtain 6 billion dollars in the short space of four years by any method. It is clear that Ponzi will face a major problem in a much shorter time.
2) Investor-Based Model
As it happens, Ponzi had one advantage that gave him a head start on the fast-growing model above: his extraordinary capacity for inspiring hope and trust using his silver tongue. From day one his charm and persuasiveness helped the number of his investors grow at an incredible rate, and as he began paying the promised dividends to those who chose not to leave capital and interest in his hands, the news spread like wildfire. Widespread interest was aroused by the agents Ponzi hired to circulate through the Boston area spreading an unbelievable tale of profit and bringing in ever more money. Indeed, for several months Ponzi actually managed to double the number of his investors each month, which is much faster than the model above, in which the number of investors needed to double every ninety days. Of course, this fast increase in the number of investors brought with it the terrifying necessity of paying out that much more money to all those people.
Let us make another model of Ponzi’s scheme, this time based on the doubling of the number of investors every month. As before, we’ll start with 100 investors putting in $1,000 each, and assume an investment of $1,000 from every new investor.



The progress of the scheme under these conditions is shown in table 8.2, starting in January 1920, Ponzi’s first month of operations, and ending in late July, when he ran into trouble. Instead of showing what Ponzi needed to pay out at the end of each month, we show the total amount that he took in, regardless of his expenditures.
This simple model is astoundingly close to what really happened. Adding up the numbers in the table yields a total of 10,500 investors and a total investment of a corresponding $10,500,000. Ponzi’s actual records showed that 10,550 investors entrusted him with their money from January through July 1920, for a total of $9,800,000, and that by July he was taking in $200,000 a day, which, amazingly, averages out to exactly $4,200,000 in the twenty-one days of July (not counting Sundays) that passed before the Ponzi scheme collapsed.
If the scheme had not failed—the story is worth telling—it could have been projected into the following months along the same lines (table 8.3):



At the speed at which Ponzi was recruiting new investors, it would have taken him a little over a year to reach the billion-dollar point, and the number of investors would have to correspond to the entire adult population of the Boston area in 1920. At this rate his scheme had no chance of lasting three years as in the more minimal model given earlier; indeed, it could barely have lasted even a few months longer than it actually did.
If investors had made this kind of simple calculation from the start, Ponzi’s operation would never have gotten off the ground. As it happens, however, it was cut short before he ever reached the point of being unable to reimburse investors, by the actions of one angry and greedy man.
A FURNITURE salesman named Joseph Daniels had loaned Ponzi $200 in December 1919, just before the whole moneymaking frenzy started. Ponzi had used part of the money to buy some furniture and the other part as investment in his new company. He paid back the debt punctually, but as the money began flowing in over the course of the ensuing months, Daniels decided to claim that Ponzi had promised him a half share in all the profits from the investment. When Ponzi bought his luxury mansion in Lexington on May 28, Daniels paid him a visit and demanded that Ponzi give him a share of the profits. The request was so outrageous that Ponzi refused, upon which Daniels hired a lawyer and sued him on July 2. The district attorney of Massachusetts, acting as a mediator, requested that Ponzi halt operations while an auditor went over his books to confirm that his company was sound.
If Ponzi had cared more about profit than anything else, he would have absconded with everything he held that same day. However, he stayed put. Perhaps he dared not reveal the truth to his wife, or perhaps he believed that his charm would get him through. In any case, he not only remained, but he also kept his doors wide open and a smile on his face.
On Monday, July 26, Ponzi was obliged by court order to suspend operations, which meant turning away dozens of investors who came to him, money in hand. At that time he was taking in nearly $200,000 a day. The next day, however, the news of his frozen operations led to a run on his offices, as investors, frightened by the news of an investigation, came to demand their money. Ponzi made it known that he would redeem unmatured notes in the amount of the original investment and matured notes with the promised returns. Faced with crowds of people who smashed his window-panes and tried to force their way into his offices, he took over a nearby bar for the day, turned it into a makeshift office, set up a cashier’s booth in one corner, and managed to persuade the applicants to form a line. That day some 1,000 clients managed to get their money back, for an estimated total of $1,000,000. When the day’s rush was over, Ponzi entertained a group of journalists and shared with them his grandiose plans for the future: he would run for office, make Boston into the largest import-export center in the world, donate millions of dollars to charity, and reform the banking system. The reporters ate it up.
The following day the rush was larger than ever, with thousands of people crowding the street. Ponzi had coffee and sandwiches brought out, and with his best smile he reassured the investors. Anyone who wanted out could have their money at once, but those who believed in him would do better to wait, because all would be well. Many believed him and went home. Ponzi paid the others in full, again for an estimated $1,000,000. On Thursday he paid out half a million, and on Friday only a small sum was paid. His words and actions had calmed the remaining investors and reestablished their belief in him. In the meantime Daniels’ lawsuit proceeded.
On Friday and Saturday of that week all was quiet, and on Sunday, August 1, Ponzi attended a fair organized in the nearby town of Jamaica Plain in support of the Italian Children’s Home. There, standing on the steps of the home, Ponzi promised the charity $100,000—and paid for every woman and child at the fair to have a free ice cream, a gesture that earned him a rousing ovation as his limousine pulled away (and for which he is remembered affectionately in Jamaica Plain to this day).
On Monday, August 2, the newspapers published an article authored by a former publicity agent for Ponzi, claiming that Ponzi would soon be unable to continue reimbursing clients. This produced another giant run on the offices, which lasted through Wednesday. Once again Ponzi was able to meet demands, although by then he was borrowing from his bank to do it. On Thursday, August 5, things quieted down. But Ponzi knew that if anything provoked a third run, he would be in serious trouble, as the lawsuit had caused $500,000 worth of his assets to be frozen, unusable for paying creditors. He therefore called for a meeting with Daniels to come to an agreement. Daniels agreed to settle for $40,000—it was nothing less than blackmail, as he knew that Ponzi was strapped for cash—and Ponzi handed it over in return for having his assets unfrozen. Unfortunately for him, the whole story filtered into the news, and Ponzi could not avoid another run on Monday, August 9. Once again, he honored his debts. The Hanover Trust Company allowed him to overdraw his account to the tune of $500,000. “I am sick and tired of the whole business,” Ponzi is said to have declared on that day.
Tuesday morning Ponzi closed his office and went to give a lunchtime lecture before the Kiwanis Club that had been arranged long before. An enormous crowd attended and asked a host of questions, not all of them easy. People were beginning to wonder about Ponzi’s past. On Wednesday the truth about his criminal record was made public, as was his inability to show assets to cover his liabilities.
Ponzi was arrested on Thursday, August 12. He called his wife to tell her that he would be spending the night going over his records with the auditors. She received the guests they had invited for that evening alone, smiling courageously. She was the only person there who did not know that her husband was already in prison.



Article from the New York Times, August 15, 1920
THE RUN continued over the following days until Ponzi’s investors finally realized the truth: nothing further was forthcoming. Everything Ponzi owned was seized and sold to satisfy at least some part of his obligation to his creditors. It provides a small measure of satisfaction to note that the $40,000 extorted by Joseph Daniels was also seized and used to fulfill more legitimate claims. Nevertheless, as is necessarily the case in any Ponzi scheme, the greatest number of investors lost their money for good.
Utterly bankrupt, Ponzi was condemned by a federal grand jury to five years in prison for mail fraud. Humiliatingly, he was further sentenced to seven years of prison by the state of Massachusetts, which pronounced him a “common and notorious thief.” Because it took such a long time to get around to his trial, and then three tries on different counts before a jury finally found him guilty, at this point it was 1925, and Ponzi had already completed his first prison sentence. He appealed his second sentence at once—one cannot help thinking that it was the adjective “common” that he was appealing more than the accusation of being a thief—and was released while the appeal was pending.
Ponzi had learned his lesson, and in no time he was far from Boston, organizing yet another get-rich-quick scheme to earn money on sketchy land deals in a marshy area of Florida. This time his speculation turned sour quickly, and he and his wife were arrested. On April 21, 1926, he was sentenced to one year of hard labor. Charges against Rose Ponzi were dismissed. Ponzi appealed again, but the sentence was upheld on May 28, by which point, yet again, Ponzi had fled. Tired of the United States—or too frightened to stay—he had managed to find employment on a ship bound for Italy.
Unfortunately for Ponzi, the ship stopped at Port Houston, Texas, where he somehow attracted the notice of the authorities. The Texas sheriff recognized him and quickly wired Boston for his Bertillon measurements (the system of corporal measurements used to identify criminals at the time; more on this in chapter 10, in which this same Bertillon plays a remarkable role). But by the time they arrived, the ship had left Texas for New Orleans. The sheriff immediately contacted a colleague in New Orleans, who inveigled Ponzi off the boat on the grounds of needing standard paperwork, captured him, and brought him straight back to Houston. Ponzi complained that his arrest was no more than an unlawful kidnapping, but he was ignored and Massachusetts demanded his extradition. It took months, but Ponzi was eventually extradited and began serving his Massachusetts prison term in 1927. Released in 1933, he was deported to Italy in 1934, whence he traveled to Brazil in 1939 and held various jobs before a stroke left him paralyzed and penniless. He died early in 1949. The obituary printed by Time magazine on January 31 of that year sums up his personality quite well:
As the dapper little man with the straw hat, the walking stick and the boutonniere emerged from Boston’s State House, a cheer went up for “the greatest Italian of them all.” Charles (“Get-Rich-Quick”) Ponzi shrugged off the compliment. “No,” he admitted, “Columbus and Marconi were greater. Columbus discovered America, Marconi discovered the wireless.” Hysterical voice from the crowd: “But you discovered money!”
AS THE recent case of Bernie Madoff revealed, Ponzi schemes still have the power to lure unsuspecting—but greedy—investors. And not just one, but thousands and thousands of people; otherwise the plan would never get off the ground. But how is it possible that people did not learn their lesson from the crash of Ponzi’s legendary scheme? There are two answers to this question, and one of them comes straight from J. P. Morgan: trust.
The trouble is that, for people like Charles Ponzi—or the Python Kaa in The Jungle Book—charisma can produce trust where there should be none. Madoff himself, during the investigation of his own case, noted with amazement that the regulators who investigated his stockbroking company never even asked to look at his stock records. It must be added that Madoff entertained close and affectionate friendships with most of the people in important positions at the US Securities and Exchange Commission who were responsible for such investigations. Between 1992 and 2008, when Madoff was arrested, the SEC was responsible for no less than six different investigations of Madoff, not one of which noticed any anomaly. However, no one has accused the SEC of a cover-up. It is accepted that Madoff’s charisma was so overwhelming that investigators could not do otherwise but place their trust in him, exactly as his clients did when they placed their money in his hands. And the investigators continued to do so for years, in spite of the strident cries of a few—there are always some people who simply cannot be hypnotized—such as financial analyst Harry Markopolos, who repeatedly told the SEC that Madoff’s returns were mathematically impossible.
And this leads us directly to the second answer to our question above. Ponzi schemes still exist—and work—because not enough people are sufficiently mathematically aware to make the deduction that Harry Markopolos made. As he recounts in his colorful book, No One Would Listen, Markopolos tried to alert the industry, the government, and the press about the problem for a period of over ten years. The title of his book succinctly expresses the reactions he received.
Madoff was not arrested until the day his scheme collapsed, as it was mathematically certain to do, and he could not meet the payments he had promised to clients. That day he confessed the truth to his sons. Shocked, they reported him to the police. He was arrested at once, tried, and sentenced to 150 years in prison, where he now hobnobs with such celebrities as Israeli-American spy Jonathan Pollard and crime boss Carmine Persico. An estimated total of 18 billion dollars was definitively lost to his investors, a large number of which were charitable institutions devoted to the support of education, youth groups, and hospitals.
The public failed to learn the lesson of the Ponzi scheme from its namesake. Perhaps the experience with Bernie Madoff can have at least one positive consequence: public understanding of the mathematical impossibility of such terms.
Beware exponential growth investment—it cannot work!
 
*How do you prove this? The simple circumference formula for a circle: C = 2πr. Here C is the circumference of the earth, which is about 40,000 km, and π = 3.14159. So assuming the earth is a perfect sphere, the radius r = 6,366.197722 km. The length of our original wire is 40,000 km, and we add one meter to that length. A meter is one-thousandth of a kilometer, so the new length of the wire is 40,000.001 km, and we divide this by 2π to obtain the radius of the new circle formed by the lengthened wire. As expected, the new radius is very close to the old one; the calculation gives the answer 6,366.197881 km. The difference between the earth’s radius and the new one corresponding to the longer wire is just the difference between the two—the tiny-looking number, 0.000159 km. This is equal to 0.159 meters, or almost 16 centimeters.
*Roughly speaking, a dollar after the war was worth about 44 lire and an IRC could be bought for 1.5 lire. Of course the exchange rate was fluctuating, but 1919 marked an all-time low. In 1926 Mussolini curbed Italian inflation by pegging the dollar at just 19 lire.

MATH ERROR NUMBER 9 »
CHOOSING A WRONG MODEL
A farmer is troubled because his hens are not laying eggs. After visiting a veterinarian, a doctor, and a psychotherapist with no result, he ends up going to a physicist in despair. The physicist scratches his head and says, “Give me a week to think about it.”
A few days later the anxious farmer phones the physicist. An enthusiastic voice shouts into his ear, “Yes! I have found a solution to your problem! The thing is this, though. My solution only works for perfectly spherical hens in a vacuum.”
—ADAPTED FROM THE BIG BANG THEORY
 
IF YOU LAUGHED at this little story you probably understand that the funniness of the joke lies in the contrast between a purely scientific situation and the complexity of real life. It’s amazing how often scientists fall into the trap of believing that their models accurately describe real situations when in fact everyone knows that reality can be stranger than even the wildest fiction.
Applying a mathematical model to a real-life situation is never likely to be completely accurate; the simpler the model and the more individual the behavior, the worse it will turn out. It should go without saying that this kind of reasoning cannot be used in a court of law without incurring a serious danger of being wrong.
 
 
The Case of Hetty Green: A Battle of Wills
Hetty Green’s life was not what you could call ordinary. The only surviving child of a hard-nosed, extremely successful businessman, she grew up under her father’s wing, learning the ABCs of money management before age ten by reading the financial news to him every day. Instead of dolls, stocks and bonds were her playthings. Her bulls and bears were not stuffed ones, and legend has it that upon receiving her first cash gift at the age of eight, she rushed to the town bank on her own to open an account. Like her father, Hetty grew up stubborn and thrifty—the amassing and later the multiplying of money became her passion, her obsession, and finally the only activity of her life. Known in old age as “the witch of Wall Street,” she was the richest woman in America and the only female investor on Wall Street, with railroads, factories, and entire city blocks in her hands. More than once she bailed out the entire city of New York by offering a gigantic loan to shore up the city’s failing budget. During the famous Panic of 1907, she came to the city’s aid with a loan of $1.1 million from her personal fortune. When she died in 1916, she was worth $100 million (estimated at $1.6 billion today), the thirty-sixth largest American fortune of all time. Hetty Green, née Robinson, was a legend in her own time, a legend fueled by innumerable anecdotes about her peculiar behavior anywhere the spending of even a penny was concerned.
In 1865, Hetty was thirty years old, engaged to be married to a wealthy man, and possessed of a generous fortune left to her by her father on his death shortly earlier: a million dollars in cash and real estate and another five million in trust, with the interest to be paid to her by the trustees over her lifetime. One might think she had everything a young nineteenth-century woman could possibly want, but at that point in her life, Hetty was a very angry and frustrated person. The source of her anger was her father’s will, which, far from the boon it might appear to be, struck her more like an insult or a slap in the face. Being deprived of control over her own money was a humiliation that Hetty found unendurable. Her father had raised her and had shared his financial knowledge with her practically since her birth. He knew her passion for the management of money; he knew her care, her thrift, her frugal habits, her intelligence, and her instinct. He knew who she was. And yet he dared to leave her money—her five million dollars—in trust, handled and managed by men, as though she were some foolish girl who might spend it all on ribbons and parties. Hetty was deeply wounded by her father’s will, and she never forgave him for it.



Hetty Green in her old age
AT THE time of her father’s death, Hetty was expecting a second inheritance: that of her mother’s sister, Sylvia Howland. Hetty’s mother had died when Hetty was still a child, and the rambunctious, temperamental, strong-willed young girl had spent a great deal of time at the house of her invalid maiden aunt in New Bedford, Massachusetts. Sylvia’s fortune was reputed to be immense—Hetty’s father had married into money—and Hetty had been brought up with the expectation that she would inherit her aunt’s money, since there were no other close relations. Determined that the misfortune of her father’s legacy would not be repeated, and seeing her aunt constantly surrounded by companions, nurses, and caretakers, Hetty undertook to ensure that her inheritance would not be altered or diminished by any untoward fancy of the old lady, and decided to convince her aunt to make a will.
Poor Sylvia was reluctant to do so, according to the testimony of her companions. It was not that she didn’t want to leave her money to Hetty, but she was disturbed by her niece’s overbearing ways, her inelegant insistence on the matter of this will, her emerging eccentricities of stinginess and personal negligence, and her temper, which made her fly into a rage and reproach her aunt bitterly for such things as wishing to build an addition to her house. And perhaps Sylvia also disliked the idea of writing her will with Hetty standing over her, breathing down her neck, frowning and throwing tantrums at every mention of a legacy left to someone else, no matter how dear to Sylvia Howland’s heart. In any case, Sylvia had already made a will that satisfied her, by which Hetty was to receive two-thirds of her estate in trust, with the remaining third divided among legacies and charities that Sylvia cared about.
But this proposal was not acceptable to Hetty. A third of the estate passing out of family hands horrified her, the idea of a trust even more. She began to pressure her aunt to rewrite the will. Sylvia initially resisted, but Hetty insisted and they eventually made a bargain: they would both write wills. Sylvia would write a will in Hetty’s favor, and Hetty would write a will leaving half of her own money to her children, should she have any, and the rest (or all of it if she remained childless) to Aunt Sylvia’s favorite causes, the local children’s home in particular. Young and strong, Hetty was well aware that she had nothing to lose; her will was a mere gesture of goodwill to persuade her aunt to make another in return. Sylvia yielded, probably out of weariness, and “dictated” a new will to Hetty—one can imagine how that dictation proceeded—according to the terms of which Hetty inherited every single bit of her aunt’s estate, houses, land, money, investments, and holdings.
Once the will was written, however, Sylvia refused to sign it. A tense standoff ensued, with Hetty fuming, Sylvia withdrawn, and the nurses and servants embarrassed. Hetty declared that she would not return home to New York until the will was signed and witnessed. Thus the bedridden patient’s only pleasure—a life of peaceful, quiet enjoyment with her caretakers, friends, and visitors—was denied her by her intransigent niece. In the end, Sylvia’s desire to return to her normal habits overcame her resistance. She called for Hetty and for two trusted friends, and the will was signed and witnessed with all due formality. It was then put into an envelope and placed in a trunk containing Sylvia’s private affairs, to which only she and her housekeeper had the key. Hetty, relieved, left for New York.
Despite everything, Hetty remained unsettled, because it was obvious to her how lonely her aunt was and how dependent she was on those who called themselves her dependents. Sylvia could write another will anytime she chose, and there wouldn’t be much that Hetty could do about it. And she must have been aware that having forced Sylvia’s hand so rudely, the event she feared was all the more likely to occur.
There wasn’t much for Hetty to do, however, except to hope for the best and keep her ears open. She went back to New York, became engaged to Edward Green, and wrote conciliatory, affectionate letters to her aunt. And she waited.
IT WAS not long before a worrisome rumor reached her ears. There was a new influence in Sylvia’s life. A doctor named William Gordon, who had arrived recently in New Bedford, had been called in by Sylvia to treat her chronic back pain and had by degrees become her regular and then her constant doctor. In fact, she took up so much of his time and attention that she eventually became his only patient, with him spending most of the day at her bedside. Dr. Gordon brought Sylvia much relief, but there was a steep price to pay, as the painkiller he prescribed was the popular nineteenth-century opium-based drug laudanum, which kept her in a feeble, drowsy, and addicted state. Sylvia’s health was in rapid decline, and the doctor’s influence over her reached a point that appeared excessive to everyone around her.
News of the doctor’s rise in fortune reached Hetty and caused her tremendous anxiety. What pushed her over the edge was the receipt of a letter from the same Dr. Gordon, informing her that according to her aunt’s wishes, Hetty was no longer welcome to visit the house. Because this maneuver effectively tied her hands, she was compelled to stew in New York, virtually certain that all the while she was being robbed of the fortune that she considered rightfully hers, and that it was being diverted to unworthy and scheming hands.
It must have been a difficult time for Hetty, and she can be forgiven for indulging in numerous plans destined to foil her aunt’s project. But from a distance of over one hundred miles, even the most willful and headstrong young woman cannot have the same influence on a failing invalid as a helpful and caring doctor who is present at her bedside every single day. Nearly two years after her deal with Hetty, Sylvia made a new will, one that was calculated to send her niece mad with rage.
Of the two million dollars Sylvia’s estate was worth altogether, she bequeathed fully one-half to a collection of charities and individuals she wished to benefit—above all, the town of New Bedford and members of her family, together with her faithful companions, housekeeper, and nurse, all of whom received legacies of between three thousand and twenty thousand dollars. The remaining million dollars was left to Hetty, but in the way her niece would most abhor: bound up in a trust, administered by yet more men—one of whom was the detested Dr. Gordon himself. The trustees were given complete freedom to control Hetty’s money; indeed, though they were directed in Sylvia’s will to pay the net income from their investments to Hetty, they were not bound by any express stipulation to actually do so, as she wrote: “I wish said Trustees to make said payments when and as often as it may in their judgment be convenient for them to do so . . . It is my will that the said Trustees shall exercise their own judgment, and shall act and do in all respects what shall be deemed by them to be for the interest of all parties . . .” And the cherry on the cake was that, not content with providing for generous and permanent trustees’ fees to ensure the helpful doctor’s future, Sylvia left him outright the sum of fifty thousand dollars! The will was dictated to and written down entirely by the good doctor himself, who all the while was administering to his patient increasing doses of laudanum.
Hetty, of course, was kept in the dark about all these changes, but when Sylvia died six months later and the complete state of affairs was revealed to Hetty’s shocked ears, she must have seen the signs of what is now known as “undue influence.” As with her father’s will, she felt that her aunt’s will was a betrayal. And Hetty resolved, come what may, to contest the document in court.
Hetty was no fool, and she immediately realized that she could not contest the will on the grounds of Sylvia’s feeble mental state. She had not seen her aunt for over two years, and all of Sylvia’s friends would testify that she was in full possession of all her faculties. Even those who might have felt that Dr. Gordon had reaped more than his due were unlikely to protest a will that also carried benefits for them. Hetty wanted everything for herself, and she knew well that she would have no supporters for the position she was going to take—no supporters, at least, aside from her fiancé, Edward Green, and a few carefully chosen and well-paid lawyers. If she wanted to contest the will, she would have to do it on grounds that were more solid than mental incompetence. The best angle would be the mutual promises that she and Sylvia had made to each other, proven by their cosigned wills. But in order to support this position, it was first necessary for Hetty to obtain the will that she herself had written down at Sylvia’s dictation. At that time it was not as common as it is now to leave one’s last will and testament in a bank vault or in the care of a lawyer. Sylvia had not written that first will with the help of a lawyer, so Hetty suspected it would probably still be in the house. If it was, she knew where to find it: in Sylvia’s special trunk, the one to which only Sylvia and her housekeeper held the key.
On the very evening of Sylvia Howland’s funeral, Hetty, holding a candle and accompanied by the housekeeper and the nurse, went up the dark stairs to Sylvia’s room, had the trunk opened, and retrieved some papers that were inside: two large envelopes, one containing her own will, and the other, the one dictated to her by her aunt. Both the housekeeper and the nurse later testified to seeing Hetty remove these papers, although they did not know what they were. But Hetty must have been excited to find that her aunt had not destroyed the previous will. On the strength of the document, she contacted the probate court judge who would decide whether to admit Sylvia’s will, and presented her strongest arguments against it (not excluding a hint of bribery). The judge ignored them, however, and admitted the newer will. Hetty decided to sue the trustees.
In her suit Hetty claimed that as the sole legitimate heir to the estate, she was entitled to inherit it in its entirety. She accused Dr. Gordon of drugging and manipulating a feeble, elderly lady for his own benefit. When not under his pernicious influence, she claimed, Sylvia had meant Hetty to inherit the entire estate, as the earlier will clearly proved. The trustees countered with a response, filled with witness statements, pointing out that during the last years of her life Sylvia had changed her mind about her niece because Hetty was so pushy and unpleasant. They cited Sylvia’s nurse as saying that when Hetty used to visit, Sylvia would beg not to be left alone with her; other members of the household staff came forth with a plethora of unpleasant anecdotes in which Hetty was described in such embarrassing postures as screaming and rolling on the floor or pushing servants violently down the stairs. The document described Sylvia’s relief at being able to dispose of her money as she wished, providing all the kindnesses she had always desired to the children’s home, to local widows, and to her friends. The trustees agreed that Sylvia’s will was absolutely sound and unbreakable. Thus the ball was back in Hetty’s court, and she swept it into the air with a backhand as astonishing as it was unexpected.
There was a second page attached to her aunt’s old will, Hetty explained, which had been dictated to her by Sylvia on the same day as the will itself, in secret. The witnesses had not seen it, and it had been signed by Sylvia alone. There was nothing surprising in that, given the contents, which were intended to be kept from everyone except Hetty. Even at that time, Hetty contended, Sylvia was aware of the dangers of exploitation that surrounded her, a wealthy woman dependent on others for her care, and she had written this letter in order to protect herself from possible quarrels with her carers over questions of inheritance. The letter automatically invalidated any future will that she might write.
Be it remembered that I, Sylvia Ann Howland, of New Bedford, in the County of Bristol, do hereby make, publish and declare this the second page of this will and testament made on the eleventh of January in manner following, to wit: Hereby revoking all wills made by me before or after this one—I give this will to my niece to shew if there appears a will made without notifying her, and without returning her will to her through Thomas Mandell as I have promised to do. I implore the Judge to decide in favor of this will, as nothing would induce me to make a will unfavorable to my niece, but being ill and afraid if any of my caretakers insisted on my making a will to refuse, as they might leave or be angry, and knowing my niece had this will to show—my niece fearing also after she went away—I hearing but one side, might feel hurt at what they might say of her, as they tried to make trouble by not telling the truth to me, when she was here even herself. I give this will to my niece to shew if absolutely necessary, to have it, to appear against another will found after my death. I wish her to shew this will, made when I am in good health for me, and my old torn will made on the fourth of March, in the year of our Lord one thousand eight hundred and fifty, to show also as proof that it has been my lifetime wish for her to have my property. I therefore give my property to my niece as freely as my father gave it to me. I have promised him once, and my sister a number of times, to give it all to her, all excepting about one hundred thousand dollars in presents to my friends and relations.
The letter, dated January 11, 1862, was written out in Hetty’s handwriting but signed by Sylvia. Hetty presented it to the court. The trustees learned about it, looked at it, and pronounced it a fake. And the battle began.
FOR A woman whose entire life had dealt with numbers and calculations, forecasts and predictions, and statistically informed investments, it is striking that Hetty Green’s major brush with the arcana of probability theory occurred not within the framework of monetary activities, but in a different arena altogether: the trustees’ accusation of forgery.
Thomas Mandell, the executor of Sylvia Howland’s will, challenged Hetty’s story, as well as the validity of the earlier will altogether. Mandell examined the signatures on the earlier will—the one on the main page of legacies and the ones on the additional document (in two copies) deeming all future versions worthless—and found all three to be virtually identical. Accusing Hetty of having forged the second page and its signature in order to inherit the whole of her aunt’s fortune, he stood up to her in court.
It is hard to imagine a trial taking place today in which neither side, uplifted as they were by a sense of wealth and entitlement, hesitated to call upon the most important academics of the day as expert witnesses on a question as trivial as that of a forged signature. But unlike most other accused forgers, Hetty’s privileged family background gave her access to the East Coast’s intellectual elite.



Louis Agassiz, naturalist
Her defense opened by claiming that near-identical signatures are not as rare as one might think. To prove it they called in an engraver, J. C. Crossman, who testified to the effect that many people have signatures of astounding regularity. As an example, he provided several specimens of the signatures of former president John Quincy Adams, some virtually identical to each other. Next, the defense sought to prove that Sylvia Howland’s signature on the addendum letter was not forged. For this they called upon no less an authority than Louis Agassiz, professor of natural history at Harvard and the first scientist ever to theorize the existence of an Ice Age. Agassiz examined the purportedly forged signatures under a microscope and declared that he could see no signs of forging, none of the minuscule tremors that appear in inked lines that have been drawn carefully and slowly, or traced, rather than put down with a bold, firm stroke.



Oliver Wendell Holmes
Finally, to disprove the theory that Hetty might have first traced Sylvia’s signature with a pencil and subsequently gone over it with a pen, Hetty’s legal team called upon Oliver Wendell Holmes, Parkman Professor of Anatomy and Physiology at the Harvard Medical School. Holmes was one of the most famous men in America, not only for the popular poetry and essays he published in the Atlantic Monthly but also for his medical innovations. Not only was he one of the first proponents of the use of anesthesia during operations, but he even coined the word itself, predicting that it would soon “be repeated by the tongues of every civilized race of mankind.”* Ahead of his time both scientifically and socially, he was also famous (or infamous) for trying to admit the first woman applicant to Harvard Medical School in 1847. The united opposition of the student body, the university overseers, and the other faculty members thwarted his attempt to do so, but three years later he managed to briefly admit three black men to the school. Alas, a petition was circulated and signed by more than half the student body, saying, “We have no objection to the education and evaluation of blacks but do decidedly remonstrate against their presence in College with us,” and once again Holmes was obliged to bow to public pressure and shorten the black students’ education to a single semester.
The illustrious but controversial Oliver Wendell Holmes agreed to make a detailed scientific examination of the signatures that Hetty Green was accused of having forged, using the best possible equipment his laboratory at Harvard could provide. He rendered his personal opinion as a witness that they showed neither pencil marks nor any other of the typical signs of tracing.
For the prosecution, this provided something of a puzzle. There was obviously no easy way to prove that the signatures were forged in the face of such illustrious scientists claiming the contrary. Thus they came up with a new strategy: instead of calling upon specialists in the microscopic biological sciences, they decided to counter the scientific testimony with mathematics. For this purpose they also went straight to the top, consulting the professional opinion of Benjamin Peirce, a professor of mathematics at Harvard (whose name is attached today to the prestigious Benjamin Peirce lectureships there) and his son Charles Sanders Peirce, a renowned logician and philosopher. Benjamin Peirce undertook to test whether or not the disputed signatures were forgeries, using a most original method.
THE IDEA in itself appears simple and quite convincing. Under instructions from his father, Charles took 42 examples of Sylvia Ann Howland’s signature from documents found on her estate, laid every single signature over every single other one for a total of 861 comparisons of pairs, and in each case observed how similar the two signatures were.
As a measure of similarity, he chose to count the number of downstrokes that were superimposed on each other. In order to analyze the lettering in detail, he counted as many downstrokes as possible, including the tiny loops at the start of each capital letter, and came to a total of 30: 9 in the word “Sylvia,” 7 in the word “Ann,” and 14 in “Howland” with its complicated capital H.



Charles Sanders Peirce
Next, he made a table showing how many of the 861 pairs had 1 downstroke in common, how many 2 downstrokes, how many 3, and so forth, up to 30 strokes in common. The table that remains in the trial transcripts, given in the first and second columns of table 9.1, shows a bit of abbreviation in what concerns the very similar signatures, lumping all those with 13 to 30 downstrokes in common into a single group.



Some of the 42 signature samples of Sylvia Ann Howland measured by C. S. Peirce



The signature on the first page of the will and the two disputed signatures
This table indicates that most of the pairs, or 617 out of the total 861, had 3 to 7 downstrokes in common, and only 20 had more than 12 downstrokes in common. So how did the two Peirces use this table to calculate the probability that some pair might actually have all 30 downstrokes in common?
In court, Benjamin Peirce gave an estimation of that probability as a chance of 1 in 530, which he qualified as unspeakably small. He told the court that this number was equal to 1 in 2,666 millions of millions of millions (which is actually about three times too large—but there were no calculators in the nineteenth century). In any case, the words he used to describe the quantity 1/530 apply just as well to the correct value: it was a “number far transcending human experience . . . so vast an improbability is practically an impossibility. Such evanescent shadows of probability cannot belong to actual life. They are unimaginably less than those least things which the law cares not for.”



What he meant, of course, and what the jury took him to mean, was that the probability that the two signatures were identical by pure chance was so tiny as to be utterly negligible, and therefore they must be identical by design. And whose design could that be, if not that of the interested party, Hetty herself? In other words, Peirce’s statement was tantamount to a straightforward but unspoken accusation of forgery. But this statement, and the calculation in general, deserve closer attention. Why, if there were 20 signatures having 13 to 30 downstrokes in common, was the probability he calculated for two signatures having 30 common downstrokes so incredibly tiny? And for that matter, how did he calculate that surprising figure at all?
What Peirce did was to approximate the numbers in the table of measured values using a simple standard mathematical model, the binomial formula.* The numbers predicted by the binomial formula are in the third column, titled “Theoretical Model,” of table 9.1. A brief glance shows why Peirce picked that model: the numbers in the third column and those in the second column seem fairly close to each other, which means that the model seemed like a good choice.
But a closer look shows that the numbers are not as similar as they seem at first glance. To make a more accurate comparison, let’s put the two tables of values in the form of a graph: white for the actual measurements, and black for the binomial model.



 
Although the black and white graphs have similar shapes, they are actually quite different from each other at both ends. What do these differences mean?
The absence or smallness of the white (real) bars compared to the black (theoretical model) bars on the left side of the graph indicates that Sylvia Howland’s signatures were generally more similar to one another than a purely random distribution would predict. Next, the greater height of the white bars compared to the black ones on the right edge of the graph shows that Peirce found 20 pairs with 13 to 30 downstrokes in common when the model only predicted 3. And for pairs having more than 11 strokes in common, the model (black) predicts only 8 altogether, whereas Peirce’s measurements (white) revealed 35 such pairs, more than four times as many.
It is curious that the number of signatures having 13–30 strokes in common were not specified in the Peirces’ table. Of course, if even one pair were to be found with a large number in common, such as 27, 28, or 29 strokes, the probability of such an event happening would be shown to be at least large enough to justify the fact that it just might have happened in the particular case at court—so certainly not anything as small as the “vanishing” (1/5)30. It would have been interesting to know if they had actually found any such pair or not.
In any event, comparison of the theoretical model with the reality shows that not only is the correspondence far from perfect, but it also underestimates the similarities that Sylvia Howland tended to have among signatures. It was therefore quite daring on the part of Benjamin Peirce to conclude by a (1/5)30 probability of two signatures being identical on that basis. In fact, with all due respect for the great man, the figure he gave and the comments he made about it are downright absurd.
For one thing, the model that gave rise to the transcendentally small probability takes no account of a number of factors that could explain the large number of similar pairs. Sylvia’s signature could have slowly changed over time, so signatures made soon after one another would be very similar, whereas those far apart in time might be different. Also, signatures made using the same pen, at almost the same moment, sitting in the same position, might be expected to be more similar than those made under different physical conditions. A model taking these considerations into account would have yielded a much larger probability for identical signatures. According to Hetty, the signatures on the will and on the addendum letter were made one right after the other, with Sylvia presumably not moving between the two. This would naturally yield signatures more similar to each other than to other signatures made months or years earlier.
There is also the matter of the interpretation of Peirce’s vanishingly tiny figure. Because he calculated this number as the probability that the two signatures were identical purely by chance, he concluded that such a thing was virtually impossible, and therefore the second signature must have been forged by Hetty. But as statisticians Paul Meier and Sandy Zabell have humorously pointed out, there are many other possibilities that, however outrageous, are all far more probable than (1/5)30. Sylvia Howland might have decided to trace her own signature, they suggest. Or Thomas Mandell, Sylvia’s executor, might have stolen the real second page of the will and forged a copy of the whole thing with a traced signature in order to destroy Hetty’s claim. Or Charles Sanders Peirce might have been convinced of Hetty’s guilt and thus have been particularly severe in his measurements of similarities of those two particular signatures, compared to the manner in which he measured the others. All of these scenarios (and many others one could reasonably imagine) are unlikely, to be sure. But they are nowhere near as unlikely as Benjamin Peirce’s 1 in 2,666 millions of millions of millions!
Yet not a single one of these questions was raised at the trial. The judge simply opted to reject Hetty’s testimony altogether, as she was an interested party, and the case ended with a settlement that was essentially identical to Sylvia’s latest will. Some members of the family, furious with Hetty for her behavior, threatened to bring her to court over the forgery. Hetty married Edward Green and, probably to avoid another trial, went to live with him in England, where the couple had two children. Therefore it is left to historians to ask themselves whether, had that second trial taken place, she would have been convicted. Our conclusion is that although it is not unlikely that she did forge the signature, the Peirces’ calculation certainly did not establish that fact beyond a reasonable doubt.
WHAT IS CERTAIN, though, is that Hetty’s frustrating experiences with money played an essential role in forming her into the intransigent, indomitable moneymaking machine that she later became; the story is worth telling. The family did not return to the United States until 1879, when they settled in Green’s hometown in Vermont, Bellows Falls. Hetty’s husband was a wealthy and successful businessman, but unlike his wife, he enjoyed spending his money and living well. At first, she allowed him to do as he liked on the condition that he never touch her personal fortune, most of which was held in trust for her, with the interest paid out in small installments. Hetty never spent these amounts, but deposited them immediately in the bank, where eventually they grew to form an appreciable sum. During these years, however, she developed increasingly miserly habits, to the point where she ended up furnishing the townspeople with frequent laughs—”Did you hear how Hetty Green awoke her hostler late at night and forced him to spend hours with her in the chill darkness, searching her carriage and stable, and then the lawns and grounds of an inn where she had dined that day, for a two-cent stamp that she lost?”—and seriously annoying her husband. It is told that she rendered him speechless with rage on the day of his mother’s funeral, when in answer to a sharp question of why wine was being served to the guests in cheap glassware, Hetty explained that she had put all the expensive crystal glasses away in boxes, as “there was no point risking valuable heirlooms when everyday glasses held the liquid just as well.” Contemporary accounts have it that Edward stared at her, dashed his glass straight into the wall, and walked out of the room. By this time Hetty’s attitude about money was causing tremendous tensions in her marriage.
Although not deeply religious, Hetty was of Quaker background, and it was to this that she often attributed her desire for a simple life, devoid of the trappings of luxury and external indicators of wealth. But there may have been another reason for her asceticism. Without engaging in amateur psychological analysis, one may note that the following passage from the Encyclopedia of Mental Disorders closely resembles the portrait of Hetty that emerges from numerous biographies.
Obsessive-compulsive personality disorder is a type of personality disorder marked by rigidity, control, perfectionism, and an over-concern with work at the expense of close interpersonal relationships. Persons with this disorder often have trouble relaxing because they are preoccupied with details, rules, and productivity. They are often perceived by others as stubborn, stingy, self-righteous, and uncooperative.
Difficult to live with she surely was, but both parents dearly loved their son Ned and their daughter Sylvia, and even after raising their children to teenage, they might have hobbled along as a couple for many more years had not a catastrophe struck, close to Hetty’s fiftieth birthday, in the form of a bank collapse.
Cisco and Son was the New York bank where both Hetty and Edward placed the bulk of their money, which in Hetty’s case amounted then to some half a million dollars, not counting the much larger amount of money held in the bank in the form of securities. When rumors that the bank was troubled reached Hetty, she hurried to New York at once and demanded that her entire deposit be transferred to another bank. Although Hetty had every right to request what she did, she was shocked when the bank refused. It was then that she learned for the first time that her husband was not the wealthy man she had believed him to be. He was in debt to Cisco and Son for a whopping $702,000—and the bank refused to let Hetty’s money go until she made good on her husband’s debt!
Oh, the humiliations of marriage. In vain Hetty stormed, raged, refused to pay back loans that had not been made to her, and told the bank that she was not responsible for her husband’s affairs. In vain she ignored the increasingly pointed series of articles about “Mrs. E. H. Green’s behavior” that appeared in New York newspapers, pointing the finger squarely—and not at all fairly—at her as the major cause of the bank’s demise. But Cisco and Son, now taken over by another firm, continued to refuse to give her the money until she paid off at least a significant part of her husband’s debt.
Over several days in January 1885, visitors to the bank, mostly small depositors desperate to take their savings out before Hetty’s demands made doing so impossible, were witnesses to an astonishing scene. Hetty sat at the new bank director’s desk and raged. It is said that she also stomped, cried, and even screamed. The director sat calm and unmoved. Passersby in the street gathered at the windows to watch.
Hetty wanted her half-million deposit paid out to her and her securities returned. The bank wanted her to pay back her husband’s debt. Unfortunately for Hetty, the main bargaining chip was the fact that the securities were on paper, and that bundle of paper was located in the bank’s strongbox. She could not have them until the bank decided she could, and they were not going to decide that until she paid her husband’s debt.
Hetty repeated that her husband’s finances were no concern of hers. The bank director fiddled with his pen, worked quietly at his desk, and made it clear that he was not in any hurry. Hetty was furious to be unable to get hold of her securities, which deprived her of control over her money, a galling situation that she had already had to endure twice with the trusts inherited from her father and aunt. It was a question of one humiliation weighed against another. With fingers stiff as claws, as one can well imagine, Hetty wrote out a check to the bank for the disputed $702,000, took her bag of securities, and marched out, pale with rage, to place her remaining fortune at a more trusted place, the Chemical National Bank.
As might be expected, her anger was soon turned toward its real cause: her husband. That he should misspend and squander his own fortune was not her affair, and perhaps she would not even have cared much about his losing his own money. But he had committed the unforgivable sin of making a hole in her wealth, and this she could not and would not accept. She took her children, then ages seventeen and fourteen, and moved out of the family home in Bellows Falls.
For the remaining thirty years of her life, Hetty Green lived in a series of modest two-room flats in brick tenements in Hoboken, New Jersey, and other cheap towns that allowed her to reach New York by an inexpensive early morning commute—by public transportation, of course, since she did not feel that she could afford a carriage. Each weekday, she went to the desk that had been placed at her disposal in the main banking room of the Chemical National Bank on Wall Street and spent her working hours selecting and buying her investments—rarely either developing or selling, but buying, buying, buying, and waiting for values to rise. She described most of her work there as “cutting bond coupons with a large pair of scissors.” At lunchtime, having rejected most of the surrounding eateries as too expensive (“Ten cents for a cup of tea? It isn’t worth it”) or annoying the waiters by offering them advice instead of tips, she would often simply add water to a small pail of dry oatmeal she brought in with her from home, and set it on the radiator to heat. The only thing in life on which Hetty seemed willing to actually spend money was lawsuits, directed against those she felt had wronged her, including the director of Cisco and Son who had forced her to write the dreadful check. When questioned—and quite often scolded for interrupting proceedings—by the judge, Hetty would say: “I come of good old Quaker blood. All I care for is to do right. Then I am sure to go to heaven.” As the years went by, she became recognizable everywhere, by her reputation, which made people point her out to each other, and by her strange garb, always a long, black dress and a cloak and bonnet, giving rise to the half-admiring, half-frightened epithet “witch of Wall Street.”
Her son left home to become a respected and talented investor and moneymaker in his own right, and her daughter got married. Hetty lived alone and worked, never spending, but steadily increasing her fortune, investing in chunks of America itself: whole streets in Chicago, newly developed railways, empty land tracts. As prices rose and fell, she sometimes cleared as much as two hundred thousand dollars in a single day, and unlike Ponzi, she did so both honestly and legally. It is a feat that would be considered spectacular even now, 130 years later. Everyone agreed that Hetty had flair, even a kind of genius, for investment opportunities. The money that she had started with, inherited and left to her in trust, hardly increased over all those years due to poor management and ended up being a tiny, almost unnoticeable part of her gigantic fortune, one of the largest that America had ever seen.



Green Hall, Wellesley College
When Hetty Green died in 1916, her fortune passed to her son and her daughter, both childless. Upon their deaths, it filtered away in gifts to individuals and associations, universities, libraries, and charities. Wellesley College’s Green Hall in Massachusetts is the only public building actually named for Hetty. Partly because her children did not leave many legacies specifically in her name, it has been largely forgotten in comparison with the other unforgettable makers of fortune of her time: Carnegie, Morgan, Rockefeller. But Hetty had always wanted a modest life and probably would prefer it this way.
IN THE 150 years that have elapsed since the trial, it has become pretty widely accepted that Hetty did forge her aunt’s signature on the famous second page. But is it true? If she did, one wonders, for example, why Sylvia would have kept the first will in her house instead of simply destroying it.
When Hetty presented the first will and the famous letter to the court, the two pages were pierced with tiny holes around the edges. Hetty explained that they had been sewn together, face-to-face, so as to discourage the curious, by which she meant Sylvia’s companions, nurses, and servants—Hetty’s sworn enemies. If that were true, however, she would have been wiser to show these sewn papers to those same sworn enemies at the very moment when she extracted them from Sylvia’s old trunk, so that she would have witnesses to their existence. Instead, she carried the papers home to examine them by herself. It is a suspicious circumstance, yet one that corresponds to the controlling, power-hungry element of her personality.
At no time in her life, subsequently, was Hetty ever accused of any kind of cheating or dishonesty. She was known for many colorful character defects, but certainly not that one. Nor did she ever admit to the forgery of which the court’s judgment implicitly accused her. For that matter, it is important to note that she was never formally accused or brought to trial for that forgery, not even by Thomas Mandell or Dr. Gordon, the executors of Sylvia’s will, who had every reason to execrate her. No one will ever know the truth.
Hetty’s subsequent history does show, however, that whether she cheated on a gamble and lost, or whether she was actually defrauded of something that was legally hers, everything that happened worked out for the best, financially. Without overcoming the frustrations and obstacles that forged her character, Hetty Green would probably never have become the legendary witch of Wall Street, female tycoon.
 
*On top of this, Holmes is still known today as the discoverer of the fact that the puerperal fever, which caused the death of thousands of new mothers in hospitals all over the country, was spread from one mother to another by the hands of the physician attending to her. It is thanks to Holmes that doctors now routinely sterilize their hands, clothing, and instruments. This theory caused considerable furor in the obstetric milieu when Holmes first published it, as many doctors were angry about being accused of having killed their patients through lack of hygiene. But Holmes, having studied hundreds of cases of puerperal fever and its spread, knew that he was right and implored the world to heed his words: “I beg to be heard on behalf of the women whose lives are at stake, until some stronger voice shall plead for them.”
*This formula is given by 861 × 

(1/5)n(4/5)(30-n), where 

 is the binomial coefficient for each number n between 0 and 30.

MATH ERROR NUMBER 10 »
MATHEMATICAL MADNESS
LIKE THE “INCREDIBLE COINCIDENCE” in Math Error Number 7, the error addressed in this chapter involves the likelihood of an unlikely event occurring, except that here we deal with the case where an event occurs several times, rather than just once as in the lottery example. This error consists in calculating the probability, for instance, that some relatively rare event will happen ten times, but forgetting that those ten “successes” were the result of one hundred attempts. For example, before being amazed that your friend shot five arrows into the bull’s-eye, you might want to count how many arrows he shot into the colored rings and the surrounding wall. The fewer total arrows he shot altogether, the more impressive his performance; if he shot a hundred arrows or more, it becomes less of an achievement.
The website www.anxieties.com has a page devoted to overcoming a fear of flying. While the site’s goals are laudable, it is unfortunate that such misleading passages as the following are used to reassure people:
Dr. Arnold Barnett, of the Massachusetts Institute of Technology, has done extensive research in the field of commercial flight safety. He found that over the fifteen years between 1975 and 1994, the death risk per flight was one in seven million. This statistic is the probability that someone who randomly selected one of the airline’s flights over the 19-year study period would be killed in route [sic]. That means that any time you board a flight on a major carrier in this country, your chance of being in a fatal accident is one in seven million. It doesn’t matter whether you fly once every few years or every day of the year.
Apart from the facts that the period from 1975 to 1994 does not comprise fifteen years, that the term “the airline” seems to contradict “a major carrier,” and that Dr. Barnett’s research appears to be valid only for flights originating in the United States, this passage contains a major mathematical flaw. Try replacing “boarding a flight” with “playing Russian roulette” and the probability of “one in seven million” with “one in six.” The last part of the passage now reads: “Any time you play Russian roulette, your chance of being in a fatal accident is one in six. It doesn’t matter whether you play once every few years or every day of the year.” Is “one in six” really the right figure to consider here? Does it really not matter if you play Russian roulette once every few years or every day of the year?
How do you calculate the probability of getting a particular result several times over a given number of tries? Imagine you roll dice against a partner 6 times, and 3 of those times he rolls a six, with the end result that he wins the game and carries off the stakes. Rolling a six 3 times may seem so extra lucky, so unlikely to occur naturally, that you might be tempted to accuse your gaming partner of having a loaded die. Before accusing him of cheating, however, a little calculation is in order. Exactly how unlikely is it? The only way to answer this is to calculate the probability that in 6 rolls of dice, we land exactly 3 times on the number six.
There is a 1/6 chance of landing on six, and one common error would be to conclude that the probability we are looking for is (1/6)3 = 1/216. Such an error is what makes coincidences appear so much less likely than they really are. In fact, 1/216 is not the probability of throwing 3 sixes in 6 tries—it’s the probability of throwing 3 sixes in 3 tries! Most people correctly intuit that one is more likely to roll 3 sixes in 6 tries than to roll 3 sixes in 3 tries, and indeed the probability of the former is equal to 20/216, or a bit less than 1/10.
And what if your friend had thrown not 3, but 4, 5, or even 6 sixes? The probability one should compute to see if cheating has occurred is the sum of the probabilities for each of these increasingly unlikely possibilities. As it turns out, the probabilities for 4, 5, or 6 sixes occurring in 6 rolls of a die are tiny, but they make a difference: the probability of throwing 3 or more sixes in 6 tries is not slightly under, but slightly over 1/10. In other words, such a result can be expected to occur reasonably often.
The incriminating witness in one of the most famous trials of the nineteenth century made exactly the error described above, and it took ten years and a team of the greatest mathematicians of the time to convince the world that it was wrong.
 
 
The Dreyfus Affair: Spy or Scapegoat?
December 22, 1894: Alfred Dreyfus, a captain in the French army, is tried by court-martial and declared guilty of high treason by the unanimous verdict of a jury of seven officers, who sentence him to life imprisonment in perpetual isolation on Devil’s Island, a disease- and mosquito-infested rock off the coast of French Guiana.
The incriminating evidence: the “bordereau,” an unsigned letter found in the wastebasket of Maximilian von Schwartzkoppen, military attaché at the German Embassy, offering to sell him certain French military documents given in the form of a numbered list.
The main witnesses for the prosecution: Major Armand du Paty de Clam of the army’s secret service, who, charged with obtaining a sample of Dreyfus’ writing to compare to the bordereau, tells the jury how Dreyfus’ fingers trembled as he came into the room, revealing a guilty conscience,* while at the same time his calm demeanor betrayed the emotional mastery of a practiced deceiver. Du Paty’s colleague Major Hubert-Joseph Henry, who recounts how the discovery of the bordereau exposed the existence of a spy within the army, and then, at a loss for further proof, flings his arm dramatically in the direction of the accused, bellowing “And the traitor is—here!” And finally, five handwriting experts, two of whom claim that the bordereau could not have been written by Dreyfus, while the other three claim that it was.
The secret: a file transmitted illegally to the jury of officers during their deliberations, a file containing papers apparently so sensitive that for reasons of state security they could not be shown to the accused or to his lawyer. One of the documents—a letter from an Italian military attaché, Alessandro Panizzardi, who was involved in an intense homosexual affair with the German Schwartzkoppen (addressing him as “Maximilienne” and signing his letters “your Alexandrine”)—contained a reference to someone he called “that scoundrel D.” The others were months-old reports from police informers, carefully modified just before the court-martial to add intimations that the police knew about a French spy delivering material to the Germans.
The facts no one mentioned at the trial: Dreyfus was an Alsatian at a time of French suspicion and resentment of Germany, which had annexed the region of Alsace in 1871. Moreover, he was Jewish at a time of rampant anti-Semitism. It also happened that Dreyfus was an intensely patriotic man, imbued with a deep sense of personal honor. But under the circumstances, that characteristic was ignored, or worse, taken as an insincere pose. After all, Dreyfus was the ideal outsider, and therefore the ideal spy. Or the ideal scapegoat.
ALFRED DREYFUS was subjected to a public degradation ceremony that has lingered in France’s collective memory as among the nation’s most shameful moments. While Dreyfus repeatedly protested his innocence and proclaimed his love of his country, an adjutant of the Republican Guard broke his sword, tore the epaulettes and buttons from his uniform, and flung them to the ground. All of this was accompanied by screams of “Kill the traitor!” and “Hang the Jew!” emanating from the crowd pressed up against the wrought-iron grilles enclosing the courtyard. Soon after this, the disgraced captain was transferred onto a boat and locked in a barred cell on deck, open to the freezing February winds of the Atlantic. It took the boat two weeks to arrive at Devil’s Island.
During the four years that Dreyfus spent on that tiny, sweltering, fever-infested rock, he was the only prisoner there, living in a bare hut under twenty-four-hour surveillance by guards with whom he was not allowed to exchange a single word; deprived of even the basic utensils with which to cook and wash; forbidden to approach the sea (let alone bathe in it); and kept in total ignorance of the efforts being made on his behalf by his wife, Lucie, his brother Mathieu, and his friends. As events in France escalated, Dreyfus was treated with increasing harshness. False reports of an escape attempt that were circulated in French newspapers led to his being shackled to his bed at night by iron rings, and to the construction of an enormous fence around his hut that cut off his view of the sea and restricted his movements to a small rectangle devoid of vegetation. Although Lucie was allowed to write to him and he to her, their letters were censored and delivered months after they were sent. When he was ill, which was most of the time, Dreyfus was allowed to be examined by a doctor from the mainland, but was then forbidden to follow any of the doctor’s recommendations concerning diet, hygiene, and sea bathing. His brother attempted to improve his diet by arranging for a shopkeeper in Cayenne to send over canned goods, but the shopkeeper was so harassed by police that he gave up the project.
Except during moments of particular courage, Alfred Dreyfus believed that he was going to die on Devil’s Island. Forbidden to receive any news, and ignorant of the enormous effect his case was having on French politics and society, he had to content himself with writing letter after letter to everyone—from his wife, Lucie, up through the chief of the general staff to the president of the Republic, protesting his innocence and begging that the true traitor continue to be hunted. Apart from Lucie, he received no replies.
Actually, the true traitor was being hunted—not by the government, or by the army, but by Lucie and Mathieu Dreyfus with the help of the few public figures whom they had managed to convert to their cause. But even as the net drew closer around him, Major Charles-Ferdinand Walsin-Esterhazy, the true author of the bordereau, didn’t turn a hair. A freewheeling and pleasure-loving scamp, he didn’t let the uproar around Dreyfus bother him, but continued lightheartedly with his usual behavior, which consisted of any activity that might earn him a few francs, including gambling, cheating, begging, and informing—as well as spying—along with the frequent seduction of women, particularly the mistresses of his friends.
If the arrest and condemnation of Dreyfus had stopped Esterhazy in his tracks, it is possible that the truth might never have emerged. But Esterhazy didn’t know that the document that had convicted Dreyfus was the bordereau written by his own hand; the document had been kept secret so that only Dreyfus, his lawyer, and the judges and witnesses at the court-martial had been allowed to see it. So Esterhazy kept up his amateurish spying activities, which brought such insignificant documents to the German Embassy that finally Schwartzkoppen had enough of them. The German officer penned a telegram (handwritten, in those days, on special thin blue paper) informing his correspondent in thinly veiled language that without some more useful information, their relations might not be worth continuing.
He addressed the telegram (le petit bleu, as the little blue telegraph papers were called) to Major Esterhazy by name, but then, perhaps regretting the severity of his language, he ripped it to shreds, dropped it in his wastebasket, and sent off another, gentler version. The shreds were gathered up by the cleaning lady, who delivered them as usual straight to the offices of the French army’s secret service.
The head of the secret service who had presided over the Dreyfus affair had recently retired. Major Henry was eager to replace him but had been passed over in favor of Colonel Georges Picquart, an Alsatian known for his rigor and honesty. The army would bitterly regret this decision later, as Picquart, or Picquart’s probity, turned out to be an unexpected thorn in their side.
Picquart had been one of the two government observers allowed to remain in the room when Dreyfus’ trial was declared closed to the public. He had presided at the ceremony during which the condemned traitor’s military insignia were publicly torn off and broken. He had not questioned Dreyfus’ guilt for a single moment. Nor did he do so even when the little blue telegram, its thirty or forty shreds attached together with thin bands of transparent paper, was brought to his attention. His first thought was that there must be a second spy at work. But unlike the previous case, here he had a name to go on, and nothing more to do than to keep an eye on Major Esterhazy in order to catch him in the act. In an effort to determine the extent of his spying activities, Picquart had Esterhazy followed, his flat searched, and his mail intercepted. Thus, a couple of letters written by Esterhazy ended up in Picquart’s hands. And when he saw them he received a tremendous shock. He recognized the handwriting. It was exactly that of the bordereau. Not similar, or somehow related, as Dreyfus’ handwriting had seemed. He set the two documents side by side, Esterhazy’s letter and the bordereau, and stared at them.
“I was horrified,” he later wrote. “They were not just similar. They were identical.”
In the months since Picquart had become head of the secret service, he had never once asked to look at the file that had been secretly communicated to the judges at the Dreyfus trial during their deliberation and that, as rumor had it, had tipped the balance of the verdict to guilt. But he asked for it now and looked inside. He saw one letter referring to someone as “that scoundrel D.” He saw some police reports that obviously had been modified to make vague reference to a spy somewhere. That was all he saw. There was nothing else to see.
Picquart summoned handwriting expert Alphonse Bertillon, head of the judicial identity department of the police, who had testified with the utmost certainty that the handwriting of the bordereau was that of Dreyfus, giving what he called an absolutely mathematical proof. Picquart showed Bertillon the bordereau and Esterhazy’s letter, with the signature hidden, and asked him what he thought.
“Those were written by the same person,” said Bertillon at once.
“But this is a letter that was written very recently,” Picquart informed him.
“Well, then,” came the immediate response, “the Jews must have been training someone to write exactly like this for a whole year!”
ALTHOUGH PREJUDICED and perhaps a little mad, Alphonse Bertillon was no idiot. He founded the first police laboratory in France for criminal identification and invented some remarkable methods for identifying repeat criminals. Indeed, it was particularly easy in the nineteenth century for a convicted murderer to leave prison, change his identity, and strike again, and extremely difficult to prove that he was the same person as the previous convict. Until the early part of the nineteenth century, physical branding of prisoners had served as a method for identifying repeat offenders, but its abolishment in 1832 left the police with a serious problem. In response, Bertillon invented the ingenious method of “anthropometry,” which consisted in taking fourteen precise measurements of the body of every convicted criminal, measurements that, he claimed, could identify any person in a population of 300 million. By writing down the measurements of every criminal in his or her police file, he was able to identify certain repeat offenders, such as the elusive “Ravachol,” an anarchist responsible for innumerable deaths by bomb explosions in and around Paris. A few years later, in 1902, Bertillon was the first police investigator ever to identify a murderer by the fingerprints that he had left on a smashed windowpane.
Bertillon was not a specialist in handwriting analysis, but when the army invited him to contribute his expertise to identifying the author of the bordereau, he flung himself with zeal into the task. To prove that it could be no other than Dreyfus, he built up an extraordinary, well-argued theory that Dreyfus had purposely forged an imitation of his own handwriting so that if he were caught, he could attempt to explain away any evidence against him by claiming he had been framed. Bertillon decided that the method used by Dreyfus to imitate yet disguise his own handwriting consisted of tracing over certain of his own words or parts of words from other letters and documents, and certain words written by other members of his family. He also asserted that there was far more to the bordereau than the rather anodyne information it contained. Certain unexplained dots on the page were separated from each other, he claimed, by a distance that was exactly one one-hundred-thousandth part of a distance found on important and secret military maps. Then there were some apparent pinpricks or irregularities in the paper, which he interpreted as the places where Dreyfus had pinned the thin onionskin paper over the other documents to trace their words. Various other features of the bordereau indicated a definite method or code, intended to transmit a great deal more information than the written words. In pursuing this direction, Bertillon applied his own personal version of probability theory to reliable studies made by real experts in the field of military cryptography and code breaking.
From these studies he gleaned two important pieces of information. One was that coded messages are sometimes written using a “key,” which at that time often consisted of a single secret word written again and again. The other was that the seven letters that appear most frequently in French writing are e, n, a, i, r, s, and t.
Having noticed that the words intéressants and intéresse in the bordereau appeared in handwriting similar to a copy of the word intérêt that he found written in a letter on Dreyfus’ desk at home, and that this particular word contains five of the seven most common letters of the French alphabet, he made some tests on the possibility of the word intérêt being the key on which the whole bordereau was built.
He traced the word intérêt from the letter from the desk repeatedly along the lines of a piece of white paper, with no spaces between the words:
Intérêtintérêtintérêtintérêtintérêtintérêtintérêtintérêtintérêtintérêtintérêt
Then he placed the semitransparent bordereau over it. To his amazement, he saw that many of the letters in the bordereau exactly overlaid the letters in his “key,” although of course most did not. He noticed that if he shifted the bordereau over by a little more than one millimeter, the letters that fit previously no longer did so, but a large number of those that hadn’t fit now did. So he made two keys, one in red and one in green, which were identical except for the thin vertical lines he drew on them, the same distance apart as those of the bordereau.
When he placed the bordereau over the red key with the vertical lines matching up, many letters were overlaid and many others were not properly placed. When he laid it over the green key, the same thing occurred, but with different letters, of course. The two keys were identical except that all the vertical lines were very slightly displaced.
Bertillon then counted the letters e, n, r, t of the bordereau that overlaid the exact same letters in the word intérêt on the two keys underneath. He was astounded and delighted to discover what he considered an enormous number of these “coincidences,” far beyond, as he said, what the probability calculation would justify. In his report to the court, he wrote:
Instead of being found to lie on top of the t of intérêt 7 times, it is found 15 times; on the first é, instead of 26, one finds 40, on the r, 20 instead of 9, on the second ê, 39 instead of 19, on the final t, 10 instead of 6. The n is an exception since instead of finding 11, one finds only 10, but in reality, they are placed over the r, since n is almost always preceded and followed by a vowel which is placed over the e. Indeed, on top of the r, instead of finding 8, we find 17.
Such methods may appear of dubious utility, but in Bertillon’s mind, the high probability figures gave rise to a strong suspicion of tracing.
The expected probabilities of 7, 26, 9, 19, 6, and so forth were calculated according to the frequency of occurrence of those letters in the key. Consider, for example, the letter t. The bordereau contains about 800 letters, and 49 of them are t’s. Since two of the letters in the word intérêt are t’s, one would expect to find 2/7 of the 49 t’s in the bordereau lying over t’s in the key, making about 14. Of these, one would expect about half of them, 7, to lie over the first t in intérêt. Instead, Bertillon found 15.
Similarly, there are about 60 r’s in the bordereau and only one in the word intérêt, so one would expect to find 1/7 of those r’s from the bordereau lying over an r in the key, which is 8 or 9 r’s. Instead, Bertillon found 17. The French analyst was wildly excited by this discovery and became absolutely convinced that his key had been used to write the message.
The fallacy of Bertillon’s reasoning is incredibly simple, yet it was not revealed until 1904 by three famous French mathematicians: Henri Poincaré, Paul Appell, and Gaston Darboux. They pointed out that when Bertillon used a single key, say the red one, he found about the expected number of correspondences (same letter over same letter). But he did not want to count only these, because too many of the letters in the bordereau were not even superimposed over letters of the key at all, let alone the correct letters. The only way to get all the letters of the bordereau to be superimposed over letters of the key was the way he did it: two identical keys, one red, one green, slightly shifted with respect to each other. What Bertillon failed to realize is that by using two keys, he was doubling the probability of coincidence of certain letters lying over the same letters.
Think about it for a moment. If you take the two copies of the key and shift one of them over by about one letter, and then you count every time an r of the bordereau appears over an r of the red key, or an r of the green key—the r’s of those keys never being on top of each other, because you’ve shifted the whole key over by about one place—you are simply counting double the number of r’s.



Just take the example above, looking at the last line of the bordereau, Je vais partir en manoeuvres.
This sentence contains three r’s. Using the top key, the r of “manoeuvres” corresponds to an r of the key. Using the bottom key, it no longer corresponds, of course, but now the first r of “partir” corresponds to an r of the key.
Using a single key, one r out of three corresponds to the key, which is close enough to the expected one out of seven, given that there are only three r’s in the sentence anyway. But counting both keys, we find that instead of the expected one r out of seven, we get two-thirds (two out of three) r’s corresponding. This is obviously much higher than expected. If this happened for every letter, we should start feeling suspicious—until we realize that it simply happened because we’re using two keys, not one, and thus doubling the probability.
BERTILLON’S TESTIMONY contributed to Dreyfus’ conviction. It was years before the details of Bertillon’s analysis were examined closely. In the meantime, Dreyfus’ family and supporters continued to fight against all odds for recognition of his innocence. Thanks to their efforts, the story eventually gained such a high profile that it reached the dimensions of a national crisis. One of the most important architects of that crisis was Colonel Picquart, who realized—on sight, with no need for either expertise or calculation—that the handwriting on the bordereau belonged to Esterhazy, not to Dreyfus.
Less convinced by Bertillon’s explanations than by the evidence in front of his eyes, Picquart went to his army superiors, Generals Charles Arthur Gonse and Raoul Le Mouton de Boisdeffre, and to the minister of war. He was anxious to share with them the two pieces of news he had discovered: the existence of an active spy whose identity was actually known, and the innocence of Alfred Dreyfus.
To Picquart’s shock, he discovered that his superiors had no desire to acknowledge that the army had been guilty of a miscarriage of justice. Instead of receiving praise and honor, instead of securing the real spy’s immediate arrest, Picquart found himself dispatched on a long trip to the south of France, with multiple duties to keep him busy, and then on to Tunisia for an indefinite length of time. Major Henry took over Picquart’s duties during his absence, and it was made quite clear to the major that his role was to calm what could potentially grow into a large storm.
Only too willing to help, Henry took home some of the papers that had been found in Schwartzkoppen’s wastebasket, and with the help of his wife, did a little “cooking”—that is to say, a little cutting, a bit of forging, a dash of imitating, and a dose of tearing off bits of paper and reattaching them differently. What resulted was a “letter” to Schwartzkoppen whose beginning and whose signature, “Alexandrine,” were legitimate—ripped from a real letter to Schwartzkoppen from the Italian spy Panizzardi—but whose body contained a sentence straight out of Henry’s head, about how they must never ever admit to having had any dealings with the Jew Dreyfus. Henry took care to write the name Dreyfus out in full. After all, it didn’t appear in a single other document involved in the case.
Henry showed this letter to Generals Gonse and Boisdeffre, his superiors and Picquart’s, and they were pleased. History does not recount whether or not they fully realized what the major had been up to, but in any case they probably avoided even asking themselves the question. They made a careful copy of the letter by hand, signed it with their names and ranks, and added it to the file for anyone who might care to have a look. The original fake was put in a different file, a secret one.
All this time, Dreyfus was suffering on Devil’s Island, writing letters and struggling with severe illness and depression; Picquart was traveling from place to place and worrying about what he should do; Esterhazy was gambling, cheating, stealing, and spying; and Lucie and Mathieu Dreyfus were knocking on doors trying, with little success, to drum up sympathy for their cause. But no one cared. No one was thinking about Dreyfus yet; the country had other concerns.
Then a friend suggested leaking news of an escape attempt to the newspapers in an attempt to bring the story back to the front pages. The maneuver worked to gain publicity, but it also backfired badly, as a spate of virulent anti-Semitic articles followed, and the aforementioned punishments were inflicted on Dreyfus on his lonely island. The idea would have been a catastrophe but for one important consequence: in the heat of the moment, one person saw a way to make a little money. One of the handwriting experts who had testified at the trial still possessed the photograph of the bordereau that he had worked on, and he sold it to a newspaper, which printed it.
For the first time, Lucie Dreyfus saw with her own eyes the document that had convicted her husband. She saw that the handwriting, although similar, was not her husband’s, and she saw black-and-white proof of the terrible injustice that had been committed against him. She and Mathieu hatched a simple but effective plan. They had the bordereau printed on thousands of flyers, together with a sample of Dreyfus’ own handwriting and a declaration of his innocence, and distributed them all over Paris, where they were sold at newspapers stands in the manner of the British broadsheets of the nineteenth century.
Their tactic bore fruit. In November 1897, a stockbroker happened to buy the flyer and immediately recognized the handwriting of one of his clients. He contacted Mathieu Dreyfus and showed him correspondence from Major Esterhazy. Mathieu sat down and studied it letter by letter, comparing the dotting of the i’s, the turning of the s’s, the crossing of the t’s with those of the bordereau. When he got up, he, too, knew the name of the real traitor.
BEFORE THIS discovery, the truth about Esterhazy had been known only to a select group of people. There were those who were informed by Colonel Picquart, namely Generals Gonse and Boisdeffre and General Jean-Baptiste Billot, the minister of war, and the two devoted underlings, Majors du Paty de Clam and Henry, who had been instrumental in Dreyfus’ condemnation. Apart from these, only two others were aware of the situation: a close friend of Picquart’s, the lawyer Louis Leblois, and another important member of the government, who was informed by Leblois reluctantly but as a matter of conscience when he came to realize that Picquart was being purposely maintained at a distance. This was the situation when the name of the traitor was discovered by Mathieu and Lucie Dreyfus, and it was at this point that Gonse, Billot, du Paty, and Henry made the decision to “save the country,” which meant going to any length necessary to prevent the judicial error against Dreyfus from coming to light. Thus, it was decided among the four military officers that it was necessary to fatten up the secret file containing proof against Dreyfus.
This task was again left to Major Henry, who—willingly, if rather crudely and incompetently—modified dates and names in a number of compromising documents taken from Schwartzkoppen’s wastebasket to make them appear older than they really were. At the same time, Henry amused himself by writing anonymous spy-style letters about “secret combinations,” “hidden documents,” and “the Syndicate” (by which term he referred to a supposed Jewish lobby seeking to free Dreyfus and destroy the army) and addressing them to Dreyfus on Devil’s Island. He then arranged for them to be intercepted and “discovered” en route. And in case Colonel Picquart was intending to return to Paris and tell his side of the story, Henry addressed a few telegrams in a similar style to him, so as to be able to accuse Picquart of engaging in spying activities himself if it should become necessary to discredit him. Unfortunately for Picquart, he had a married mistress at the time who also wrote him secret letters, which were mailed by a mutual friend and contained a similar type of veiled reference. Having taken to intercepting all of Picquart’s correspondence, Henry soon discovered this affair, and it made him all the happier. But even this was not enough.
The conspirators decided that Esterhazy must be protected at all costs, for if his guilt were known, then the truth about Dreyfus’ innocence—and the army’s error—would follow, causing irreparable harm to the country’s integrity and prestige. And so began a process unheard of in the annals of political history: members of the government began aiding and covering up for a known spy. The indefatigable Majors du Paty de Clam and Henry took to arranging meetings with Esterhazy in secret nooks and shady corners. They encouraged him to write to the president of the Republic declaring his innocence. They even gave him papers from the Dreyfus file and helped him write letters to the government in which he declared that Picquart was leaking or selling these top-secret papers, and virtually demanded ransom in protective measures in order to return them.
Under normal circumstances the aggressive blackmail that Esterhazy addressed to Félix Faure, president of the Republic, would have landed him in jail. Instead, he was surrounded by a halo of honor. Esterhazy and his helpers also spread rumors that he was being framed as a substitute for the traitor Dreyfus by the Jewish lobby, but that he was being aided in secret by a veiled lady who delivered valuable papers to him out of undeclared love. Newspapers published letters defending the base attacks by the so-called Syndicate against the honorable soldier Esterhazy. Meanwhile, press friendly to Mathieu Dreyfus printed articles calling for a revision of the Dreyfus trial, a reexamination of the handwriting on the bordereau, and a public rendering of the true circumstances of his conviction.
Slowly but surely the situation began to heat up as people started questioning the prevailing story. There were rumblings in Parliament. Famous journalists and writers began to shift their sympathies. Public opinion became starkly divided between those who were horrified by the jingoistic nationalism and blind respect for authority that were leading the government into denial of an obvious error and those who saw the case as an example of how the Jewish element was undermining and rotting the country from within, trying to save one of their own by smearing a good and honest soldier.
Esterhazy decided to seize the bull by the horns and demanded a court-martial to prove his innocence. The generals happily accepted, hoping to put the matter to rest once and for all. However, all did not go as smoothly as they had hoped. During the lead-up to the trial, the press made public numerous pieces of information that could have potentially destroyed their case.
First to appear was the letter that Major Henry had forged on the part of the Italian military attaché Alessandro Panizzardi. Panizzardi publicly denied writing it and demanded to be heard as a witness at the trial. This caused a moment of agitation for the conspirators, but the army found a solution in refusing to hear him on the grounds that as a known spy, nothing Panizzardi said could be believed.
But then the newspapers began expressing passionate interest in the testimony of Colonel Picquart, who had been recalled to Paris as a witness. This seriously worried the generals, but they decreed that his testimony would be “dangerous to public safety” and must therefore be held behind closed doors. Once again, danger was averted and all was under control.
But now, to the horror of Esterhazy and his supporters, a former mistress of Esterhazy’s, who had turned against him because he had stolen and dilapidated most of her modest fortune, gave the newspapers a series of letters he had written to her fifteen years earlier, expressing contempt and hatred for the French army and the French people! “Paris, stormed, defeated and delivered to the looting and pillage of a hundred thousand drunken soldiers—that is a celebration I dream of!” he had written in some kind of wild delirium of anger. “I would never hurt a little dog, but I would have a hundred thousand French people killed with pleasure!” This letter—the worst of a bad lot—was published in the daily newspaper Le Figaro the very next day.
Esterhazy panicked and initially claimed it was a forgery. But when his former mistress revealed that she had a great many other similar ones, he backpedaled, admitting that he had written the letters, but insisting that the above passages had been added by a forger’s hand. The anti-Dreyfus journalists were embarrassed and fished desperately for excuses. One described the letters as the product of a “bitter, exalted nature in an access of anger.” Another claimed that the letters had no relation with the spying affair anyway and should be ignored. A third criticized the “nasty woman who sold for money the letters that her officer friend had written to her in trusting confidence.”
The generals hastily hired some friendly handwriting experts and waited tensely for their conclusions, which soon emerged as hoped: the looting letter was declared to be merely an imitation of Esterhazy’s handwriting. There was no need to openly name the Jewish “Syndicate” as the instigator of these forgeries. Everyone knew what everyone else was thinking.
Esterhazy’s court-martial opened to a packed hall. Esterhazy was interrogated and responded to all questions with his head held high in the role of the noble and unjustly slandered officer. Picquart testified behind closed doors; he told his story, but only the generals heard it. Majors Henry and du Paty de Clam and their assistants swore that they had seen Picquart in his office, fabricating forged papers and discussing the secret file with his friend Leblois, and that Picquart had asked them to lie. Esterhazy’s lawyer gave an impassioned five-hour speech in his defense.
After a three-minute deliberation, Esterhazy was acquitted and carried in triumph back to the jail, from which he was released in an organized ceremony. Hundreds of spectators lined the street. A powerful bass voice was heard to shout, “Hats off to the martyr of the Jews!” Heads were uncovered up and down the street, all the way to the back of the crowd. The next day, Colonel Georges Picquart was arrested and sent to prison.
THE ARMY had won yet again. But this time their triumph appeared so egregious that it raised the indignation of a larger group of protesters than before. Most noticeably, the ranks of the Dreyfus supporters were joined by the highly successful author Émile Zola, who suddenly leaped into the fray with a panache that no one associated with the case had yet been able to muster.
J’ACCUSE! . . .
The headline blazoned across the newspaper the day after Esterhazy’s acquittal. And the article that followed, actually an open letter to the president of the Republic, contained an astoundingly accurate description of the mechanisms at work behind the twists and turns of the case, written in a language the incisive and inflammatory power of which could only have been produced by a truly great writer.



Émile Zola, the accuser
Zola’s “J’accuse” remains one of the seminal texts of French literature. On the hundredth anniversary of its publication, a copy of the text two stories high was hung on the National Assembly building in Paris. Entering the words “j’accuse” into Google will bring hundreds of thousands of hits leading directly to Zola’s unforgettable words. After describing his view of the case and the danger of dishonor that hung over the country, Zola ended the article by pointing his finger directly at those he considered the guiltiest.
I accuse Lt. Col. du Paty de Clam of being the diabolical creator of this miscarriage of justice—unwittingly, I would like to believe—and of defending this sorry deed, over the last three years, by all manner of ludicrous and evil machinations.
I accuse General Mercier of complicity, at least by mental weakness, in one of the greatest iniquities of the century.
I accuse General Billot of having held in his hands absolute proof of Dreyfus’s innocence and covering it up, and making himself guilty of this crime against mankind and justice, as a political expedient and a way for the compromised General Staff to save face.
He goes on to address others complicit in the crime, including Generals Boisdeffre and Gonse, the handwriting experts who examined Esterhazy’s letter, the War Office, the first court-martial for convicting Dreyfus on secret information, and the second one for knowingly acquitting a guilty man. His project is not mere finger-pointing, but rather the search for truth:
As for the people I am accusing, I do not know them, I have never seen them, and I bear them neither ill will nor hatred. To me they are mere entities, agents of harm to society. The action I am taking is no more than a radical measure to hasten the explosion of truth and justice.
I have but one passion: to enlighten those who have been kept in the dark, in the name of humanity which has suffered so much and is entitled to happiness. My fiery protest is simply the cry of my very soul. Let them dare, then, to bring me before a court of law and let the enquiry take place in broad daylight! I am waiting.
As Zola had anticipated and indeed desired, the War Office sued him for slander, and in February 1898 he was sent to trial. Together with his lawyers and the increasingly large group of influential intellectuals supporting the cause of innocence, he worked to turn his own trial into a trial of the army. Two hundred witnesses were summoned; every single person associated with the case in any way was called to the stand. The country’s best experts from schools devoted to the study of manuscripts testified that the handwriting of the bordereau was Esterhazy’s. Alphonse Bertillon alone testified to the contrary, repeating his “geometric” theory, but it was so complicated that some members of the public were actually heard laughing incredulously.
Colonel Picquart was brought from his prison cell for cross-examination and told the court the story of the discovery of the petit bleu, of how he had realized first that Esterhazy was a spy, and then that he was the author of the bordereau. He also related how he had informed his superiors of his findings only to be sent away, and had subsequently become the victim of a campaign of lies and harassment ending with his arrest.
Major du Paty de Clam—now promoted to lieutenant colonel—testified, Major Henry testified, the generals concerned in the case were questioned, and Esterhazy came to testify. Hundreds of questions were blocked by the judge, who intervened before the witnesses had time to respond with the oft-repeated words: “The question shall not be asked.” For the questions that were allowed, the witnesses all invoked the necessity to remain silent in order to protect the country’s safety. Esterhazy himself, after filling the newspapers with inflammatory exclamations about “something” he was going to do that would “fill the streets of Paris with corpses!” was compelled to remain silent in obedience to his protectors in the army. He listened without response to the increasingly pointed questions about whether he was the author of the letter to his former lover, where he obtained his money, whether he had known Schwartzkoppen, whether he had written the bordereau, and whether he had ever been paid for spying, all while gripping the bar with white-knuckled hands. The generals avoided answering all direct questions by invoking the higher interest, the honor of the country, national security, and the necessity of preserving the good name of France on the international scene.*
One of the fieriest generals ended the trial by giving a speech evoking the terrifying consequences that a lack of confidence in the army would have on the nation.
Then what do you expect the army to be, on the day of danger, which may come sooner than you think? What do you want the poor soldiers to do, led into battle by chiefs that have been discredited in their eyes? Our sons will be led into a butchery, members of the Jury! But Mr. Zola here, he will have won his own battle. He will write a book about the defeat—he will transport the French language into every corner of the universe—and France will have been struck off the map on that day!
The public was on its feet. The jury was in tears. It took them just thirty-five minutes to convict Zola.
Condemned on appeal to a year in prison, Zola fled to England, where he was homesick and miserable. The army breathed a sigh of relief. The pro-Dreyfus forces were in disarray, and it seemed unlikely that they could regain their lost terrain in the face of massive public disapproval. Partly due to the Dreyfus affair and the giant wave of anti-Semitism it unleashed, the May 1898 parliamentary elections swept a powerful reactionary, nationalistic, anti-Semitic, and anti-Dreyfus faction to power. The year 1898 saw an incredible polarization of society as people took sides on the issue, fracturing the country down a line that cut across distinctions due to social class, profession, or age. A famous newspaper drawing from 1898 shows two scenes from a family dinner, the first with the caption, “Welcome! Let’s not talk about the Dreyfus affair,” and the second, “They talked about it.”
Around this time General Billot, the minister of war who had overseen every phase of the Dreyfus affair, was replaced by the willful and charismatic Godefroy Cavaignac. Cavaignac was appointed because of his intransigence, his ability to influence people by sheer force of will, and his staunchly anti-Dreyfus position. But General Billot and the military elite who had been involved in the affair did not realize what trouble such a personality could bring.
In the end, it was the same indomitable will that had made Cavaignac so attractive to the government, that desire to have full control, that brought the whole house of cards down. Irritated by the continued public words and actions of the reduced but vocal group of Dreyfus supporters, Cavaignac announced his intention to put a smashing end to the entire affair. His first idea was to organize a massive trial in which every notable Dreyfusard, from Lucie and Mathieu to Zola and Picquart, together with all the lawyers who had worked for them, and all Dreyfus-friendly journalists and newspaper editors, were to be publicly accused of treason and of conspiring against the good of the country.
Horrified, the army convinced Cavaignac that this project, far from settling the question, would open a Pandora’s box too dangerous to contemplate. But he was not in on the whirlpool of cheating, lying, and forgery that had swirled ceaselessly around the case. He believed sincerely in Dreyfus’ guilt and in the possibility of obtaining totally incontrovertible proof. Foiled in his grandiose plan, he next decided to go through the Dreyfus file, pick out the most convincing documents, and make them public. He demanded the file and had it examined, classified, and labeled by a young and devoted officer called Captain Cuignet. Cavaignac wanted to see everything, and by now, thanks to Major Henry’s indefatigable efforts, there were well over a thousand documents, which filled ten boxes.



They talked about it
He picked out the three documents he considered absolutely damning, and over the weak and slightly desperate objections of Generals Billot, Gonse, and Boisdeffre, he triumphantly carried them into the Chamber of Deputies and read them aloud from the tribune. One was the original “that scoundrel D.” letter from Panizzardi to Schwartzkoppen. The second was a letter from Panizzardi to Schwartzkoppen mentioning a certain “P.,” dated from 1896—except that unbeknownst to Cavaignac, Henry had altered the P to a D, and the date to 1894. Finally, the third document selected by Cavaignac was the fake letter from Panizzardi to Schwartzkoppen written by Henry and his wife, containing the name of Dreyfus written out in full.
Not only did Cavaignac read out these documents in public and proclaim his absolute belief in Dreyfus’ guilt and the utter impossibility of the case ever being reopened, but also he had his speech, together with a photograph of the last of the three documents, printed on posters that were then placed on the wall of every single town hall in all of France. Thus, he proudly declared, he would stamp with his heel once and for all on the traitorous Jewish snake that kept raising its head. End of story.
Or so he thought. But in fact, as the Dreyfus camp soon realized, he had made some tremendous errors in his rashness. First, breaking away from the army’s declaration of absolute respect for “the thing that had been judged,” he had as much as admitted that the court-martial’s decision could be called into question by an individual. Second, he had shown that Dreyfus had been convicted on documents that were not the one—the single bordereau—that had been introduced against him at his trial. Third, by reading the documents aloud, he had put an end to the notion that they must be kept secret for reasons of national security, and therefore removed any reason to have held or to continue to hold parts of the trials behind closed doors. And finally—this was a major point—he had stated a simple truth, but one that was being denied with increasing vehemence by a large section of both the government and the population: what mattered, after all, was whether or not Dreyfus was guilty, and not the fact that questioning his guilt might constitute a blow against the honor of the army and the nation. Cavaignac himself had posed the question of whether or not Dreyfus was guilty. He had answered loudly in the affirmative, to be sure, but the very fact that he had posed the question at all showed that it could be done without a loss of honor to anyone.
The Dreyfus supporters took heart. Cavaignac’s actions showed that the time was ripe for Lucie Dreyfus to make an official demand for the revision of her husband’s trial. Cavaignac geared himself up to exert all of his influence in order to ensure that her demand be rejected. But he was foiled, for a second time, by an unexpected reaction from the heart of his own side, the army.
During this time, young Captain Cuignet had been continuing his work on the Dreyfus file, examining and classifying the documents one by one with the aim of helping his superiors gain a complete understanding of the case and put a final end to their problems. He worked late into the night. Sitting at his desk, he took up the main folder for the umpteenth time and stared at the papers it contained. The letter naming “that Jew Dreyfus,” the one that had been printed on posters and put up in every town hall in the country, particularly attracted his attention. He held it up to the light and turned it this way and that. Indeed, a strong lamplight was necessary to see what Cuignet then saw: the thin writing lines on the beginning and end of the letter were violet in color, while the lines on the paper containing the middle part were blue. The letter was actually composed of two different letters stuck together. Now that Cuignet realized this, he also saw that the handwriting of the middle part was slightly different, as was the pen used. Furthermore, he noticed, Panizzardi had not made quite so many mistakes in his French in any of the other letters he had written.
Cuignet was a firm believer in Dreyfus’ guilt, but he was an honest man, and not personally involved in the case. He waited, anxious and unhappy, till the next morning and then took the letter straight to Cavaignac. In his office in the light of day, with the August sun streaming through the windows, Cavaignac couldn’t see what Cuignet was talking about. But Cuignet insisted he look more closely. He had the shutters closed, the curtains drawn, and the lamps lit, and he held the letter up close to the light. Then Cavaignac saw the two colors, and he also saw that this was not a moment for him to lie. His credibility was at stake, and he had an honest and independent officer standing in front of him.
“Yes, this letter is a fake,” said Cavaignac, but it wasn’t an admission of fault; that simply wasn’t in his character. It was an attack.
The credit he would gain from public recognition of his truthfulness, he thought, would help his cause rather than hurt it. As for the question of guilt, there were plenty of other incriminating documents in the file—or so he believed. Still, the new discovery that had been made necessitated some kind of exemplary reaction.
Cavaignac called Henry, Gonse, and Boisdeffre into his office, and there he subjected Henry to a severe and pointed interrogation the likes of which he had never experienced before. Major Henry broke down. He admitted that he had done everything to please the two generals, to bring calm to their ruffled spirits. He had done it all for his country. He wept and looked pleadingly at his two erstwhile protectors, but they sat without a word. Silently, Boisdeffre took pen and paper and wrote out a letter of resignation in which he stated that he had been deceived by Major Henry, a man he trusted, and that he felt the major had thereby lost the authority to continue in his position.
Henry was taken immediately to prison, where he drank himself into a stupor, having been provided, surprisingly, with a bottle of rum. He wrote a panicked letter to General Gonse: “Please come to see me. I absolutely have to talk to you.” No response. Hours later, Henry wrote a loving letter to his wife, enjoining her to take care of their son and swearing that he had not done anything wrong, but had merely written down facts that he had been told. Leaving this letter on the table, he finished the rum, then picked up another sheet of paper: “My beloved Berthe, I’m going mad, a dreadful pain is squeezing my brain, I’m going to bathe in the Seine . . .” The letter remained unfinished. The officer who came to bring him dinner found Henry lying on his bed, a razor in his hand, his throat slashed, blood flowing over his chest and hands, soaking the sheets, and running in a pool across the floor.
The French supreme court judges accepted Lucie Dreyfus’ demand for the revision of her husband’s trial, and a boat was sent to Devil’s Island to bring Alfred Dreyfus home.
IN ORDER to avoid mass riots, the retrial was held in the city of Rennes, in Normandy, and Dreyfus was kept in prison there while awaiting its start, set for August 7, 1899. Lucie came to Rennes, and husband and wife were allowed to take each other in their arms, to look into each other’s faces for the first time in four and a half years. She was shocked to see how changed he was.
Weak, ill, and malnourished, he asked that his military uniform, which he was once again allowed to wear, be thickened with cotton pads in order to give him some semblance of solidity. He forced himself to walk into court with small steps in order to hide his tendency to stagger. Dreyfus wanted to be acquitted on the evidence. He wanted the judicial error of which he had been a victim to be set right. He did not want anybody’s pity. Whenever the lawyers tried to discuss the horror and suffering that he had endured on Devil’s Island, he cut the debate short in a voice that the journalists who were present found dry and emotionless. He did not make loud or passionate declarations, nor did he want his lawyers to make them. He simply wanted it to be publicly, rationally, and factually proven that he was not the author of the bordereau.



Alfred Dreyfus at his retrial, 1899
The witnesses were the same who had testified at the original trial in 1894, with the exception, of course, of Major Henry. Some of the handwriting experts were called back to testify again. One in particular, Charavay, made a startling statement that moved and impressed both the jury and the public. “I wish to declare that in 1894, I was misled by a certain resemblance of handwriting into attributing the bordereau to Dreyfus. But since then, having been presented with a new sample of handwriting [Esterhazy’s], I have understood my error, and it is a great relief to my conscience to be able to stand here before you, the judges, and above all before him who was the victim of my error, and to declare that I made a mistake in 1894.”
But Alphonse Bertillon, he of the devastating “geometric proof” that the bordereau was written by Dreyfus, came back with more of the same. Utterly convinced that Dreyfus had written the bordereau in a purposely modified version of his own handwriting, Bertillon once again explained his theory in detail.
BERTILLON’S THEORY about the construction of the bordereau as self-forgery had never ceased to develop over the five years between 1894 and 1899. As we saw earlier, his “geometric proof” was riddled with serious probabilistic errors. His greatest fallacy was to detect what he called “coincidences” in the bordereau, to miscalculate the probabilities of such “coincidences” arising, and to conclude that they were simply too unlikely not to be the result of a purposeful act.
The onionskin paper the bordereau was written on was lined with nearly invisible, fine vertical fibers spaced exactly half a centimeter apart. Given the width of the stroke made by the pen that was used to write the bordereau, Bertillon calculated that there were about five possible positions that a pen stroke could occupy with respect to these lines: on a line, just touching a line to the left, between two lines but nearer to the left-hand one, between two lines but nearer to the right-hand one, and just touching a line to the right. Thus, he claimed that the probability for a given pen stroke—for example, the initial pen stroke of any given word in the bordereau—to occupy one of these positions was equal to 1/5. So far his deduction is reasonable enough.
Bertillon also chose to restrict his attention to 26 particular words in the bordereau, namely the 13 words of more than one syllable that happened to be repeated more than once within the text of the letter. His explanation was that graphologists concentrate particularly on such words because they afford a greater terrain for comparison. In any case, those words constituted a reasonable sample of all the words in the letter.
He then observed with a magnifying glass the positioning of the initial pen strokes of the initial letters of these 26 words and discovered that out of the 13 pairs of initial pen strokes and the 13 pairs of final pen strokes belonging to the 13 pairs of repeated words, so 26 pairs of pen strokes in all, 8 of these pairs appeared to have a peculiar property: they were all placed identically with respect to the vertical lines running faintly down the paper.
Bertillon then gave the following reasoning, described during his testimony at Dreyfus’ second court-martial, and reported in its entirety in Le Figaro on August 25, 1899. We include part of that article here, not for the purpose of serious study, but to give a sense of what the readers of Le Figaro were subjected to, not to mention the jury members who sat through such argumentation for hours. What nonprofessional has the patience to listen to or read such a speech with enough attention to argue coherently against it?
The striking observation is that when you look at the bordereau, and place on top of it this transparent sheet marked with vertical lines separated by exactly half a centimetre, the repeated words often occur with their initial letters placed exactly the same with respect to these vertical lines.
Take the word modification on line 10 and the word modification on line 6. The initial pen stroke is at exactly the same distance from the vertical line just to the right of it.
What is the probability that such coincidences could be the fruit of chance? From a practical point of view, how many naturally written letters would you need to have some chance of finding these pairs of words set so similarly? [Murmurs in the court.]
Just consider one of the words I mentioned, at random, say the two occurrences of modification.
Once the writer has written this word once, with the m just touching one of the invisible vertical lines separated by half-centimeters, what is the probability that he writes the word a second time with the second m also just touching one of these lines? Given the thickness of the pen stroke, that probability is about 1/5.
Thus, if we have this bordereau written out ten thousand times naturally, we would only find two thousand copies in which the two letter m’s appeared in the same position with respect to the vertical lines.
Now, could this fact imply that the initial d of the two occurrences of the word disposition should also be in the same position?
Obviously not.
The placing of those two pairs of words is totally independent. Placing one pair can have nothing to do with the placing of the second pair.
Thus, if the first occurrence of the word disposition is placed as in the bordereau, then the second one could only be placed in the same way about 1/5 of the time.
We saw that out of 10,000 copies written normally, we had only two thousand with the two occurrences of modification placed the same; now we have only 400 in which also the two occurrences of disposition are placed the same.
We must re-divide this 400 by 5 because of the two occurrences of the word manoeuvre, whose initial m’s are also placed identically with respect to the vertical lines. Thus we find only 80 possibilities, which must be again divided by 5, giving 16, because of the two occurrences of the word copie. [Murmurs in the court.]
Finally, after dividing again by 5 because the same phenomenon occurs for the word nouveau, we find that we have barely 3 chances out of the original 10,000 to have these five coincidences all satisfied at once.
And there are more coincidences that we could give. Thus, we can state that even out of one hundred million copies written naturally, there would hardly be even one or two that could contain all the coincidences shown here.
Conclusion: Whoever the author, whatever the purpose, what we have here is unquestionably an artificially constructed document.
Given the position of the initial (or final) pen stroke of the first occurrence of the repeated word, there is a 1/5 chance that the corresponding pen stroke of the second occurrence of the same word occupies exactly the same position. This coincidence happens 8 times in the bordereau, so the total probability is (1/5)8 = .00000256, which is roughly one chance out of four hundred thousand. That probability is much too small to have been a mere product of chance. Therefore, the placing of so many initial or final letters in equivalent positions must have been done carefully on purpose, and must denote a purposeful intention, probably a secret code.
—Le Figaro, August 25, 1899
That little calculation convinced a jury of seven. It is, however, quite a perfect example of the situation with the dice explained in the example of Math Error Number 10 at the beginning of this chapter. First, the probability that Bertillon computed is not that of 8 pairs of letters out of 26 being in identical positions, but 8 pairs out of 8, exactly as in the example of the arrows in the bull’s-eye. If he had made the proper computation, he would have come up with a probability of slightly over 7 chances in 100, instead of the 1 in 400,000 he claimed.
On top of that, since Bertillon calculated only the probability of 8 coincidences, forgetting the others, he also necessarily forgot the fact that he would have been equally or even more surprised by 9, 10, 11, or 12 coincidences . . . all the way up to 26. So one should really calculate not the probability of 8 coincidences, but the probability of all numbers equal to or greater than 8, and add them together. Now the result is that Bertillon found surprising and highly suspicious something that actually occurs with a probability of over 13 in 100!
Perhaps 13 in 100 denotes an event that is fairly rare, but certainly not so rare as to make anyone think that such a number of coincidences must be due to a purposeful placement of the letters denoting a secret code. If Bertillon had made the correct mathematical calculation, he would never have made that strange deduction. But at the court-martial of Alfred Dreyfus, there was no one who could see or correct his errors and the specious deductions to which they led him.
WHOM TO believe and whom to doubt? At this point in the trial, the outcome was impossible to predict. One thing was clear, however: an acquittal would lead immediately to accusations of the original creators of the case against Dreyfus: Generals Mercier, Gonse, and Boisdeffre, and Major du Paty de Clam. The price was too great for the army to pay. Emergency measures were necessary, and General Mercier undertook to apply them.
Mercier took the stand and delivered a piece of information that shocked and stunned everyone present, most of all Dreyfus himself. The general claimed that the bordereau analyzed by the experts, written on thin onionskin paper, was only a traced copy of a secretly kept true original version of the bordereau. This original bordereau, he claimed, was in the possession of the army’s secret service, and the absolute, definitive proof of its authenticity was an annotation to that effect by no less a personage than Kaiser Wilhelm II of Germany himself!
Mercier’s statement was an outright lie, but no one could prove this, because for the usual “reasons of national security,” he refused to produce the document in court. Instead, he gave his word of honor (for what it was worth) that he knew for a fact that Dreyfus was guilty. He stepped down from the stand with the air of a hero saving his country from indignity, dishonor, and defeat at the hands of a despicable enemy.
As a result, the jury brought in a majority verdict of guilty “with extenuating circumstances” for Dreyfus (prompting Dreyfus to exclaim, “What kind of extenuating circumstances exist for treason?!”) with two of the judges voting for acquittal. He was condemned to ten years in prison, but spared a repetition of the disgraceful scene of degradation.
The government, aware of the enormous injustice that had been committed, but unable to rectify it without inflicting a public humiliation on the army, entered a phase of intense negotiations with Dreyfus’ supporters, which resulted in his being offered a full and immediate pardon, setting him free at once. It was a bargain of sorts: the government would publicly uphold the verdict of the court-martial but explain that it was simply acting out of pity. In return, Dreyfus could return to the life and the family from which he had been so dramatically separated.
It hurt him to accept a pardon, knowing he was innocent, but he was physically unable to endure more imprisonment and desperate to return to his loved ones and help raise his children, who had not seen him for almost five years. Thus Dreyfus accepted the presidential pardon with a letter in which he proclaimed his innocence, and declared his intention of pursuing the full and public revelation of the truth for as long as it would take to obtain it.
It took another seven years of relentless struggle, during which the documents that had been used to condemn him were legally recognized as forgeries, and during which time three of the most famous mathematicians in France—Henri Poincaré, Gaston Darboux, and Paul Appell—wrote a detailed report analyzing each and every one of Bertillon’s mathematical errors. Their text ends with the claim that Bertillon’s claims are “utterly deprived of scientific value . . . because the rules of probability calculation were not applied correctly.”
On July 12, 1906, the French supreme court read aloud a declaration that annulled the Rennes judgment and reinstated Dreyfus in the army. On July 21, 1906, he was awarded the Legion of Honor in a ceremony at the same military school where he had undergone the excruciating degradation in 1894. Eight years later, already fifty-five years old, he fought for his country, participating in some of the worst battles of World War I, including the infamous Battle of Verdun. At the end of the war he retired and devoted the rest of his life to his family and to the history of his appalling affair.
None of the generals and majors involved in knowingly building the case against Dreyfus ever confessed, but their pact of silence could not withstand the march of history, and their role was eventually recognized for what it really was. As for Esterhazy, he went to settle in an English village under an assumed name. His tombstone can still be seen in the churchyard at Harpenden, Hertfordshire, but no one would recognize it as his. It is inscribed:
IN LOVING MEMORY OF
COUNTDE VOILEMENT
1849–1923
HE HAS OUTSOARED THE SHADOWOF OUR NIGHT
 
*Later, Gribelin, one of the officers present at the scene, would state that Dreyfus claimed that he was shivering because it was extremely cold outside, but that this claim must have been false, as it had been a fine October day, and furthermore there was a good fire in the office. Joseph Reinach, one of Dreyfus’ staunchest defenders and the author of a grand History of the Dreyfus Affair, responded to Gribelins contention with the famous line of repartee: “It is good to avoid too much detail when lying. If it was so fine outside, why did you have to have a good fire? Are you in the habit of lighting fires in summer?” after which he brought out a newspaper dating back to that very October day and showed that the early morning temperature was a chilly 5 degrees Centigrade (41 degrees Fahrenheit).
*If France’s good name on the international scene was to be preserved by insisting that Dreyfus was guilty, then other countries were not aware of it. During the course of the trial, German, English, American, Italian, Spanish, and Dutch newspapers expressed the most extreme astonishment at the blindness of the French government, which was crushing the notion of justice underfoot, arbitrarily turning it into a concept that opposed, rather than supported, the ideal of nationalism. “The French are hypnotized with fear of the truth,” wrote a Russian newspaper. “Mr. Zola’s crime was to stand up in defense of truth and civil liberty!” screamed the Times of London. “Europe must defend the values of France against France itself,” appeared in the Belgian headlines. And so on and so forth.

CONCLUSION
In nine of the ten cases described in this book, not only did math obscure the truth, but in some cases it led to real miscarriages of justice. The only exception is the Berkeley sex discrimination case, in which the first level of mathematical analysis—examination of the statistics—led to an impression of injustice, but the second level, consisting in a correct breakdown and analysis of the statistics, revealed the true answer. In the other cases, even when the mathematical errors were eventually spotted by experts—Sally Clark, the Collins couple, Joe Sneed, Lucia de Berk, and the Dreyfus affair—the final results were not obtained by correcting the math, but by ignoring it, and sometimes by introducing new evidence; for example, the medical evidence of infection in Sally Clark’s son, Sneed’s wife’s testimony about his violence, the evidence proving that baby Amber did not have an unusual amount of digoxin in her body when she died, and the fact that the document that had originally incriminated Alfred Dreyfus was eventually recognized as having been penned by Esterhazy.
This leads to the question of whether mathematics should be used in trials at all. Should it really have a role in the detection and proof of crime? The obvious disadvantage, which is the major subject of this book, is that it is only too easy for non-mathematicians, or for mathematicians who are not used to applying math in real-life situations, to misunderstand and misuse mathematics in all sorts of different ways.
As a matter of fact, there are a number of people working in law and crime detection who have sought a solution to the problem of the use and role of mathematics in criminal law. Over the last forty years, several scholarly articles have appeared on the subject, published in places like the Harvard Law Review and other renowned law journals (see the “Sources” section). However, they are rarely if ever read by mathematicians or by members of the general public.
One of the most famous articles on the subject, perhaps even the best known, is “Trial by Mathematics: Precision and Ritual in the Legal Process,” by Laurence Tribe. Tribe is a professor at Harvard Law School and was the young aide who wrote the mathematical portion of the supreme court of California’s judgment reversing the Collins conviction. Because of this case and others he encountered over a long career, some of which have been detailed in this book, Tribe has thought deeply about the question of mathematics at trial and has come to the conclusion that the danger of the kind of error we have seen here is too great to make it worth allowing. He fears that the logical and numerical approach used in mathematical thinking is so different from the intuitive approach that must be taken by jury members when evaluating evidence that the two approaches cannot properly be combined. He concludes that mathematics does not belong at trial.
Tribe wrote his article as a beautifully argued, passionate response to an earlier article by Michael Finkelstein and William Fairley, who had proposed a specific example of a situation in which they believed a simple probability calculation could produce an important insight that was unlikely to be grasped properly in any other way. Tribe argues that the situation is rarely if ever so simple that a mathematical model takes all of its human subtleties into account; he raises the double specter of errors made in the mathematics itself and of math that is not wrong but is too simple to apply to the situation at hand. We have seen both types of problem illustrated in this book.
Above and beyond these issues, Tribe fears the psychological effect of mathematics, which can overwhelm jurors, and the use of which “threatens to make the legal system seem even more alien and inhuman than it already does to distressingly many. . . . The need now is to enhance the community comprehension of the trial process, not to exacerbate an already serious problem by shrouding the process in mathematical obscurity.” He argues that some of the basic values of our traditional justice system may be lost if mathematics becomes commonly used in the courtroom, and that “guided and perhaps intimidated by the seeming inexorability of numbers, induced by the persuasive force of formulas and the precision of the decimal points to perceive themselves as performing a largely mechanical and automatic role, few jurors could be relied upon to recall, let alone to perform, this humanizing function, to employ their intuition and their sense of community values to shape their ultimate conclusions.”
Written forty years ago, Tribe’s article has had so strong an influence on courtroom procedures that some claim he single-handedly set back the progress of statistics in the courtroom by decades. During this time it was risky to introduce such arguments in the courtroom and run the danger of having the verdict overturned on appeal with citations of the many cases such as the ones in this book.
Yet in the twenty-first century, probability is making a comeback in the courtroom. The primary reason for this is the omnipresence of DNA analysis, which did not exist when Tribe wrote his article in 1971. In order to understand the deep relationship between DNA analysis and the general use of probability in the courtroom, it is necessary to make an argument that perhaps runs counter to some commonly held views about DNA.
If an identification is made from a high-quality unmixed DNA sample, then it is generally held, inside and outside the courtroom, to be a virtual certainty. Nevertheless, the means used to arrive at such an identification are nothing but the type of probability calculation that we have seen so much of in this book: a statistically established probability for the occurrence in given populations of each of the thirteen genetic loci usually considered in establishing a match, and the product of these (independent) probabilities when several loci are present.
The problems that arise with this type of probability calculation in DNA analysis tend to occur, as we have seen, when the DNA is degraded, partial, or a mixed sample. Then, assuming that the forensic work is done in the most accurate possible manner and without error or carelessness, actual probability calculations in the courtroom become unavoidable, unless the DNA is to be thrown out altogether, which is impossible. And this will increasingly lead to the use of probability theory in other situations as well, on the grounds that it is exactly the same theory; thus there is no reason at all to allow it in one situation and not in another. Thanks to DNA, the mathematics that was ceremoniously chased out of the courtroom by Laurence Tribe and the judges who agreed with him is sneaking in by the back door.
Still, however, as we saw in the cases in this book involving DNA (the murders of Meredith Kercher and Diana Sylvester), the results of any DNA analysis that is not a straightforward, high-quality, single-individual identification are open to question and debate in the courtroom, and the mathematics involved is subject to error in the hands of lawyers. Because math is going to be present in the courtroom as long as forensic analysis takes place, it is becoming a rather urgent problem to establish criteria for its use. At the same time, it is probably going to be necessary to educate the public, from which juries are drawn, to recognize some of the most common mathematical principles that forensic analysis cannot do without. Although Tribe saw the public attitude toward mathematics as a kind of uncomprehending awe, we do not believe that this is really the prevailing attitude toward mathematics. Even if it is, we are convinced that it can be changed incrementally without recourse to any extreme measures. Indeed, the public familiarity with at least some of the basic features of DNA analysis proves that others can become equally familiar, and the frequency and popularity of television series focusing on crime detection prove that people are not indifferent to this theme.
Chief among the probability techniques that are making their appearance more frequently of late is Bayesian reasoning: the use of the so-called Bayes’ theorem and its generalization to Bayesian networks. Bayes’ theorem has already been used in court many times, but given the lack of a coherent attitude on the part of the courts toward probability, its use has met with varied success. Sometimes it is accepted, other times challenged, and most recently, in a British case dating from July 2011, it was rejected out of hand by the appeal judge at a murder trial, in a judgment that was interpreted by many as rejecting the use of Bayes’ theorem at trial in general.
This judgment served as a catalyst for the community of mathematicians and statisticians who are involved with criminal trials, either theoretically or as expert witnesses. An international team led by statisticians at Queen Mary, University of London, the “Bayes and the Law” Research Consortium, founded as a reaction to the anti-Bayes ruling, has begun work on a research project whose goal, drawing on past cases of mathematics in trial, is to put together a set of criteria and a set of analytic tools that should ensure that probability at trial will henceforth be used correctly, applied only to situations in which it can give a meaningful result, and, by virtue of these advantages, be proof against attack at appeal.
It seems that such a plan is the only possible approach to seriously using math at trial without confronting the prejudices, fears, and manipulation that have so often characterized it, as our book rather sadly proves. We are optimistic about the project and hope to follow its progress and share further cases of the use and misuse of math at trial in future books.

SOURCES
A few of the cases studied in this book came to our attention through the media. It was originally the stories of victims Sally Clark, Lucia de Berk, and Meredith Kercher that caught our eye and made us sensitive to the issue of statistics used in trial, as well as the Madoff affair, of course, which led us to Ponzi. The Collins case is evoked in Ben Goldacre’s Bad Science (Fourth Estate, 2008) and other popular books on the subject. Many thanks are due to Jordan Ellenberg for pointing out the mathematically fascinating case of Diana Sylvester. The importance of mathematics in the Dreyfus affair is known to mathematicians, although not to most historians, let alone the public. The remaining cases—the Berkeley affair, Joe Sneed, and Hetty Green—came up as we deepened our research into the scholarly literature. Many of these cases are cited repeatedly in scholarly articles on the subject of the use of mathematics in trial; the Sneed case, in particular, is a ubiquitous reference. Below is a list of those scholarly references that were the most useful and relevant to us in our research.
For anyone interested in the theoretical aspects of math at trial, the best starting point is the profound and sensitive article by Laurence Tribe, “Trial by Mathematics: Precision and Ritual in the Legal Process” (84 Harvard Law Review 1329 [1970–1971]). This article arose as a response to M. Finkelstein and W. Fairley’s article “A Bayesian Approach to Identification Evidence” (83 Harvard Law Review 489 [1970]). They wrote a rebuttal, “The Continuing Debate over Mathematics in the Law of Evidence” (84 Harvard Law Review 1801 [1970–1971]), and Tribe again responded with “A Further Critique of Mathematical Proof” (84 Harvard Law Review 1810 [1970–1971]). This fascinating debate among intellectuals of the legal profession provided us with ideas, information, and great stimulation. We found out only later that Tribe studied mathematics as an undergraduate and was directly, although anonymously, involved in the Collins case.
Two other authors have written articles that were both fascinating and helpful to us. David Kaye is a specialist in the subject of math at trial. Apart from an interesting account of the Dreyfus affair, he is also the author of “The Admissibility of ‘Probability Evidence’ in Criminal Trials,” parts 1 and 2 (Jurimetrics 26, no. 4 [1986], and 27, no. 2 [1987]), and dozens of other relevant articles. Alan Cullison’s “Identification by Probabilities and Trial by Arithmetic: A Lesson for Beginners in How to Be Wrong with Greater Precision” (6 Houston Law Review 473 [1968–1969]) also shed light on the many problems with mathematics in trials.
Finally, the book Applying Statistics in the Courtroom, by Phillip I. Good (Chapman and Hall, 2001), led us much further into the realm of complicated statistics than we ever meant to venture.
What follows is a list of the documents and references we studied for each individual case.
Chapter 1: The Case of Sally Clark
Biographical material on the life and career of Roy Meadow is available from a large number of online sources, starting with Wikipedia. The website msbp.com (by MAMA, or Mothers Against Munchausen Allegations) contains information from an interview of Roy Meadow during the time when Sally Clark was already in prison. (He says, “I probably have more sympathy for her than the rest of the population.”) On his being struck off by the GMC there is again ample information; see, for example, the BBC online news article “Sir Roy Meadow Struck Off by GMC” from July 15, 2005. There is the transcript of Dr. Robert Kaplan’s lecture “The Rise and Fall of Sir Roy Meadow.” And of course there are Meadow’s scholarly publications in medical journals, particularly the seminal “Munchausen Syndrome by Proxy: the hinterland of child abuse,” in Lancet (August 13, 1977), and the subsequent “What is, and what is not, Munchausen’s Syndrome by Proxy,” in Archives of Disease in Childhood, a medical journal that also contains articles suspicious of MSbP (cf. the articles “Practical concerns about the diagnosis of Munchausen syndrome by proxy” by C. J. Morley, and “Is Munchausen syndrome by proxy really a syndrome?” by G. C. Fisher and I. Mitchell from 1995). Information on the case of Philip P. comes from court documents from the state of Tennessee.
For details of the Sally Clark case, the best sources are John Batt’s book Stolen Innocence (Ebury Press, 2005) and Sally Clark’s website, www.sallyclark.org.uk. Contemporary newspaper accounts reported her tragic death (see, for example, The Times, November 8, 2007). Angela Cannings has given a remarkable account of her own terrible experiences and her brush with Roy Meadow in her autobiography, Against All Odds (Little, Brown, 2006).
The Clark case is discussed in almost every book and scholarly article concerned with the misuse of probability in medicine. See, for example, “Conviction by mathematical error? Doctors and lawyers should get probability theory right,” British Medical Journal 320, no. 7226 (January 1, 2000), or the book Bad Science by Ben Goldacre. A fascinating televised lecture by Oxford statistician Peter Donnelly can be viewed at http://www.ted.com/speakers/peter_donnelly.html.
Chapter 2: The Case of Janet Collins
Our primary source for the Collins case was the California state supreme court judgment People v. Collins, 68 Cal.2d 319. This fascinating text contains the basic facts of the case, many quotes from original testimony, and the mathematical analysis of the errors made in the original trial. We also studied contemporary newspaper accounts, in particular, articles from the Los Angeles Times and the Independent shortly after the trial; the article “Trials: The Laws of Probability” in the January 8, 1965, issue of Time magazine; and articles from the Independent following the appeal judgment in 1968.
A valuable secondary source was the article “Green Felt Jungle,” by George Fisher, in the collection Evidence Stories, edited by Richard Lempert (Foundation Press, 2006). Fisher actually interviewed both prosecutor Ray Sinetar and mathematician–expert witness Daniel Martinez by telephone in 2005. We also dug into a set of course notes on evidence, law, and reason by Professor Bruce Hay of Harvard Law School, dating from the spring semester of 2009, on the topic of “Reasonable Doubt.”
Chapter 3: The Case of Joe Sneed
It is difficult to find a reference for the details of the Joe Sneed murder trial. Apart from scattered articles in the newspaper archives, this case survives essentially in its very frequent citations in other legal judgments examining mathematical questions raised in court, and of course in the scholarly works on the question. In order to delve more deeply into the case, we contacted the Dona Ana County district court in Las Cruces, New Mexico, where Sneed was tried. For a fee, the court sent us a complete set of photocopies of the archived trial documents, which are the source of nearly everything we were able to learn about the case, with the exception of Kathy Storey’s testimony, reported in the El Paso Herald on the day after the appeal trial. The court documents are not transcripts—none remain, and the stenographer who took notes is now deceased—but some two or three hundred pages of various affidavits, motions, requests, records of jury selection, letters between lawyers and judges, occasional quoted testimony, and of course the final judgments. From these documents we were able to piece together much information and write a first version of our chapter.
At this point, we realized that we could actually make direct contact with the main mathematical witness in the murder trial, Dr. Edward Thorp. A long telephone conversation with him gave us precious insights into the Sneed case, which allowed us to improve our chapter greatly. We are very grateful to him for all the information he provided to us, as well as a photo of himself from that time.
Chapter 4: The Case of Meredith Kercher
The main source for information about the murder of Meredith Kercher and the facts surrounding this murder and the subsequent arrest and trial of Amanda Knox, Raffaele Sollecito, and Rudy Guede come from original court documents from the two trials in Perugia, Italy. The 427-page “motivations report” submitted after the original verdict by Giancarlo Massei, the judge in the first trial of Amanda and Raffaele, contains an enormous amount of factual detail. Other aspects emerge from the appeal briefs, reports of court sessions, and from the motivations report of Rudy Guede’s supreme court appeal trial. Finally, the motivations report submitted following Amanda’s and Raffaele’s acquittal on appeal by Judge Claudio Pratillo Hellman not only was a source of information, but also contains the particular mathematical example analyzed in this chapter. English translations of most of these documents can be found online at the Perugia Murder File message board (perugiamurderfile.org).
Numerous books have been written about the case, among which we cite Barbie Latza Nadeau’s Angel Face: The True Story of Student Killer Amanda Knox (Beast Books, 2010), John Follain’s A Death in Italy: The Definitive Account of the Amanda Knox Case (Hodder & Stoughton, 2011), and of course John Kercher’s recent book about his daughter, Meredith: Our Daughter’s Murder and the Heartbreaking Quest for the Truth (Hodder & Stoughton, 2012), as well as Raffaele Sollecito’s first-person account, Honor Bound: My Journey to Hell and Back with Amanda Knox (Gallery Books, 2012).
Online blogs and message boards devoted to this unusual and tragic murder proliferate. Perugia Murder File hosts both an ongoing discussion in which facts are analyzed as they emerge and a set of translations of documents from the court file, including court testimony as well as many original writings and statements from the accused. Other sites devoted to the case are True Justice for Meredith Kercher (truejustice.org) and a slew of sites supporting Amanda’s innocence (Injustice in Perugia [injusticeinperugia.org], Perugia Shock [perugiashock.com], Friends of Amanda[friendsofamanda.org], and more).
Chapter 5: The Case of Diana Sylvester
Our main source of information for this case, including some of the mathematics, comes directly from the appellant’s and respondent’s briefs prepared for John Puckett’s upcoming appeal.
An in-depth study of the case titled “FBI resists scrutiny of ‘matches,’” by Jason Felch and Maura Dolan, was published in the Los Angeles Times on July 20, 2008. Another article, “Sex Offender, 74, convicted in 1972 murder,” by Jaxon van Derbeken, appeared in the San Francisco Chronicle on February 22, 2008. Both are available online, as is the article “DNA’s identity crisis,” by Chris Smith, in San Francisco Magazine from September 2008, which tells the story from Bicka Barlow’s point of view, and the article “DNA’s Dirty Little Secret,” by Michael Bobelian, in the Washington Monthly of March/April 2010. All of these contain interesting information. David Kaye’s important article “Rounding Up the Usual Suspects: A Legal and Logical Analysis of DNA Database Trawling Cases” (North Carolina Law Review 87, no. 2 [2009]) gave important insights into the mathematics of database trawling.
Many articles and blogs have analyzed the mathematics used by both the prosecution and the defense. Here are some articles concerning the birthday problem and the Arizona data: Steven Levitt, one of the authors of Freakonomics, gives his take on the math of the situation in his August 19, 2008, article “Are the FBI’s Probabilities About DNA Matches Crazy?” at http://www.freakonomics.com/2008/08/19/are-the-fbis-probabilities-about-dna-matches-crazy. An amusing online dispute between National Public Radio’s “Math Guy,” Keith Devlin, and Charles Brenner can be found at Arizona DNA Database Matches, http://dna-view.com/ArizonaMatch.htm. On the more delicate question of the probability that the match found in the California database is actually the criminal, see the article “Rehash and Mishmash in the Washington Monthly,” by David Kaye, at the Double Helix Law blog, http://www.personal.psu.edu/dhk3/blogs/DoubleHelixLaw/2010/02/rehash-and-mishmash-in-the-washington-monthly.html (February 27, 2010); the article “Guilt by the Numbers,” by Edward Humes, in The California Lawyer, available at http://www.callawyer.com/clstory.cfm?eid=900572&ref=updates (April 2009); and a Quomodocumque blog post titled “Prosecutor’s Fallacy—Now with Less Fallaciousness!” by Jordan Ellenberg, simplifying Kaye’s explanation, at http://quomodocumque.wordpress.com/2010/05/18/prosecutors-fallacy-now-with-less-fallaciousness (May 18, 2010). Our analysis contains elements of all these, but we do not fully agree with them, as explained in the chapter.
Chapter 6: The Berkeley Sex Bias Case
The essential source of information for the statistics and mathematical analysis of the 1973 Berkeley admissions lawsuit was the report by the investigating committee, “Sex Bias in Graduate Admissions: Data from Berkeley,” by P. J. Bickel, E. A. Hammel, and J. W. O’Connell, published in Science 187, no. 4175 (February 7, 1975).
For the particular case of Professor Jenny Harrison, sources included conversations with Berkeley department members (including Professor Harrison, who also provided us with a photo) and press reports of her lawsuit as it progressed. A particularly detailed account was given in the article “Fighting for Tenure: The Jenny Harrison Case Opens Pandora’s Box of Issues About Tenure, Discrimination, and the Law,” by Allyn Jackson, published in Notices of the American Mathematical Society 41, no. 3 (March 1994). Paul Selvin also covered the case and some of the interesting (and rather depressing) effects of its aftermath in two articles in Science: “Jenny Harrison Finally Gets Tenure in Math at Berkeley” (July 16, 1993) and “Harrison Case: No Calm After Storm” (October 15, 1993).
Chapter 7: The Case of Lucia de Berk
The website devoted to Lucia’s case, http://www.luciadeb.nl/english (for the English-language page), contains a mine of articles and a list of the most important references on the case. Although Ton Derksen’s book Lucia de B.: Reconstruction of a Miscarriage of Justice (Veen Magazines, 2006) has not been published in English, the website contains a chapter-by-chapter synopsis, a twenty-four-page summary, and the complete translation of chapter 3, concerning the death of baby Amber. Dutch readers can also consult the book Es werd mij verteld, over Lucia de B., by Metta de Noo (Aspekt Ed.) and Lucia de Berk’s own book about her terrible experience, Lucia de B.: Levenslang en tbs (Arbeiderspers).
This is one of the cases whose mathematical aspect has been most deeply investigated by professionals. It is discussed in chapter 5 of Derksen’s book. Piet Groeneboom’s blog, http://www.pietg.wordpress.com, contains a prescient entry that dates back to May 2007 titled “Lucia de Berk and the Amateur Statisticians.” Richard Gill, a professional statistician who was very active in having Lucia’s conviction overturned, has links on his Leiden University homepage, http://www.leidenuniv.nl/~gill, to his own informative comments, slides of technical lectures he has given, and actual research articles that he authored on the subject. Some of these date back as far as 2007, when the errors in court provoked by the testimony of expert witness Henk Elffers began to emerge. An informative although fairly mathematically superficial article called “Lucia de Berk: a martyr to stupidity,” by Ben Goldacre, appeared in the Guardian on April 10, 2010. The comments to the online version contain a letter from expert witness Henk Elffers to Goldacre and a letter he wrote to the Guardian, as well as lengthy and highly relevant comments from Richard Gill. The latter also provided us, via e-mail, discussions with important information and interesting documents, particularly the two original statistical memos by Elffers. Finally, personal communication with Metta de Noo gave us special insight into the workings of the movement that eventually led to Lucia’s release; we also thank her for providing us with two photos of Lucia, one taken in her own garden.
Chapter 8: The Case of Charles Ponzi
Charles Ponzi’s adventures have been wonderfully documented, first in his 1935 autobiography, The Rise of Mr. Ponzi, long out of print but reprinted by Inkwell Publishers (2001), and then in a number of other biographies, of which we appreciated Ponzi’s Scheme: The True Story of a Financial Legend, by Mitchell Zuckoff (Random House, 2005), which adds a number of new facts to the autobiography. There were far too many interesting and amusing contemporary press accounts of Ponzi’s doings to include in the chapter, but the interviews in the local papers, the announcements of his bankruptcy, and his obituary in Time were revealing of the popular attitude toward Ponzi during his life. On the story of Bernie Madoff, which should never have happened if the lessons of Ponzi had really been learned, Harry Markopolos’ book No One Would Listen: A True Financial Thriller (Wiley, 2010) is filled with remarkable, almost incredible information. Like a reincarnation of Ponzi’s magnetic personality, Madoff’s inexplicable charisma deafened people to what should have been obvious.
Chapter 9: The Case of Hetty Green
There is a great deal of biographical information about Hetty Green on the Internet and innumerable articles about her in the newspaper archives; she was a highly visible figure in her time. An excellent and extremely informative biography is Hetty: The Genius and Madness of America’s First Female Tycoon, by Charles Slack (HarperPerennial, 2005). Also Daniel Alef’s book, Hetty Green: Witch of Wall Street (Titans of Fortune Publishing, 2009), contains interesting information. William Emery’s The Howland Heirs (E. Anthony & Sons, 1919), a book devoted to the genealogy of the Howland family, quotes the most important passages of Sylvia’s will verbatim and gives a brief account of the trial and its outcome.
On the subject of Benjamin Peirce and his mathematical analysis of the signatures on Sylvia Howland’s will, most sources accept his conclusion more or less unquestioningly. However, a fascinating and much more critical analysis was given by statisticians Paul Meier and Sandy Zabell in their article “Benjamin Peirce and the Howland Will” (Journal of the American Statistical Association 75, no. 371 [September 1980]). Our arguments for and against Peirce’s use of the binomial model owe a great deal to this unusual paper.
Chapter 10: The Dreyfus Affair
The sources we used for the chapter on the Dreyfus affair are essentially in French. For the actual set of historical events around the Dreyfus case, the definitive book is L’Affaire Dreyfus, by Jean-Denis Bredin. For firsthand accounts there are the letters Dreyfus wrote from Devil’s Island to his wife and brother during his incarceration (Lettres d’un innocent [P. V. Stock, 1898; rprt. Nabu Press, 2010]) and the personal memoirs of Dreyfus’ brother Mathieu (L’Affaire telle que je l’ai vécue [Grasset 1978]). The full transcripts of the Zola trial are available in print (Le Procès Zola: Compte-rendu sténographique [P. V. Stock, 1898]). Newspaper archives contain a mine of contemporary articles on all aspects of the case, frequently accompanied by line drawings.
On the mathematical aspects of the case, sources were rarer and more difficult to locate. One fascinating discovery was a pamphlet published in 1904, authored by A. Bertillon and his assistant Capitaine Valério, containing a complete exposition of the mathematical analysis he applied to the famous bordereau (Le Bordereau [Imprimerie Hardy & Bernard, 1904]). The website Poincaré and Dreyfus, http://www.maths.ed.ac.uk/~aar/dreyfus.htm, contains a collection of materials concerning the mathematics involved in the Dreyfus affair, in particular a facsimile of the original 1904 report on Bertillon’s work written by Darboux, Appel, and Poincaré; a retyped version in French; a translation into English; and a list of scholarly articles. One interesting introductory article is “Revisiting Dreyfus: A more complete account of a trial by mathematics,” by D. H. Kaye (Minnesota Law Review 91, no. 3 [2007]). More scholarly articles precisely concerning the Poincaré report can be found in French journals devoted to the history of mathematics; for example “Un mathématicien dans l’affaire Dreyfus: Henri Poincaré,” in the Seminar on History of Mathematics of the Institut Henri Poincaré, February 13, 2002, and “Introduction au rapport de Poincaré pour le procès en cassation de Dreyfus en 1904,” by Roger Mansuy and Laurent Mazliak, Electronic Journ@l for History of Probability and Statistics 1, no. 1 (2005).






Freakonomics:
Freakonomics
A Rogue Economist Explores the Hidden Side of Everything
Revised and Expanded Edition
Steven D. Levitt 
and 
Stephen J. Dubner





 Contents
An Explanatory Note
Preface to the Revised and Expanded Edition
Introduction: The Hidden Side of Everything
1. What Do Schoolteachers and Sumo Wrestlers Have in Common?
2. How Is the Ku Klux Klan Like a Group of Real-Estate Agents?
3. Why Do Drug Dealers Still Live with Their Moms?
4. Where Have All the Criminals Gone?
5. What Makes a Perfect Parent?
6. Perfect Parenting, Part II; or: Would a Roshanda by Any Other Name Smell as Sweet?
Epilogue: Two Paths to Harvard
Bonus Material Added to the Revised and Expanded 2006 Edition
Notes
Acknowledgments
Searchable Terms
About the Authors
Credits
Copyright
About the Publisher


 AN EXPLANATORY NOTE
In the summer of 2003, the New York Times Magazine sent Stephen J. Dubner, an author and journalist, to write a profile of Steven D. Levitt, a heralded young economist at the University of Chicago.
Dubner, who was researching a book about the psychology of money, had lately been interviewing many economists and found that they often spoke English as if it were a fourth or fifth language. Levitt, who had just won the John Bates Clark Medal (a sort of junior Nobel Prize for young economists), had lately been interviewed by many journalists and found that their thinking wasn’t very…robust, as an economist might say.
But Levitt decided that Dubner wasn’t a complete idiot. And Dubner found that Levitt wasn’t a human slide rule. The writer was dazzled by the inventiveness of the economist’s work and his knack for explaining it. Despite Levitt’s elite credentials (Harvard undergrad, a PhD from MIT, a stack of awards), he approached economics in a notably unorthodox way. He seemed to look at the world not so much as an academic but as a very smart and curious explorer—a documentary filmmaker, perhaps, or a forensic investigator or a bookie whose markets ranged from sports to crime to pop culture. He professed little interest in the sort of monetary issues that come to mind when most people think about economics; he practically blustered with self-effacement. “I just don’t know very much about the field of economics,” he told Dubner at one point, swiping the hair from his eyes. “I’m not good at math, I don’t know a lot of econometrics, and I also don’t know how to do theory. If you ask me about whether the stock market’s going to go up or down, if you ask me whether the economy’s going to grow or shrink, if you ask me whether deflation’s good or bad, if you ask me about taxes—I mean, it would be total fakery if I said I knew anything about any of those things.”
What interested Levitt were the riddles of everyday life. His investigations were a feast for anyone wanting to know how the world really works. His singular attitude was evoked in Dubner’s resulting article:
As Levitt sees it, economics is a science with excellent tools for gaining answers but a serious shortage of interesting questions. His particular gift is the ability to ask such questions. For instance: If drug dealers make so much money, why do they still live with their mothers? Which is more dangerous, a gun or a swimming pool? What really caused crime rates to plunge during the past decade? Do real-estate agents have their clients’ best interests at heart? Why do black parents give their children names that may hurt their career prospects? Do schoolteachers cheat to meet high-stakes testing standards? Is sumo wrestling corrupt?
Many people—including a fair number of his peers—might not recognize Levitt’s work as economics at all. But he has merely distilled the so-called dismal science to its most primal aim: explaining how people get what they want. Unlike most academics, he is unafraid of using personal observations and curiosities; he is also unafraid of anecdote and storytelling (although he is afraid of calculus). He is an intuitionist. He sifts through a pile of data to find a story that no one else has found. He figures a way to measure an effect that veteran economists had declared unmeasurable. His abiding interests—though he says he has never trafficked in them himself—are cheating, corruption, and crime.
Levitt’s blazing curiosity also proved attractive to thousands of New York Times readers. He was beset by questions and queries, riddles and requests—from General Motors and the New York Yankees and U.S. senators but also from prisoners and parents and a man who for twenty years had kept precise data on his sales of bagels. A former Tour de France champion called Levitt to ask his help in proving that the current Tour is rife with doping; the Central Intelligence Agency wanted to know how Levitt might use data to catch money launderers and terrorists.
What they were all responding to was the force of Levitt’s underlying belief: that the modern world, despite a surfeit of obfuscation, complication, and downright deceit, is not impenetrable, is not unknowable, and—if the right questions are asked—is even more intriguing than we think. All it takes is a new way of looking.
In New York City, the publishers were telling Levitt he should write a book.
“Write a book?” he said. “I don’t want to write a book.” He already had a million more riddles to solve than time to solve them. Nor did he think himself much of a writer. So he said that no, he wasn’t interested—“unless,” he proposed, “maybe Dubner and I could do it together.”
Collaboration isn’t for everyone. But the two of them—henceforth known as the two of us—decided to talk things over to see if such a book might work. We decided it could. We hope you agree.


PREFACE TO THE REVISED AND EXPANDED EDITION
As we were writing Freakonomics, we had grave doubts that anyone would actually read it—and we certainly never envisioned the need for this revised and expanded edition. But we are very happy, and grateful, to have been wrong.
So why bother with a revised edition?
There are a few reasons. The first is that the world is a living, breathing, changing thing, whereas a book is not. Once a manuscript is finished, it sits, dead in the water, for nearly a year until it is made ready by the publisher for its debut. This doesn’t pose much of a problem if you have written, say, a history of the Third Punic War. But because Freakonomics explores all sorts of modern real-world issues, and because the modern world tends to change quite fast, we have gone through the book and made a number of minor updates.
Also, we made some mistakes. It was usually a reader who would bring a mistake to our attention, and we very much appreciate this input. Again, most of these changes are quite minor.
The most aggressively revised section of the book is the beginning of chapter 2, which tells the story of one man’s crusade against the Ku Klux Klan. Several months after Freakonomics was first published, it was brought to our attention that this man’s portrayal of his crusade, and of various other Klan matters, was considerably overstated. (For a fuller explanation, see an essay called “Hoodwinked?”.) As unpleasant as it was to acknowledge this error, and to diminish the reputation of a man beloved in many quarters, we felt it was important to set straight the historical record.
We have also futzed a bit with the architecture of the book. In the original version, each chapter was preceded by an excerpt from the New York Times Magazine profile that one of us (Dubner) wrote about the other (Levitt), and which led to our collaboration on this book. Because some readers found these excerpts intrusive (and/or egomaniacal, and/or sycophantic), we have removed them, instead reprinting the complete Times profile in the back of this edition in the section called “Bonus Material”. There, it can be easily skipped over if one so chooses, or read in isolation.
The further bonus material is what accounts for our having called this edition “expanded” in addition to “revised.” Soon after the original publication of Freakonomics, in April 2005, we began writing a monthly column for the New York Times Magazine. We have included in this edition several of these columns, on subjects ranging from voting behavior to dog poop to the economics of sexual preference.
We have also included a variety of writings from our blog (www.freakonomics.com/blog/)—which, like this revised edition, was not planned. In the beginning, we built a website merely to perform archival and trafficking functions. We blogged reluctantly, tentatively, infrequently. But as the months went on, and as we discovered an audience of people who had read Freakonomics and were eager to bat its ideas back and forth, we took to it more enthusiastically.
A blog, as it turns out, is an author’s perfect antidote for that sickening feeling of being dead in the water once a manuscript has been completed. Particularly for a book like this one, a book of ideas, there is nothing more intoxicating than to be able to extend those ideas, to continue to refine and challenge and wrestle with them, even as the world marches on.


INTRODUCTION: 
The Hidden Side of Everything
Anyone living in the United States in the early 1990s and paying even a whisper of attention to the nightly news or a daily paper could be forgiven for having been scared out of his skin.
The culprit was crime. It had been rising relentlessly—a graph plotting the crime rate in any American city over recent decades looked like a ski slope in profile—and it seemed now to herald the end of the world as we knew it. Death by gunfire, intentional and otherwise, had become commonplace. So too had carjacking and crack dealing, robbery and rape. Violent crime was a gruesome, constant companion. And things were about to get even worse. Much worse. All the experts were saying so.
The cause was the so-called superpredator. For a time, he was everywhere. Glowering from the cover of newsweeklies. Swaggering his way through foot-thick government reports. He was a scrawny, big-city teenager with a cheap gun in his hand and nothing in his heart but ruthlessness. There were thousands out there just like him, we were told, a generation of killers about to hurl the country into deepest chaos.
In 1995 the criminologist James Alan Fox wrote a report for the U.S. attorney general that grimly detailed the coming spike in murders by teenagers. Fox proposed optimistic and pessimistic scenarios. In the optimistic scenario, he believed, the rate of teen homicides would rise another 15 percent over the next decade; in the pessimistic scenario, it would more than double. “The next crime wave will get so bad,” he said, “that it will make 1995 look like the good old days.”
Other criminologists, political scientists, and similarly learned forecasters laid out the same horrible future, as did President Clinton. “We know we’ve got about six years to turn this juvenile crime thing around,” Clinton said, “or our country is going to be living with chaos. And my successors will not be giving speeches about the wonderful opportunities of the global economy; they’ll be trying to keep body and soul together for people on the streets of these cities.” The smart money was plainly on the criminals.
And then, instead of going up and up and up, crime began to fall. And fall and fall and fall some more. The crime drop was startling in several respects. It was ubiquitous, with every category of crime falling in every part of the country. It was persistent, with incremental decreases year after year. And it was entirely unanticipated—especially by the very experts who had been predicting the opposite.
The magnitude of the reversal was astounding. The teenage murder rate, instead of rising 100 percent or even 15 percent as James Alan Fox had warned, fell more than 50 percent within five years. By 2000 the overall murder rate in the United States had dropped to its lowest level in thirty-five years. So had the rate of just about every other sort of crime, from assault to car theft.
Even though the experts had failed to anticipate the crime drop—which was in fact well under way even as they made their horrifying predictions—they now hurried to explain it. Most of their theories sounded perfectly logical. It was the roaring 1990s economy, they said, that helped turn back crime. It was the proliferation of gun control laws, they said. It was the sort of innovative policing strategies put into place in New York City, where murders would fall from 2,262 in 1990 to 540 in 2005.
These theories were not only logical; they were also encouraging, for they attributed the crime drop to specific and recent human initiatives. If it was gun control and clever police strategies and better-paying jobs that quelled crime—well then, the power to stop criminals had been within our reach all along. As it would be the next time, God forbid, that crime got so bad.
These theories made their way, seemingly without friction, from the experts’ mouths to journalists’ ears to the public’s mind. In short course, they became conventional wisdom.
There was only one problem: they weren’t true.
There was another factor, meanwhile, that had greatly contributed to the massive crime drop of the 1990s. It had taken shape more than twenty years earlier and concerned a young woman in Dallas named Norma McCorvey.
Like the proverbial butterfly that flaps its wings on one continent and eventually causes a hurricane on another, Norma McCorvey dramatically altered the course of events without intending to. All she had wanted was an abortion. She was a poor, uneducated, unskilled, alcoholic, drug-using twenty-one-year-old woman who had already given up two children for adoption and now, in 1970, found herself pregnant again. But in Texas, as in all but a few states at that time, abortion was illegal. McCorvey’s cause came to be adopted by people far more powerful than she. They made her the lead plaintiff in a class-action lawsuit seeking to legalize abortion. The defendant was Henry Wade, the Dallas County district attorney. The case ultimately made it to the U.S. Supreme Court, by which time McCorvey’s name had been disguised as Jane Roe. On January 22, 1973, the court ruled in favor of Ms. Roe, allowing legalized abortion throughout the United States. By this time, of course, it was far too late for Ms. McCorvey/Roe to have her abortion. She had given birth and put the child up for adoption. (Years later she would renounce her allegiance to legalized abortion and become a pro-life activist.)
So how did Roe v. Wade help trigger, a generation later, the greatest crime drop in recorded history?
As far as crime is concerned, it turns out that not all children are born equal. Not even close. Decades of studies have shown that a child born into an adverse family environment is far more likely than other children to become a criminal. And the millions of women most likely to have an abortion in the wake of Roe v. Wade—poor, unmarried, and teenage mothers for whom illegal abortions had been too expensive or too hard to get—were often models of adversity. They were the very women whose children, if born, would have been much more likely than average to become criminals. But because of Roe v. Wade, these children weren’t being born. This powerful cause would have a drastic, distant effect: years later, just as these unborn children would have entered their criminal primes, the rate of crime began to plummet.
It wasn’t gun control or a strong economy or new police strategies that finally blunted the American crime wave. It was, among other factors, the reality that the pool of potential criminals had dramatically shrunk.
Now, as the crime-drop experts (the former crime doomsayers) spun their theories to the media, how many times did they cite legalized abortion as a cause?
Zero.
 
It is the quintessential blend of commerce and camaraderie: you hire a real-estate agent to sell your home.
She sizes up its charms, snaps some pictures, sets the price, writes a seductive ad, shows the house aggressively, negotiates the offers, and sees the deal through to its end. Sure, it’s a lot of work, but she’s getting a nice cut. On the sale of a $300,000 house, a typical 6 percent agent fee yields $18,000. Eighteen thousand dollars, you say to yourself: that’s a lot of money. But you also tell yourself that you never could have sold the house for $300,000 on your own. The agent knew how to—what’s that phrase she used?—“maximize the house’s value.” She got you top dollar, right?
Right?
A real-estate agent is a different breed of expert than a criminologist, but she is every bit the expert. That is, she knows her field far better than the layman on whose behalf she is acting. She is better informed about the house’s value, the state of the housing market, even the buyer’s frame of mind. You depend on her for this information. That, in fact, is why you hired an expert.
As the world has grown more specialized, countless such experts have made themselves similarly indispensable. Doctors, lawyers, contractors, stockbrokers, auto mechanics, mortgage brokers, financial planners: they all enjoy a gigantic informational advantage. And they use that advantage to help you, the person who hired them, get exactly what you want for the best price.
Right?
It would be lovely to think so. But experts are human, and humans respond to incentives. How any given expert treats you, therefore, will depend on how that expert’s incentives are set up. Sometimes his incentives may work in your favor. For instance: a study of California auto mechanics found they often passed up a small repair bill by letting failing cars pass emissions inspections—the reason being that lenient mechanics are rewarded with repeat business. But in a different case, an expert’s incentives may work against you. In a medical study, it turned out that obstetricians in areas with declining birth rates are much more likely to perform cesarean-section deliveries than obstetricians in growing areas—suggesting that, when business is tough, doctors try to ring up more expensive procedures.
It is one thing to muse about experts’ abusing their position and another to prove it. The best way to do so would be to measure how an expert treats you versus how he performs the same service for himself. Unfortunately a surgeon doesn’t operate on himself. Nor is his medical file a matter of public record; neither is an auto mechanic’s repair log for his own car.
Real-estate sales, however, are a matter of public record. And real-estate agents often do sell their own homes. A recent set of data covering the sale of nearly 100,000 houses in suburban Chicago shows that more than 3,000 of those houses were owned by the agents themselves.
Before plunging into the data, it helps to ask a question: what is the real-estate agent’s incentive when she is selling her own home? Simple: to make the best deal possible. Presumably this is also your incentive when you are selling your home. And so your incentive and the real-estate agent’s incentive would seem to be nicely aligned. Her commission, after all, is based on the sale price.
But as incentives go, commissions are tricky. First of all, a 6 percent real-estate commission is typically split between the seller’s agent and the buyer’s. Each agent then kicks back roughly half of her take to the agency. Which means that only 1.5 percent of the purchase price goes directly into your agent’s pocket.
So on the sale of your $300,000 house, her personal take of the $18,000 commission is $4,500. Still not bad, you say. But what if the house was actually worth more than $300,000? What if, with a little more effort and patience and a few more newspaper ads, she could have sold it for $310,000? After the commission, that puts an additional $9,400 in your pocket. But the agent’s additional share—her personal 1.5 percent of the extra $10,000—is a mere $150. If you earn $9,400 while she earns only $150, maybe your incentives aren’t aligned after all. (Especially when she’s the one paying for the ads and doing all the work.) Is the agent willing to put out all that extra time, money, and energy for just $150?
There’s one way to find out: measure the difference between the sales data for houses that belong to real-estate agents themselves and the houses they sold on behalf of clients. Using the data from the sales of those 100,000 Chicago homes, and controlling for any number of variables—location, age and quality of the house, aesthetics, whether or not the property was an investment, and so on—it turns out that a real-estate agent keeps her own home on the market an average of ten days longer and sells it for an extra 3-plus percent, or $10,000 on a $300,000 house. When she sells her own house, an agent holds out for the best offer; when she sells yours, she encourages you to take the first decent offer that comes along. Like a stockbroker churning commissions, she wants to make deals and make them fast. Why not? Her share of a better offer—$150—is too puny an incentive to encourage her to do otherwise.
 
Of all the truisms about politics, one is held to be truer than the rest: money buys elections. Arnold Schwarzenegger, Michael Bloomberg, Jon Corzine—these are but a few recent, dramatic examples of the truism at work. (Disregard for a moment the contrary examples of Steve Forbes, Michael Huffington, and especially Thomas Golisano, who over the course of three gubernatorial elections in New York spent $93 million of his own money and won 4 percent, 8 percent, and 14 percent, respectively, of the vote.) Most people would agree that money has an undue influence on elections and that far too much money is spent on political campaigns.
Indeed, election data show it is true that the candidate who spends more money in a campaign usually wins. But is money the cause of the victory?
It might seem logical to think so, much as it might have seemed logical that a booming 1990s economy helped reduce crime. But just because two things are correlated does not mean that one causes the other. A correlation simply means that a relationship exists between two factors—let’s call them X and Y—but it tells you nothing about the direction of that relationship. It’s possible that X causes Y; it’s also possible that Y causes X; and it may be that X and Y are both being caused by some other factor, Z.
Think about this correlation: cities with a lot of murders also tend to have a lot of police officers. Consider now the police/murder correlation in a pair of real cities. Denver and Washington, D.C., have about the same population—but Washington has nearly three times as many police as Denver, and it also has eight times the number of murders. Unless you have more information, however, it’s hard to say what’s causing what. Someone who didn’t know better might contemplate these figures and conclude that it is all those extra police in Washington who are causing the extra murders. Such wayward thinking, which has a long history, generally provokes a wayward response. Consider the folktale of the czar who learned that the most disease-ridden province in his empire was also the province with the most doctors. His solution? He promptly ordered all the doctors shot dead.
Now, returning to the issue of campaign spending: in order to figure out the relationship between money and elections, it helps to consider the incentives at play in campaign finance. Let’s say you are the kind of person who might contribute $1,000 to a candidate. Chances are you’ll give the money in one of two situations: a close race, in which you think the money will influence the outcome; or a campaign in which one candidate is a sure winner and you would like to bask in reflected glory or receive some future in-kind consideration. The one candidate you won’t contribute to is a sure loser. (Just ask any presidential hopeful who bombs in Iowa and New Hampshire.) So front-runners and incumbents raise a lot more money than long shots. And what about spending that money? Incumbents and front-runners obviously have more cash, but they only spend a lot of it when they stand a legitimate chance of losing; otherwise, why dip into a war chest that might be more useful later on, when a more formidable opponent appears?
Now picture two candidates, one intrinsically appealing and the other not so. The appealing candidate raises much more money and wins easily. But was it the money that won him the votes, or was it his appeal that won the votes and the money?
That’s a crucial question but a very hard one to answer. Voter appeal, after all, isn’t easy to quantify. How can it be measured?
It can’t, really—except in one special case. The key is to measure a candidate against…himself. That is, Candidate A today is likely to be similar to Candidate A two or four years hence. The same could be said for Candidate B. If only Candidate A ran against Candidate B in two consecutive elections but in each case spent different amounts of money. Then, with the candidates’ appeal more or less constant, we could measure the money’s impact.
As it turns out, the same two candidates run against each other in consecutive elections all the time—indeed, in nearly a thousand U.S. congressional races since 1972. What do the numbers have to say about such cases?
Here’s the surprise: the amount of money spent by the candidates hardly matters at all. A winning candidate can cut his spending in half and lose only 1 percent of the vote. Meanwhile, a losing candidate who doubles his spending can expect to shift the vote in his favor by only that same 1 percent. What really matters for a political candidate is not how much you spend; what matters is who you are. (The same could be said—and will be said, in chapter 5—about parents.) Some politicians are inherently attractive to voters and others simply aren’t, and no amount of money can do much about it. (Messrs. Forbes, Huffington, and Golisano already know this, of course.)
And what about the other half of the election truism—that the amount of money spent on campaign finance is obscenely huge? In a typical election period that includes campaigns for the presidency, the Senate, and the House of Representatives, about $1 billion is spent per year—which sounds like a lot of money, unless you care to measure it against something seemingly less important than democratic elections.
It is the same amount, for instance, that Americans spend every year on chewing gum.
 
This isn’t a book about the cost of chewing gum versus campaign spending per se, or about disingenuous real-estate agents, or the impact of legalized abortion on crime. It will certainly address these scenarios and dozens more, from the art of parenting to the mechanics of cheating, from the inner workings of a crack-selling gang to racial discrimination on The Weakest Link. What this book is about is stripping a layer or two from the surface of modern life and seeing what is happening underneath. We will ask a lot of questions, some frivolous and some about life-and-death issues. The answers may often seem odd but, after the fact, also rather obvious. We will seek out these answers in the data—whether those data come in the form of schoolchildren’s test scores or New York City’s crime statistics or a crack dealer’s financial records. Often we will take advantage of patterns in the data that were incidentally left behind, like an airplane’s sharp contrail in a high sky. It is well and good to opine or theorize about a subject, as humankind is wont to do, but when moral posturing is replaced by an honest assessment of the data, the result is often a new, surprising insight.
Morality, it could be argued, represents the way that people would like the world to work—whereas economics represents how it actually does work. Economics is above all a science of measurement. It comprises an extraordinarily powerful and flexible set of tools that can reliably assess a thicket of information to determine the effect of any one factor, or even the whole effect. That’s what “the economy” is, after all: a thicket of information about jobs and real estate and banking and investment. But the tools of economics can be just as easily applied to subjects that are more—well, more interesting.
This book, then, has been written from a very specific worldview, based on a few fundamental ideas:
Incentives are the cornerstone of modern life. And understanding them—or, often, ferreting them out—is the key to solving just about any riddle, from violent crime to sports cheating to online dating.
The conventional wisdom is often wrong. Crime didn’t keep soaring in the 1990s, money alone doesn’t win elections, and—surprise—drinking eight glasses of water a day has never actually been shown to do a thing for your health. Conventional wisdom is often shoddily formed and devilishly difficult to see through, but it can be done.
Dramatic effects often have distant, even subtle, causes. The answer to a given riddle is not always right in front of you. Norma McCorvey had a far greater impact on crime than did the combined forces of gun control, a strong economy, and innovative police strategies. So did, as we shall see, a man named Oscar Danilo Blandon, aka the Johnny Appleseed of Crack.
“Experts”—from criminologists to real-estate agents—use their informational advantage to serve their own agenda. However, they can be beat at their own game. And in the face of the Internet, their informational advantage is shrinking every day—as evidenced by, among other things, the falling price of coffins and life-insurance premiums.
Knowing what to measure and how to measure it makes a complicated world much less so. If you learn to look at data in the right way, you can explain riddles that otherwise might have seemed impossible. Because there is nothing like the sheer power of numbers to scrub away layers of confusion and contradiction.
So the aim of this book is to explore the hidden side of…everything. This may occasionally be a frustrating exercise. It may sometimes feel as if we are peering at the world through a straw or even staring into a funhouse mirror; but the idea is to look at many different scenarios and examine them in a way they have rarely been examined. In some regards, this is a strange concept for a book. Most books put forth a single theme, crisply expressed in a sentence or two, and then tell the entire story of that theme: the history of salt; the fragility of democracy; the use and misuse of punctuation. This book has no such unifying theme. We did consider, for about six minutes, writing a book that would revolve around a single theme—the theory and practice of applied microeconomics, anyone?—but opted instead for a sort of treasure-hunt approach. Yes, this approach employs the best analytical tools that economics can offer, but it also allows us to follow whatever freakish curiosities may occur to us. Thus our invented field of study: Freakonomics. The sort of stories told in this book are not often covered in Econ 101, but that may change. Since the science of economics is primarily a set of tools, as opposed to a subject matter, then no subject, however offbeat, need be beyond its reach.
It is worth remembering that Adam Smith, the founder of classical economics, was first and foremost a philosopher. He strove to be a moralist and, in doing so, became an economist. When he published The Theory of Moral Sentiments in 1759, modern capitalism was just getting under way. Smith was entranced by the sweeping changes wrought by this new force, but it wasn’t just the numbers that interested him. It was the human effect, the fact that economic forces were vastly changing the way a person thought and behaved in a given situation. What might lead one person to cheat or steal while another didn’t? How would one person’s seemingly innocuous choice, good or bad, affect a great number of people down the line? In Smith’s era, cause and effect had begun to wildly accelerate; incentives were magnified tenfold. The gravity and shock of these changes were as overwhelming to the citizens of his time as the gravity and shock of modern life may seem to us today.
Smith’s true subject was the friction between individual desire and societal norms. The economic historian Robert Heilbroner, writing in The Worldly Philosophers, wondered how Smith was able to separate the doings of man, a creature of self-interest, from the greater moral plane in which man operated. “Smith held that the answer lay in our ability to put ourselves in the position of a third person, an impartial observer,” Heilbroner wrote, “and in this way to form a notion of the objective…merits of a case.”
Consider yourself, then, in the company of a third person—or, if you will, a pair of third people—eager to explore the objective merits of interesting cases. These explorations generally begin with the asking of a simple unasked question. Such as: what do schoolteachers and sumo wrestlers have in common?


1
What Do Schoolteachers and Sumo Wrestlers Have in Common?
Imagine for a moment that you are the manager of a day-care center. You have a clearly stated policy that children are supposed to be picked up by 4 p.m. But very often parents are late. The result: at day’s end, you have some anxious children and at least one teacher who must wait around for the parents to arrive. What to do?
A pair of economists who heard of this dilemma—it turned out to be a rather common one—offered a solution: fine the tardy parents. Why, after all, should the day-care center take care of these kids for free?
The economists decided to test their solution by conducting a study of ten day-care centers in Haifa, Israel. The study lasted twenty weeks, but the fine was not introduced immediately. For the first four weeks, the economists simply kept track of the number of parents who came late; there were, on average, eight late pickups per week per day-care center. In the fifth week, the fine was enacted. It was announced that any parent arriving more than ten minutes late would pay $3 per child for each incident. The fee would be added to the parents’ monthly bill, which was roughly $380.
After the fine was enacted, the number of late pickups promptly went…up. Before long there were twenty late pickups per week, more than double the original average. The incentive had plainly backfired.
Economics is, at root, the study of incentives: how people get what they want, or need, especially when other people want or need the same thing. Economists love incentives. They love to dream them up and enact them, study them and tinker with them. The typical economist believes the world has not yet invented a problem that he cannot fix if given a free hand to design the proper incentive scheme. His solution may not always be pretty—it may involve coercion or exorbitant penalties or the violation of civil liberties—but the original problem, rest assured, will be fixed. An incentive is a bullet, a lever, a key: an often tiny object with astonishing power to change a situation.
We all learn to respond to incentives, negative and positive, from the outset of life. If you toddle over to the hot stove and touch it, you burn a finger. But if you bring home straight A’s from school, you get a new bike. If you are spotted picking your nose in class, you get ridiculed. But if you make the basketball team, you move up the social ladder. If you break curfew, you get grounded. But if you ace your SATs, you get to go to a good college. If you flunk out of law school, you have to go to work at your father’s insurance company. But if you perform so well that a rival company comes calling, you become a vice president and no longer have to work for your father. If you become so excited about your new vice president job that you drive home at eighty mph, you get pulled over by the police and fined $100. But if you hit your sales projections and collect a year-end bonus, you not only aren’t worried about the $100 ticket but can also afford to buy that Viking range you’ve always wanted—and on which your toddler can now burn her own finger.
An incentive is simply a means of urging people to do more of a good thing and less of a bad thing. But most incentives don’t come about organically. Someone—an economist or a politician or a parent—has to invent them. Your three-year-old eats all her vegetables for a week? She wins a trip to the toy store. A big steelmaker belches too much smoke into the air? The company is fined for each cubic foot of pollutants over the legal limit. Too many Americans aren’t paying their share of income tax? It was the economist Milton Friedman who helped come up with a solution to this one: automatic tax withholding from employees’ paychecks.
There are three basic flavors of incentive: economic, social, and moral. Very often a single incentive scheme will include all three varieties. Think about the anti-smoking campaign of recent years. The addition of a $3-per-pack “sin tax” is a strong economic incentive against buying cigarettes. The banning of cigarettes in restaurants and bars is a powerful social incentive. And when the U.S. government asserts that terrorists raise money by selling black-market cigarettes, that acts as a rather jarring moral incentive.
Some of the most compelling incentives yet invented have been put in place to deter crime. Considering this fact, it might be worthwhile to take a familiar question—why is there so much crime in modern society?—and stand it on its head: why isn’t there a lot more crime?
After all, every one of us regularly passes up opportunities to maim, steal, and defraud. The chance of going to jail—thereby losing your job, your house, and your freedom, all of which are essentially economic penalties—is certainly a strong incentive. But when it comes to crime, people also respond to moral incentives (they don’t want to do something they consider wrong) and social incentives (they don’t want to be seen by others as doing something wrong). For certain types of misbehavior, social incentives are terribly powerful. In an echo of Hester Prynne’s scarlet letter, many American cities now fight prostitution with a “shaming” offensive, posting pictures of convicted johns (and prostitutes) on websites or on local-access television. Which is a more horrifying deterrent: a $500 fine for soliciting a prostitute or the thought of your friends and family ogling you on www.HookersAndJohns.com?
So through a complicated, haphazard, and constantly readjusted web of economic, social, and moral incentives, modern society does its best to militate against crime. Some people would argue that we don’t do a very good job. But taking the long view, that is clearly not true. Consider the historical trend in homicide (not including wars), which is both the most reliably measured crime and the best barometer of a society’s overall crime rate. These statistics, compiled by the criminologist Manuel Eisner, track the historical homicide levels in five European regions.
 
HOMICIDES
(per 100,000 People)



The steep decline of these numbers over the centuries suggests that, for one of the gravest human concerns—getting murdered—the incentives that we collectively cook up are working better and better.
So what was wrong with the incentive at the Israeli day-care centers?
You have probably already guessed that the $3 fine was simply too small. For that price, a parent with one child could afford to be late every day and only pay an extra $60 each month—just one-sixth of the base fee. As babysitting goes, that’s pretty cheap. What if the fine had been set at $100 instead of $3? That would have likely put an end to the late pickups, though it would have also engendered plenty of ill will. (Any incentive is inherently a trade-off; the trick is to balance the extremes.)
But there was another problem with the day-care center fine. It substituted an economic incentive (the $3 penalty) for a moral incentive (the guilt that parents were supposed to feel when they came late). For just a few dollars each day, parents could buy off their guilt. Furthermore, the small size of the fine sent a signal to the parents that late pickups weren’t such a big problem. If the day-care center suffers only $3 worth of pain for each late pickup, why bother to cut short your tennis game? Indeed, when the economists eliminated the $3 fine in the seventeenth week of their study, the number of late-arriving parents didn’t change. Now they could arrive late, pay no fine, and feel no guilt.
Such is the strange and powerful nature of incentives. A slight tweak can produce drastic and often unforeseen results. Thomas Jefferson noted this while reflecting on the tiny incentive that led to the Boston Tea Party and, in turn, the American Revolution: “So inscrutable is the arrangement of causes and consequences in this world that a two-penny duty on tea, unjustly imposed in a sequestered part of it, changes the condition of all its inhabitants.”
In the 1970s, researchers conducted a study that, like the Israeli day-care study, pitted a moral incentive against an economic incentive. In this case, they wanted to learn about the motivation behind blood donations. Their discovery: when people are given a small stipend for donating blood rather than simply being praised for their altruism, they tend to donate less blood. The stipend turned a noble act of charity into a painful way to make a few dollars, and it wasn’t worth it.
What if the blood donors had been offered an incentive of $50, or $500, or $5,000? Surely the number of donors would have changed dramatically.
But something else would have changed dramatically as well, for every incentive has its dark side. If a pint of blood were suddenly worth $5,000, you can be sure that plenty of people would take note. They might literally steal blood at knifepoint. They might pass off pig blood as their own. They might circumvent donation limits by using fake IDs. Whatever the incentive, whatever the situation, dishonest people will try to gain an advantage by whatever means necessary.
Or, as W. C. Fields once said: a thing worth having is a thing worth cheating for.
 
Who cheats?
Well, just about anyone, if the stakes are right. You might say to yourself, I don’t cheat, regardless of the stakes. And then you might remember the time you cheated on, say, a board game. Last week. Or the golf ball you nudged out of its bad lie. Or the time you really wanted a bagel in the office break room but couldn’t come up with the dollar you were supposed to drop in the coffee can. And then took the bagel anyway. And told yourself you’d pay double the next time. And didn’t.
For every clever person who goes to the trouble of creating an incentive scheme, there is an army of people, clever and otherwise, who will inevitably spend even more time trying to beat it. Cheating may or may not be human nature, but it is certainly a prominent feature in just about every human endeavor. Cheating is a primordial economic act: getting more for less. So it isn’t just the boldface names—inside-trading CEOs and pill-popping ballplayers and perk-abusing politicians—who cheat. It is the waitress who pockets her tips instead of pooling them. It is the Wal-Mart payroll manager who goes into the computer and shaves his employees’ hours to make his own performance look better. It is the third grader who, worried about not making it to the fourth grade, copies test answers from the kid sitting next to him.
Some cheating leaves barely a shadow of evidence. In other cases, the evidence is massive. Consider what happened one spring evening at midnight in 1987: seven million American children suddenly disappeared. The worst kidnapping wave in history? Hardly. It was the night of April 15, and the Internal Revenue Service had just changed a rule. Instead of merely listing the name of each dependent child, tax filers were now required to provide a Social Security number. Suddenly, seven million children—children who had existed only as phantom exemptions on the previous year’s 1040 forms—vanished, representing about one in ten of all dependent children in the United States.
The incentive for those cheating taxpayers was quite clear. The same for the waitress, the payroll manager, and the third grader. But what about that third grader’s teacher? Might she have an incentive to cheat? And if so, how would she do it?
 
Imagine now that instead of running a day-care center in Haifa, you are running the Chicago Public Schools, a system that educates 400,000 students each year.
The most volatile current debate among American school administrators, teachers, parents, and students concerns “high-stakes” testing. The stakes are considered high because instead of simply testing students to measure their progress, schools are increasingly held accountable for the results.
The federal government mandated high-stakes testing as part of the No Child Left Behind law, signed by President Bush in 2002. But even before that law, most states gave annual standardized tests to students in elementary and secondary school. Twenty states rewarded individual schools for good test scores or dramatic improvement; thirty-two states sanctioned the schools that didn’t do well.
The Chicago Public School system embraced high-stakes testing in 1996. Under the new policy, a school with low reading scores would be placed on probation and face the threat of being shut down, its staff to be dismissed or reassigned. The CPS also did away with what is known as social promotion. In the past, only a dramatically inept or difficult student was held back a grade. Now, in order to be promoted, every student in third, sixth, and eighth grade had to manage a minimum score on the standardized, multiple-choice exam known as the Iowa Test of Basic Skills.
Advocates of high-stakes testing argue that it raises the standards of learning and gives students more incentive to study. Also, if the test prevents poor students from advancing without merit, they won’t clog up the higher grades and slow down good students. Opponents, meanwhile, worry that certain students will be unfairly penalized if they don’t happen to test well, and that teachers may concentrate on the test topics at the exclusion of more important lessons.
Schoolchildren, of course, have had incentive to cheat for as long as there have been tests. But high-stakes testing has so radically changed the incentives for teachers that they too now have added reason to cheat. With high-stakes testing, a teacher whose students test poorly can be censured or passed over for a raise or promotion. If the entire school does poorly, federal funding can be withheld; if the school is put on probation, the teacher stands to be fired. High-stakes testing also presents teachers with some positive incentives. If her students do well enough, she might find herself praised, promoted, and even richer: the state of California at one point introduced bonuses of $25,000 for teachers who produced big test-score gains.
And if a teacher were to survey this newly incentivized landscape and consider somehow inflating her students’ scores, she just might be persuaded by one final incentive: teacher cheating is rarely looked for, hardly ever detected, and just about never punished.
How might a teacher go about cheating? There are any number of possibilities, from brazen to subtle. A fifth-grade student in Oakland recently came home from school and gaily told her mother that her super-nice teacher had written the answers to the state exam right there on the chalkboard. Such instances are certainly rare, for placing your fate in the hands of thirty prepubescent witnesses doesn’t seem like a risk that even the worst teacher would take. (The Oakland teacher was duly fired.) There are more nuanced ways to inflate students’ scores. A teacher can simply give students extra time to complete the test. If she obtains a copy of the exam early—that is, illegitimately—she can prepare them for specific questions. More broadly, she can “teach to the test,” basing her lesson plans on questions from past years’ exams, which isn’t considered cheating but may well violate the spirit of the test. Since these tests all have multiple-choice answers, with no penalty for wrong guesses, a teacher might instruct her students to randomly fill in every blank as the clock is winding down, perhaps inserting a long string of Bs or an alternating pattern of Bs and Cs. She might even fill in the blanks for them after they’ve left the room.
But if a teacher really wanted to cheat—and make it worth her while—she might collect her students’ answer sheets and, in the hour or so before turning them in to be read by an electronic scanner, erase the wrong answers and fill in correct ones. (And you always thought that no. 2 pencil was for the children to change their answers.) If this kind of teacher cheating is truly going on, how might it be detected?
To catch a cheater, it helps to think like one. If you were willing to erase your students’ wrong answers and fill in correct ones, you probably wouldn’t want to change too many wrong answers. That would clearly be a tip-off. You probably wouldn’t even want to change answers on every student’s test—another tip-off. Nor, in all likelihood, would you have enough time, because the answer sheets have to be turned in soon after the test is over. So what you might do is select a string of eight or ten consecutive questions and fill in the correct answers for, say, one-half or two-thirds of your students. You could easily memorize a short pattern of correct answers, and it would be a lot faster to erase and change that pattern than to go through each student’s answer sheet individually. You might even think to focus your activity toward the end of the test, where the questions tend to be harder than the earlier questions. In that way, you’d be most likely to substitute correct answers for wrong ones.
If economics is a science primarily concerned with incentives, it is also—fortunately—a science with statistical tools to measure how people respond to those incentives. All you need are some data.
In this case, the Chicago Public School system obliged. It made available a database of the test answers for every CPS student from third grade through seventh grade from 1993 to 2000. This amounts to roughly 30,000 students per grade per year, more than 700,000 sets of test answers, and nearly 100 million individual answers. The data, organized by classroom, included each student’s question-by-question answer strings for reading and math tests. (The actual paper answer sheets were not included; they were habitually shredded soon after a test.) The data also included some information about each teacher and demographic information for every student, as well as his or her past and future test scores—which would prove a key element in detecting the teacher cheating.
Now it was time to construct an algorithm that could tease some conclusions from this mass of data. What might a cheating teacher’s classroom look like?
The first thing to search for would be unusual answer patterns in a given classroom: blocks of identical answers, for instance, especially among the harder questions. If ten very bright students (as indicated by past and future test scores) gave correct answers to the exam’s first five questions (typically the easiest ones), such an identical block shouldn’t be considered suspicious. But if ten poor students gave correct answers to the last five questions on the exam (the hardest ones), that’s worth looking into. Another red flag would be a strange pattern within any one student’s exam—such as getting the hard questions right while missing the easy ones—especially when measured against the thousands of students in other classrooms who scored similarly on the same test. Furthermore, the algorithm would seek out a classroom full of students who performed far better than their past scores would have predicted and who then went on to score significantly lower the following year. A dramatic one-year spike in test scores might initially be attributed to a good teacher; but with a dramatic fall to follow, there’s a strong likelihood that the spike was brought about by artificial means.
Consider now the answer strings from the students in two sixth-grade Chicago classrooms who took the identical math test. Each horizontal row represents one student’s answers. The letter a, b, c, or d indicates a correct answer; a number indicates a wrong answer, with 1 corresponding to a, 2 corresponding to b, and so on. A zero represents an answer that was left blank. One of these classrooms almost certainly had a cheating teacher and the other did not. Try to tell the difference—although be forewarned that it’s not easy with the naked eye.
Classroom A
112a4a342cb214d0001acd24a3a12dadbcb4a0000000
d4a2341cacbddad3142a2344a2ac23421c00adb4b3cb
1b2a34d4ac42d23b141acd24a3a12dadbcb4a2134141
dbaab3dcacb1dadbc42ac2cc31012dadbcb4adb40000
d12443d43232d32323c213c22d2c23234c332db4b300
db2abad1acbdda212b1acd24a3a12dadbcb400000000
d4aab2124cbddadbcb1a42cca3412dadbcb423134bc1
1b33b4d4a2b1dadbc3ca22c000000000000000000000
d43a3a24acb1d32b412acd24a3a12dadbcb422143bc0
313a3ad1ac3d2a23431223c000012dadbcb400000000
db2a33dcacbd32d313c21142323cc300000000000000
d43ab4d1ac3dd43421240d24a3a12dadbcb400000000
db223a24acb11a3b24cacd12a241cdadbcb4adb4b300
db4abadcacb1dad3141ac212a3a1c3a144ba2db41b43
1142340c2cbddadb4b1acd24a3a12dadbcb43d133bc4
214ab4dc4cbdd31b1b2213c4ad412dadbcb4adb00000
1423b4d4a23d24131413234123a243a2413a21441343
3b3ab4d14c3d2ad4cbcac1c003a12dadbcb4adb40000
dba2ba21ac3d2ad3c4c4cd40a3a12dadbcb400000000
d122ba2cacbd1a13211a2d02a2412d0dbcb4adb4b3c0
144a3adc4cbddadbcbc2c2cc43a12dadbcb4211ab343
d43aba3cacbddadbcbca42c2a3212dadbcb42344b3cb
Classroom B
db3a431422bd131b4413cd422a1acda332342d3ab4c4
d1aa1a11acb2d3dbc1ca22c23242c3a142b3adb243c1
d42a12d2a4b1d32b21ca2312a3411d00000000000000
3b2a34344c32d21b1123cdc000000000000000000000
34aabad12cbdd3d4c1ca112cad2ccd00000000000000
d33a3431a2b2d2d44b2acd2cad2c2223b40000000000
23aa32d2a1bd2431141342c13d212d233c34a3b3b000
d32234d4a1bdd23b242a22c2a1a1cda2b1baa33a0000
d3aab23c4cbddadb23c322c2a222223232b443b24bc3
d13a14313c31d42b14c421c42332cd2242b3433a3343
d13a3ad122b1da2b11242dc1a3a12100000000000000
d12a3ad1a13d23d3cb2a21ccada24d2131b440000000
314a133c4cbd142141ca424cad34c122413223ba4b40
d42a3adcacbddadbc42ac2c2ada2cda341baa3b24321
db1134dc2cb2dadb24c412c1ada2c3a341ba20000000
d1341431acbddad3c4c213412da22d3d1132a1344b1b
1ba41a21a1b2dadb24ca22c1ada2cd32413200000000
dbaa33d2a2bddadbcbca11c2a2accda1b2ba20000000
If you guessed that classroom A was the cheating classroom, congratulations. Here again are the answer strings from classroom A, now reordered by a computer that has been asked to apply the cheating algorithm and seek out suspicious patterns.
 
Classroom A
(With cheating algorithm applied)
• 112a4a342cb214d0001acd24a3a12dadbcb4a0000000
• 1b2a34d4ac42d23b141acd24a3a12dadbcb4a2134141
• db2abad1acbdda212b1acd24a3a12dadbcb400000000
• d43a3a24acb1d32b412acd24a3a12dadbcb422143bc0
• 1142340c2cbddadb4b1acd24a3a12dadbcb43d133bc4
• d43ab4d1ac3dd43421240d24a3a12dadbcb400000000
• dba2ba21ac3d2ad3c4c4cd40a3a12dadbcb400000000
• 144a3adc4cbddadbcbc2c2cc43a12dadbcb4211ab343
• 3b3ab4d14c3d2ad4cbcac1c003a12dadbcb4adb40000
• d43aba3cacbddadbcbca42c2a3212dadbcb42344b3cb
• 214ab4dc4cbdd31b1b2213c4ad412dadbcb4adb00000
• 313a3ad1ac3d2a23431223c000012dadbcb400000000
• d4aab2124cbddadbcb1a42cca3412dadbcb423134bc1
• dbaab3dcacb1dadbc42ac2cc31012dadbcb4adb40000
• db223a24acb11a3b24cacd12a241cdadbcb4adb4b300
• d122ba2cacbd1a13211a2d02a2412d0dbcb4adb4b3c0
• 1423b4d4a23d24131413234123a243a2413a21441343
• db4abadcacb1dad3141ac212a3a1c3a144ba2db41b43
• db2a33dcacbd32d313c21142323cc300000000000000
• 1b33b4d4a2b1dadbc3ca22c000000000000000000000
• d12443d43232d32323c213c22d2c23234c332db4b300
• d4a2341cacbddad3142a2344a2ac23421c00adb4b3cb
Take a look at the answers in bold. Did fifteen out of twenty-two students somehow manage to reel off the same six consecutive correct answers (the d-a-d-b-c-b string) all by themselves?
There are at least four reasons this is unlikely. One: those questions, coming near the end of the test, were harder than the earlier questions. Two: these were mainly subpar students to begin with, few of whom got six consecutive right answers elsewhere on the test, making it all the more unlikely they would get right the same six hard questions. Three: up to this point in the test, the fifteen students’ answers were virtually uncorrelated. Four: three of the students (numbers 1, 9, and 12) left more than one answer blank before the suspicious string and then ended the test with another string of blanks. This suggests that a long, unbroken string of blank answers was broken not by the student but by the teacher.
There is another oddity about the suspicious answer string. On nine of the fifteen tests, the six correct answers are preceded by another identical string, 3-a-1-2, which includes three of four incorrect answers. And on all fifteen tests, the six correct answers are followed by the same incorrect answer, a 4. Why on earth would a cheating teacher go to the trouble of erasing a student’s test sheet and then fill in the wrong answer?
Perhaps she is merely being strategic. In case she is caught and hauled into the principal’s office, she could point to the wrong answers as proof that she didn’t cheat. Or perhaps—and this is a less charitable but just as likely answer—she doesn’t know the right answers herself. (With standardized tests, the teacher is typically not given an answer key.) If this is the case, then we have a pretty good clue as to why her students are in need of inflated grades in the first place: they have a bad teacher.
Another indication of teacher cheating in classroom A is the class’s overall performance. As sixth graders who were taking the test in the eighth month of the academic year, these students needed to achieve an average score of 6.8 to be considered up to national standards. (Fifth graders taking the test in the eighth month of the year needed to score 5.8, seventh graders 7.8, and so on.) The students in classroom A averaged 5.8 on their sixth-grade tests, which is a full grade level below where they should be. So plainly these are poor students. A year earlier, however, these students did even worse, averaging just 4.1 on their fifth-grade tests. Instead of improving by one full point between fifth and sixth grade, as would be expected, they improved by 1.7 points, nearly two grades’ worth. But this miraculous improvement was short-lived. When these sixth-grade students reached seventh grade, they averaged 5.5—more than two grade levels below standard and even worse than they did in sixth grade. Consider the erratic year-to-year scores of three particular students from classroom A:



The three-year scores from classroom B, meanwhile, are also poor but at least indicate an honest effort: 4.2, 5.1, and 6.0. So an entire roomful of children in classroom A suddenly got very smart one year and very dim the next, or more likely, their sixth-grade teacher worked some magic with her pencil.
There are two noteworthy points to be made about the children in classroom A, tangential to the cheating itself. The first is that they are obviously in poor academic shape, which makes them the very children whom high-stakes testing is promoted as helping the most. The second point is that these students (and their parents) would be in for a terrible shock once they reached the seventh grade. All they knew was that they had been successfully promoted due to their test scores. (No child left behind, indeed.) They weren’t the ones who artificially jacked up their scores; they probably expected to do great in the seventh grade—and then they failed miserably. This may be the cruelest twist yet in high-stakes testing. A cheating teacher may tell herself that she is helping her students, but the fact is that she would appear far more concerned with helping herself.
An analysis of the entire Chicago data reveals evidence of teacher cheating in more than two hundred classrooms per year, roughly 5 percent of the total. This is a conservative estimate, since the algorithm was able to identify only the most egregious form of cheating—in which teachers systematically changed students’ answers—and not the many subtler ways a teacher might cheat. In a recent study among North Carolina schoolteachers, some 35 percent of the respondents said they had witnessed their colleagues cheating in some fashion, whether by giving students extra time, suggesting answers, or manually changing students’ answers.
What are the characteristics of a cheating teacher? The Chicago data shows that male and female teachers are equally prone to cheating. A cheating teacher tends to be younger and less qualified than average. She is also more likely to cheat after her incentives change. Because the Chicago data ran from 1993 to 2000, it bracketed the introduction of high-stakes testing in 1996. Sure enough, there was a pronounced spike in cheating in 1996. Nor was the cheating random. It was the teachers in the lowest-scoring classrooms who were most likely to cheat. It should also be noted that the $25,000 bonus for California teachers was eventually revoked, in part because of suspicions that too much of the money was going to cheaters.
Not every result of the Chicago cheating analysis was so dour. In addition to detecting cheaters, the algorithm could also identify the best teachers in the school system. A good teacher’s impact was nearly as distinctive as a cheater’s. Instead of getting random answers correct, her students would show real improvement on the easier types of questions they had previously missed, an indication of actual learning. And a good teacher’s students carried over all their gains into the next grade.
Most academic analyses of this sort tend to languish, unread, on a dusty library shelf. But in early 2002, the new CEO of the Chicago Public Schools, Arne Duncan, contacted the study’s authors. He didn’t want to protest or hush up their findings. Rather, he wanted to make sure that the teachers identified by the algorithm as cheaters were truly cheating—and then do something about it.
Duncan was an unlikely candidate to hold such a powerful job. He was only thirty-six when appointed, a onetime academic all-American at Harvard who later played pro basketball in Australia. He had spent just three years with the CPS—and never in a job important enough to have his own secretary—before becoming its CEO. It didn’t hurt that Duncan had grown up in Chicago. His father taught psychology at the University of Chicago; his mother ran an afterschool program for forty years, without pay, in a poor neighborhood. When Duncan was a boy, his afterschool playmates were the underprivileged kids his mother cared for. So when he took over the public schools, his allegiance lay more with schoolchildren and their families than with teachers and their union.
The best way to get rid of cheating teachers, Duncan had decided, was to readminister the standardized exam. He only had the resources to retest 120 classrooms, however, so he asked the creators of the cheating algorithm to help choose which classrooms to test.
How could those 120 retests be used most effectively? It might have seemed sensible to retest only the classrooms that likely had a cheating teacher. But even if their retest scores were lower, the teachers could argue that the students did worse merely because they were told that the scores wouldn’t count in their official record—which, in fact, all retested students would be told. To make the retest results convincing, some non-cheaters were needed as a control group. The best control group? The classrooms shown by the algorithm to have the best teachers, in which big gains were thought to have been legitimately attained. If those classrooms held their gains while the classrooms with a suspected cheater lost ground, the cheating teachers could hardly argue that their students did worse only because the scores wouldn’t count.
So a blend was settled upon. More than half of the 120 retested classrooms were those suspected of having a cheating teacher. The remainder were divided between the supposedly excellent teachers (high scores but no suspicious answer patterns) and, as a further control, classrooms with mediocre scores and no suspicious answers.
The retest was given a few weeks after the original exam. The children were not told the reason for the retest. Neither were the teachers. But they may have gotten the idea when it was announced that CPS officials, not the teachers, would administer the test. The teachers were asked to stay in the classroom with their students, but they would not be allowed to even touch the answer sheets.
The results were as compelling as the cheating algorithm had predicted. In the classrooms chosen as controls, where no cheating was suspected, scores stayed about the same or even rose. In contrast, the students with the teachers identified as cheaters scored far worse, by an average of more than a full grade level.
As a result, the Chicago Public School system began to fire its cheating teachers. The evidence was only strong enough to get rid of a dozen of them, but the many other cheaters had been duly warned. The final outcome of the Chicago study is further testament to the power of incentives: the following year, cheating by teachers fell more than 30 percent.
 
You might think that the sophistication of teachers who cheat would increase along with the level of schooling. But an exam given at the University of Georgia in the fall of 2001 disputes that idea. The course was called Coaching Principles and Strategies of Basketball, and the final grade was based on a single exam that had twenty questions. Among the questions:
 
How many halves are in a college basketball game?
• a. 1 b. 2 c. 3 d. 4
How many points does a 3-pt. field goal account for in a basketball game?
• a. 1 b. 2 c. 3 d. 4
What is the name of the exam which all high school seniors in the state of Georgia must pass?
• a. Eye Exam
• b. How Do the Grits Taste Exam
• c. Bug Control Exam
• d. Georgia Exit Exam
In your opinion, who is the best Division I assistant coach in the country?
• a. Ron Jirsa
• b. John Pelphrey
• c. Jim Harrick Jr.
• d. Steve Wojciechowski
If you are stumped by the final question, it might help to know that Coaching Principles was taught by Jim Harrick Jr., an assistant coach with the university’s basketball team. It might also help to know that his father, Jim Harrick Sr., was the head basketball coach. Not surprisingly, Coaching Principles was a favorite course among players on the Harricks’ team. Every student in the class received an A. Not long afterward, both Harricks were relieved of their coaching duties.
 
If it strikes you as disgraceful that Chicago schoolteachers and University of Georgia professors will cheat—a teacher, after all, is meant to instill values along with the facts—then the thought of cheating among sumo wrestlers may also be deeply disturbing. In Japan, sumo is not only the national sport but also a repository of the country’s religious, military, and historical emotion. With its purification rituals and its imperial roots, sumo is sacrosanct in a way that American sports will never be. Indeed, sumo is said to be less about competition than about honor itself.
It is true that sports and cheating go hand in hand. That’s because cheating is more common in the face of a bright-line incentive (the line between winning and losing, for instance) than with a murky incentive. Olympic sprinters and weightlifters, cyclists in the Tour de France, football linemen and baseball sluggers: they have all been shown to swallow whatever pill or powder may give them an edge. It is not only the participants who cheat. Cagey baseball managers try to steal an opponent’s signs. In the 2002 Winter Olympic figure-skating competition, a French judge and a Russian judge were caught trying to swap votes to make sure their skaters medaled. (The man accused of orchestrating the vote swap, a reputed Russian mob boss named Alimzhan Tokhtakhounov, was also suspected of rigging beauty pageants in Moscow.)
An athlete who gets caught cheating is generally condemned, but most fans at least appreciate his motive: he wanted so badly to win that he bent the rules. (As the baseball player Mark Grace once said, “If you’re not cheating, you’re not trying.”) An athlete who cheats to lose, meanwhile, is consigned to a deep circle of sporting hell. The 1919 Chicago White Sox, who conspired with gamblers to throw the World Series (and are therefore known forever as the Black Sox), retain a stench of iniquity among even casual baseball fans. The City College of New York’s championship basketball team, once beloved for its smart and scrappy play, was instantly reviled when it was discovered in 1951 that several players had taken mob money to shave points—intentionally missing baskets to help gamblers beat the point spread. Remember Terry Malloy, the tormented former boxer played by Marlon Brando in On the Waterfront? As Malloy saw it, all his troubles stemmed from the one fight in which he took a dive. Otherwise, he could have had class; he could have been a contender.
If cheating to lose is sport’s premier sin, and if sumo wrestling is the premier sport of a great nation, cheating to lose couldn’t possibly exist in sumo. Could it?
Once again, the data can tell the story. As with the Chicago school tests, the data set under consideration here is surpassingly large: the results from nearly every official match among the top rank of Japanese sumo wrestlers between January 1989 and January 2000, a total of 32,000 bouts fought by 281 different wrestlers.
The incentive scheme that rules sumo is intricate and extraordinarily powerful. Each wrestler maintains a ranking that affects every slice of his life: how much money he makes, how large an entourage he carries, how much he gets to eat, sleep, and otherwise take advantage of his success. The sixty-six highest-ranked wrestlers in Japan, comprising the makuuchi and juryo divisions, make up the sumo elite. A wrestler near the top of this elite pyramid may earn millions and is treated like royalty. Any wrestler in the top forty earns at least $170,000 a year. The seventieth-ranked wrestler in Japan, meanwhile, earns only $15,000 a year. Life isn’t very sweet outside the elite. Low-ranked wrestlers must tend to their superiors, preparing their meals, cleaning their quarters, and even soaping up their hardest-to-reach body parts. So ranking is everything.
A wrestler’s ranking is based on his performance in the elite tournaments that are held six times a year. Each wrestler has fifteen bouts per tournament, one per day over fifteen consecutive days. If he finishes the tournament with a winning record (eight victories or better), his ranking will rise. If he has a losing record, his ranking falls. If it falls far enough, he is booted from the elite rank entirely. The eighth victory in any tournament is therefore critical, the difference between promotion and demotion; it is roughly four times as valuable in the rankings as the typical victory.
So a wrestler entering the final day of a tournament on the bubble, with a 7–7 record, has far more to gain from a victory than an opponent with a record of 8–6 has to lose.
Is it possible, then, that an 8–6 wrestler might allow a 7–7 wrestler to beat him? A sumo bout is a concentrated flurry of force and speed and leverage, often lasting only a few seconds. It wouldn’t be very hard to let yourself be tossed. Let’s imagine for a moment that sumo wrestling is rigged. How might we measure the data to prove it?
The first step would be to isolate the bouts in question: those fought on a tournament’s final day between a wrestler on the bubble and a wrestler who has already secured his eighth win. (Because more than half of all wrestlers end a tournament with either seven, eight, or nine victories, hundreds of bouts fit these criteria.) A final-day match between two 7–7 wrestlers isn’t likely to be fixed, since both fighters badly need the victory. A wrestler with ten or more victories probably wouldn’t throw a match either, since he has his own strong incentive to win: the $100,000 prize for overall tournament champion and a series of $20,000 prizes for the “outstanding technique” award, “fighting spirit” award, and others.
Let’s now consider the following statistic, which represents the hundreds of matches in which a 7–7 wrestler faced an 8–6 wrestler on a tournament’s final day. The left column tallies the probability, based on all past meetings between the two wrestlers fighting that day, that the 7–7 wrestler will win. The right column shows how often the 7–7 wrestler actually did win.



So the 7–7 wrestler, based on past outcomes, was expected to win just less than half the time. This makes sense; their records in this tournament indicate that the 8–6 wrestler is slightly better. But in actuality, the wrestler on the bubble won almost eight out of ten matches against his 8–6 opponent. Wrestlers on the bubble also do astonishingly well against 9–5 opponents:



As suspicious as this looks, a high winning percentage alone isn’t enough to prove that a match is rigged. Since so much depends on a wrestler’s eighth win, he should be expected to fight harder in a crucial bout. But perhaps there are further clues in the data that prove collusion.
It’s worth thinking about the incentive a wrestler might have to throw a match. Maybe he accepts a bribe (which would obviously not be recorded in the data). Or perhaps some other arrangement is made between the two wrestlers. Keep in mind that the pool of elite sumo wrestlers is extraordinarily tight-knit. Each of the sixty-six elite wrestlers fights fifteen of the others in a tournament every two months. Furthermore, each wrestler belongs to a stable that is typically managed by a former sumo champion, so even the rival stables have close ties. (Wrestlers from the same stable do not wrestle one another.)
Now let’s look at the win-loss percentage between the 7–7 wrestlers and the 8–6 wrestlers the next time they meet, when neither one is on the bubble. In this case, there is no great pressure on the individual match. So you might expect the wrestlers who won their 7–7 matches in the previous tournament to do about as well as they had in earlier matches against these same opponents—that is, winning roughly 50 percent of the time. You certainly wouldn’t expect them to uphold their 80 percent clip.
As it turns out, the data show that the 7–7 wrestlers win only 40 percent of the rematches. Eighty percent in one match and 40 percent in the next? How do you make sense of that?
The most logical explanation is that the wrestlers made a quid pro quo agreement: you let me win today, when I really need the victory, and I’ll let you win the next time. (Such an arrangement wouldn’t preclude a cash bribe.) It’s especially interesting to note that by the two wrestlers’ second subsequent meeting, the win percentages revert to the expected level of about 50 percent, suggesting that the collusion spans only two matches.
And it isn’t only the individual wrestlers whose records are suspect. The collective records of the various sumo stables are similarly aberrational. When one stable’s wrestlers fare well on the bubble against wrestlers from a second stable, they tend to do especially poorly when the second stable’s wrestlers are on the bubble. This indicates that some match rigging may be choreographed at the highest level of the sport—much like the Olympic skating judges’ vote swapping.
No formal disciplinary action has ever been taken against a Japanese sumo wrestler for match rigging. Officials from the Japanese Sumo Association typically dismiss any such charges as fabrications by disgruntled former wrestlers. In fact, the mere utterance of the words “sumo” and “rigged” in the same sentence can cause a national furor. People tend to get defensive when the integrity of their national sport is impugned.
Still, allegations of match rigging do occasionally find their way into the Japanese media. These occasional media storms offer one more chance to measure possible corruption in sumo. Media scrutiny, after all, creates a powerful incentive: if two sumo wrestlers or their stables have been rigging matches, they might be leery to continue when a swarm of journalists and TV cameras descend upon them.
So what happens in such cases? The data show that in the sumo tournaments held immediately after allegations of match rigging, 7–7 wrestlers win only 50 percent of their final-day matches against 8–6 opponents instead of the typical 80 percent. No matter how the data are sliced, they inevitably suggest one thing: it is hard to argue that sumo wrestling isn’t rigged.
Several years ago, two former sumo wrestlers came forward with extensive allegations of match rigging—and more. Aside from the crooked matches, they said, sumo was rife with drug use and sexcapades, bribes and tax evasion, and close ties to the yakuza, the Japanese mafia. The two men began to receive threatening phone calls; one of them told friends he was afraid he would be killed by the yakuza. Still, they went forward with plans to hold a press conference at the Foreign Correspondents’ Club in Tokyo. But shortly beforehand, the two men died—hours apart, in the same hospital, of a similar respiratory ailment. The police declared there had been no foul play but did not conduct an investigation. “It seems very strange for these two people to die on the same day at the same hospital,” said Mitsuru Miyake, the editor of a sumo magazine. “But no one has seen them poisoned, so you can’t prove the skepticism.”
Whether or not their deaths were intentional, these two men had done what no other sumo insider had previously done: named names. Of the 281 wrestlers covered in the data cited above, they identified 29 crooked wrestlers and 11 who were said to be incorruptible.
What happens when the whistle-blowers’ corroborating evidence is factored into the analysis of the match data? In matches between two supposedly corrupt wrestlers, the wrestler who was on the bubble won about 80 percent of the time. In bubble matches against a supposedly clean opponent, meanwhile, the bubble wrestler was no more likely to win than his record would predict. Furthermore, when a supposedly corrupt wrestler faced an opponent whom the whistle-blowers did not name as either corrupt or clean, the results were nearly as skewed as when two corrupt wrestlers met—suggesting that most wrestlers who weren’t specifically named were also corrupt.
 
So if sumo wrestlers, schoolteachers, and day-care parents all cheat, are we to assume that mankind is innately and universally corrupt? And if so, how corrupt?
The answer may lie in…bagels. Consider this story about a man named Paul Feldman.
Once upon a time, Feldman dreamed big dreams. With early training in agricultural economics, he wanted to tackle world hunger. Instead, he took a job in Washington, analyzing weapons expenditures for the U.S. Navy. This was in 1962. For the next twenty-odd years, he did further analytic work in Washington. He held senior-level jobs and earned good money, but he wasn’t always recognized for his best work. At the office Christmas party, colleagues would introduce him to their wives not as “the head of the public research group” (which he was) but as “the guy who brings in the bagels.”
The bagels had begun as a casual gesture: a boss treating his employees whenever they won a research contract. Then he made it a habit. Every Friday, he would bring in some bagels, a serrated knife, and cream cheese. When employees from neighboring floors heard about the bagels, they wanted some too. Eventually he was bringing in fifteen dozen bagels a week. In order to recoup his costs, he set out a cash basket and a sign with the suggested price. His collection rate was about 95 percent; he attributed the underpayment to oversight, not fraud.
In 1984, when his research institute fell under new management, Feldman took a look at his future and grimaced. He decided to quit his job and sell bagels. His economist friends thought he had lost his mind, but his wife supported him. The last of their three children was finishing college, and they had retired their mortgage.
Driving around the office parks that encircle Washington, he solicited customers with a simple pitch: early in the morning, he would deliver some bagels and a cash basket to a company’s snack room; he would return before lunch to pick up the money and the leftovers. It was an honor-system commerce scheme, and it worked. Within a few years, Feldman was delivering 8,400 bagels a week to 140 companies and earning as much as he had ever made as a research analyst. He had thrown off the shackles of cubicle life and made himself happy.
He had also—quite without meaning to—designed a beautiful economic experiment. From the beginning, Feldman kept rigorous data on his bagel business. So by measuring the money collected against the bagels taken, he found it possible to tell, down to the penny, just how honest his customers were. Did they steal from him? If so, what were the characteristics of a company that stole versus a company that did not? Under what circumstances did people tend to steal more, or less?
As it happens, Feldman’s accidental study provides a window onto a form of cheating that has long stymied academics: white-collar crime. (Yes, shorting the bagel man is white-collar crime, writ however small.) It might seem ludicrous to address as large and intractable a problem as white-collar crime through the life of a bagel man. But often a small and simple question can help chisel away at the biggest problems.
Despite all the attention paid to rogue companies like Enron, academics know very little about the practicalities of white-collar crime. The reason? There are no good data. A key fact of white-collar crime is that we hear about only the very slim fraction of people who are caught cheating. Most embezzlers lead quiet and theoretically happy lives; employees who steal company property are rarely detected.
With street crime, meanwhile, that is not the case. A mugging or a burglary or a murder is usually tallied whether or not the criminal is caught. A street crime has a victim, who typically reports the crime to the police, who generate data, which in turn generate thousands of academic papers by criminologists, sociologists, and economists. But white-collar crime presents no obvious victim. From whom, exactly, did the masters of Enron steal? And how can you measure something if you don’t know to whom it happened, or with what frequency, or in what magnitude?
Paul Feldman’s bagel business was different. It did present a victim. The victim was Paul Feldman.
 
When he started his business, he expected a 95 percent payment rate, based on the experience at his own office. But just as crime tends to be low on a street where a police car is parked, the 95 percent rate was artificially high: Feldman’s presence had deterred theft. Not only that, but those bagel eaters knew the provider and had feelings (presumably good ones) about him. A broad swath of psychological and economic research has shown that people will pay different amounts for the same item depending on who is providing it. The economist Richard Thaler, in his 1985 “Beer on the Beach” study, showed that a thirsty sunbather would pay $2.65 for a beer delivered from a resort hotel but only $1.50 for the same beer if it came from a shabby grocery store.
In the real world, Feldman learned to settle for less than 95 percent. He came to consider a company “honest” if its payment rate was above 90 percent. He considered a rate between 80 and 90 percent “annoying but tolerable.” If a company habitually paid below 80 percent, Feldman might post a hectoring note, like this one:
The cost of bagels has gone up dramatically since the beginning of the year. Unfortunately, the number of bagels that disappear without being paid for has also gone up. Don’t let that continue. I don’t imagine that you would teach your children to cheat, so why do it yourselves?
In the beginning, Feldman left behind an open basket for the cash, but too often the money vanished. Then he tried a coffee can with a money slot in its plastic lid, which also proved too tempting. In the end, he resorted to making small plywood boxes with a slot cut into the top. The wooden box has worked well. Each year he drops off about seven thousand boxes and loses, on average, just one to theft. This is an intriguing statistic: the same people who routinely steal more than 10 percent of his bagels almost never stoop to stealing his money box—a tribute to the nuanced social calculus of theft. From Feldman’s perspective, an office worker who eats a bagel without paying is committing a crime; the office worker probably doesn’t think so. This distinction probably has less to do with the admittedly small amount of money involved (Feldman’s bagels cost one dollar each, cream cheese included) than with the context of the “crime.” The same office worker who fails to pay for his bagel might also help himself to a long slurp of soda while filling a glass in a self-serve restaurant, but he is very unlikely to leave the restaurant without paying.
So what do the bagel data have to say? In recent years, there have been two noteworthy trends in the overall payment rate. The first was a long, slow decline that began in 1992. By the summer of 2001, the overall rate had slipped to about 87 percent. But immediately after September 11 of that year, the rate spiked a full 2 percent and hasn’t slipped much since. (If a 2 percent gain in payment doesn’t sound like much, think of it this way: the nonpayment rate fell from 13 to 11 percent, which amounts to a 15 percent decline in theft.) Because many of Feldman’s customers are affiliated with national security, there may have been a patriotic element to this 9/11 Effect. Or it may have represented a more general surge in empathy.
The data also show that smaller offices are more honest than big ones. An office with a few dozen employees generally outpays by 3 to 5 percent an office with a few hundred employees. This may seem counterintuitive. In a bigger office, a bigger crowd is bound to convene around the bagel table, providing more witnesses to make sure you drop your money in the box. But in the big-office/small-office comparison, bagel crime seems to mirror street crime. There is far less street crime per capita in rural areas than in cities, in large part because a rural criminal is more likely to be known (and therefore caught). Also, a smaller community tends to exert greater social incentives against crime, the main one being shame.
The bagel data also reflect how much personal mood seems to affect honesty. Weather, for instance, is a major factor. Unseasonably pleasant weather inspires people to pay at a higher rate. Unseasonably cold weather, meanwhile, makes people cheat prolifically; so do heavy rain and wind. Worst are the holidays. The week of Christmas produces a 2 percent drop in payment rates—again, a 15 percent increase in theft, an effect on the same magnitude, in reverse, as that of 9/11. Thanksgiving is nearly as bad; the week of Valentine’s Day is also lousy, as is the week straddling April 15. There are, however, several good holidays: the weeks that include the Fourth of July, Labor Day, and Columbus Day. The difference in the two sets of holidays? The low-cheating holidays represent little more than an extra day off from work. The high-cheating holidays are fraught with miscellaneous anxieties and the high expectations of loved ones.
Feldman has also reached some of his own conclusions about honesty, based more on his experience than the data. He has come to believe that morale is a big factor—that an office is more honest when the employees like their boss and their work. He also believes that employees further up the corporate ladder cheat more than those down below. He got this idea after delivering for years to one company spread out over three floors—an executive floor on top and two lower floors with sales, service, and administrative employees. (Feldman wondered if perhaps the executives cheated out of an overdeveloped sense of entitlement. What he didn’t consider is that perhaps cheating was how they got to be executives.)
 
If morality represents the way we would like the world to work and economics represents how it actually does work, then the story of Feldman’s bagel business lies at the very intersection of morality and economics. Yes, a lot of people steal from him, but the vast majority, even though no one is watching over them, do not. This outcome may surprise some people—including Feldman’s economist friends, who counseled him twenty years ago that his honor-system scheme would never work. But it would not have surprised Adam Smith. In fact, the theme of Smith’s first book, The Theory of Moral Sentiments, was the innate honesty of mankind. “How selfish soever man may be supposed,” Smith wrote, “there are evidently some principles in his nature, which interest him in the fortune of others, and render their happiness necessary to him, though he derives nothing from it, except the pleasure of seeing it.”
There is a tale, “The Ring of Gyges,” that Feldman sometimes tells his economist friends. It comes from Plato’s Republic. A student named Glaucon offered the story in response to a lesson by Socrates—who, like Adam Smith, argued that people are generally good even without enforcement. Glaucon, like Feldman’s economist friends, disagreed. He told of a shepherd named Gyges who stumbled upon a secret cavern with a corpse inside that wore a ring. When Gyges put on the ring, he found that it made him invisible. With no one able to monitor his behavior, Gyges proceeded to do woeful things—seduce the queen, murder the king, and so on. Glaucon’s story posed a moral question: could any man resist the temptation of evil if he knew his acts could not be witnessed? Glaucon seemed to think the answer was no. But Paul Feldman sides with Socrates and Adam Smith—for he knows that the answer, at least 87 percent of the time, is yes.


2
How Is the Ku Klux Klan Like a Group of Real-Estate Agents?
As institutions go, the Ku Klux Klan has had a markedly up-and-down history. It was founded in the immediate aftermath of the Civil War by six former Confederate soldiers in Pulaski, Tennessee. The six young men, four of whom were budding lawyers, saw themselves as merely a circle of like-minded friends. Thus the name they chose, “kuklux,” a slight mangling of kuklos, the Greek word for “circle.” In the beginning, their activities were said to be harmless midnight pranks—for instance, riding horses through the countryside while draped in white sheets and pillowcase hoods. But soon the Klan evolved into a multistate terrorist organization designed to frighten and kill emancipated slaves. Among its regional leaders were five former Confederate generals; its staunchest supporters were the plantation owners for whom Reconstruction posed an economic and political nightmare. In 1872, President Ulysses S. Grant spelled out for the House of Representatives the true aims of the Ku Klux Klan: “By force and terror, to prevent all political action not in accord with the views of the members, to deprive colored citizens of the right to bear arms and of the right of a free ballot, to suppress the schools in which colored children were taught, and to reduce the colored people to a condition closely allied to that of slavery.”
The early Klan did its work through pamphleteering, lynching, shooting, burning, castrating, pistol-whipping, and a thousand forms of intimidation. They targeted former slaves and any whites who supported the blacks’ rights to vote, acquire land, or gain an education. But within barely a decade, the Klan had been extinguished, largely by legal and military interventions out of Washington, D.C.
If the Klan itself was defeated, however, its aims had largely been achieved through the establishment of Jim Crow laws. Congress, which during Reconstruction had been quick to enact measures of legal, social, and economic freedom for blacks, just as quickly began to roll them back. The federal government agreed to withdraw its occupation troops from the South, allowing the restoration of white rule. In Plessy v. Ferguson, the U.S. Supreme Court gave the go-ahead to full-scale racial segregation.
The Ku Klux Klan lay largely dormant until 1915, when D. W. Griffith’s film The Birth of a Nation (originally titled The Clansman) helped spark its rebirth. Griffith presented the Klan as crusaders for white civilization itself, and as one of the noblest forces in American history. The film quoted a line from A History of the American People, written by a renowned historian: “At last there had sprung into existence a great Ku Klux Klan, a veritable empire of the South, to protect the Southern country.” The historian in question was U.S. president Woodrow Wilson, onetime scholar and president of Princeton University.
By the 1920s, a revived Klan claimed eight million members. This time around, the Klan was not confined to the South but ranged throughout the country; this time, it concerned itself not only with blacks but also with Catholics, Jews, communists, unionists, immigrants, agitators, and other disrupters of the status quo. In 1933, with Hitler ascendant in Germany, Will Rogers was the first to draw a line between the new Klan and the new threat in Europe: “Papers all state Hitler is trying to copy Mussolini,” he wrote. “Looks to me like it’s the Ku Klux that he is copying.”
The onset of World War II and a number of internal scandals once again laid the Klan low. Public sentiment turned against the Klan as the unity of a country at war trumped its message of separatism.
But within a few years, there were already signs of a massive revival. As wartime anxiety gave way to postwar uncertainty, Klan membership flourished. Barely two months after V-J Day, the Klan in Atlanta burned a 300-foot cross on the face of Stone Mountain, site of a storied rock carving of Robert E. Lee. The extravagant cross burning, one Klansman later said, was intended “just to let the niggers know the war is over and that the Klan is back on the market.”
Atlanta had by now become Klan headquarters. The Klan was thought to hold great sway with key Georgia politicians, and its Georgia chapters were said to include many policemen and sheriff’s deputies. Yes, the Klan was a secret society, reveling in passwords and cloak-and-dagger ploys, but its real power lay in the very public fear that it fostered, exemplified by the open secret that the Ku Klux Klan and the law-enforcement establishment were brothers in arms.
Atlanta—the Imperial City of the KKK’s Invisible Empire, in Klan jargon—was also home to Stetson Kennedy, a thirty-year-old man with the bloodlines of a Klansman but a temperament that ran opposite. He came from a good southern family which claimed ancestors including two signers of the Declaration of Independence, an officer in the Confederate Army, and John B. Stetson, founder of the famed hat company and the man for whom Stetson University was named.
Stetson Kennedy grew up in a fourteen-room house in Jacksonville, Florida, the youngest of five children. His uncle Brady was a Klansman. But Kennedy would go on to become a self-described “dissident at large,” writing numberless articles and several books that railed against bigotry. He first worked as a folklorist, traveling around Florida to collect old native tales and songs. Years later, when he served as a rare white correspondent for the Pittsburgh Courier, the country’s largest black newspaper, he wrote under the pseudonym Daddy Mention—after a black folk hero who, as myth told it, could outrun the blast of a sheriff’s shotgun.
What drove Kennedy was a hatred of small-mindedness, ignorance, obstructionism, and intimidation—which, in his view, were displayed by no organization more proudly than the Ku Klux Klan. Kennedy saw the Klan as the terrorist arm of the white establishment itself. This struck him as an intractable problem, for a variety of reasons. The Klan was in cahoots with political, business, and law-enforcement leaders. The public was frightened and felt powerless to act against the Klan. And the few anti-hate groups that existed at the time had little leverage or even information about the Klan. “Almost all of the things written on the subject were editorials, not exposés,” Kennedy would later explain. “The writers were against the Klan, all right, but they had precious few inside facts about it.”
So Kennedy set out to gather those facts. He would spend years interviewing Klan leaders and sympathizers, sometimes taking advantage of his own background and lineage to pretend that he was on their side of the issues. He also attended public Klan events and, as he would later write, he even set about to infiltrate the Klan in Atlanta.
The Klan Unmasked, Kennedy’s memoir of his exploits “inside” the Klan, is in fact more of a novelization than a straight nonfiction account. Kennedy, a folklorist at heart, apparently wanted to put across the most dramatic story possible, and therefore included not only his own anti-Klan activities but those of another man, code-named John Brown. Brown was a union worker and a former Klan official who had changed his ways and offered to infiltrate the Klan. It was John Brown who apparently performed many of the most dramatic and dangerous episodes portrayed in The Klan Unmasked—physically attending Klan meetings and other functions in Atlanta—but since Stetson Kennedy was the man who later wrote the book, he rendered Brown’s actions as his own.
Regardless, there was a great deal of information to be gleaned from this Brown/Kennedy collaboration. Brown divulged what he was learning at the weekly Klan meetings: the identities of the Klan’s local and regional leaders; their upcoming plans; the Klan’s current rituals, passwords, and language. It was Klan custom, for instance, to append a Kl to many words. (Thus would two Klansmen hold a Klonversation in the local Klavern.) The secret Klan handshake was a left-handed, limp-wristed fish wiggle. When a traveling Klansman wanted to locate brethren in a strange town, he would ask for a “Mr. Ayak”—“Ayak” being code for “Are You a Klansman?” He would hope to hear this response: “Yes, and I also know a Mr. Akai”—code for “A Klansman Am I.”
Before long, John Brown was invited to join the Klavaliers, the Klan’s secret police and “flog squad.” For an infiltrator, this posed a particularly sticky problem: What would happen if he were called upon to inflict violence?
But as it happened, a central tenet of life in the Klan—and of terrorism in general—is that most of the threatened violence never goes beyond the threat stage.
Consider lynching, the Klan’s hallmark sign of violence. Here, compiled by the Tuskegee Institute, are the decade-by-decade statistics on the lynching of blacks in the United States:



Bear in mind that these figures represent not only lynchings attributed to the Ku Klux Klan but the total number of reported lynchings. The statistics reveal at least three noteworthy facts. The first is the obvious decrease in lynchings over time. The second is the absence of a correlation between lynchings and Klan membership: there were actually more lynchings of blacks between 1900 and 1909, when the Klan was dormant, than during the 1920s, when the Klan had millions of members—which suggests that the Ku Klux Klan carried out far fewer lynchings than is generally thought.
Third, relative to the size of the black population, lynchings were exceedingly rare. To be sure, one lynching is one too many. But by the turn of the century, lynchings were hardly the everyday occurrence that they are often considered in the public recollection. Compare the 281 victims of lynchings in the 1920s to the number of black infants who were dying at that time as a result of malnutrition, pneumonia, diarrhea, and the like. As of 1920, about 13 out of every 100 black children died in infancy, or roughly 20,000 children each year—compared to 28 people who were lynched in a year. As late as 1940, about 10,000 black infants died each year.
What larger truths do these lynching figures suggest? What does it mean that lynchings were relatively rare and that they fell precipitously over time, even in the face of a boom in Klan membership?
The most compelling explanation is that all those early lynchings worked. White racists—whether or not they belonged to the Ku Klux Klan—had through their actions and their rhetoric developed a strong incentive scheme that was terribly clear and terribly frightening. If a black person violated the accepted code of behavior, whether by talking back to a bus driver or daring to try to vote, he knew he might well be punished, perhaps by death.
So it may be that by the mid-1940s, when Stetson Kennedy was trying to bust up the Klan, it didn’t really need to use as much violence. Many blacks, having long been told to behave like second-class citizens—or else—simply obliged. One or two lynchings went a long way toward inducing docility among even a large group of people, for people respond strongly to strong incentives. And there are few incentives more powerful than the fear of random violence—which, in essence, is why terrorism is so effective.
But if the Ku Klux Klan of the 1940s wasn’t uniformly violent, what was it? The Klan that Stetson Kennedy wrote about was in fact a sorry fraternity of men, most of them poorly educated and with poor prospects, who needed a place to vent—and an excuse for occasionally staying out all night. That their fraternity engaged in quasi-religious chanting and oath taking and hosanna hailing, all of it top secret, made it that much more appealing.
Kennedy also found the Klan to be a slick money-making operation, at least for those near the top of the organization. Klan leaders had any number of revenue sources: thousands of dues-paying rank-and-file members; business owners who hired the Klan to scare off the unions or who paid the Klan protection money; Klan rallies that generated huge cash donations; even the occasional gunrunning or moonshine operation. Then there were rackets like the Klan’s Death Benefit Association, which sold insurance policies to Klan members and accepted only cash or personal checks made out to the Grand Dragon himself.
And, even though the Klan may not have been as deadly as generally thought, it was plenty violent and, perhaps worse, had ever greater designs on political influence. Kennedy was therefore eager to damage the Klan in any way he could. When he heard about Klan plans for a union-busting rally, he fed the information to a union friend. He passed along Klan information to the assistant attorney general of Georgia, an established Klan buster. After researching the Klan’s corporate charter, Kennedy wrote to the governor of Georgia suggesting the grounds upon which the charter should be revoked: the Klan had been designated a non-profit, non-political organization, but Kennedy had proof that it was clearly devoted to both profits and politics.
The problem was that most of Kennedy’s efforts weren’t producing the desired effect. The Klan was so entrenched and broad-based that Kennedy felt as if he were tossing pebbles at a giant. And even if he could somehow damage the Klan in Atlanta, the hundreds of other chapters around the country would go untouched.
Kennedy was supremely frustrated, and out of this frustration was born a new strategy. He had noticed one day a group of young boys playing some kind of spy game in which they exchanged silly secret passwords. It reminded him of the Klan. Wouldn’t it be nice, he thought, to get the Klan’s passwords and the rest of its secrets into the hands of kids all across the country—and their parents too? What better way to defang a secret society than to make public its most secret information? Instead of futilely attacking the Klan from the outside, what if he could somehow unleash all the secret inside information that John Brown was gathering from the Klan’s weekly meetings? Between Brown’s inside dope and everything that Kennedy had learned via his own investigations, he probably knew more Klan secrets than the average Klansman.
Kennedy turned to the most powerful mass medium of his day: radio. He began feeding Klan reports to the journalist Drew Pearson, whose Washington Merry-Go-Round program was heard by millions of adults every day, and to the producers of the Adventures of Superman show, which reached millions of children each night. He told them about Mr. Ayak and Mr. Akai, and he passed along overheated passages from the Klan’s bible, which was called the Kloran. (Kennedy never did learn why a white Christian supremacist group would give its bible essentially the same name as the most holy book of Islam.) He explained the role of Klan officers in any local Klavern: the Klaliff (vice president), Klokard (lecturer), Kludd (chaplain), Kligrapp (secretary), Klabee (treasurer), Kladd (conductor), Klarogo (inner guard), Klexter (outer guard), the Klokann (a five-man investigative committee), and the Klavaliers (whose leader was called Chief Ass Tearer). He spelled out the Klan hierarchy as it proceeded from the local to the national level: an Exalted Cyclops and his twelve Terrors; a Great Titan and his twelve Furies; a Grand Dragon and his nine Hydras; and the Imperial Wizard and his fifteen Genii. And Kennedy passed along all the information and gossip that John Brown gleaned by infiltrating the main Klan chapter, Nathan Bedford Forrest Klavern No. 1, Atlanta, Realm of Georgia.
During the war, the Adventures of Superman program had portrayed its hero fighting Hitler and Mussolini and Hirohito. But now he was in need of fresh villains. The Klan was a perfect target, and Superman turned his powers against them. Drew Pearson, an avowed Klan hater, now began giving regular Klan updates on his radio show, and then gave further updates, based on John Brown’s inside reports, to show how the original updates were infuriating Klan officials. Pearson’s work created an echo chamber that seemed to be driving Grand Dragon Samuel Green crazy. Here is Pearson’s radio report from November 17, 1948:
Speaking at Klavern No. 1, Atlanta, Ga., the week after elections, the Grand Dragon wrung his hands and once again cautioned Klansmen to be careful about leaks.
“I have to talk frankly at these meetings,” he said, “but I might as well call Drew Pearson before I come to the meeting and give him the information, for [the] next day he gives it out to everybody from coast to coast. The A.P. and U.P. are both calling me about it next morning while I am eating breakfast.”…
The Grand Dragon spoke about plans for a big cross-burning to be held in Macon, Ga., on Dec. 10. It would be the biggest in Klan history, he said, and he expected 10,000 Klansmen to be there—in their robes….
He added that the Klavalier Klub—the Klan’s whipping and flogging department—was now on the job and had plenty of friends on the Atlanta police force.
As the Pearson and Superman radio shows played on, and as Stetson Kennedy continued to relay the Klan secrets obtained by John Brown to other broadcast and print outlets, a funny thing happened: attendance at Klan meetings began to fall, as did applications for new membership. Of all the ideas that Kennedy had thought up to fight bigotry, this campaign was easily the cleverest. He turned the Klan’s secrecy against itself by making its private information public; he converted heretofore precious knowledge into ammunition for mockery.
Americans who might have been philosophically inclined to oppose the Klan had now been given enough specific information to oppose them more actively, and public sentiment began to shift. Americans who might have been philosophically inclined to embrace the Klan had now been given all sorts of caution against doing so. Although the Klan would never quite die, especially down south—David Duke, a smooth-talking Klan leader from Louisiana, mounted substantive bids for the U.S. Senate and other offices—it was certainly handicapped, at least in the short term, by Kennedy’s brazen dissemination of inside information. While it is impossible to tease out the exact impact that his work had on the Klan, many people have given him a great deal of credit for damaging an institution that was in grave need of being damaged.
This did not come about because Stetson Kennedy was courageous or resolute or unflappable, even though he was all of these. It happened because he understood the raw power of information. The Ku Klux Klan—much like politicians or real-estate agents or stockbrokers—was a group whose power was derived in large part from the fact that it hoarded information. Once that information falls into the wrong hands (or, depending on your point of view, the right hands), much of the group’s advantage disappears.
 
In the late 1990s, the price of term life insurance fell dramatically. This posed something of a mystery, for the decline had no obvious cause. Other types of insurance, including health and automobile and homeowners’ coverage, were certainly not falling in price. Nor had there been any radical changes among insurance companies, insurance brokers, or the people who buy term life insurance. So what happened?
The Internet happened. In the spring of 1996, Quotesmith.com became the first of several websites that enabled a customer to compare, within seconds, the price of term life insurance sold by dozens of different companies. For such websites, term life insurance was a perfect product. Unlike other forms of insurance—especially whole life insurance, which is a far more complicated financial instrument—term life policies are fairly homogeneous: any given thirty-year, guaranteed policy for $1 million is essentially identical to the next. So what really matters is the price. Shopping around for the cheapest policy, a process that had been convoluted and time-consuming, was suddenly made simple. With customers able to instantaneously find the cheapest policy, the more expensive companies had no choice but to lower their prices. Suddenly customers were paying $1 billion less a year for term life insurance.
It is worth noting that these websites only listed prices; they didn’t even sell the policies. So it wasn’t really insurance they were peddling. Like Stetson Kennedy, they were dealing in information. (Had the Internet been around when Kennedy was attacking the Klan, he probably would have been blogging his brains out.) To be sure, there are differences between exposing the Ku Klux Klan and exposing insurance companies’ high premiums. The Klan trafficked in secret information whose secrecy engendered fear, while insurance prices were less a secret than a set of facts dispensed in a way that made comparisons difficult. But in both instances, the dissemination of the information diluted its power. As Supreme Court Justice Louis D. Brandeis once wrote, “Sunlight is said to be the best of disinfectants.”
Information is a beacon, a cudgel, an olive branch, a deterrent—all depending on who wields it and how. Information is so powerful that the assumption of information, even if the information does not actually exist, can have a sobering effect. Consider the case of a one-day-old car.
The day that a car is driven off the lot is the worst day in its life, for it instantly loses as much as a quarter of its value. This might seem absurd, but we know it to be true. A new car that was bought for $20,000 cannot be resold for more than perhaps $15,000. Why? Because the only person who might logically want to resell a brand-new car is someone who found the car to be a lemon. So even if the car isn’t a lemon, a potential buyer assumes that it is. He assumes that the seller has some information about the car that he, the buyer, does not have—and the seller is punished for this assumed information.
And if the car is a lemon? The seller would do well to wait a year to sell it. By then, the suspicion of lemonness will have faded; by then, some people will be selling their perfectly good year-old cars, and the lemon can blend in with them, likely selling for more than it is truly worth.
It is common for one party to a transaction to have better information than another party. In the parlance of economists, such a case is known as an information asymmetry. We accept as a verity of capitalism that someone (usually an expert) knows more than someone else (usually a consumer). But information asymmetries everywhere have in fact been gravely wounded by the Internet.
Information is the currency of the Internet. As a medium, the Internet is brilliantly efficient at shifting information from the hands of those who have it into the hands of those who do not. Often, as in the case of term life insurance prices, the information existed but in a woefully scattered way. (In such instances, the Internet acts like a gigantic horseshoe magnet waved over an endless sea of haystacks, plucking the needle out of each one.) The Internet has accomplished what even the most fervent consumer advocates usually cannot: it has vastly shrunk the gap between the experts and the public.
The Internet has proven particularly fruitful for situations in which a face-to-face encounter with an expert might actually exacerbate the problem of asymmetrical information—situations in which an expert uses his informational advantage to make us feel stupid or rushed or cheap or ignoble. Consider a scenario in which your loved one has just died and now the funeral director (who knows that you know next to nothing about his business and are under emotional duress to boot) steers you to the $8,000 mahogany casket. Or consider the automobile dealership: a salesman does his best to obscure the car’s base price under a mountain of add-ons and incentives. Later, however, in the cool-headed calm of your home, you can use the Internet to find out exactly how much the dealer paid the manufacturer for that car. Or you might just log on to www.TributeDirect.com and buy that mahogany casket yourself for only $3,595, delivered overnight. Unless you decide to spend $2,300 for “The Last Hole” (a casket with golf scenes) or “Memories of the Hunt” (featuring big-racked bucks and other prey) or one of the much cheaper models that the funeral director somehow failed even to mention.
 
The Internet, powerful as it is, has hardly slain the beast that is information asymmetry. Consider the so-called corporate scandals of the early 2000s. The crimes committed by Enron included hidden partnerships, disguised debt, and the manipulation of energy markets. Henry Blodget of Merrill Lynch and Jack Grubman of Salomon Smith Barney wrote glowing research reports of companies they knew to be junk. Sam Waksal dumped his ImClone stock when he got early word of a damaging report from the Food and Drug Administration; his friend Martha Stewart also dumped her shares, then lied about the reason. WorldCom and Global Crossing fabricated billions of dollars in revenues to pump up their stock prices. One group of mutual fund companies let preferred customers trade at preferred prices, and another group was charged with hiding management fees.
Though extraordinarily diverse, these crimes all have a common trait: they were sins of information. Most of them involved an expert, or a gang of experts, promoting false information or hiding true information; in each case the experts were trying to keep the information asymmetry as asymmetrical as possible.
The practitioners of such acts, especially in the realm of high finance, inevitably offer this defense: “Everybody else was doing it.” Which may be largely true. One characteristic of information crimes is that very few of them are detected. Unlike street crimes, they do not leave behind a corpse or a broken window. Unlike a bagel criminal—that is, someone who eats one of Paul Feldman’s bagels but doesn’t pay—an information criminal typically doesn’t have someone like Feldman tallying every nickel. For an information crime to reach the surface, something drastic must happen. When it does, the results tend to be pretty revealing. The perpetrators, after all, weren’t thinking about their private actions being made public. Consider the “Enron tapes,” the secretly recorded conversations of Enron employees that surfaced after the company imploded. During a phone conversation on August 5, 2000, two traders chatted about how a wildfire in California would allow Enron to jack up its electricity prices. “The magical word of the day,” one trader said, “is ‘Burn, Baby, Burn.’” A few months later, a pair of Enron traders named Kevin and Bob talked about how California officials wanted to make Enron refund the profits of its price gouging.
KEVIN: They’re fucking taking all the money back from you guys? All the money you guys stole from those poor grandmas in California?
BOB: Yeah, Grandma Millie, man.
KEVIN: Yeah, now she wants her fucking money back for all the power you jammed right up her ass for fucking $250 a megawatt hour.
If you were to assume that many experts use their information to your detriment, you’d be right. Experts depend on the fact that you don’t have the information they do. Or that you are so befuddled by the complexity of their operation that you wouldn’t know what to do with the information if you had it. Or that you are so in awe of their expertise that you wouldn’t dare challenge them. If your doctor suggests that you have angioplasty—even though some current research suggests that angioplasty often does little to prevent heart attacks—you aren’t likely to think that the doctor is using his informational advantage to make a few thousand dollars for himself or his buddy. But as David Hillis, an interventional cardiologist at the University of Texas Southwestern Medical Center in Dallas, explained to the New York Times, a doctor may have the same economic incentives as a car salesman or a funeral director or a mutual fund manager: “If you’re an invasive cardiologist and Joe Smith, the local internist, is sending you patients, and if you tell them they don’t need the procedure, pretty soon Joe Smith doesn’t send patients anymore.”
Armed with information, experts can exert a gigantic, if unspoken, leverage: fear. Fear that your children will find you dead on the bathroom floor of a heart attack if you do not have angioplasty surgery. Fear that a cheap casket will expose your grandmother to a terrible underground fate. Fear that a $25,000 car will crumple like a toy in an accident, whereas a $50,000 car will wrap your loved ones in a cocoon of impregnable steel. The fear created by commercial experts may not quite rival the fear created by terrorists like the Ku Klux Klan, but the principle is the same.
Consider a transaction that wouldn’t seem, on the surface, to create much fear: selling your house. What’s so scary about that? Aside from the fact that selling a house is typically the largest financial transaction in your life, and that you probably have scant experience in real estate, and that you may have an enormous emotional attachment to your house, there are at least two pressing fears: that you will sell the house for far less than it is worth and that you will not be able to sell it at all.
In the first case, you fear setting the price too low; in the second, you fear setting it too high. It is the job of your real-estate agent, of course, to find the golden mean. She is the one with all the information: the inventory of similar houses, the recent sales trends, the tremors of the mortgage market, perhaps even a lead on an interested buyer. You feel fortunate to have such a knowledgeable expert as an ally in this most confounding enterprise.
Too bad she sees things differently. A real-estate agent may see you not so much as an ally but as a mark. Think back to the study cited at the beginning of this book, which measured the difference between the sale prices of homes that belonged to real-estate agents themselves and the houses they sold for their clients. The study found that an agent keeps her own house on the market an average ten extra days, waiting for a better offer, and sells it for over 3 percent more than your house—or $10,000 on the sale of a $300,000 house. That’s $10,000 going into her pocket that does not go into yours, a nifty profit produced by the abuse of information and a keen understanding of incentives. The problem is that the agent only stands to personally gain an additional $150 by selling your house for $10,000 more, which isn’t much reward for a lot of extra work. So her job is to convince you that a $300,000 offer is in fact a very good offer, even a generous one, and that only a fool would refuse it.
This can be tricky. The agent does not want to come right out and call you a fool. So she merely implies it—perhaps by telling you about the much bigger, nicer, newer house down the block that has sat unsold for six months. Here is the agent’s main weapon: the conversion of information into fear. Consider this true story, related by John Donohue, a law professor who in 2001 was teaching at Stanford University: “I was just about to buy a house on the Stanford campus,” he recalls, “and the seller’s agent kept telling me what a good deal I was getting because the market was about to zoom. As soon as I signed the purchase contract, he asked me if I would need an agent to sell my previous Stanford house. I told him that I would probably try to sell without an agent, and he replied, ‘John, that might work under normal conditions, but with the market tanking now, you really need the help of a broker.’”
Within five minutes, a zooming market had tanked. Such are the marvels that can be conjured by an agent in search of the next deal.
Consider now another true story of a real-estate agent’s information abuse. The tale involves K., a close friend of one of this book’s authors. K. wanted to buy a house that was listed at $469,000. He was prepared to offer $450,000 but he first called the seller’s agent and asked her to name the lowest price that she thought the homeowner might accept. The agent promptly scolded K. “You ought to be ashamed of yourself,” she said. “That is clearly a violation of real-estate ethics.”
K. apologized. The conversation turned to other, more mundane issues. After ten minutes, as the conversation was ending, the agent told K., “Let me say one last thing. My client is willing to sell this house for a lot less than you might think.”
Based on this conversation, K. then offered $425,000 for the house instead of the $450,000 he had planned to offer. In the end, the seller accepted $430,000. Thanks to his own agent’s intervention, the seller lost at least $20,000. The agent, meanwhile, only lost $300—a small price to pay to ensure that she would quickly and easily lock up the sale, which netted her a commission of $6,450.
So a big part of a real-estate agent’s job, it would seem, is to persuade the homeowner to sell for less than he would like while at the same time letting potential buyers know that a house can be bought for less than its listing price. To be sure, there are more subtle means of doing so than coming right out and telling the buyer to bid low. The study of real-estate agents cited above also includes data that reveals how agents convey information through the for-sale ads they write. A phrase like “well maintained,” for instance, is as full of meaning to an agent as “Mr. Ayak” was to a Klansman; it means that a house is old but not quite falling down. A savvy buyer will know this (or find out for himself once he sees the house), but to the sixty-five-year-old retiree who is selling his house, “well maintained” might sound like a compliment, which is just what the agent intends.
An analysis of the language used in real-estate ads shows that certain words are powerfully correlated with the final sale price of a house. This doesn’t necessarily mean that labeling a house “well maintained” causes it to sell for less than an equivalent house. It does, however, indicate that when a real-estate agent labels a house “well maintained,” she may be subtly encouraging a buyer to bid low.
Listed below are ten terms commonly used in real-estate ads. Five of them have a strong positive correlation to the ultimate sale price, and five have a strong negative correlation. Guess which are which.
 
Ten Common Real-Estate Ad Terms
Fantastic
Granite
Spacious
State-of-the-Art
!
Corian
Charming
Maple
Great Neighborhood
Gourmet
A “fantastic” house is surely fantastic enough to warrant a high price, isn’t it? What about a “charming” and “spacious” house in a “great neighborhood!”? No, no, no, and no. Here’s the breakdown:
 
Five Terms Correlated to a Higher Sale Price
Granite
State-of-the-Art
Corian
Maple
Gourmet
Five Terms Correlated to a Lower Sale Price
Fantastic
Spacious
!
Charming
Great Neighborhood
Three of the five terms correlated with a higher sale price are physical descriptions of the house itself: granite, Corian, and maple. As information goes, such terms are specific and straightforward—and therefore pretty useful. If you like granite, you might like the house; but even if you don’t, “granite” certainly doesn’t connote a fixer-upper. Nor does “gourmet” or “state-of-the-art,” both of which seem to tell a buyer that a house is, on some level, truly fantastic.
“Fantastic,” meanwhile, is a dangerously ambiguous adjective, as is “charming.” Both these words seem to be real-estate agent code for a house that doesn’t have many specific attributes worth describing. “Spacious” homes, meanwhile, are often decrepit or impractical. “Great neighborhood” signals a buyer that, well, this house isn’t very nice but others nearby may be. And an exclamation point in a real-estate ad is bad news for sure, a bid to paper over real shortcomings with false enthusiasm.
If you study the words in ads for a real-estate agent’s own home, meanwhile, you see that she indeed emphasizes descriptive terms (especially “new,” “granite,” “maple,” and “move-in condition”) and avoids empty adjectives (including “wonderful,” “immaculate,” and the telltale “!”). Then she patiently waits for the best buyer to come along. She might tell this buyer about a house nearby that just sold for $25,000 above the asking price, or another house that is currently the subject of a bidding war. She is careful to exercise every advantage of the information asymmetry she enjoys.
Does this make her a bad person? That’s hard to say, at least hard for us to say. The point here is not that real-estate agents are bad people, but that they simply are people—and people inevitably respond to incentives. The incentives of the real-estate business, as currently configured, plainly encourage some agents to act against the best interests of their customers.
But like the funeral director and the car salesman and the life-insurance company, the real-estate agent has also seen her advantage eroded by the Internet. After all, anyone selling a home can now get online and gather her own information about sales trends and housing inventory and mortgage rates. The information has been set loose. And recent sales data show the results. Real-estate agents still get a higher price for their own homes than comparable homes owned by their clients, but since the proliferation of real-estate websites, the gap between the two prices has shrunk by a third.
 
It would be naïve to suppose that people abuse information only when they are acting as experts or as agents of commerce. After all, agents and experts are people too—which suggests that we are likely to abuse information in our personal lives as well, whether by withholding true information or editing the information we choose to put forth. A real-estate agent may wink and nod when she lists a “well-maintained” house, but we each have our equivalent hedges.
Think about how you describe yourself during a job interview versus how you might describe yourself on a first date. (For even more fun, compare that first-date conversation to a conversation with the same person during your tenth year of marriage.) Or think about how you might present yourself if you were going on national television for the first time. What sort of image would you want to project? Perhaps you want to seem clever or kind or good-looking; presumably you don’t want to come off as cruel or bigoted. During the heyday of the Ku Klux Klan, its members took pride in publicly disparaging anybody who wasn’t a conservative white Christian. But public bigotry has since been vastly curtailed. Even subtle displays of bigotry, if they become public, are now costly. Trent Lott, the majority leader of the U.S. Senate, learned this in 2002 after making a toast at a one hundredth birthday party for Strom Thurmond, his fellow senator and fellow southerner. Lott made a reference in his toast to Thurmond’s 1948 campaign for president, which was built on a platform of segregation; Mississippi—Lott’s home state—was one of just four states that Thurmond carried. “We’re proud of it,” Lott told the partygoers. “And if the rest of the country had followed our lead, we wouldn’t have had all these problems over all these years either.” The implication that Lott was a fan of segregation raised enough of a fury that he was forced to quit his Senate leadership post.
 
Even if you are a private citizen, you surely wouldn’t want to seem bigoted while appearing in public. Might there be a way to test for discrimination in a public setting?
Unlikely as it may seem, the television game show The Weakest Link provides a unique laboratory to study discrimination. An import from the United Kingdom, The Weakest Link for a short time became wildly popular in the United States. The game includes eight contestants (or, in a later daytime version, six) who each answer trivia questions and compete for a single cash jackpot. But the player who answers the most questions correctly isn’t necessarily the player who advances. After each round, every contestant votes to eliminate one other contestant. A player’s trivia-answering ability is presumably the only worthwhile factor to consider; race, gender, and age wouldn’t seem to matter. But do they? By measuring a contestant’s actual votes against the votes that would truly best serve his self-interest, it’s possible to tell if discrimination is at play.
The voting strategy changes as the game progresses. In the first several rounds, it makes sense to eliminate bad players since the jackpot grows only when correct answers are given. In later rounds, the strategic incentives are flipped. The value of building the jackpot is now outweighed by each contestant’s desire to win the jackpot. It’s easier to do that if you eliminate the other good players. So, roughly speaking, the typical contestant will vote to eliminate the worse players in the early rounds and the better players in the later rounds.
The key to measuring the Weakest Link voting data is to tease out a contestant’s playing ability from his race, gender, and age. If a young black man answers a lot of questions correctly but is voted off early, discrimination would seem to be a factor. Meanwhile, if an elderly white woman doesn’t answer a single question correctly and is still not voted off, some sort of discriminatory favoritism would seem to be at play.
Again, keep in mind that all of this is happening on camera. A contestant knows that his friends, family, and co-workers—along with a few million strangers—are watching. So who, if anyone, is discriminated against on The Weakest Link?
Not, as it turns out, blacks. An analysis of more than 160 episodes reveals that black contestants, in both the early and late rounds of the game, are eliminated at a rate commensurate with their trivia-answering abilities. The same is true for female contestants. In a way, neither of these findings is so surprising. Two of the most potent social campaigns of the past half-century were the civil rights movement and the feminist movement, which demonized discrimination against blacks and women, respectively.
So perhaps, you say hopefully, discrimination was practically eradicated during the twentieth century, like polio.
Or more likely, it has become so unfashionable to discriminate against certain groups that all but the most insensitive people take pains to at least appear fair-minded, at least in public. This hardly means that discrimination itself has ended—only that people are embarrassed to show it. How might you determine whether the lack of discrimination against blacks and women represents a true absence or just a charade? The answer can be found by looking at other groups that society doesn’t protect as well. Indeed, the Weakest Link voting data do indicate two kinds of contestants who are consistently discriminated against: the elderly and Latinos.
Among economists, there are two leading theories of discrimination. Interestingly, elderly Weakest Link contestants seem to suffer from one type, while Latinos suffer the other. The first type is called taste-based discrimination, which means that one person discriminates simply because he prefers to not interact with a particular type of other person. In the second type, known as information-based discrimination, one person believes that another type of person has poor skills, and acts accordingly.
On The Weakest Link, Latinos suffer information-based discrimination. Other contestants seem to view the Latinos as poor players, even when they are not. This perception translates into Latinos’ being eliminated in the early rounds even if they are doing well and not being eliminated in the later rounds, when other contestants want to keep the Latinos around to weaken the field.
Elderly players, meanwhile, are victims of taste-based discrimination: in the early rounds and late rounds, they are eliminated far out of proportion to their skills. It seems as if the other contestants—this is a show on which the average age is thirty-four—simply don’t want the older players around.
It’s quite possible that a typical Weakest Link contestant isn’t even cognizant of his discrimination toward Latinos and the elderly (or, in the case of blacks and women, his lack of discrimination). He is bound to be nervous, after all, and excited, playing a fast-moving game under the glare of television lights. Which naturally suggests another question: how might that same person express his preferences—and reveal information about himself—in the privacy of his home?
 
In a given year, some forty million Americans swap intimate truths about themselves with complete strangers. It all happens on Internet dating sites. Some of them, like Match.com, eHarmony.com, and Yahoo! Personals, appeal to a broad audience. Others cater to more specific tastes: ChristianSingles.com, JDate.com, LatinMatcher .com, BlackSinglesConnection.com, CountryWesternSingles.com, USMilitarySingles.com, OverweightDate.com, and Gay.com. Dating websites are the most successful subscription-based business on the Internet.
Each site operates a bit differently, but the gist is this: You compose a personal ad about yourself that typically includes a photo, vital statistics, your income range, level of education, likes and dislikes, and so on. If the ad catches someone’s fancy, that someone will e-mail you and perhaps arrange a date. On many sites, you also specify your dating aims: “long-term relationship,” “a casual lover,” or “just looking.”
So there are two massive layers of data to be mined here: the information that people include in their ads and the level of response gleaned by any particular ad. Each layer of the data can be asked its own question. In the case of the ads, how forthright (and honest) are people when it comes to sharing their personal information? And in the case of the responses, what kind of information in personal ads is considered the most (and least) desirable?
Two economists and a psychologist recently banded together to address these questions. Günter J. Hitsch, Ali Hortaçsu, and Dan Ariely analyzed the data from one of the mainstream dating sites, focusing on more than 20,000 active users, half in Boston and half in San Diego. Fifty-six percent of the users were men, and the median age range for all users was twenty-one to thirty-five. Although they represented an adequate racial mix to reach some conclusions about race, they were predominantly white.
They were also a lot richer, taller, skinnier, and better-looking than average. That, at least, is what they wrote about themselves. More than 4 percent of the online daters claimed to earn more than $200,000 a year, whereas fewer than 1 percent of typical Internet users actually earn that much, suggesting that three of the four big earners were exaggerating. Male and female users typically reported that they are about an inch taller than the national average. As for weight, the men were in line with the national average, but the women typically said they weighed about twenty pounds less than the national average.
Most impressively, fully 72 percent of the women claimed “above average” looks, including 24 percent claiming “very good looks.” The online men too were gorgeous: 68 percent called themselves “above average,” including 19 percent with “very good looks.” This leaves only about 30 percent of the users with “average” looks, including a paltry 1 percent with “less than average” looks—which suggests that the typical online dater is either a fabulist, a narcissist, or simply resistant to the meaning of “average.” (Or perhaps they are all just pragmatists: as any real-estate agent knows, the typical house isn’t “charming” or “fantastic,” but unless you say it is, no one will even bother to take a look.) Twenty-eight percent of the women on the site said they were blond, a number far beyond the national average, which indicates a lot of dyeing, or lying, or both.
Some users, meanwhile, were bracingly honest. Seven percent of the men conceded that they were married, with a significant minority of these men reporting that they were “happily married.” But the fact that they were honest doesn’t mean they were rash. Of the 243 “happily married” men in the sample, only 12 chose to post a picture of themselves. The reward of gaining a mistress was evidently outweighed by the risk of having your wife discover your personal ad. (“And what were you doing on that website?” the husband might bluster, undoubtedly to little avail.)
Of the many ways to fail on a dating website, not posting a photo of yourself is perhaps the most certain. (Not that the photo necessarily is a photo of yourself; it may well be some better-looking stranger, but such deception would obviously backfire in time.) A man who does not include his photo gets only 60 percent of the volume of e-mail response of a man who does; a woman who doesn’t include her photo gets only 24 percent as much. A low-income, poorly educated, unhappily employed, not very attractive, slightly overweight, and balding man who posts his photo stands a better chance of gleaning some e-mails than a man who says he makes $200,000 and is deadly handsome but doesn’t post a photo. There are plenty of reasons someone might not post a photo—he’s technically challenged or is ashamed of being spotted by friends or is just plain unattractive—but as in the case of a brand-new car with a For Sale sign, prospective customers will assume he’s got something seriously wrong under the hood.
Getting a date is hard enough as it is. Fifty-six percent of the men who post ads don’t receive even one e-mail; 21 percent of the women don’t get a single response. The traits that do draw a big response, meanwhile, will not be a big surprise to anyone with even a passing knowledge of the sexes. In fact, the preferences expressed by online daters fit snugly with the most common stereotypes about men and women.
For instance, men who say they want a long-term relationship do much better than men looking for an occasional lover. But women looking for an occasional lover do great. For men, a woman’s looks are of paramount importance. For women, a man’s income is terribly important. The richer a man is, the more e-mails he receives. But a woman’s income appeal is a bell-shaped curve: men do not want to date low-earning women, but once a woman starts earning too much, they seem to be scared off. Women are eager to date military men, policemen, and firemen (possibly the result of a 9/11 Effect, like the higher payments to Paul Feldman’s bagel business), along with lawyers and doctors; they generally avoid men with manufacturing jobs. For men, being short is a big disadvantage (which is probably why so many lie about it), but weight doesn’t much matter. For women, being overweight is deadly (which is probably why they lie). For a man, having red hair or curly hair is a downer, as is “bald with a fringe”—but a shaved head is okay. For a woman, salt-and-pepper hair is bad, while blond hair is, not surprisingly, very good.
In addition to all the information about income, education, and looks, men and women on the dating site listed their race. They were also asked to indicate a preference regarding the race of their potential dates. The two preferences were “the same as mine” or “it doesn’t matter.” Like the Weakest Link contestants, the website users were now publicly declaring how they felt about people who didn’t look like them. They would reveal their actual preferences later, in confidential e-mails to the people they wanted to date.
Roughly half of the white women on the site and 80 percent of the white men declared that race didn’t matter to them. But the response data tell a different story. The white men who said that race didn’t matter sent 90 percent of their e-mail queries to white women. The white women who said race didn’t matter sent about 97 percent of their e-mail queries to white men. This means that an Asian man who is good-looking, rich, and well educated will receive fewer than 25 percent as many e-mails from white women as a white man with the same qualifications would receive; similarly, black and Latino men receive about half as many e-mails from white women as they would if they were white.
Is it possible that race really didn’t matter for these white women and men and that they simply never happened to browse a nonwhite date that interested them? Or, more likely, did they say that race didn’t matter because they wanted to come across—especially to potential mates of their own race—as open-minded?
 
The gulf between the information we publicly proclaim and the information we know to be true is often vast. (Or, put a more familiar way: we say one thing and do another.) This can be seen in personal relationships, in commercial transactions, and of course in politics.
By now we are fully accustomed to the false public proclamations of politicians themselves. But voters lie too. Consider an election between a black candidate and a white candidate. Might white voters lie to pollsters, claiming they will vote for the black candidate in order to appear more color-blind than they actually are? Apparently so. In New York City’s 1989 mayoral race between David Dinkins (a black candidate) and Rudolph Giuliani (who is white), Dinkins won by only a few points. Although Dinkins became the city’s first black mayor, his slender margin of victory came as a surprise, for preelection polls showed Dinkins winning by nearly 15 points. When the white supremacist David Duke ran for the U.S. Senate in 1990, he garnered nearly 20 percent more of the vote than pre-election polls had projected, an indication that thousands of Louisiana voters did not want to admit their preference for a candidate with racist views.
Duke, though he never won the high political office he often sought, proved himself a master of information abuse. As Grand Wizard of the Knights of the Ku Klux Klan, he was able to compile a mailing list of thousands of rank-and-file Klansmen and other supporters who would eventually become his political base. Not content to use the list only for himself, he sold it for $150,000 to the governor of Louisiana. Years later, Duke would once again use the list himself, letting his supporters know that he’d fallen on hard times and needed their donations. In this way Duke was able to raise hundreds of thousands of dollars for his continuing work in the field of white supremacy. He had explained to his supporters in a letter that he was so broke that the bank was trying to repossess his house.
In truth, Duke had already sold his house for a solid profit. (It isn’t known whether he used a real-estate agent.) And most of the money he raised from his supporters was being used not to promote any white supremacist cause but rather to satisfy Duke’s gambling habit. It was a sweet little scam he was running—until he was arrested and sent to federal prison in Big Spring, Texas.


3
Why Do Drug Dealers Still Live with Their Moms?
The two previous chapters were built around a pair of admittedly freakish questions: What do schoolteachers and sumo wrestlers have in common? and How is the Ku Klux Klan like a group of real-estate agents? But if you ask enough questions, strange as they seem at the time, you may eventually learn something worthwhile.
The first trick of asking questions is to determine if your question is a good one. Just because a question has never been asked does not make it good. Smart people have been asking questions for quite a few centuries now, so many of the questions that haven’t been asked are bound to yield uninteresting answers.
But if you can question something that people really care about and find an answer that may surprise them—that is, if you can overturn the conventional wisdom—then you may have some luck.
It was John Kenneth Galbraith, the hyperliterate economic sage, who coined the phrase “conventional wisdom.” He did not consider it a compliment. “We associate truth with convenience,” he wrote, “with what most closely accords with self-interest and personal well-being or promises best to avoid awkward effort or unwelcome dislocation of life. We also find highly acceptable what contributes most to self-esteem.” Economic and social behaviors, Galbraith continued, “are complex, and to comprehend their character is mentally tiring. Therefore we adhere, as though to a raft, to those ideas which represent our understanding.”
So the conventional wisdom in Galbraith’s view must be simple, convenient, comfortable, and comforting—though not necessarily true. It would be silly to argue that the conventional wisdom is never true. But noticing where the conventional wisdom may be false—noticing, perhaps, the contrails of sloppy or self-interested thinking—is a nice place to start asking questions.
Consider the recent history of homelessness in the United States. In the early 1980s, an advocate for the homeless named Mitch Snyder took to saying that there were about 3 million homeless Americans. The public duly sat up and took notice. More than 1 of every 100 people were homeless? That sure seemed high, but…well, the expert said it. A heretofore quiescent problem was suddenly catapulted into the national consciousness. Snyder even testified before Congress about the magnitude of the problem. He also reportedly told a college audience that 45 homeless people die each second—which would mean a whopping 1.4 billion dead homeless every year. (The U.S. population at the time was about 225 million.) Assuming that Snyder misspoke or was misquoted and meant to say that one homeless person died every forty-five seconds, that’s still 701,000 dead homeless people every year—roughly one-third of all deaths in the United States. Hmm. Ultimately, when Snyder was pressed on his figure of 3 million homeless, he admitted that it was a fabrication. Journalists had been hounding him for a specific number, he said, and he hadn’t wanted them to walk away empty-handed.
It may be sad but not surprising to learn that experts like Snyder can be self-interested to the point of deceit. But they cannot deceive on their own. Journalists need experts as badly as experts need journalists. Every day there are newspaper pages and television newscasts to be filled, and an expert who can deliver a jarring piece of wisdom is always welcome. Working together, journalists and experts are the architects of much conventional wisdom.
Advertising too is a brilliant tool for creating conventional wisdom. Listerine, for instance, was invented in the nineteenth century as a powerful surgical antiseptic. It was later sold, in distilled form, as a floor cleaner and a cure for gonorrhea. But it wasn’t a runaway success until the 1920s, when it was pitched as a solution for “chronic halitosis”—a then obscure medical term for bad breath. Listerine’s new ads featured forlorn young women and men, eager for marriage but turned off by their mate’s rotten breath. “Can I be happy with him in spite of that?” one maiden asked herself. Until that time, bad breath was not conventionally considered such a catastrophe. But Listerine changed that. As the advertising scholar James B. Twitchell writes, “Listerine did not make mouthwash as much as it made halitosis.” In just seven years, the company’s revenues rose from $115,000 to more than $8 million.
However created, the conventional wisdom can be hard to budge. The economist Paul Krugman, a New York Times columnist and devout critic of George W. Bush, bemoaned this fact as the President’s reelection campaign got under way in early 2004: “The approved story line about Mr. Bush is that he’s a bluff, honest, plainspoken guy, and anecdotes that fit that story get reported. But if the conventional wisdom were instead that he’s a phony, a silver-spoon baby who pretends to be a cowboy, journalists would have plenty of material to work with.”
In the months leading up to the U.S. invasion of Iraq in 2003, dueling experts floated diametrically opposite forecasts about Iraq’s weapons of mass destruction. But more often, as with Mitch Snyder’s homeless “statistics,” one side wins the war of conventional wisdom. Women’s rights advocates, for instance, have hyped the incidence of sexual assault, claiming that one in three American women will in her lifetime be a victim of rape or attempted rape. (The actual figure is more like one in eight—but the advocates know it would take a callous person to publicly dispute their claims.) Advocates working for the cures of various tragic diseases regularly do the same. Why not? A little creative lying can draw attention, indignation, and—perhaps most important—the money and political capital to address the actual problem.
Of course an expert, whether a women’s health advocate or a political advisor or an advertising executive, tends to have different incentives than the rest of us. And an expert’s incentives may shift 180 degrees, depending on the situation.
Consider the police. A recent audit discovered that the police in Atlanta were radically underreporting crime since the early 1990s. The practice apparently began when Atlanta was working to land the 1996 Olympics. The city needed to shed its violent image, and fast. So each year thousands of crime reports were either downgraded from violent to nonviolent or simply thrown away. (Despite these continuing efforts—there were more than 22,000 missing police reports in 2002 alone—Atlanta regularly ranks among the most violent American cities.)
Police in other cities, meanwhile, were spinning a different story during the 1990s. The sudden, violent appearance of crack cocaine had police departments across the country scrapping for resources. They made it known that it wasn’t a fair fight: the drug dealers were armed with state-of-the-art weapons and a bottomless supply of cash. This emphasis on illicit cash proved to be a winning effort, for nothing infuriated the law-abiding populace more than the image of the millionaire crack dealer. The media eagerly glommed on to this story, portraying crack dealing as one of the most profitable jobs in America.
But if you were to have spent a little time around the housing projects where crack was so often sold, you might have noticed something strange: not only did most of the crack dealers still live in the projects, but most of them still lived at home with their moms. And then you may have scratched your head and said, “Why is that?”
The answer lies in finding the right data, and the secret to finding the right data usually means finding the right person—which is more easily said than done. Drug dealers are rarely trained in economics, and economists rarely hang out with crack dealers. So the answer to this question begins with finding someone who did live among the drug dealers and managed to walk away with the secrets of their trade.
 
Sudhir Venkatesh—his boyhood friends called him Sid, but he has since reverted to Sudhir—was born in India, raised in the suburbs of upstate New York and southern California, and graduated from the University of California at San Diego with a degree in mathematics. In 1989 he began to pursue his PhD in sociology at the University of Chicago. He was interested in understanding how young people form their identities; to that end, he had just spent three months following the Grateful Dead around the country. What he was not interested in was the grueling fieldwork that typifies sociology.
But his graduate advisor, the eminent poverty scholar William Julius Wilson, promptly sent Venkatesh into the field. His assignment: to visit Chicago’s poorest black neighborhoods with a clipboard and a seventy-question, multiple-choice survey. This was the first question on the survey:
How do you feel about being black and poor?
• a. Very bad
• b. Bad
• c. Neither bad nor good
• d. Somewhat good
• e. Very good
One day Venkatesh walked twenty blocks from the university to a housing project on the shore of Lake Michigan to administer his survey. The project comprised three sixteen-story buildings made of yellow-gray brick. Venkatesh soon discovered that the names and addresses he had been given were badly outdated. These buildings were condemned, practically abandoned. Some families lived on the lower floors, pirating water and electricity, but the elevators didn’t work. Neither did the lights in the stairwell. It was late afternoon in early winter, nearly dark outside.
Venkatesh, who is a thoughtful, handsome, and well-built but not aberrationally brave person, had made his way up to the sixth floor, trying to find someone willing to take his survey. Suddenly, on the stairwell landing, he startled a group of teenagers shooting dice. They turned out to be a gang of junior-level crack dealers who operated out of the building, and they were not happy to see him.
“I’m a student at the University of Chicago,” Venkatesh sputtered, sticking to his survey script, “and I am administering—”
“Fuck you, nigger, what are you doing in our stairwell?”
There was an ongoing gang war in Chicago. Things had been violent lately, with shootings nearly every day. This gang, a branch of the Black Gangster Disciple Nation, was plainly on edge. They didn’t know what to make of Venkatesh. He didn’t seem to be a member of a rival gang. But maybe he was some kind of spy? He certainly wasn’t a cop. He wasn’t black, wasn’t white. He wasn’t exactly threatening—he was armed only with his clipboard—but he didn’t seem quite harmless either. Thanks to his three months trailing the Grateful Dead, he still looked, as he would later put it, “like a genuine freak, with hair down to my ass.”
The gang members started arguing over what should be done with Venkatesh. Let him go? But if he did tell the rival gang about this stairwell hangout, they’d be susceptible to a surprise attack. One jittery kid kept wagging something back and forth in his hands—in the dimming light, Venkatesh eventually realized it was a gun—and muttering, “Let me have him, let me have him.” Venkatesh was very, very scared.
The crowd grew bigger and louder. Then an older gang member appeared. He snatched the clipboard from Venkatesh’s hands and, when he saw that it was a written questionnaire, looked puzzled.
“I can’t read any of this shit,” he said.
“That’s because you can’t read,” said one of the teenagers, and everyone laughed at the older gangster.
He told Venkatesh to go ahead and ask him a question from the survey. Venkatesh led with the how-does-it-feel-to-be-black-and-poor question. It was met with a round of guffaws, some angrier than others. As Venkatesh would later tell his university colleagues, he realized that the multiple-choice answers A through E were insufficient. In reality, he now knew, the answers should have looked like this:
• a. Very bad
• b. Bad
• c. Neither bad nor good
• d. Somewhat good
• e. Very good
• f. Fuck you
Just as things were looking their bleakest for Venkatesh, another man appeared. This was J. T., the gang’s leader. J. T. wanted to know what was going on. Then he told Venkatesh to read him the survey question. He listened but then said he couldn’t answer the question because he wasn’t black.
“Well then,” Venkatesh said, “how does it feel to be African American and poor?”
“I ain’t no African American either, you idiot. I’m a nigger.” J. T. then administered a lively though not unfriendly taxonomical lesson in “nigger” versus “African American” versus “black.” When he was through, there was an awkward silence. Still nobody seemed to know what to do with Venkatesh. J. T., who was in his late twenties, had cooled down his subordinates, but he didn’t seem to want to interfere directly with their catch. Darkness fell and J. T. left. “People don’t come out of here alive,” the jittery teenager with the gun told Venkatesh. “You know that, don’t you?”
As night deepened, his captors eased up. They gave Venkatesh one of their beers, and then another and another. When he had to pee, he went where they went—on the stairwell landing one floor up. J. T. stopped by a few times during the night but didn’t have much to say. Daybreak came and then noon. Venkatesh would occasionally try to discuss his survey, but the young crack dealers just laughed and told him how stupid his questions were. Finally, nearly twenty-four hours after Venkatesh stumbled upon them, they set him free.
He went home and took a shower. He was relieved but he was also curious. It struck Venkatesh that most people, including himself, had never given much thought to the daily life of ghetto criminals. He was now eager to learn how the Black Disciples worked, from top to bottom.
After a few hours, he decided to walk back to the housing project. By now he had thought of some better questions to ask.
Having seen firsthand that the conventional method of data gathering was in this case absurd, Venkatesh vowed to scrap his questionnaire and embed himself with the gang. He tracked down J. T. and sketched out his proposal. J. T. thought Venkatesh was crazy, literally—a university student wanting to cozy up to a crack gang? But he also admired what Venkatesh was after. As it happened, J. T. was a college graduate himself, a business major. After college, he had taken a job in the Loop, working in the marketing department of a company that sold office equipment. But he felt so out of place there—like a white man working at Afro Sheen headquarters, he liked to say—that he quit. Still, he never forgot what he learned. He knew the importance of collecting data and finding new markets; he was always on the lookout for better management strategies. It was no coincidence, in other words, that J. T. was the leader of this crack gang. He was bred to be a boss.
After some wrangling, J. T. promised Venkatesh unfettered access to the gang’s operations as long as J. T. retained veto power over any information that, if published, might prove harmful.
When the yellow-gray buildings on the lakefront were demolished, shortly after Venkatesh’s first visit, the gang relocated to another housing project even deeper in Chicago’s south side. For the next six years, Venkatesh practically lived there. Under J. T.’s protection he watched the gang members up close, at work and at home. He asked endless questions. Sometimes the gangsters were annoyed by his curiosity; more often they took advantage of his willingness to listen. “It’s a war out here, man,” one dealer told him. “I mean, every day people struggling to survive, so you know, we just do what we can. We ain’t got no choice, and if that means getting killed, well, shit, it’s what niggers do around here to feed their family.”
Venkatesh would move from one family to the next, washing their dinner dishes and sleeping on the floor. He bought toys for their children; he once watched a woman use her baby’s bib to sop up the blood of a teenaged drug dealer who was shot to death in front of Venkatesh. William Julius Wilson, back at the U. of C., was having regular nightmares on Venkatesh’s behalf.
Over the years the gang endured bloody turf wars and, eventually, a federal indictment. A member named Booty, who was one rank beneath J. T., came to Venkatesh with a story. Booty was being blamed by the rest of the gang for bringing about the indictment, he told Venkatesh, and therefore suspected that he would soon be killed. (He was right.) But first Booty wanted to do a little atoning. For all the gang’s talk about how crack dealing didn’t do any harm—they even liked to brag that it kept black money in the black community—Booty was feeling guilty. He wanted to leave behind something that might somehow benefit the next generation. He handed Venkatesh a stack of well-worn spiral notebooks—blue and black, the gang’s colors. They represented a complete record of four years’ worth of the gang’s financial transactions. At J. T.’s direction, the ledgers had been rigorously compiled: sales, wages, dues, even the death benefits paid out to the families of murdered members.
At first Venkatesh didn’t even want the notebooks. What if the Feds found out he had them—perhaps he’d be indicted too? Besides, what was he supposed to do with the data? Despite his math background, he had long ago stopped thinking in numbers.
 
Upon completing his graduate work at the University of Chicago, Venkatesh was awarded a three-year stay at Harvard’s Society of Fellows. Its environment of sharp thinking and bonhomie—the walnut paneling, the sherry cart once owned by Oliver Wendell Holmes—delighted Venkatesh. He went so far as to become the society’s wine steward. And yet he regularly left Cambridge, returning again and again to the crack gang in Chicago. This street-level research made Venkatesh something of an anomaly. Most of the other young Fellows were dyed-in-the-tweed intellectuals who liked to pun in Greek.
One of the society’s aims was to bring together scholars from various fields who might not otherwise have occasion to meet. Venkatesh soon encountered another anomalous young Fellow, one who also failed the society stereotype. This one happened to be an economist who, instead of thinking grand macro thoughts, favored his own list of offbeat micro curiosities. At the very top of his list was crime. And so, within ten minutes of their meeting, Sudhir Venkatesh told Steven Levitt about the spiral notebooks from Chicago and they decided to collaborate on a paper. It would be the first time that such priceless financial data had fallen into an economist’s hands, affording an analysis of a heretofore uncharted criminal enterprise.
 
So how did the gang work? An awful lot like most American businesses, actually, though perhaps none more so than McDonald’s. In fact, if you were to hold a McDonald’s organizational chart and a Black Disciples org chart side by side, you could hardly tell the difference.
The gang that Venkatesh had fallen in with was one of about a hundred branches—franchises, really—of a larger Black Disciples organization. J. T., the college-educated leader of his franchise, reported to a central leadership of about twenty men that was called, without irony, the board of directors. (At the same time that white suburbanites were studiously mimicking black rappers’ ghetto culture, black ghetto criminals were studiously mimicking the suburbanites’ dads’ corp-think.) J. T. paid the board of directors nearly 20 percent of his revenues for the right to sell crack in a designated twelve-square-block area. The rest of the money was his to distribute as he saw fit.
Three officers reported directly to J. T.: an enforcer (who ensured the gang members’ safety), a treasurer (who watched over the gang’s liquid assets), and a runner (who transported large quantities of drugs and money to and from the supplier). Beneath the officers were the street-level salesmen known as foot soldiers. The goal of a foot soldier was to someday become an officer. J. T. had anywhere from twenty-five to seventy-five foot soldiers on his payroll at any given time, depending on the time of year (autumn was the best crack-selling season; summer and Christmastime were slow) and the size of the gang’s territory (which doubled at one point when the Black Disciples engineered a hostile takeover of a rival gang’s turf). At the very bottom of J. T.’s organization were as many as two hundred members known as the rank and file. They were not employees at all. They did, however, pay dues to the gang—some for protection from rival gangs, others for the chance to eventually earn a job as a foot soldier.
The four years recorded in the gang’s notebooks coincided with the peak years of the crack boom, and business was excellent. J. T.’s franchise quadrupled its revenues during this period. In the first year, it took in an average of $18,500 each month; by the final year, it was collecting $68,400 a month. Here’s a look at the monthly revenues in the third year:



“Drug sales” represents only the money from dealing crack cocaine. The gang did allow some rank-and-file members to sell heroin on its turf but accepted a fixed licensing fee in lieu of a share of profits. (This was off-the-books money and went straight into J. T.’s pocket; he probably skimmed from other sources as well.) The $5,100 in dues came from rank-and-file members only, since full gang members didn’t pay dues. The extortionary taxes were paid by other businesses that operated on the gang’s turf, including grocery stores, gypsy cabs, pimps, and people selling stolen goods or repairing cars on the street.
Now, here’s what it cost J. T., excluding wages, to bring in that $32,000 per month:



Mercenary fighters were nonmembers hired on short-term contracts to help the gang fight turf wars. The cost of weapons is small here because the Black Disciples had a side deal with local gunrunners, helping them navigate the neighborhood in exchange for free or steeply discounted guns. The miscellaneous expenses include legal fees, parties, bribes, and gang-sponsored “community events.” (The Black Disciples worked hard to be seen as a pillar rather than a scourge of the housing-project community.) The miscellaneous expenses also include the costs associated with a gang member’s murder. The gang not only paid for the funeral but often gave a stipend of up to three years’ wages to the victim’s family. Venkatesh had once asked why the gang was so generous in this regard. “That’s a fucking stupid question,” he was told, “’cause as long as you been with us, you still don’t understand that their families is our families. We can’t just leave ’em out. We been knowing these folks our whole lives, man, so we grieve when they grieve. You got to respect the family.” There was another reason for the death benefits: the gang feared community backlash (its enterprise was plainly a destructive one) and figured it could buy some goodwill for a few hundred dollars here and there.
The rest of the money the gang took in went to its members, starting with J. T. Here is the single line item in the gang’s budget that made J. T. the happiest:
 
Net monthly profit accruing to leader $8,500
 
At $8,500 per month, J. T.’s annual salary was about $100,000—tax-free, of course, and not including the various off-the-books money he pocketed. This was a lot more than he earned at his short-lived office job in the Loop. And J. T. was just one of roughly 100 leaders at this level within the Black Disciples network. So there were indeed some drug dealers who could afford to live large—or, in the case of the gang’s board of directors, extremely large. Each of those top 20 bosses stood to earn about $500,000 a year. (A third of them, however, were typically imprisoned at any time, a significant downside of an up position in an illicit industry.)
So the top 120 men on the Black Disciples’ pyramid were paid very well. But the pyramid they sat atop was gigantic. Using J. T.’s franchise as a yardstick—3 officers and roughly 50 foot soldiers—there were some 5,300 other men working for those 120 bosses. Then there were another 20,000 unpaid rank-and-file members, many of whom wanted nothing more than an opportunity to become a foot soldier. They were even willing to pay gang dues to have their chance.
And how well did that dream job pay? Here are the monthly totals for the wages that J. T. paid his gang members:



So J. T. paid his employees $9,500, a combined monthly salary that was only $1,000 more than his own official salary. J. T.’s hourly wage was $66. His three officers, meanwhile, each took home $700 a month, which works out to about $7 an hour. And the foot soldiers earned just $3.30 an hour, less than the minimum wage. So the answer to the original question—if drug dealers make so much money, why are they still living with their mothers?—is that, except for the top cats, they don’t make much money. They had no choice but to live with their mothers. For every big earner, there were hundreds more just scraping along. The top 120 men in the Black Disciples gang represented just 2.2 percent of the full-fledged gang membership but took home well more than half the money.
In other words, a crack gang works pretty much like the standard capitalist enterprise: you have to be near the top of the pyramid to make a big wage. Notwithstanding the leadership’s rhetoric about the family nature of the business, the gang’s wages are about as skewed as wages in corporate America. A foot soldier had plenty in common with a McDonald’s burger flipper or a Wal-Mart shelf stocker. In fact, most of J. T.’s foot soldiers also held minimum-wage jobs in the legitimate sector to supplement their skimpy illicit earnings. The leader of another crack gang once told Venkatesh that he could easily afford to pay his foot soldiers more, but it wouldn’t be prudent. “You got all these niggers below you who want your job, you dig?” he said. “So, you know, you try to take care of them, but you know, you also have to show them you the boss. You always have to get yours first, or else you really ain’t no leader. If you start taking losses, they see you as weak and shit.”
Along with the bad pay, the foot soldiers faced terrible job conditions. For starters, they had to stand on a street corner all day and do business with crackheads. (The gang members were strongly advised against using the product themselves, advice that was enforced by beatings if necessary.) Foot soldiers also risked arrest and, more worrisome, violence. Using the gang’s financial documents and the rest of Venkatesh’s research, it is possible to construct an adverse-events index of J. T.’s gang during the four years in question. The results are astonishingly bleak. If you were a member of J. T.’s gang for all four years, here is the typical fate you would have faced during that period:
 
Number of times arrested 5.9
Number of nonfatal wounds or injuries (not including injuries meted out by the gang itself for rules violations) 2.4
Chance of being killed 1 in 4
 
A 1-in-4 chance of being killed! Compare these odds with those for a timber cutter, which the Bureau of Labor Statistics calls the most dangerous job in the United States. Over four years’ time, a timber cutter would stand only a 1-in-200 chance of being killed. Or compare the crack dealer’s odds to those of a death-row inmate in Texas, which executes more prisoners than any other state. In 2003, Texas put to death twenty-four inmates—or just 5 percent of the nearly 500 inmates on its death row during that time. Which means that you stand a greater chance of dying while dealing crack in a Chicago housing project than you do while sitting on death row in Texas.
 
So if crack dealing is the most dangerous job in America, and if the salary was only $3.30 an hour, why on earth would anyone take such a job?
Well, for the same reason that a pretty Wisconsin farm girl moves to Hollywood. For the same reason that a high-school quarterback wakes up at 5 a.m. to lift weights. They all want to succeed in an extremely competitive field in which, if you reach the top, you are paid a fortune (to say nothing of the attendant glory and power).
To the kids growing up in a housing project on Chicago’s south side, crack dealing seemed like a glamour profession. For many of them, the job of gang boss—highly visible and highly lucrative—was easily the best job they thought they had access to. Had they grown up under different circumstances, they might have thought about becoming economists or writers. But in the neighborhood where J. T.’s gang operated, the path to a decent legitimate job was practically invisible. Fifty-six percent of the neighborhood’s children lived below the poverty line (compared to a national average of 18 percent). Seventy-eight percent came from single-parent homes. Fewer than 5 percent of the neighborhood’s adults had a college degree; barely one in three adult men worked at all. The neighborhood’s median income was about $15,000 a year, well less than half the U.S. average. During the years that Venkatesh lived with J. T.’s gang, foot soldiers often asked his help in landing what they called “a good job”: working as a janitor at the University of Chicago.
The problem with crack dealing is the same as in every other glamour profession: a lot of people are competing for a very few prizes. Earning big money in the crack gang wasn’t much more likely than the Wisconsin farm girl becoming a movie star or the high-school quarterback playing in the NFL. But criminals, like everyone else, respond to incentives. So if the prize is big enough, they will form a line down the block just hoping for a chance. On the south side of Chicago, people wanting to sell crack vastly outnumbered the available street corners.
These budding drug lords bumped up against an immutable law of labor: when there are a lot of people willing and able to do a job, that job generally doesn’t pay well. This is one of four meaningful factors that determine a wage. The others are the specialized skills a job requires, the unpleasantness of a job, and the demand for services that the job fulfills.
The delicate balance between these factors helps explain why, for instance, the typical prostitute earns more than the typical architect. It may not seem as though she should. The architect would appear to be more skilled (as the word is usually defined) and better educated (again, as usually defined). But little girls don’t grow up dreaming of becoming prostitutes, so the supply of potential prostitutes is relatively small. Their skills, while not necessarily “specialized,” are practiced in a very specialized context. The job is unpleasant and forbidding in at least two significant ways: the likelihood of violence and the lost opportunity of having a stable family life. As for demand? Let’s just say that an architect is more likely to hire a prostitute than vice versa.
In the glamour professions—movies, sports, music, fashion—there is a different dynamic at play. Even in second-tier glamour industries like publishing, advertising, and media, swarms of bright young people throw themselves at grunt jobs that pay poorly and demand unstinting devotion. An editorial assistant earning $22,000 at a Manhattan publishing house, an unpaid high-school quarterback, and a teenage crack dealer earning $3.30 an hour are all playing the same game, a game that is best viewed as a tournament.
The rules of a tournament are straightforward. You must start at the bottom to have a shot at the top. (Just as a Major League shortstop probably played Little League and just as a Grand Dragon of the Ku Klux Klan probably started out as a lowly spear-carrier, a drug lord typically began by selling drugs on a street corner.) You must be willing to work long and hard at substandard wages. In order to advance in the tournament, you must prove yourself not merely above average but spectacular. (The way to distinguish yourself differs from profession to profession, of course; while J. T. certainly monitored his foot soldiers’ sales performance, it was their force of personality that really counted—more than it would for, say, a shortstop.) And finally, once you come to the sad realization that you will never make it to the top, you will quit the tournament. (Some people hang on longer than others—witness the graying “actors” who wait tables in New York—but people generally get the message quite early.)
Most of J. T.’s foot soldiers were unwilling to stay foot soldiers for long after they realized they weren’t advancing. Especially once the shooting started. After several relatively peaceful years, J. T.’s gang got involved in a turf war with a neighboring gang. Drive-by shootings became a daily event. For a foot soldier—the gang’s man on the street—this development was particularly dangerous. The nature of the business demanded that customers be able to find him easily and quickly; if he hid from the other gang, he couldn’t sell his crack.
Until the gang war, J. T.’s foot soldiers had been willing to balance the risky, low-paying job with the reward of advancement. But as one foot soldier told Venkatesh, he now wanted to be compensated for the added risk: “Would you stand around here when all this shit is going on? No, right? So if I gonna be asked to put my life on the line, then front me the cash, man. Pay me more ’cause it ain’t worth my time to be here when they’re warring.”
J. T. hadn’t wanted this war. For one thing, he was forced to pay his foot soldiers higher wages because of the added risk. Far worse, gang warfare was bad for business. If Burger King and McDonald’s launch a price war to gain market share, they partly make up in volume what they lose in price. (Nor is anyone getting shot.) But with a gang war, sales plummet because customers are so scared of the violence that they won’t come out in the open to buy their crack. In every way, war was expensive for J. T.
So why did he start the war? As a matter of fact, he didn’t. It was his foot soldiers who started it. It turns out that a crack boss didn’t have as much control over his subordinates as he would have liked. That’s because they had different incentives.
For J. T., violence was a distraction from the business at hand; he would have preferred that his members never fired a single gunshot. For a foot soldier, however, violence served a purpose. One of the few ways that a foot soldier could distinguish himself—and advance in the tournament—was by proving his mettle for violence. A killer was respected, feared, talked about. A foot soldier’s incentive was to make a name for himself; J. T.’s incentive was, in effect, to keep the foot soldiers from doing so. “We try to tell these shorties that they belong to a serious organization,” he once told Venkatesh. “It ain’t all about killing. They see these movies and shit, they think it’s all about running around tearing shit up. But it’s not. You’ve got to learn to be part of an organization; you can’t be fighting all the time. It’s bad for business.”
In the end, J. T. prevailed. He oversaw the gang’s expansion and ushered in a new era of prosperity and relative peace. J. T. was a winner. He was paid well because so few people could do what he did. He was a tall, good-looking, smart, tough man who knew how to motivate people. He was shrewd too, never tempting arrest by carrying guns or cash. While the rest of his gang lived in poverty with their mothers, J. T. had several homes, several women, several cars. He also had his business education, of course. He constantly worked to extend this advantage. That was why he ordered the corporate-style bookkeeping that eventually found its way into Sudhir Venkatesh’s hands. No other franchise leader had ever done such a thing. J. T. once showed his ledgers to the board of directors to prove, as if proof were needed, the extent of his business acumen.
And it worked. After six years running his local gang, J. T. was promoted to the board of directors. He was now thirty-four years old. He had won the tournament. But this tournament had a catch that publishing and pro sports and even Hollywood don’t have. Selling drugs, after all, is illegal. Not long after he made the board of directors, the Black Disciples were essentially shut down by a federal indictment—the same indictment that led the gangster named Booty to turn over his notebooks to Venkatesh—and J. T. was sent to prison.
 
Now for another unlikely question: what did crack cocaine have in common with nylon stockings?
In 1939, when DuPont introduced nylons, countless American women felt as if a miracle had been performed in their honor. Until then, stockings were made of silk, and silk was delicate, expensive, and in ever shorter supply. By 1941, some sixty-four million pairs of nylon stockings had been sold—more stockings than there were adult women in the United States. They were easily affordable, immensely appealing, practically addictive.
DuPont had pulled off the feat that every marketer dreams of: it brought class to the masses. In this regard, the invention of nylon stockings was markedly similar to the invention of crack cocaine.
In the 1970s, if you were the sort of person who did drugs, there was no classier drug than cocaine. Beloved by rock stars and movie stars, ballplayers and even the occasional politician, cocaine was a drug of power and panache. It was clean, it was white, it was pretty. Heroin was droopy and pot was foggy but cocaine provided a beautiful high.
Alas, it was also very expensive. Nor did the high last long. This led cocaine users to try jacking up the drug’s potency. They did this primarily by freebasing—adding ammonia and ethyl ether to cocaine hydrochloride, or powdered cocaine, and burning it to free up the “base” cocaine. But this could be dangerous. As more than a few flame-scarred drug users could attest, chemistry is best left to chemists.
Meanwhile, cocaine dealers and aficionados across the country, and perhaps also in the Caribbean and South America, were working on a safer version of distilled cocaine. They found that mixing powdered cocaine in a saucepan with baking soda and water, and then cooking off the liquid, produced tiny rocks of smokeable cocaine. It came to be called crack for the crackling sound the baking soda made when it was burned. More affectionate nicknames would soon follow: Rock, Kryptonite, Kibbles ’n Bits, Scrabble, and Love. By the early 1980s, the class drug was ready for the masses. Now only two things were needed to turn crack into a phenomenon: an abundant supply of raw cocaine and a way to get the new product to a mass market.
The cocaine was easy to come by, for the invention of crack coincided with a Colombian cocaine glut. During the late 1970s, the wholesale price of cocaine in the United States fell dramatically, even as its purity was rising. One man, a Nicaraguan émigré named Oscar Danilo Blandon, was suspected of importing far more Colombian cocaine than anyone else. Blandon did so much business with the budding crack dealers of South Central Los Angeles that he came to be known as the Johnny Appleseed of Crack. Blandon would later claim that he was selling the cocaine to raise money for the CIA-sponsored Contras back home in Nicaragua. He liked to say that the CIA was in turn watching his back in the United States, allowing him to sell cocaine with impunity. This claim would spark a belief that still seethes to this day, especially among urban blacks, that the CIA itself was the chief sponsor of the American crack trade.
Verifying that claim is beyond the purview of this book. What is demonstrably true is that Oscar Danilo Blandon helped establish a link—between Colombian cocaine cartels and inner-city crack merchants—that would alter American history. By putting massive amounts of cocaine into the hands of street gangs, Blandon and others like him gave rise to a devastating crack boom. And gangs like the Black Gangster Disciple Nation were given new reason to exist.
As long as there have been cities, there have been gangs of one sort or another. In the United States, gangs have traditionally been a sort of halfway house for recent immigrants. In the 1920s, Chicago alone had more than 1,300 street gangs, catering to every ethnic, political, and criminal leaning imaginable. As a rule, gangs would prove much better at making mayhem than money. Some fancied themselves commercial enterprises, and a few—the Mafia, most notably—actually did make money (at least for the higher-ups). But most gangsters were, as the cliché assures us, two-bit gangsters.
Black street gangs in particular flourished in Chicago, with membership in the tens of thousands by the 1970s. They constituted the sort of criminals, petty and otherwise, who sucked the life out of urban areas. Part of the problem was that these criminals never seemed to get locked up. The 1960s and 1970s were, in retrospect, a great time to be a street criminal in most American cities. The likelihood of punishment was so low—this was the heyday of a liberal justice system and the criminals’ rights movement—that it simply didn’t cost very much to commit a crime.
By the 1980s, however, the courts had begun to radically reverse that trend. Criminals’ rights were curtailed and stricter sentencing guidelines put in place. More and more of Chicago’s black gangsters were getting sent to federal prisons. By happy coincidence, some of their fellow inmates were Mexican gang members with close ties to Colombian drug dealers. In the past, the black gangsters had bought their drugs from a middleman, the Mafia—which, as it happened, was then being pummeled by the federal government’s new anti-racketeering laws. But by the time crack came to Chicago, the black gangsters had made the connections to buy their cocaine directly from Colombian dealers.
Cocaine had never been a big seller in the ghetto: it was too expensive. But that was before the invention of crack. This new product was ideal for a low-income, street-level customer. Because it required such a tiny amount of pure cocaine, one hit of crack cost only a few dollars. Its powerful high reached the brain in just a few seconds—and then faded fast, sending the user back for more. From the outset, crack was bound to be a huge success.
And who better to sell it than the thousands of junior members of all those street gangs like the Black Gangster Disciple Nation? The gangs already owned the territory—real estate was, in essence, their core business—and they were suitably menacing to keep customers from even thinking about ripping them off. Suddenly the urban street gang evolved from a club for wayward teenagers into a true commercial enterprise.
The gang also presented an opportunity for longtime employment. Before crack, it was just about impossible to earn a living in a street gang. When it was time for a gangster to start supporting a family, he would have to quit. There was no such thing as a thirty-year-old gangster: he was either working a legitimate job, dead, or in prison. But with crack, there was real money to be made. Instead of moving on and making way for the younger gangsters to ascend, the veterans stayed put. This was happening just as the old-fashioned sort of lifetime jobs—factory jobs especially—were disappearing. In the past, a semi-skilled black man in Chicago could earn a decent wage working in a factory. With that option narrowing, crack dealing looked even better. How hard could it be? The stuff was so addictive that a fool could sell it.
Who cared if the crack game was a tournament that only a few of them could possibly win? Who cared if it was so dangerous—standing out there on a corner, selling it as fast and anonymously as McDonald’s sells hamburgers, not knowing any of your customers, wondering who might be coming to arrest or rob or kill you? Who cared if your product got twelve-year-olds and grandmothers and preachers so addicted that they stopped thinking about anything except their next hit? Who cared if crack killed the neighborhood?
For black Americans, the four decades between World War II and the crack boom had been marked by steady and often dramatic improvement. Particularly since the civil rights legislation of the mid-1960s, the telltale signs of societal progress had finally taken root among black Americans. The black-white income gap was shrinking. So was the gap between black children’s test scores and those of white children. Perhaps the most heartening gain had been in infant mortality. As late as 1964, a black infant was twice as likely to die as a white infant, often of a cause as basic as diarrhea or pneumonia. With segregated hospitals, many black patients received what amounted to Third World care. But that changed when the federal government ordered the hospitals to be desegregated: within just seven years, the black infant mortality rate had been cut in half. By the 1980s, virtually every facet of life was improving for black Americans, and the progress showed no sign of stopping.
Then came crack cocaine.
While crack use was hardly a black-only phenomenon, it hit black neighborhoods much harder than most. The evidence can be seen by measuring the same indicators of societal progress cited above. After decades of decline, black infant mortality began to soar in the 1980s, as did the rate of low-birthweight babies and parent abandonment. The gap between black and white schoolchildren widened. The number of blacks sent to prison tripled. Crack was so dramatically destructive that if its effect is averaged for all black Americans, not just crack users and their families, you will see that the group’s postwar progress was not only stopped cold but was often knocked as much as ten years backward. Black Americans were hurt more by crack cocaine than by any other single cause since Jim Crow.
And then there was the crime. Within a five-year period, the homicide rate among young urban blacks quadrupled. Suddenly it was just as dangerous to live in parts of Chicago or St. Louis or Los Angeles as it was to live in Bogotá.
The violence associated with the crack boom was various and relentless. It coincided with an even broader American crime wave that had been building for two decades. Although the rise of this crime wave long predated crack, the trend was so exacerbated by crack that criminologists got downright apocalyptic in their predictions. James Alan Fox, perhaps the most widely quoted crime expert in the popular press, warned of a coming “bloodbath” of youth violence.
But Fox and the other purveyors of conventional wisdom turned out to be wrong. The bloodbath did not materialize. The crime rate in fact began to fall—so unexpectedly and dramatically and thoroughly that now, from the distance of several years, it is almost hard to recall the crushing grip of that crime wave.
Why did it fall?
For a few reasons, but one of them more surprising than the rest. Oscar Danilo Blandon, the so-called Johnny Appleseed of Crack, may have been the instigator of one ripple effect, in which by his actions a single person inadvertently causes an ocean of despair. But unbeknownst to just about everybody, another remarkably powerful ripple effect—this one moving in the opposite direction—had just come into play.


4
Where Have All the Criminals Gone?
In 1966, one year after Nicolae Ceauşescu became the Communist dictator of Romania, he made abortion illegal. “The fetus is the property of the entire society,” he proclaimed. “Anyone who avoids having children is a deserter who abandons the laws of national continuity.”
Such grandiose declarations were commonplace during Ceauşescu’s reign, for his master plan—to create a nation worthy of the New Socialist Man—was an exercise in grandiosity. He built palaces for himself while alternately brutalizing and neglecting his citizens. Abandoning agriculture in favor of manufacturing, he forced many of the nation’s rural dwellers into unheated apartment buildings. He gave government positions to forty family members including his wife, Elena, who required forty homes and a commensurate supply of fur and jewels. Madame Ceauşescu, known officially as the Best Mother Romania Could Have, was not particularly maternal. “The worms never get satisfied, regardless of how much food you give them,” she said when Romanians complained about the food shortages brought on by her husband’s mismanagement. She had her own children bugged to ensure their loyalty.
Ceauşescu’s ban on abortion was designed to achieve one of his major aims: to rapidly strengthen Romania by boosting its population. Until 1966, Romania had had one of the most liberal abortion policies in the world. Abortion was in fact the main form of birth control, with four abortions for every live birth. Now, virtually overnight, abortion was forbidden. The only exemptions were mothers who already had four children or women with significant standing in the Communist Party. At the same time, all contraception and sex education were banned. Government agents sardonically known as the Menstrual Police regularly rounded up women in their workplaces to administer pregnancy tests. If a woman repeatedly failed to conceive, she was forced to pay a steep “celibacy tax.”
Ceauşescu’s incentives produced the desired effect. Within one year of the abortion ban, the Romanian birth rate had doubled. These babies were born into a country where, unless you belonged to the Ceauşescu clan or the Communist elite, life was miserable. But these children would turn out to have particularly miserable lives. Compared to Romanian children born just a year earlier, the cohort of children born after the abortion ban would do worse in every measurable way: they would test lower in school, they would have less success in the labor market, and they would also prove much more likely to become criminals.
The abortion ban stayed in effect until Ceauşescu finally lost his grip on Romania. On December 16, 1989, thousands of people took to the streets of Timisoara to protest his corrosive regime. Many of the protestors were teenagers and college students. The police killed dozens of them. One of the opposition leaders, a forty-one-year-old professor, later said it was his thirteen-year-old daughter who insisted he attend the protest, despite his fear. “What is most interesting is that we learned not to be afraid from our children,” he said. “Most were aged thirteen to twenty.” A few days after the massacre in Timisoara, Ceauşescu gave a speech in Bucharest before one hundred thousand people. Again the young people were out in force. They shouted down Ceauşescu with cries of “Timisoara!” and “Down with the murderers!” His time had come. He and Elena tried to escape the country with $1 billion, but they were captured, given a crude trial, and, on Christmas Day, executed by firing squad.
Of all the Communist leaders deposed in the years bracketing the collapse of the Soviet Union, only Nicolae Ceauşescu met a violent death. It should not be overlooked that his demise was precipitated in large measure by the youth of Romania—a great number of whom, were it not for his abortion ban, would never have been born at all.
 
The story of abortion in Romania might seem an odd way to begin telling the story of American crime in the 1990s. But it’s not. In one important way, the Romanian abortion story is a reverse image of the American crime story. The point of overlap was on that Christmas Day of 1989, when Nicolae Ceauşescu learned the hard way—with a bullet to the head—that his abortion ban had much deeper implications than he knew.
On that day, crime was just about at its peak in the United States. In the previous fifteen years, violent crime had risen 80 percent. It was crime that led the nightly news and the national conversation.
When the crime rate began falling in the early 1990s, it did so with such speed and suddenness that it surprised everyone. It took some experts many years to even recognize that crime was falling, so confident had they been of its continuing rise. Long after crime had peaked, in fact, some of them continued to predict ever darker scenarios. But the evidence was irrefutable: the long and brutal spike in crime was moving in the opposite direction, and it wouldn’t stop until the crime rate had fallen back to the levels of forty years earlier.
Now the experts hustled to explain their faulty forecasting. The criminologist James Alan Fox explained that his warning of a “bloodbath” was in fact an intentional overstatement. “I never said there would be blood flowing in the streets,” he said, “but I used strong terms like ‘bloodbath’ to get people’s attention. And it did. I don’t apologize for using alarmist terms.” (If Fox seems to be offering a distinction without a difference—“bloodbath” versus “blood flowing in the streets”—we should remember that even in retreat mode, experts can be self-serving.)
After the relief had settled in, after people remembered how to go about their lives without the pressing fear of crime, there arose a natural question: just where did all those criminals go?
At one level, the answer seemed puzzling. After all, if none of the criminologists, police officials, economists, politicians, or others who traffic in such matters had foreseen the crime decline, how could they suddenly identify its causes?
But this diverse army of experts now marched out a phalanx of hypotheses to explain the drop in crime. A great many newspaper articles would be written on the subject. Their conclusions often hinged on which expert had most recently spoken to which reporter. Here, ranked by frequency of mention, are the crime-drop explanations cited in articles published from 1991 to 2001 in the ten largest-circulation papers in the LexisNexis database:



If you are the sort of person who likes guessing games, you may wish to spend the next few moments pondering which of the preceding explanations seem to have merit and which don’t. Hint: of the seven major explanations on the list, only three can be shown to have contributed to the drop in crime. The others are, for the most part, figments of someone’s imagination, self-interest, or wishful thinking. Further hint: one of the greatest measurable causes of the crime drop does not appear on the list at all, for it didn’t receive a single newspaper mention.
 
Let’s begin with a fairly uncontroversial one: the strong economy. The decline in crime that began in the early 1990s was accompanied by a blistering national economy and a significant drop in unemployment. It might seem to follow that the economy was a hammer that helped beat down crime. But a closer look at the data destroys this theory. It is true that a stronger job market may make certain crimes relatively less attractive. But that is only the case for crimes with a direct financial motivation—burglary, robbery, and auto theft—as opposed to violent crimes like homicide, assault, and rape. Moreover, studies have shown that an unemployment decline of 1 percentage point accounts for a 1 percent drop in nonviolent crime. During the 1990s, the unemployment rate fell by 2 percentage points; nonviolent crime, meanwhile, fell by roughly 40 percent. But an even bigger flaw in the strong-economy theory concerns violent crime. Homicide fell at a greater rate during the 1990s than any other sort of crime, and a number of reliable studies have shown virtually no link between the economy and violent crime. This weak link is made even weaker by glancing back to a recent decade, the 1960s, when the economy went on a wild growth spurt—as did violent crime. So while a strong 1990s economy might have seemed, on the surface, a likely explanation for the drop in crime, it almost certainly didn’t affect criminal behavior in any significant way.
Unless, that is, “the economy” is construed in a broader sense—as a means to build and maintain hundreds of prisons. Let’s now consider another crime-drop explanation: increased reliance on prisons. It might help to start by flipping the crime question around. Instead of wondering what made crime fall, think about this: why had it risen so dramatically in the first place?
During the first half of the twentieth century, the incidence of violent crime in the United States was, for the most part, fairly steady. But in the early 1960s, it began to climb. In retrospect, it is clear that one of the major factors pushing this trend was a more lenient justice system. Conviction rates declined during the 1960s, and criminals who were convicted served shorter sentences. This trend was driven in part by an expansion in the rights of people accused of crimes—a long overdue expansion, some would argue. (Others would argue that the expansion went too far.) At the same time, politicians were growing increasingly softer on crime—“for fear of sounding racist,” as the economist Gary Becker has written, “since African-Americans and Hispanics commit a disproportionate share of felonies.” So if you were the kind of person who might want to commit a crime, the incentives were lining up in your favor: a slimmer likelihood of being convicted and, if convicted, a shorter prison term. Because criminals respond to incentives as readily as anyone, the result was a surge in crime.
It took some time, and a great deal of political turmoil, but these incentives were eventually curtailed. Criminals who would have previously been set free—for drug-related offenses and parole revocation in particular—were instead locked up. Between 1980 and 2000, there was a fifteenfold increase in the number of people sent to prison on drug charges. Many other sentences, especially for violent crime, were lengthened. The total effect was dramatic. By 2000, more than two million people were in prison, roughly four times the number as of1972. Fully half of that increase took place during the 1990s.
The evidence linking increased punishment with lower crime rates is very strong. Harsh prison terms have been shown to act as both deterrent (for the would-be criminal on the street) and prophylactic (for the would-be criminal who is already locked up). Logical as this may sound, some criminologists have fought the logic. A 1977 academic study called “On Behalf of a Moratorium on Prison Construction” noted that crime rates tend to be high when imprisonment rates are high, and concluded that crime would fall if imprisonment rates could only be lowered. (Fortunately, jailers did not suddenly turn loose their wards and sit back waiting for crime to fall. As the political scientist John J. DiIulio Jr. later commented, “Apparently, it takes a Ph.D. in criminology to doubt that keeping dangerous criminals incarcerated cuts crime.”)
The “Moratorium” argument rests on a fundamental confusion of correlation and causality. Consider a parallel argument. The mayor of a city sees that his citizens celebrate wildly when their team wins the World Series. He is intrigued by this correlation but, like the “Moratorium” author, fails to see the direction in which the correlation runs. So the following year, the mayor decrees that his citizens start celebrating the World Series before the first pitch is thrown—an act that, in his confused mind, will ensure a victory.
There are certainly plenty of reasons to dislike the huge surge in the prison population. Not everyone is pleased that such a significant fraction of Americans, especially black Americans, live behind bars. Nor does prison even begin to address the root causes of crime, which are diverse and complex. Lastly, prison is hardly a cheap solution: it costs about $25,000 a year to keep someone incarcerated. But if the goal here is to explain the drop in crime in the 1990s, imprisonment is certainly one of the key answers. It accounts for roughly one-third of the drop in crime.
Another crime-drop explanation is often cited in tandem with imprisonment: the increased use of capital punishment. The number of executions in the United States quadrupled between the 1980s and the 1990s, leading many people to conclude—in the context of a debate that has been going on for decades—that capital punishment helped drive down crime. Lost in the debate, however, are two important facts.
First, given the rarity with which executions are carried out in this country and the long delays in doing so, no reasonable criminal should be deterred by the threat of execution. Even though capital punishment quadrupled within a decade, there were still only 478 executions in the entire United States during the 1990s. Any parent who has ever said to a recalcitrant child, “Okay, I’m going to count to ten and this time I’m really going to punish you,” knows the difference between deterrent and empty threat. New York State, for instance, has not as of this writing executed a single criminal since reinstituting its death penalty in 1995. Even among prisoners on death row, the annual execution rate is only 2 percent—compared with the 7 percent annual chance of dying faced by a member of the Black Gangster Disciple Nation crack gang. If life on death row is safer than life on the streets, it’s hard to believe that the fear of execution is a driving force in a criminal’s calculus. Like the $3 fine for late-arriving parents at the Israeli day-care centers, the negative incentive of capital punishment simply isn’t serious enough for a criminal to change his behavior.
The second flaw in the capital punishment argument is even more obvious. Assume for a moment that the death penalty is a deterrent. How much crime does it actually deter? The economist Isaac Ehrlich, in an oft-cited 1975 paper, put forth an estimate that is generally considered optimistic: executing 1 criminal translates into 7 fewer homicides that the criminal might have committed. Now do the math. In 1991, there were 14 executions in the United States; in 2001, there were 66. According to Ehrlich’s calculation, those 52 additional executions would have accounted for 364 fewer homicides in 2001—not a small drop, to be sure, but less than 4 percent of the actual decrease in homicides that year. So even in a death penalty advocate’s best-case scenario, capital punishment could explain only one twenty-fifth of the drop in homicides in the 1990s. And because the death penalty is rarely given for crimes other than homicide, its deterrent effect cannot account for a speck of decline in other violent crimes.
It is extremely unlikely, therefore, that the death penalty, as currently practiced in the United States, exerts any real influence on crime rates. Even many of its onetime supporters have come to this conclusion. “I feel morally and intellectually obligated simply to concede that the death penalty experiment has failed,” said U.S. Supreme Court Justice Harry A. Blackmun in 1994, nearly twenty years after he had voted for its reinstatement. “I no longer shall tinker with the machinery of death.”
 
So it wasn’t capital punishment that drove crime down, nor was it the booming economy. But higher rates of imprisonment did have a lot to do with it. All those criminals didn’t march into jail by themselves, of course. Someone had to investigate the crime, catch the bad guy, and put together the case that would get him convicted. Which naturally leads to a related pair of crime-drop explanations:
Innovative policing strategies
Increased number of police
Let’s address the second one first. The number of police officers per capita in the United States rose about 14 percent during the 1990s. Does merely increasing the number of police, however, reduce crime? The answer would seem obvious—yes—but proving that answer isn’t so easy. That’s because when crime is rising, people clamor for protection, and invariably more money is found for cops. So if you just look at raw correlations between police and crime, you will find that when there are more police, there tends to be more crime. That doesn’t mean, of course, that the police are causing the crime, just as it doesn’t mean, as some criminologists have argued, that crime will fall if criminals are released from prison.
To show causality, we need a scenario in which more police are hired for reasons completely unrelated to rising crime. If, for instance, police were randomly sprinkled in some cities and not in others, we could look to see whether crime declines in the cities where the police happen to land.
As it turns out, that exact scenario is often created by vote-hungry politicians. In the months leading up to Election Day, incumbent mayors routinely try to lock up the law-and-order vote by hiring more police—even when the crime rate is standing still. So by comparing the crime rate in one set of cities that have recently had an election (and which therefore hired extra police) with another set of cities that had no election (and therefore no extra police), it’s possible to tease out the effect of the extra police on crime. The answer: yes indeed, additional police substantially lower the crime rate.
Again, it may help to look backward and see why crime had risen so much in the first place. From 1960 to 1985, the number of police officers fell more than 50 percent relative to the number of crimes. In some cases, hiring additional police was considered a violation of the era’s liberal aesthetic; in others, it was simply deemed too expensive. This 50 percent decline in police translated into a roughly equal decline in the probability that a given criminal would be caught. Coupled with the above-cited leniency in the other half of the criminal justice system, the courtrooms, this decrease in policing created a strong positive incentive for criminals.
By the 1990s, philosophies—and necessities—had changed. The policing trend was put in reverse, with wide-scale hiring in cities across the country. Not only did all those police act as a deterrent, but they also provided the manpower to imprison criminals who might have otherwise gone uncaught. The hiring of additional police accounted for roughly 10 percent of the 1990s crime drop.
But it wasn’t only the number of police that changed in the 1990s; consider the most commonly cited crime-drop explanation of all: innovative policing strategies.
There was perhaps no more attractive theory than the belief that smart policing stops crime. It offered a set of bona fide heroes rather than simply a dearth of villains. This theory rapidly became an article of faith because it appealed to the factors that, according to John Kenneth Galbraith, most contribute to the formation of conventional wisdom: the ease with which an idea may be understood and the degree to which it affects our personal well-being.
The story played out most dramatically in New York City, where newly elected mayor Rudolph Giuliani and his handpicked police commissioner, William Bratton, vowed to fix the city’s desperate crime situation. Bratton took a novel approach to policing. He ushered the NYPD into what one senior police official later called “our Athenian period,” in which new ideas were given weight over calcified practices. Instead of coddling his precinct commanders, Bratton demanded accountability. Instead of relying solely on old-fashioned cop know-how, he introduced technological solutions like CompStat, a computerized method of addressing crime hot spots.
The most compelling new idea that Bratton brought to life stemmed from the broken window theory, which was conceived by the criminologists James Q. Wilson and George Kelling. The broken window theory argues that minor nuisances, if left unchecked, turn into major nuisances: that is, if someone breaks a window and sees it isn’t fixed immediately, he gets the signal that it’s all right to break the rest of the windows and maybe set the building afire too.
So with murder raging all around, Bill Bratton’s cops began to police the sort of deeds that used to go unpoliced: jumping a subway turnstile, panhandling too aggressively, urinating in the streets, swabbing a filthy squeegee across a car’s windshield unless the driver made an appropriate “donation.”
Most New Yorkers loved this crackdown on its own merit. But they particularly loved the idea, as stoutly preached by Bratton and Giuliani, that choking off these small crimes was like choking off the criminal element’s oxygen supply. Today’s turnstile jumper might easily be wanted for yesterday’s murder. That junkie peeing in an alley might have been on his way to a robbery.
As violent crime began to fall dramatically, New Yorkers were more than happy to heap laurels on their operatic, Brooklyn-bred mayor and his hatchet-faced police chief with the big Boston accent. But the two strong-willed men weren’t very good at sharing the glory. Soon after the city’s crime turnaround landed Bratton—and not Giuliani—on the cover of Time, Bratton was pushed to resign. He had been police commissioner for just twenty-seven months.
New York City was a clear innovator in police strategies during the 1990s crime drop, and it also enjoyed the greatest decline in crime of any large American city. Homicide rates fell from 30.7 per 100,000 people in 1990 to 8.4 per 100,000 people in 2000, a change of 73.6 percent. But a careful analysis of the facts shows that the innovative policing strategies probably had little effect on this huge decline.
First, the drop in crime in New York began in 1990. By the end of 1993, the rate of property crime and violent crime, including homicides, had already fallen nearly 20 percent. Rudolph Giuliani, however, did not become mayor—and install Bratton—until early 1994. Crime was well on its way down before either man arrived. And it would continue to fall long after Bratton was bumped from office.
Second, the new police strategies were accompanied by a much more significant change within the police force: a hiring binge. Between 1991 and 2001, the NYPD grew by 45 percent, more than three times the national average. As argued above, an increase in the number of police, regardless of new strategies, has been proven to reduce crime. By a conservative calculation, this huge expansion of New York’s police force would be expected to reduce crime in New York by 18 percent relative to the national average. If you subtract that 18 percent from New York’s homicide reduction, thereby discounting the effect of the police-hiring surge, New York no longer leads the nation with its 73.6 percent drop; it goes straight to the middle of the pack. Many of those new police were in fact hired by David Dinkins, the mayor whom Giuliani defeated. Dinkins had been desperate to secure the law-and-order vote, having known all along that his opponent would be Giuliani, a former federal prosecutor. (The two men had run against each other four years earlier as well.) So those who wish to credit Giuliani with the crime drop may still do so, for it was his own law-and-order reputation that made Dinkins hire all those police. In the end, of course, the police increase helped everyone—but it helped Giuliani a lot more than Dinkins.
Most damaging to the claim that New York’s police innovations radically lowered crime is one simple and often overlooked fact: crime went down everywhere during the 1990s, not only in New York. Few other cities tried the kind of strategies that New York did, and certainly none with the same zeal. But even in Los Angeles, a city notorious for bad policing, crime fell at about the same rate as it did in New York once the growth in New York’s police force is accounted for.
It would be churlish to argue that smart policing isn’t a good thing. Bill Bratton certainly deserves credit for invigorating New York’s police force. But there is frighteningly little evidence that his strategy was the crime panacea that he and the media deemed it. The next step will be to continue measuring the impact of police innovations—in Los Angeles, for instance, where Bratton himself became police chief in late 2002. While he duly instituted some of the innovations that were his hallmark in New York, Bratton announced that his highest priority was a more basic one: finding the money to hire thousands of new police officers.
 
Now to explore another pair of common crime-drop explanations:
Tougher gun laws
Changes in crack and other drug markets
First, the guns. Debates on this subject are rarely coolheaded. Gun advocates believe that gun laws are too strict; opponents believe exactly the opposite. How can intelligent people view the world so differently? Because a gun raises a complex set of issues that change according to one factor: whose hand happens to be holding the gun.
It might be worthwhile to take a step back and ask a rudimentary question: what is a gun? It’s a tool that can be used to kill someone, of course, but more significantly, a gun is a great disrupter of the natural order.
A gun scrambles the outcome of any dispute. Let’s say that a tough guy and a not-so-tough guy exchange words in a bar, which leads to a fight. It’s pretty obvious to the not-so-tough guy that he’ll be beaten, so why bother fighting? The pecking order remains intact. But if the not-so-tough guy happens to have a gun, he stands a good chance of winning. In this scenario, the introduction of a gun may well lead to more violence.
Now instead of the tough guy and the not-so-tough guy, picture a high-school girl out for a nighttime stroll when she is suddenly set upon by a mugger. What if only the mugger is armed? What if only the girl is armed? What if both are armed? A gun opponent might argue that the gun has to be kept out of the mugger’s hands in the first place. A gun advocate might argue that the high-school girl needs to have a gun to disrupt what has become the natural order: it’s the bad guys that have the guns. (If the girl scares off the mugger, then the introduction of a gun in this case may lead to less violence.) Any mugger with even a little initiative is bound to be armed, for in a country like the United States, with a thriving black market in guns, anyone can get hold of one.
There are enough guns in the United States that if you gave one to every adult, you would run out of adults before you ran out of guns. Nearly two-thirds of U.S. homicides involve a gun, a far greater fraction than in other industrialized countries. Our homicide rate is also much higher than in those countries. It would therefore seem likely that our homicide rate is so high in part because guns are so easily available. Research indeed shows this to be true.
But guns are not the whole story. In Switzerland, every adult male is issued an assault rifle for militia duty and is allowed to keep the gun at home. On a per capita basis, Switzerland has more firearms than just about any other country, and yet it is one of the safest places in the world. In other words, guns do not cause crime. That said, the established U.S. methods of keeping guns away from the people who do cause crime are, at best, feeble. And since a gun—unlike a bag of cocaine or a car or a pair of pants—lasts pretty much forever, even turning off the spigot of new guns still leaves an ocean of available ones.
So bearing all this in mind, let’s consider a variety of recent gun initiatives to see the impact they may have had on crime in the 1990s.
The most famous gun-control law is the Brady Act, passed in 1993, which requires a criminal check and a waiting period before a person can purchase a handgun. This solution may have seemed appealing to politicians, but to an economist it doesn’t make much sense. Why? Because regulation of a legal market is bound to fail when a healthy black market exists for the same product. With guns so cheap and so easy to get, the standard criminal has no incentive to fill out a firearms application at his local gun shop and then wait a week. The Brady Act, accordingly, has proven to be practically impotent in lowering crime. (A study of imprisoned felons showed that even before the Brady Act, only about one-fifth of the criminals had bought their guns through a licensed dealer.) Various local gun-control laws have also failed. Washington, D.C., and Chicago both instituted handgun bans well before crime began to fall across the country in the 1990s, and yet those two cities were laggards, not leaders, in the national reduction in crime. One deterrent that has proven moderately effective is a stiff increase in prison time for anyone caught in possession of an illegal gun. But there is plenty of room for improvement. Not that this is likely, but if the death penalty were assessed to anyone carrying an illegal gun, and if the penalty were actually enforced, gun crimes would surely plunge.
Another staple of 1990s crime fighting—and of the evening news—was the gun buyback. You remember the image: a menacing, glistening heap of firearms surrounded by the mayor, the police chief, the neighborhood activists. It made for a nice photo op, but that’s about as meaningful as a gun buyback gets. The guns that are turned in tend to be heirlooms or junk. The payoff to the gun seller—usually $50 or $100, but in one California buyback, three free hours of psychotherapy—isn’t an adequate incentive for anyone who actually plans to use his gun. And the number of surrendered guns is no match for even the number of new guns simultaneously coming to market. Given the number of handguns in the United States and the number of homicides each year, the likelihood that a particular gun was used to kill someone that year is 1 in 10,000. The typical gun buyback program yields fewer than 1,000 guns—which translates into an expectation of less than one-tenth of one homicide per buyback. Not enough, that is, to make even a sliver of impact on the fall of crime.
Then there is an opposite argument—that we need more guns on the street, but in the hands of the right people (like the high-school girl above, instead of her mugger). The economist John R. Lott Jr. is the main champion of this idea. His calling card is the book More Guns, Less Crime, in which he argues that violent crime has decreased in areas where law-abiding citizens are allowed to carry concealed weapons. His theory might be surprising, but it is sensible. If a criminal thinks his potential victim may be armed, he may be deterred from committing the crime. Handgun opponents call Lott a pro-gun ideologue, and Lott let himself become a lightning rod for gun controversy. He exacerbated his trouble by creating a pseudonym, “Mary Rosh,” to defend his theory in online debates. Rosh, identifying herself as a former student of Lott’s, praised her teacher’s intellect, his evenhandedness, his charisma. “I have to say that he was the best professor that I ever had,” s/he wrote. “You wouldn’t know that he was a ‘right-wing’ ideologue from the class….There were a group of us students who would try to take any class that he taught. Lott finally had to tell us that it was best for us to try and take classes from other professors more to be exposed to other ways of teaching graduate material.” Then there was the troubling allegation that Lott actually invented some of the survey data that support his more-guns/less-crime theory. Regardless of whether the data were faked, Lott’s admittedly intriguing hypothesis doesn’t seem to be true. When other scholars have tried to replicate his results, they found that right-to-carry laws simply don’t bring down crime.
 
Consider the next crime-drop explanation: the bursting of the crack bubble. Crack cocaine was such a potent, addictive drug that a hugely profitable market had been created practically overnight. True, it was only the leaders of the crack gangs who were getting rich. But that only made the street-level dealers all the more desperate to advance. Many of them were willing to kill their rivals to do so, whether the rival belonged to the same gang or a different one. There were also gun battles over valuable drug-selling corners. The typical crack murder involved one crack dealer shooting another (or two of them, or three) and not, contrary to conventional wisdom, some bug-eyed crackhead shooting a shopkeeper over a few dollars. The result was a huge increase in violent crime. One study found that more than 25 percent of the homicides in New York City in 1988 were crack-related.
The violence associated with crack began to ebb in about 1991. This has led many people to think that crack itself went away. It didn’t. Smoking crack remains much more popular today than most people realize. Nearly 5 percent of all arrests in the United States are still related to cocaine (as against 6 percent at crack’s peak); nor have emergency room visits for crack users diminished all that much.
What did go away were the huge profits for selling crack. The price of cocaine had been falling for years, and it got only cheaper as crack grew more popular. Dealers began to underprice one another; profits vanished. The crack bubble burst as dramatically as the Nasdaq bubble would eventually burst. (Think of the first generation of crack dealers as the Microsoft millionaires; think of the second generation as Pets.com.) As veteran crack dealers were killed or sent to prison, younger dealers decided that the smaller profits didn’t justify the risk. The tournament had lost its allure. It was no longer worth killing someone to steal their crack turf, and certainly not worth being killed.
So the violence abated. From 1991 to 2001, the homicide rate among young black men—who were disproportionately represented among crack dealers—fell 48 percent, compared to 30 percent for older black men and older white men. (Another minor contributor to the falling homicide rate is the fact that some crack dealers took to shooting their enemies in the buttocks rather than murdering them; this method of violent insult was considered more degrading—and was obviously less severely punished—than murder.) All told, the crash of the crack market accounted for roughly 15 percent of the crime drop of the 1990s—a substantial factor, to be sure, though it should be noted that crack was responsible for far more than 15 percent of the crime increase of the 1980s. In other words, the net effect of crack is still being felt in the form of violent crime, to say nothing of the miseries the drug itself continues to cause.
 
The final pair of crime-drop explanations concern two demographic trends. The first one received many media citations: aging of the population.
Until crime fell so drastically, no one talked about this theory at all. In fact, the “bloodbath” school of criminology was touting exactly the opposite theory—that an increase in the teenage share of the population would produce a crop of superpredators who would lay the nation low. “Just beyond the horizon, there lurks a cloud that the winds will soon bring over us,” James Q. Wilson wrote in 1995. “The population will start getting younger again….Get ready.”
But overall, the teenage share of the population wasn’t getting much bigger. Criminologists like Wilson and James Alan Fox had badly misread the demographic data. The real population growth in the 1990s was in fact among the elderly. While this may have been scary news in terms of Medicare and Social Security, the average American had little to fear from the growing horde of oldsters. It shouldn’t be surprising to learn that elderly people are not very criminally intent; the average sixty-five-year-old is about one-fiftieth as likely to be arrested as the average teenager. That is what makes this aging-of-the-population theory of crime reduction so appealingly tidy: since people mellow out as they get older, more older people must lead to less crime. But a thorough look at the data reveals that the graying of America did nothing to bring down crime in the 1990s. Demographic change is too slow and subtle a process—you don’t graduate from teenage hoodlum to senior citizen in just a few years—to even begin to explain the suddenness of the crime decline.
There was another demographic change, however, unforeseen and long-gestating, that did drastically reduce crime in the 1990s.
Think back for a moment to Romania in 1966. Suddenly and without warning, Nicolae Ceauşescu declared abortion illegal. The children born in the wake of the abortion ban were much more likely to become criminals than children born earlier. Why was that? Studies in other parts of Eastern Europe and in Scandinavia from the 1930s through the 1960s reveal a similar trend. In most of these cases, abortion was not forbidden outright, but a woman had to receive permission from a judge in order to obtain one. Researchers found that in the instances where the woman was denied an abortion, she often resented her baby and failed to provide it with a good home. Even when controlling for the income, age, education, and health of the mother, the researchers found that these children too were more likely to become criminals.
The United States, meanwhile, has had a different abortion history than Europe. In the early days of the nation, it was permissible to have an abortion prior to “quickening”—that is, when the first movements of the fetus could be felt, usually around the sixteenth to eighteenth week of pregnancy. In 1828, New York became the first state to restrict abortion; by 1900 it had been made illegal throughout the country. Abortion in the twentieth century was often dangerous and usually expensive. Fewer poor women, therefore, had abortions. They also had less access to birth control. What they did have, accordingly, was a lot more babies.
In the late 1960s, several states began to allow abortion under extreme circumstances: rape, incest, or danger to the mother. By 1970 five states had made abortion entirely legal and broadly available: New York, California, Washington, Alaska, and Hawaii. On January 22, 1973, legalized abortion was suddenly extended to the entire country with the U.S. Supreme Court’s ruling in Roe v. Wade. The majority opinion, written by Justice Harry Blackmun, spoke specifically to the would-be mother’s predicament:
The detriment that the State would impose upon the pregnant woman by denying this choice altogether is apparent…. Maternity, or additional offspring, may force upon the woman a distressful life and future. Psychological harm may be imminent. Mental and physical health may be taxed by child care. There is also the distress, for all concerned, associated with the unwanted child, and there is the problem of bringing a child into a family already unable, psychologically and otherwise, to care for it.
The Supreme Court gave voice to what the mothers in Romania and Scandinavia—and elsewhere—had long known: when a woman does not want to have a child, she usually has good reason. She may be unmarried or in a bad marriage. She may consider herself too poor to raise a child. She may think her life is too unstable or unhappy, or she may think that her drinking or drug use will damage the baby’s health. She may believe that she is too young or hasn’t yet received enough education. She may want a child badly but in a few years, not now. For any of a hundred reasons, she may feel that she cannot provide a home environment that is conducive to raising a healthy and productive child.
In the first year after Roe v. Wade, some 750,000 women had abortions in the United States (representing one abortion for every 4 live births). By 1980 the number of abortions reached 1.6 million (one for every 2.25 live births), where it leveled off. In a country of 225 million people, 1.6 million abortions per year—one for every 140 Americans—may not have seemed so dramatic. In the first year after Nicolae Ceauşescu’s death, when abortion was reinstated in Romania, there was one abortion for every twenty-two Romanians. But still: 1.6 million American women a year who got pregnant were suddenly not having those babies.
Before Roe v. Wade, it was predominantly the daughters of middle-or upper-class families who could arrange and afford a safe illegal abortion. Now, instead of an illegal procedure that might cost $500, any woman could easily obtain an abortion, often for less than $100.
What sort of woman was most likely to take advantage of Roe v. Wade? Very often she was unmarried or in her teens or poor, and sometimes all three. What sort of future might her child have had? One study has shown that the typical child who went unborn in the earliest years of legalized abortion would have been 50 percent more likely than average to live in poverty; he would have also been 60 percent more likely to grow up with just one parent. These two factors—childhood poverty and a single-parent household—are among the strongest predictors that a child will have a criminal future. Growing up in a single-parent home roughly doubles a child’s propensity to commit crime. So does having a teenage mother. Another study has shown that low maternal education is the single most powerful factor leading to criminality.
In other words, the very factors that drove millions of American women to have an abortion also seemed to predict that their children, had they been born, would have led unhappy and possibly criminal lives.
To be sure, the legalization of abortion in the United States had myriad consequences. Infanticide fell dramatically. So did shotgun marriages, as well as the number of babies put up for adoption (which has led to the boom in the adoption of foreign babies). Conceptions rose by nearly 30 percent, but births actually fell by 6 percent, indicating that many women were using abortion as a method of birth control, a crude and drastic sort of insurance policy.
Perhaps the most dramatic effect of legalized abortion, however, and one that would take years to reveal itself, was its impact on crime. In the early 1990s, just as the first cohort of children born after Roe v. Wade was hitting its late teen years—the years during which young men enter their criminal prime—the rate of crime began to fall. What this cohort was missing, of course, were the children who stood the greatest chance of becoming criminals. And the crime rate continued to fall as an entire generation came of age minus the children whose mothers had not wanted to bring a child into the world. Legalized abortion led to less unwantedness; unwantedness leads to high crime; legalized abortion, therefore, led to less crime.
This theory is bound to provoke a variety of reactions, ranging from disbelief to revulsion, and a variety of objections, ranging from the quotidian to the moral. The likeliest first objection is the most straightforward one: is the theory true? Perhaps abortion and crime are merely correlated and not causal.
It may be more comforting to believe what the newspapers say, that the drop in crime was due to brilliant policing and clever gun control and a surging economy. We have evolved with a tendency to link causality to things we can touch or feel, not to some distant or difficult phenomenon. We believe especially in near-term causes: a snake bites your friend, he screams with pain, and he dies. The snakebite, you conclude, must have killed him. Most of the time, such a reckoning is correct. But when it comes to cause and effect, there is often a trap in such open-and-shut thinking. We smirk now when we think of ancient cultures that embraced faulty causes—the warriors who believed, for instance, that it was their raping of a virgin that brought them victory on the battlefield. But we too embrace faulty causes, usually at the urging of an expert proclaiming a truth in which he has a vested interest.
How, then, can we tell if the abortion-crime link is a case of causality rather than simply correlation?
One way to test the effect of abortion on crime would be to measure crime data in the five states where abortion was made legal before the Supreme Court extended abortion rights to the rest of the country. In New York, California, Washington, Alaska, and Hawaii, a woman had been able to obtain a legal abortion for at least two years before Roe v. Wade. And indeed, those early-legalizing states saw crime begin to fall earlier than the other forty-five states and the District of Columbia. Between 1988 and 1994, violent crime in the early-legalizing states fell 13 percent compared to the other states; between 1994 and 1997, their murder rates fell 23 percent more than those of the other states.
But what if those early legalizers simply got lucky? What else might we look for in the data to establish an abortion-crime link?
One factor to look for would be a correlation between each state’s abortion rate and its crime rate. Sure enough, the states with the highest abortion rates in the 1970s experienced the greatest crime drops in the 1990s, while states with low abortion rates experienced smaller crime drops. (This correlation exists even when controlling for a variety of factors that influence crime: a state’s level of incarceration, number of police, and its economic situation.) Since 1985, states with high abortion rates have experienced a roughly 30 percent drop in crime relative to low-abortion states. (New York City had high abortion rates and lay within an early-legalizing state, a pair of facts that further dampen the claim that innovative policing caused the crime drop.) Moreover, there was no link between a given state’s abortion rate and its crime rate before the late 1980s—when the first cohort affected by legalized abortion was reaching its criminal prime—which is yet another indication that Roe v. Wade was indeed the event that tipped the crime scale.
There are even more correlations, positive and negative, that shore up the abortion-crime link. In states with high abortion rates, the entire decline in crime was among the post-Roe cohort as opposed to older criminals. Also, studies of Australia and Canada have since established a similar link between legalized abortion and crime. And the post-Roe cohort was not only missing thousands of young male criminals but also thousands of single, teenage mothers—for many of the aborted baby girls would have been the children most likely to replicate their own mothers’ tendencies.
To discover that abortion was one of the greatest crime-lowering factors in American history is, needless to say, jarring. It feels less Darwinian than Swiftian; it calls to mind a long-ago dart attributed to G. K. Chesterton: when there aren’t enough hats to go around, the problem isn’t solved by lopping off some heads. The crime drop was, in the language of economists, an “unintended benefit” of legalized abortion. But one need not oppose abortion on moral or religious grounds to feel shaken by the notion of a private sadness being converted into a public good.
Indeed, there are plenty of people who consider abortion itself to be a violent crime. One legal scholar called legalized abortion worse than either slavery (since it routinely involves death) or the Holocaust (since the number of post-Roe abortions in the United States, roughly thirty-seven million as of 2004, outnumber the six million Jews killed in Europe). Whether or not one feels so strongly about abortion, it remains a singularly charged issue. Anthony V. Bouza, a former top police official in both the Bronx and Minneapolis, discovered this when he ran for Minnesota governor in 1994. A few years earlier, Bouza had written a book in which he called abortion “arguably the only effective crime-prevention device adopted in this nation since the late 1960s.” When Bouza’s opinion was publicized just before the election, he fell sharply in the polls. And then he lost.
However a person feels about abortion, a question is likely to come to mind: what are we to make of the trade-off of more abortion for less crime? Is it even possible to put a number on such a complicated transaction?
As it happens, economists have a curious habit of affixing numbers to complicated transactions. Consider the effort to save the northern spotted owl from extinction. One economic study found that in order to protect roughly five thousand owls, the opportunity costs—that is, the income surrendered by the logging industry and others—would be $46 billion, or just over $9 million per owl. After the Exxon Valdez oil spill in 1989, another study estimated the amount that the typical American household would be willing to pay to avoid another such disaster: $31. An economist can affix a value even to a particular body part. Consider the schedule that the state of Connecticut uses to compensate for work-related injuries.



Now, for the sake of argument, let’s ask an outrageous question: what is the relative value of a fetus and a newborn? If faced with the Solomonic task of sacrificing the life of one newborn for an indeterminate number of fetuses, what number might you choose? This is nothing but a thought exercise—obviously there is no right answer—but it may help clarify the impact of abortion on crime.
For a person who is either resolutely pro-life or resolutely pro-choice, this is a simple calculation. The first, believing that life begins at conception, would likely consider the value of a fetus versus the value of a newborn to be 1:1. The second person, believing that a woman’s right to an abortion trumps any other factor, would likely argue that no number of fetuses can equal even one newborn.
But let’s consider a third person. (If you identify strongly with either person number one or person number two, the following exercise might strike you as offensive, and you may want to skip this paragraph and the next.) This third person does not believe that a fetus is the 1:1 equivalent of a newborn, yet neither does he believe that a fetus has no relative value. Let’s say that he is forced, for the sake of argument, to affix a relative value, and he decides that 1 newborn is worth 100 fetuses.
There are roughly 1.5 million abortions in the United States every year. For a person who believes that 1 newborn is worth 100 fetuses, those 1.5 million abortions would translate—dividing 1.5 million by 100—into the equivalent of a loss of 15,000 human lives. Fifteen thousand lives: that happens to be about the same number of people who die in homicides in the United States every year. And it is far more than the number of homicides eliminated each year due to legalized abortion. So even for someone who considers a fetus to be worth only one one-hundredth of a human being, the trade-off between higher abortion and lower crime is, by an economist’s reckoning, terribly inefficient.
What the link between abortion and crime does say is this: when the government gives a woman the opportunity to make her own decision about abortion, she generally does a good job of figuring out if she is in a position to raise the baby well. If she decides she can’t, she often chooses the abortion.
But once a woman decides she will have her baby, a pressing question arises: what are parents supposed to do once a child is born?


5
What Makes a Perfect Parent?
Has there ever been another art so devoutly converted into a science as the art of parenting?
Over the recent decades, a vast and diverse flock of parenting experts has arisen. Anyone who tries even casually to follow their advice may be stymied, for the conventional wisdom on parenting seems to shift by the hour. Sometimes it is a case of one expert differing from another. At other times the most vocal experts suddenly agree en masse that the old wisdom was wrong and that the new wisdom is, for a little while at least, irrefutably right. Breast feeding, for example, is the only way to guarantee a healthy and intellectually advanced child—unless bottle feeding is the answer. A baby should always be put to sleep on her back—until it is decreed that she should only be put to sleep on her stomach. Eating liver is either a) toxic or b) imperative for brain development. Spare the rod and spoil the child; spank the child and go to jail.
In her book Raising America: Experts, Parents, and a Century of Advice About Children, Ann Hulbert documented how parenting experts contradict one another and even themselves. Their banter might be hilarious were it not so confounding and, often, scary. Gary Ezzo, who in the Babywise book series endorses an “infant-management strategy” for moms and dads trying to “achieve excellence in parenting,” stresses how important it is to train a baby, early on, to sleep alone through the night. Otherwise, Ezzo warns, sleep deprivation might “negatively impact an infant’s developing central nervous system” and lead to learning disabilities. Advocates of “co-sleeping,” meanwhile, warn that sleeping alone is harmful to a baby’s psyche and that he should be brought into the “family bed.” What about stimulation? In 1983 T. Berry Brazelton wrote that a baby arrives in the world “beautifully prepared for the role of learning about him-or herself and the world all around.” Brazelton favored early, ardent stimulation—an “interactive” child. One hundred years earlier, however, L. Emmett Holt cautioned that a baby is not a “plaything.” There should be “no forcing, no pressure, no undue stimulation” during the first two years of a child’s life, Holt believed; the brain is growing so much during that time that overstimulation might cause “a great deal of harm.” He also believed that a crying baby should never be picked up unless it is in pain. As Holt explained, a baby should be left to cry for fifteen to thirty minutes a day: “It is the baby’s exercise.”
The typical parenting expert, like experts in other fields, is prone to sound exceedingly sure of himself. An expert doesn’t so much argue the various sides of an issue as plant his flag firmly on one side. That’s because an expert whose argument reeks of restraint or nuance often doesn’t get much attention. An expert must be bold if he hopes to alchemize his homespun theory into conventional wisdom. His best chance of doing so is to engage the public’s emotions, for emotion is the enemy of rational argument. And as emotions go, one of them—fear—is more potent than the rest. The superpredator, Iraqi weapons of mass destruction, mad-cow disease, crib death: how can we fail to heed the expert’s advice on these horrors when, like that mean uncle telling too-scary stories to too-young children, he has reduced us to quivers?
No one is more susceptible to an expert’s fearmongering than a parent. Fear is in fact a major component of the act of parenting. A parent, after all, is the steward of another creature’s life, a creature who in the beginning is more helpless than the newborn of nearly any other species. This leads a lot of parents to spend a lot of their parenting energy simply being scared.
The problem is that they are often scared of the wrong things. It’s not their fault, really. Separating facts from rumors is always hard work, especially for a busy parent. And the white noise generated by the experts—to say nothing of the pressure exerted by fellow parents—is so overwhelming that they can barely think for themselves. The facts they do manage to glean have usually been varnished or exaggerated or otherwise taken out of context to serve an agenda that isn’t their own.
Consider the parents of an eight-year-old girl named, say, Molly. Her two best friends, Amy and Imani, each live nearby. Molly’s parents know that Amy’s parents keep a gun in their house, so they have forbidden Molly to play there. Instead, Molly spends a lot of time at Imani’s house, which has a swimming pool in the backyard. Molly’s parents feel good about having made such a smart choice to protect their daughter.
But according to the data, their choice isn’t smart at all. In a given year, there is one drowning of a child for every 11,000 residential pools in the United States. (In a country with 6 million pools, this means that roughly 550 children under the age of ten drown each year.) Meanwhile, there is 1 child killed by a gun for every 1 million-plus guns. (In a country with an estimated 200 million guns, this means that roughly 175 children under ten die each year from guns.) The likelihood of death by pool (1 in 11,000) versus death by gun (1 in 1 million-plus) isn’t even close: Molly is far more likely to die in a swimming accident at Imani’s house than in gunplay at Amy’s.
But most of us are, like Molly’s parents, terrible risk assessors. Peter Sandman, a self-described “risk communications consultant” in Princeton, New Jersey, made this point in early 2004 after a single case of mad-cow disease in the United States prompted an antibeef frenzy. “The basic reality,” Sandman told the New York Times, “is that the risks that scare people and the risks that kill people are very different.”
Sandman offered a comparison between mad-cow disease (a superscary but exceedingly rare threat) and the spread of food-borne pathogens in the average home kitchen (exceedingly common but somehow not very scary). “Risks that you control are much less a source of outrage than risks that are out of your control,” Sandman said. “In the case of mad-cow, it feels like it’s beyond my control. I can’t tell if my meat has prions in it or not. I can’t see it, I can’t smell it. Whereas dirt in my own kitchen is very much in my own control. I can clean my sponges. I can clean the floor.”
Sandman’s “control” principle might also explain why most people are more scared of flying in an airplane than driving a car. Their thinking goes like this: since I control the car, I am the one keeping myself safe; since I have no control of the airplane, I am at the mercy of myriad external factors.
So which should we actually fear more, flying or driving?
It might first help to ask a more basic question: what, exactly, are we afraid of? Death, presumably. But the fear of death needs to be narrowed down. Of course we all know that we are bound to die, and we might worry about it casually. But if you are told that you have a 10 percent chance of dying within the next year, you might worry a lot more, perhaps even choosing to live your life differently. And if you are told that you have 10 percent chance of dying within the next minute, you’ll probably panic. So it’s the imminent possibility of death that drives the fear—which means that the most sensible way to calculate fear of death would be to think about it on a per-hour basis.
If you are taking a trip and have the choice of driving or flying, you might wish to consider the per-hour death rate of driving versus flying. It is true that many more people die in the United States each year in motor vehicle accidents (roughly forty thousand) than in airplane crashes (fewer than one thousand). But it’s also true that most people spend a lot more time in cars than in airplanes. (More people die even in boating accidents each year than in airplane crashes; as we saw with swimming pools versus guns, water is a lot more dangerous than most people think.) The per-hour death rate of driving versus flying, however, is about equal. The two contraptions are equally likely (or, in truth, unlikely) to lead to death.
But fear best thrives in the present tense. That is why experts rely on it; in a world that is increasingly impatient with long-term processes, fear is a potent short-term play. Imagine that you are a government official charged with procuring the funds to fight one of two proven killers: terrorist attacks and heart disease. Which cause do you think the members of Congress will open up the coffers for? The likelihood of any given person being killed in a terrorist attack is far smaller than the likelihood that the same person will clog up his arteries with fatty food and die of heart disease. But a terrorist attack happens now; death by heart disease is some distant, quiet catastrophe. Terrorist acts lie beyond our control; french fries do not. Just as important as the control factor is what Peter Sandman calls the dread factor. Death by terrorist attack (or mad-cow disease) is considered wholly dreadful; death by heart disease is, for some reason, not.
Sandman is an expert who works both sides of the aisle. One day he might help a group of environmentalists expose a public health hazard. His client the next day could be a fast-food CEO trying to deal with an E. coli outbreak. Sandman has reduced his expertise to a tidy equation: Risk = hazard + outrage. For the CEO with the bad hamburger meat, Sandman engages in “outrage reduction” for the environmentalists, it’s “outrage increase.”
Note that Sandman addresses the outrage but not the hazard itself. He concedes that outrage and hazard do not carry equal weight in his risk equation. “When hazard is high and outrage is low, people underreact,” he says. “And when hazard is low and outrage is high, they overreact.”
So why is a swimming pool less frightening than a gun? The thought of a child being shot through the chest with a neighbor’s gun is gruesome, dramatic, horrifying—in a word, outrageous. Swimming pools do not inspire outrage. This is due in part to the familiarity factor. Just as most people spend more time in cars than in airplanes, most of us have a lot more experience swimming in pools than shooting guns. But it takes only about thirty seconds for a child to drown, and it often happens noiselessly. An infant can drown in water as shallow as a few inches. The steps to prevent drowning, meanwhile, are pretty straightforward: a watchful adult, a fence around the pool, a locked back door so a toddler doesn’t slip outside unnoticed.
If every parent followed these precautions, the lives of perhaps four hundred young children could be saved each year. That would outnumber the lives saved by two of the most widely promoted inventions in recent memory: safer cribs and child car seats. The data show that car seats are, at best, nominally helpful. It is certainly safer to keep a child in the rear seat than sitting on a lap in the front seat, where in the event of an accident he essentially becomes a projectile. But the safety to be gained here is from preventing the kids from riding shotgun, not from strapping them into a $200 car seat. Nevertheless, many parents so magnify the benefit of a car seat that they trek to the local police station or firehouse to have it installed just right. Theirs is a gesture of love, surely, but also a gesture of what might be called obsessive parenting. (Obsessive parents know who they are and are generally proud of the fact; non-obsessive parents also know who the obsessives are and tend to snicker at them.)
Most innovations in the field of child safety are affiliated with—shock of shocks—a new product to be marketed. (Nearly five million car seats are sold each year.) These products are often a response to some growing scare in which, as Peter Sandman might put it, the outrage outweighs the hazard. Compare the four hundred lives that a few swimming pool precautions might save to the number of lives saved by far noisier crusades: child-resistant packaging (an estimated fifty lives a year), flame-retardant pajamas (ten lives), keeping children away from airbags in cars (fewer than five young children a year have been killed by airbags since their introduction), and safety drawstrings on children’s clothing (two lives).
Hold on a minute, you say. What does it matter if parents are manipulated by experts and marketers? Shouldn’t we applaud any effort, regardless of how minor or manipulative, that makes even one child safer? Don’t parents already have enough to worry about? After all, parents are responsible for one of the most awesomely important feats we know: the very shaping of a child’s character. Aren’t they?
 
The most radical shift of late in the conventional wisdom on parenting has been provoked by one simple question: how much do parents really matter?
Clearly, bad parenting matters a great deal. As the link between abortion and crime makes clear, unwanted children—who are disproportionately subject to neglect and abuse—have worse outcomes than children who were eagerly welcomed by their parents. But how much can those eager parents actually accomplish for their children’s sake?
This question represents a crescendo of decades’ worth of research. A long line of studies, including research into twins who were separated at birth, had already concluded that genes alone are responsible for perhaps 50 percent of a child’s personality and abilities.
So if nature accounts for half of a child’s destiny, what accounts for the other half? Surely it must be the nurturing—the Baby Mozart tapes, the church sermons, the museum trips, the French lessons, the bargaining and hugging and quarreling and punishing that, in toto, constitute the act of parenting. But how then to explain another famous study, the Colorado Adoption Project, which followed the lives of 245 babies put up for adoption and found virtually no correlation between the child’s personality traits and those of his adopted parents? Or the other studies showing that a child’s character wasn’t much affected whether or not he was sent to day care, whether he had one parent or two, whether his mother worked or didn’t, whether he had two mommies or two daddies or one of each?
These nature-nurture discrepancies were addressed in a 1998 book by a little-known textbook author named Judith Rich Harris. The Nurture Assumption was in effect an attack on obsessive parenting, a book so provocative that it required two subtitles: Why Children Turn Out the Way They Do and Parents Matter Less than You Think and Peers Matter More. Harris argued, albeit gently, that parents are wrong to think they contribute so mightily to their child’s personality. This belief, she wrote, was a “cultural myth.” Harris argued that the top-down influence of parents is overwhelmed by the grassroots effect of peer pressure, the blunt force applied each day by friends and schoolmates.
The unlikeliness of Harris’s bombshell—she was a grandmother, no less, without PhD or academic affiliation—prompted both wonder and chagrin. “The public may be forgiven for saying, ‘Here we go again,’” wrote one reviewer. “One year we’re told bonding is the key, the next that it’s birth order. Wait, what really matters is stimulation. The first five years of life are the most important; no, the first three years; no, it’s all over by the first year. Forget that: It’s all genetics!”
But Harris’s theory was duly endorsed by a slate of heavyweights. Among them was Steven Pinker, the cognitive psychologist and bestselling author, who in his own book Blank Slate called Harris’s views “mind-boggling” (in a good way). “Patients in traditional forms of psychotherapy while away their fifty minutes reliving childhood conflicts and learning to blame their unhappiness on how their parents treated them,” Pinker wrote. “Many biographies scavenge through the subject’s childhood for the roots of the grown-up’s tragedies and triumphs. ‘Parenting experts’ make women feel like ogres if they slip out of the house to work or skip a reading of Goodnight Moon. All these deeply held beliefs will have to be rethought.”
Or will they? Parents must matter, you tell yourself. Besides, even if peers exert so much influence on a child, isn’t it the parents who essentially choose a child’s peers? Isn’t that why parents agonize over the right neighborhood, the right school, the right circle of friends?
Still, the question of how much parents matter is a good one. It is also terribly complicated. In determining a parent’s influence, which dimension of the child are we measuring: his personality? his school grades? his moral behavior? his creative abilities? his salary as an adult? And what weight should we assign each of the many inputs that affect a child’s outcome: genes, family environment, socioeconomic level, schooling, discrimination, luck, illness, and so on?
For the sake of argument, let’s consider the story of two boys, one white and one black.
The white boy is raised in a Chicago suburb by parents who read widely and involve themselves in school reform. His father, who has a decent manufacturing job, often takes the boy on nature hikes. His mother is a housewife who will eventually go back to college and earn a bachelor’s degree in education. The boy is happy and performs very well in school. His teachers think he may be a bona fide math genius. His parents encourage him and are terribly proud when he skips a grade. He has an adoring younger brother who is also very bright. The family even holds literary salons in their home.
The black boy is born in Daytona Beach, Florida, and his mother abandons him at the age of two. His father has a good job in sales but is a heavy drinker. He often beats the little boy with the metal end of a garden hose. One night when the boy is eleven, he is decorating a tabletop Christmas tree—the first one he has ever had—when his father starts beating up a lady friend in the kitchen. He hits her so hard that some teeth fly out of her mouth and land at the base of the boy’s Christmas tree, but the boy knows better than to speak up. At school he makes no effort whatsoever. Before long he is selling drugs, mugging suburbanites, carrying a gun. He makes sure to be asleep by the time his father comes home from drinking, and to be out of the house before his father awakes. The father eventually goes to jail for sexual assault. By the age of twelve, the boy is essentially fending for himself.
You don’t have to believe in obsessive parenting to think that the second boy doesn’t stand a chance and that the first boy has it made. What are the odds that the second boy, with the added handicap of racial discrimination, will turn out to lead a productive life? What are the odds that the first boy, so deftly primed for success, will somehow fail? And how much of his fate should each boy attribute to his parents?
 
One could theorize forever about what makes the perfect parent. For two reasons, the authors of this book will not do so. The first is that neither of us professes to be a parenting expert (although between us we do have six children under the age of five). The second is that we are less persuaded by parenting theory than by what the data have to say.
Certain facets of a child’s outcome—personality, for instance, or creativity—are not easily measured by data. But school performance is. And since most parents would agree that education lies at the core of a child’s formation, it would make sense to begin by examining a telling set of school data.
These data concern school choice, an issue that most people feel strongly about in one direction or another. True believers of school choice argue that their tax dollars buy them the right to send their children to the best school possible. Critics worry that school choice will leave behind the worst students in the worst schools. Still, just about every parent seems to believe that her child will thrive if only he can attend the right school, the one with an appropriate blend of academics, extracurriculars, friendliness, and safety.
School choice came early to the Chicago Public School system. That’s because the CPS, like most urban school districts, had a disproportionate number of minority students. Despite the U.S. Supreme Court’s 1954 ruling in Brown v. Board of Education of Topeka, which dictated that schools be desegregated, many black CPS students continued to attend schools that were nearly all-black. So in 1980 the U.S. Department of Justice and the Chicago Board of Education teamed up to try to better integrate the city’s schools. It was decreed that incoming freshmen could apply to virtually any high school in the district.
Aside from its longevity, there are several reasons the CPS school-choice program is a good one to study. It offers a huge data set—Chicago has the third-largest school system in the country, after New York and Los Angeles—as well as an enormous amount of choice (more than sixty high schools) and flexibility. Its take-up rates are accordingly very high, with roughly half of the CPS students opting out of their neighborhood school. But the most serendipitous aspect of the CPS program—for the sake of a study, at least—is how the school-choice game was played.
As might be expected, throwing open the doors of any school to every freshman in Chicago threatened to create bedlam. The schools with good test scores and high graduation rates would be rabidly oversubscribed, making it impossible to satisfy every student’s request.
In the interest of fairness, the CPS resorted to a lottery. For a researcher, this is a remarkable boon. A behavioral scientist could hardly design a better experiment in his laboratory. Just as the scientist might randomly assign one mouse to a treatment group and another to a control group, the Chicago school board effectively did the same. Imagine two students, statistically identical, each of whom wants to attend a new, better school. Thanks to how the ball bounces in the hopper, one student goes to the new school and the other stays behind. Now imagine multiplying those students by the thousands. The result is a natural experiment on a grand scale. This was hardly the goal in the mind of the Chicago school officials who conceived the lottery. But when viewed in this way, the lottery offers a wonderful means of measuring just how much school choice—or, really, a better school—truly matters.
So what do the data reveal?
The answer will not be heartening to obsessive parents: in this case, school choice barely mattered at all. It is true that the Chicago students who entered the school-choice lottery were more likely to graduate than the students who didn’t—which seems to suggest that school choice does make a difference. But that’s an illusion. The proof is in this comparison: the students who won the lottery and went to a “better” school did no better than equivalent students who lost the lottery and were left behind. That is, a student who opted out of his neighborhood school was more likely to graduate whether or not he actually won the opportunity to go to a new school. What appears to be an advantage gained by going to a new school isn’t connected to the new school at all. What this means is that the students—and parents—who choose to opt out tend to be smarter and more academically motivated to begin with. But statistically, they gained no academic benefit by changing schools.
And is it true that the students left behind in neighborhood schools suffered? No: they continued to test at about the same levels as before the supposed brain drain.
There was, however, one group of students in Chicago who did see a dramatic change: those who entered a technical school or career academy. These students performed substantially better than they did in their old academic settings and graduated at a much higher rate than their past performance would have predicted. So the CPS school-choice program did help prepare a small segment of otherwise struggling students for solid careers by giving them practical skills. But it doesn’t appear that it made anyone much smarter.
Could it really be that school choice doesn’t much matter? No self-respecting parent, obsessive or otherwise, is ready to believe that. But wait: maybe it’s because the CPS study measures high-school students; maybe by then the die has already been cast. “There are too many students who arrive at high school not prepared to do high school work,” Richard P. Mills, the education commissioner of New York State, noted recently, “too many students who arrive at high school reading, writing, and doing math at the elementary level. We have to correct the problem in the earlier grades.”
Indeed, academic studies have substantiated Mills’s anxiety. In examining the income gap between black and white adults—it is well established that blacks earn significantly less—scholars have found that the gap is virtually eradicated if the blacks’ lower eighth-grade test scores are taken into account. In other words, the black-white income gap is largely a product of a black-white education gap that could have been observed many years earlier. “Reducing the black-white test score gap,” wrote the authors of one study, “would do more to promote racial equality than any other strategy that commands broad political support.”
So where does that black-white test gap come from? Many theories have been put forth over the years: poverty, genetic makeup, the “summer setback” phenomenon (blacks are thought to lose more ground than whites when school is out of session), racial bias in testing or in teachers’ perceptions, and a black backlash against “acting white.”
In a paper called “The Economics of ‘Acting White,’” the young black Harvard economist Roland G. Fryer Jr. argues that some black students “have tremendous disincentives to invest in particular behaviors (i.e., education, ballet, etc.) due to the fact that they may be deemed a person who is trying to act like a white person (a.k.a. ‘selling-out’). Such a label, in some neighborhoods, can carry penalties that range from being deemed a social outcast, to being beaten or killed.” Fryer cites the recollections of a young Kareem Abdul-Jabbar, known then as Lew Alcindor, who had just entered the fourth grade in a new school and discovered that he was a better reader than even the seventh graders: “When the kids found this out, I became a target….It was my first time away from home, my first experiencein an all-black situation, and I found myself being punished for everything I’d ever been taught was right. I got all A’s and was hated for it; I spoke correctly and was called a punk. I had to learn a new language simply to be able to deal with the threats. I had good manners and was a good little boy and paid for it with my hide.”
Fryer is also one of the authors of “Understanding the Black-White Test Score Gap in the First Two Years of School.” This paper takes advantage of a new trove of government data that helps reliably address the black-white gap. Perhaps more interestingly, the data do a nice job of answering the question that every parent—black, white, and otherwise—wants to ask: what are the factors that do and do not affect a child’s performance in the early school years?
 
In the late 1990s, the U.S. Department of Education undertook a monumental project called the Early Childhood Longitudinal Study. The ECLS sought to measure the academic progress of more than twenty thousand children from kindergarten through the fifth grade. The subjects were chosen from across the country to represent an accurate cross section of American schoolchildren.
The ECLS measured the students’ academic performance and gathered typical survey information about each child: his or her race, gender, family structure, socioeconomic status, the level of his or her parents’ education, and so on. But the study went well beyond these basics. It also included interviews with the students’ parents (and teachers and school administrators), posing a long list of questions more intimate than those in the typical government interview: whether the parents spanked their children, and how often; whether they took them to libraries or museums; how much television the children watched.
The result is an incredibly rich set of data—which, if the right questions are asked of it, tells some surprising stories.
How can this type of data be made to tell a reliable story? By subjecting it to the economist’s favorite trick: regression analysis. No, regression analysis is not some forgotten form of psychiatric treatment. It is a powerful—if limited—tool that uses statistical techniques to identify otherwise elusive correlations.
Correlation is nothing more than a statistical term that indicates whether two variables move together. It tends to be cold outside when it snows; those two factors are positively correlated. Sunshine and rain, meanwhile, are negatively correlated. Easy enough—as long as there are only a couple of variables. But with a couple of hundred variables, things get harder. Regression analysis is the tool that enables an economist to sort out these huge piles of data. It does so by artificially holding constant every variable except the two he wishes to focus on, and then showing how those two co-vary.
In a perfect world, an economist could run a controlled experiment just as a physicist or a biologist does: setting up two samples, randomly manipulating one of them, and measuring the effect. But an economist rarely has the luxury of such pure experimentation. (That’s why the school-choice lottery in Chicago was such a happy accident.) What an economist typically has is a data set with a great many variables, none of them randomly generated, some related and others not. From this jumble, he must determine which factors are correlated and which are not.
In the case of the ECLS data, it might help to think of regression analysis as performing the following task: converting each of those twenty thousand schoolchildren into a sort of circuit board with an identical number of switches. Each switch represents a single category of the child’s data: his first-grade math score, his third-grade math score, his first-grade reading score, his third-grade reading score, his mother’s education level, his father’s income, the number of books in his home, the relative affluence of his neighborhood, and so on.
Now a researcher is able to tease some insights from this very complicated set of data. He can line up all the children who share many characteristics—all the circuit boards that have their switches flipped the same direction—and then pinpoint the single characteristic they don’t share. This is how he isolates the true impact of that single switch on the sprawling circuit board. This is how the effect of that switch—and, eventually, of every switch—becomes manifest.
Let’s say that we want to ask the ECLS data a fundamental question about parenting and education: does having a lot of books in your home lead your child to do well in school? Regression analysis can’t quite answer that question, but it can answer a subtly different one: does a child with a lot of books in his home tend to do better than a child with no books? The difference between the first and second questions is the difference between causality (question 1) and correlation (question 2). A regression analysis can demonstrate correlation, but it doesn’t prove cause. After all, there are several ways in which two variables can be correlated. X can cause Y; Y can cause X; or it may be that some other factor is causing both X and Y. A regression alone can’t tell you whether it snows because it’s cold, whether it’s cold because it snows, or if the two just happen to go together.
The ECLS data do show, for instance, that a child with a lot of books in his home tends to test higher than a child with no books. So those factors are correlated, and that’s nice to know. But higher test scores are correlated with many other factors as well. If you simply measure children with a lot of books against children with no books, the answer may not be very meaningful. Perhaps the number of books in a child’s home merely indicates how much money his parents make. What we really want to do is measure two children who are alike in every way except one—in this case, the number of books in their homes—and see if that one factor makes a difference in their school performance.
It should be said that regression analysis is more art than science. (In this regard, it has a great deal in common with parenting itself.) But a skilled practitioner can use it to tell how meaningful a correlation is—and maybe even tell whether that correlation does indicate a causal relationship.
So what does an analysis of the ECLS data tell us about schoolchildren’s performance? A number of things. The first one concerns the black-white test score gap.
It has long been observed that black children, even before they set foot in a classroom, underperform their white counterparts. Moreover, black children didn’t measure up even when controlling for a wide array of variables. (To control for a variable is essentially to eliminate its influence, much as one golfer uses a handicap against another. In the case of an academic study such as the ECLS, a researcher might control for any number of disadvantages that one student might carry when measured against the average student.) But this new data set tells a different story. After controlling for just a few variables—including the income and education level of the child’s parents and the mother’s age at the birth of her first child—the gap between black and white children is virtually eliminated at the time the children enter school.
This is an encouraging finding on two fronts. It means that young black children have continued to make gains relative to their white counterparts. It also means that whatever gap remains can be linked to a handful of readily identifiable factors. The data reveal that black children who perform poorly in school do so not because they are black but because a black child is more likely to come from a low-income, low-education household. A typical black child and white child from the same socioeconomic background, however, have the same abilities in math and reading upon entering kindergarten.
Great news, right? Well, not so fast. First of all, because the average black child is more likely to come from a low-income, low-education household, the gap is very real: on average, black children still are scoring worse. Worse yet, even when the parents’ income and education are controlled for, the black-white gap reappears within just two years of a child’s entering school. By the end of first grade, a black child is underperforming a statistically equivalent white child. And the gap steadily grows over the second and third grades.
Why does this happen? That’s a hard, complicated question. But one answer may lie in the fact that the school attended by the typical black child is not the same school attended by the typical white child, and the typical black child goes to a school that is simply…bad. Even fifty years after Brown v. Board, many American schools are virtually segregated. The ECLS project surveyed roughly one thousand schools, taking samples of twenty children from each. In 35 percent of those schools, not a single black child was included in the sample. The typical white child in the ECLS study attends a school that is only 6 percent black; the typical black child, meanwhile, attends a school that is about 60 percent black.
Just how are the black schools bad? Not, interestingly, in the ways that schools are traditionally measured. In terms of class size, teachers’ education, and computer-to-student ratio, the schools attended by blacks and whites are similar. But the typical black student’s school has a far higher rate of troublesome indicators, such as gang problems, nonstudents loitering in front of the school, and lack of PTA funding. These schools offer an environment that is simply not conducive to learning.
Black students are hardly the only ones who suffer in bad schools. White children in these schools also perform poorly. In fact, there is essentially no black-white test score gap within a bad school in the early years once you control for students’ backgrounds. But all students in a bad school, black and white, do lose ground to students in good schools. Perhaps educators and researchers are wrong to be so hung up on the black-white test score gap; the bad-school/good-school gap may be the more salient issue. Consider this fact: the ECLS data reveal that black students in good schools don’t lose ground to their white counterparts, and black students in good schools outperform whites in poor schools.
So according to these data, a child’s school does seem to have a clear impact on his academic progress, at least in the early years. Can the same be said for parenting? Did all those Baby Mozart tapes pay off? What about those marathon readings of Goodnight Moon? Was the move to the suburbs worthwhile? Do the kids with PTA parents do better than the kids whose parents have never heard of the PTA?
 
The wide-ranging ECLS data offer a number of compelling correlations between a child’s personal circumstances and his school performance. For instance, once all other factors are controlled for, it is clear that students from rural areas tend to do worse than average. Suburban children, meanwhile, are in the middle of the curve, while urban children tend to score higher than average. (It may be that cities attract a more educated workforce and, therefore, parents with smarter children.) On average, girls test higher than boys, and Asians test higher than whites—although blacks, as we have already established, test similarly to whites from comparable backgrounds and in comparable schools.
Knowing what you now know about regression analysis, conventional wisdom, and the art of parenting, consider the following list of sixteen factors. According to the ECLS data, eight of the factors show a strong correlation—positive or negative—with test scores. The other eight don’t seem to matter. Feel free to guess which are which. Keep in mind that these results reflect only a child’s early test scores, a useful but fairly narrow measurement; poor testing in early childhood isn’t necessarily a great harbinger of future earnings, creativity, or happiness.
 
The child has highly educated parents.
The child’s family is intact.
The child’s parents have high socioeconomic status.
The child’s parents recently moved into a better neighborhood.
The child’s mother was thirty or older at the time of her first child’s birth.
The child’s mother didn’t work between birth and kindergarten.
The child had low birthweight.
The child attended Head Start.
The child’s parents speak English in the home.
The child’s parents regularly take him to museums.
The child is adopted.
The child is regularly spanked.
The child’s parents are involved in the PTA.
The child frequently watches television.
The child has many books in his home.
The child’s parents read to him nearly every day.
 
Here now are the eight factors that are strongly correlated with test scores:
 
The child has highly educated parents.
The child’s parents have high socioeconomic status.
The child’s mother was thirty or older at the time of her first child’s birth.
The child had low birthweight.
The child’s parents speak English in the home.
The child is adopted.
The child’s parents are involved in the PTA.
The child has many books in his home.
 
And the eight that aren’t:
 
The child’s family is intact.
The child’s parents recently moved into a better neighborhood.
The child’s mother didn’t work between birth and kindergarten.
The child attended Head Start.
The child’s parents regularly take him to museums.
The child is regularly spanked.
The child frequently watches television.
The child’s parents read to him nearly every day.
 
Now, two by two:
Matters: The child has highly educated parents.
Doesn’t: The child’s family is intact.
A child whose parents are highly educated typically does well in school; not much surprise there. A family with a lot of schooling tends to value schooling. Perhaps more important, parents with higher IQs tend to get more education, and IQ is strongly hereditary. But whether a child’s family is intact doesn’t seem to matter. Just as the earlier-cited studies show that family structure has little impact on a child’s personality, it does not seem to affect his academic abilities either, at least in the early years. This is not to say that families ought to go around splitting up willy-nilly. It should, however, offer encouragement to the roughly twenty million American schoolchildren being raised by a single parent.
Matters: The child’s parents have high socioeconomic status.
Doesn’t: The child’s parents recently moved into a better neighborhood.
A high socioeconomic status is strongly correlated to higher test scores, which seems sensible. Socioeconomic status is a strong indicator of success in general—it suggests a higher IQ and more education—and successful parents are more likely to have successful children. But moving to a better neighborhood doesn’t improve a child’s chances in school. It may be that moving itself is a disruptive force; more likely, it’s because a nicer house doesn’t improve math or reading scores any more than nicer sneakers make you jump higher.
Matters: The child’s mother was thirty or older at the time of her first child’s birth.
Doesn’t: The child’s mother didn’t work between birth and kindergarten.
A woman who doesn’t have her first child until she is at least thirty is likely to see that child do well in school. This mother tends to be a woman who wanted to get some advanced education or develop traction in her career. She is also likely to want a child more than a teenage mother wants a child. This doesn’t mean that an older first-time mother is necessarily a better mother, but she has put herself—and her children—in a more advantageous position. (It is worth noting that this advantage is nonexistent for a teenage mother who waits until she is thirty to have her second child. The ECLS data show that her second child will perform no better than her first.) At the same time, a mother who stays home from work until her child goes to kindergarten does not seem to provide any advantage. Obsessive parents might find this lack of correlation bothersome—what was the point of all those Mommy and Me classes?—but that is what the data tell us.
Matters: The child had low birthweight.
Doesn’t: The child attended Head Start.
A child who had a low birthweight tends to do poorly in school. It may be that being born prematurely is simply hurtful to a child’s overall well-being. It may also be that low birthweight is a strong forecaster of poor parenting, since a mother who smokes or drinks or otherwise mistreats her baby in utero isn’t likely to turn things around just because the baby is born. A low-birthweight child, in turn, is more likely to be a poor child—and, therefore, more likely to attend Head Start, the federal preschool program. But according to the ECLS data, Head Start does nothing for a child’s future test scores. Despite a deep reservoir of appreciation for Head Start (one of this book’s authors was a charter student), we must acknowledge that it has repeatedly been proven ineffectual in the long term. Here’s a likely reason: instead of spending the day with his own undereducated, overworked mother, the typical Head Start child spends the day with someone else’s undereducated, overworked mother. (And a whole roomful of similarly needy children.) As it happens, fewer than 30 percent of Head Start teachers have even a bachelor’s degree. And the job pays so poorly—about $21,000 for a Head Start teacher versus $40,000 for the average public-school kindergarten teacher—that it is unlikely to attract better teachers any time soon.
Matters: The child’s parents speak English in the home.
Doesn’t: The child’s parents regularly take him to museums.
A child with English-speaking parents does better in school than one whose parents don’t speak English. Again, not much of a surprise. This correlation is further supported by the performance of Hispanic students in the ECLS study. As a group, Hispanic students test poorly; they are also disproportionately likely to have non-English-speaking parents. (They do, however, tend to catch up with their peers in later grades.) So how about the opposite case: what if a mother and father are not only proficient in English but spend their weekends broadening their child’s cultural horizons by taking him to museums? Sorry. Culture cramming may be a foundational belief of obsessive parenting, but the ECLS data show no correlation between museum visits and test scores.
Matters: The child is adopted.
Doesn’t: The child is regularly spanked.
There is a strong correlation—a negative one—between adoption and school test scores. Why? Studies have shown that a child’s academic abilities are far more influenced by the IQs of his biological parents than the IQs of his adoptive parents, and mothers who offer up their children for adoption tend to have significantly lower IQs than the people who are doing the adopting. There is another explanation for low-achieving adoptees which, though it may seem distasteful, jibes with the basic economic theory of self-interest: a woman who knows she will offer her baby for adoption may not take the same prenatal care as a woman who is keeping her baby. (Consider—at the risk of furthering the distasteful thinking—how you treat a car you own versus a car you are renting for the weekend.)
But if an adopted child is prone to lower test scores, a spanked child is not. This may seem surprising—not because spanking itself is necessarily detrimental but because, conventionally speaking, spanking is considered an unenlightened practice. We might therefore assume that parents who spank are unenlightened in other ways. Perhaps that isn’t the case at all. Or perhaps there is a different spanking story to be told. Remember, the ECLS survey included direct interviews with the children’s parents. So a parent would have to sit knee to knee with a government researcher and admit to spanking his child. This would suggest that a parent who does so is either unenlightened or—more interestingly—congenitally honest. It may be that honesty is more important to good parenting than spanking is to bad parenting.
Matters: The child’s parents are involved in the PTA.
Doesn’t: The child frequently watches television.
A child whose parents are involved in the PTA tends to do well in school—which probably indicates that parents with a strong relationship to education get involved in the PTA, not that their PTA involvement somehow makes their children smarter. The ECLS data show no correlation, meanwhile, between a child’s test scores and the amount of television he watches. Despite the conventional wisdom, watching television apparently does not turn a child’s brain to mush. (In Finland, whose education system has been ranked the world’s best, most children do not begin school until age seven but have often learned to read on their own by watching American television with Finnish subtitles.) Nor, however, does using a computer at home turn a child into Einstein: the ECLS data show no correlation between computer use and school test scores.
 
Now for the final pair of factors:
Matters: The child has many books in his home.
Doesn’t: The child’s parents read to him nearly every day.
As noted earlier, a child with many books in his home has indeed been found to do well on school tests. But regularly reading to a child doesn’t affect early childhood test scores.
This would seem to present a riddle. It bounces us back to our original question: just how much, and in what ways, do parents really matter?
Let’s start with the positive correlation: books in the home equal higher test scores. Most people would look at this correlation and infer an obvious cause-and-effect relationship. To wit: a little boy named Isaiah has a lot of books at home; Isaiah does beautifully on his reading test at school; this must be because his mother or father regularly reads to him. But Isaiah’s friend Emily, who also has a lot of books in her home, practically never touches them. She would rather dress up her Bratz or watch cartoons. And Emily tests just as well as Isaiah. Meanwhile, Isaiah and Emily’s friend Ricky doesn’t have any books at home. But Ricky goes to the library every day with his mother. And yet he does worse on his school tests than either Emily or Isaiah.
What are we to make of this? If reading books doesn’t have an impact on early childhood test scores, could it be that the books’ mere physical presence in the house makes the children smarter? Do books perform some kind of magical osmosis on a child’s brain? If so, one might be tempted to simply deliver a truckload of books to every home that contains a preschooler.
That, in fact, is what the governor of Illinois tried to do. In early 2004, Governor Rod Blagojevich announced a plan to mail one book a month to every child in Illinois from the time they were born until they entered kindergarten. The plan would cost $26 million a year. But, Blagojevich argued, this was a vital intervention in a state where 40 percent of third graders read below their grade level. “When you own [books] and they’re yours,” he said, “and they just come as part of your life, all of that will contribute to a sense…that books should be part of your life.”
So all children born in Illinois would end up with a sixty-volume library by the time they entered school. Does this mean they would all perform better on their reading tests?
Probably not. (Although we may never know for sure: in the end, the Illinois legislature rejected the book plan.) After all, the ECLS data don’t say that books in the house cause high test scores; it says only that the two are correlated.
How should this correlation be interpreted? Here’s a likely theory: most parents who buy a lot of children’s books tend to be smart and well educated to begin with. (And they pass on their smarts and work ethic to their kids.) Or perhaps they care a great deal about education, and about their children in general. (Which means they create an environment that encourages and rewards learning.) Such parents may believe—as fervently as the governor of Illinois believed—that every children’s book is a talisman that leads to unfettered intelligence. But they are probably wrong. A book is in fact less a cause of intelligence than an indicator.
So what does all this have to say about the importance of parents in general? Consider again the eight ECLS factors that are correlated with school test scores:
 
The child has highly educated parents.
The child’s parents have high socioeconomic status.
The child’s mother was thirty or older at the time of her first child’s birth.
The child had low birthweight.
The child’s parents speak English in the home.
The child is adopted.
The child’s parents are involved in the PTA.
The child has many books in his home.
 
And the eight factors that are not:
 
The child’s family is intact.
The child’s parents recently moved into a better neighborhood.
The child’s mother didn’t work between birth and kindergarten.
The child attended Head Start.
The child’s parents regularly take him to museums.
The child is regularly spanked.
The child frequently watches television.
The child’s parents read to him nearly every day.
 
To overgeneralize a bit, the first list describes things that parents are; the second list describes things that parents do. Parents who are well educated, successful, and healthy tend to have children who test well in school; but it doesn’t seem to much matter whether a child is trotted off to museums or spanked or sent to Head Start or frequently read to or plopped in front of the television.
For parents—and parenting experts—who are obsessed with child-rearing technique, this may be sobering news. The reality is that technique looks to be highly overrated.
But this is not to say that parents don’t matter. Plainly they matter a great deal. Here is the conundrum: by the time most people pick up a parenting book, it is far too late. Most of the things that matter were decided long ago—who you are, whom you married, what kind of life you lead. If you are smart, hardworking, well educated, well paid, and married to someone equally fortunate, then your children are more likely to succeed. (Nor does it hurt, in all likelihood, to be honest, thoughtful, loving, and curious about the world.) But it isn’t so much a matter of what you do as a parent; it’s who you are. In this regard, an overbearing parent is a lot like a political candidate who believes that money wins elections—whereas in truth, all the money in the world can’t get a candidate elected if the voters don’t like him to start with.
In a paper titled “The Nature and Nurture of Economic Outcomes,” the economist Bruce Sacerdote addressed the nature-nurture debate by taking a long-term quantitative look at the effects of parenting. He used three adoption studies, two American and one British, each of them containing in-depth data about the adopted children, their adoptive parents, and their biological parents. Sacerdote found that parents who adopt children are typically smarter, better educated, and more highly paid than the baby’s biological parents. But the adoptive parents’ advantages had little bearing on the child’s school performance. As also seen in the ECLS data, adopted children test relatively poorly in school; any influence the adoptive parents might exert is seemingly outweighed by the force of genetics. But, Sacerdote found, the parents were not powerless forever. By the time the adopted children became adults, they had veered sharply from the destiny that IQ alone might have predicted. Compared to similar children who were not put up for adoption, the adoptees were far more likely to attend college, to have a well-paid job, and to wait until they were out of their teens before getting married. It was the influence of the adoptive parents, Sacerdote concluded, that made the difference.


6
Perfect Parenting, Part II; or: Would a Roshanda by Any Other Name Smell as Sweet?
Obsessive or not, any parent wants to believe that she is making a big difference in the kind of person her child turns out to be. Otherwise, why bother?
The belief in parental power is manifest in the first official act a parent commits: giving the baby a name. As any modern parent knows, the baby-naming industry is booming, as evidenced by a proliferation of books, websites, and baby-name consultants. Many parents seem to believe that a child cannot prosper unless it is hitched to the right name; names are seen to carry great aesthetic or even predictive powers.
This might explain why, in 1958, a New York City man named Robert Lane decided to call his baby son Winner. The Lanes, who lived in a housing project in Harlem, already had several children, each with a fairly typical name. But this boy—well, Robert Lane apparently had a special feeling about this one. Winner Lane: how could he fail with a name like that?
Three years later, the Lanes had another baby boy, their seventh and last child. For reasons that no one can quite pin down today, Robert decided to name this boy Loser. It doesn’t appear that Robert was unhappy about the new baby; he just seemed to get a kick out of the name’s bookend effect. First a Winner, now a Loser. But if Winner Lane could hardly be expected to fail, could Loser Lane possibly succeed?
Loser Lane did in fact succeed. He went to prep school on a scholarship, graduated from Lafayette College in Pennsylvania, and joined the New York Police Department (this was his mother’s longtime wish), where he made detective and, eventually, sergeant. Although he never hid his name, many people were uncomfortable using it. “So I have a bunch of names,” he says today, “from Jimmy to James to whatever they want to call you. Timmy. But they rarely call you Loser.” Once in a while, he said, “they throw a French twist on it: ‘Losier.’” To his police colleagues, he is known as Lou.
And what of his brother with the can’t-miss name? The most noteworthy achievement of Winner Lane, now in his midforties, is the sheer length of his criminal record: nearly three dozen arrests for burglary, domestic violence, trespassing, resisting arrest, and other mayhem.
These days, Loser and Winner barely speak. The father who named them is no longer alive. Clearly he had the right idea—that naming is destiny—but he must have gotten the boys mixed up.
Then there is the recent case of Temptress, a fifteen-year-old girl whose misdeeds landed her in Albany County Family Court in New York. The judge, W. Dennis Duggan, had long taken note of the strange names borne by some offenders. One teenage boy, Amcher, had been named for the first thing his parents saw upon reaching the hospital: the sign for Albany Medical Center Hospital Emergency Room. But Duggan considered Temptress the most outrageous name he had come across.
“I sent her out of the courtroom so I could talk to her mother about why she named her daughter Temptress,” the judge later recalled. “She said she was watching The Cosby Show and liked the young actress. I told her the actress’s name was actually Tempestt Bledsoe. She said she found that out later, that they had misspelled the name. I asked her if she knew what ‘temptress’ meant, and she said she also found that out at some later point. Her daughter was charged with ungovernable behavior, which included bringing men into the home while the mother was at work. I asked the mother if she had ever thought the daughter was living out her name. Most all of this went completely over her head.”
Was Temptress actually “living out her name,” as Judge Duggan saw it? Or would she have wound up in trouble even if her mother had called her Chastity?* 
It isn’t much of a stretch to assume that Temptress didn’t have ideal parents. Not only was her mother willing to name her Temptress in the first place, but she wasn’t smart enough to know what that word even meant. Nor is it so surprising, on some level, that a boy named Amcher would end up in family court. People who can’t be bothered to come up with a name for their child aren’t likely to be the best parents either.
So does the name you give your child affect his life? Or is it your life reflected in his name? In either case, what kind of signal does a child’s name send to the world—and most important, does it really matter?
 
As it happens, Loser and Winner, Temptress and Amcher were all black. Is this fact merely a curiosity or does it have something larger to say about names and culture?
Every generation seems to produce a few marquee academics who advance the thinking on black culture. Roland G. Fryer Jr., the young black economist who analyzed the “acting white” phenomenon and the black-white test score gap, may be among the next. His ascension has been unlikely. An indifferent high-school student from an unstable family, he went to the University of Texas at Arlington on an athletic scholarship. Two things happened to him during college: he quickly realized he would never make the NFL or the NBA; and, taking his studies seriously for the first time in his life, he found he liked them. After graduate work at Penn State and the University of Chicago, he was hired as a Harvard professor at age twenty-five. His reputation for candid thinking on race was already well established.
Fryer’s mission is the study of black underachievement. “One could rattle off all the statistics about blacks not doing so well,” he says. “You can look at the black-white differential in out-of-wedlock births or infant mortality or life expectancy. Blacks are the worst-performing ethnic group on SATs. Blacks earn less than whites. They are still just not doing well, period. I basically want to figure out where blacks went wrong, and I want to devote my life to this.”
In addition to economic and social disparity between blacks and whites, Fryer had become intrigued by the virtual segregation of culture. Blacks and whites watch different television shows. (Monday Night Football is the only show that typically appears on each group’s top ten list; Seinfeld, one of the most popular sitcoms in history, never ranked in the top fifty among blacks.) They smoke different cigarettes. (Newports enjoy a 75 percent market share among black teenagers versus 12 percent among whites; the white teenagers are mainly smoking Marlboros.) And black parents give their children names that are starkly different from white children’s.
Fryer came to wonder: is distinctive black culture a cause of the economic disparity between blacks and whites or merely a reflection of it?
As with the ECLS study, Fryer went looking for the answer in a mountain of data: birth-certificate information for every child born in California since 1961. The data, covering more than sixteen million births, included standard items such as name, gender, race, birth-weight, and the parents’ marital status, as well as more telling factors about the parents: their zip code (which indicates socioeconomic status and a neighborhood’s racial composition), their means of paying the hospital bill (again, an economic indicator), and their level of education.
The California data prove just how dissimilarly black and white parents name their children. White and Asian-American parents, meanwhile, give their children remarkably similar names; there is some disparity between white and Hispanic-American parents, but it is slim compared to the black-white naming gap.
The data also show the black-white gap to be a recent phenomenon. Until the early 1970s, there was a great overlap between black and white names. The typical baby girl born in a black neighborhood in 1970 was given a name that was twice as common among blacks than whites. By 1980 she received a name that was twenty times more common among blacks. (Boys’ names moved in the same direction but less aggressively—probably because parents of all races are less adventurous with boys’ names than with girls’.) Given the location and timing of this change—dense urban areas where Afro-American activism was gathering strength—the most likely cause of the explosion in distinctively black names was the Black Power movement, which sought to accentuate African culture and fight claims of black inferiority. If this naming revolution was indeed inspired by Black Power, it would be one of the movement’s most enduring remnants. Afros today are rare, dashikis even rarer; Black Panther founder Bobby Seale is best known today for peddling a line of barbecue products.
A great many black names today are unique to blacks. More than 40 percent of the black girls born in California in a given year receive a name that not one of the roughly 100,000 baby white girls received that year. Even more remarkably, nearly 30 percent of the black girls are given a name that is unique among the names of every baby, white and black, born that year in California. (There were also 228 babies named Unique during the 1990s alone, and 1 each of Uneek, Uneque, and Uneqqee.) Even among very popular black names, there is little overlap with whites. Of the 626 baby girls named Deja in the 1990s, 591 were black. Of the 454 girls named Precious, 431 were black. Of the 318 Shanices, 310 were black.
What kind of parent is most likely to give a child such a distinctively black name? The data offer a clear answer: an unmarried, low-income, undereducated teenage mother from a black neighborhood who has a distinctively black name herself. In Fryer’s view, giving a child a superblack name is a black parent’s signal of solidarity with the community. “If I start naming my kid Madison,” he says, “you might think, ‘Oh, you want to go live across the railroad tracks, don’t you?’” If black kids who study calculus and ballet are thought to be “acting white,” Fryer says, then mothers who call their babies Shanice are simply “acting black.”
The California study shows that many white parents send as strong a signal in the opposite direction. More than 40 percent of the white babies are given names that are at least four times more common among whites. Consider Connor and Cody, Emily and Abigail. In one recent ten-year stretch, each of these names was given to at least two thousand babies in California—fewer than 2 percent of them black.
So what are the “whitest” names and the “blackest” names?
The Twenty “Whitest” Girl Names
• 1. Molly
• 2. Amy
• 3. Claire
• 4. Emily
• 5. Katie
• 6. Madeline
• 7. Katelyn
• 8. Emma
• 9. Abigail
• 10. Carly
• 11. Jenna
• 12. Heather
• 13. Katherine
• 14. Caitlin
• 15. Kaitlin
• 16. Holly
• 17. Allison
• 18. Kaitlyn
• 19. Hannah
• 20. Kathryn
The Twenty “Blackest” Girl Names
• 1. Imani
• 2. Ebony
• 3. Shanice
• 4. Aaliyah
• 5. Precious
• 6. Nia
• 7. Deja
• 8. Diamond
• 9. Asia
• 10. Aliyah
• 11. Jada
• 12. Tierra
• 13. Tiara
• 14. Kiara
• 15. Jazmine
• 16. Jasmin
• 17. Jazmin
• 18. Jasmine
• 19. Alexus
• 20. Raven
The Twenty “Whitest” Boy Names
• 1. Jake
• 2. Connor
• 3. Tanner
• 4. Wyatt
• 5. Cody
• 6. Dustin
• 7. Luke
• 8. Jack
• 9. Scott
• 10. Logan
• 11. Cole
• 12. Lucas
• 13. Bradley
• 14. Jacob
• 15. Garrett
• 16. Dylan
• 17. Maxwell
• 18. Hunter
• 19. Brett
• 20. Colin
The Twenty “Blackest” Boy Names
• 1. DeShawn
• 2. DeAndre
• 3. Marquis
• 4. Darnell
• 5. Terrell
• 6. Malik
• 7. Trevon
• 8. Tyrone
• 9. Willie
• 10. Dominique
• 11. Demetrius
• 12. Reginald
• 13. Jamal
• 14. Maurice
• 15. Jalen
• 16. Darius
• 17. Xavier
• 18. Terrance
• 19. Andre
• 20. Darryl
So how does it matter if you have a very white name or a very black name? Over the years, a series of “audit studies” have tried to measure how people perceive different names. In a typical audit study, a researcher would send two identical (and fake) résumés, one with a traditionally white name and the other with an immigrant or minority-sounding name, to potential employers. The “white” résumés have always gleaned more job interviews.
According to such a study, if DeShawn Williams and Jake Williams sent identical résumés to the same employer, Jake Williams would be more likely to get a callback. The implication is that black-sounding names carry an economic penalty. Such studies are tantalizing but severely limited, for they can’t explain why DeShawn didn’t get the call. Was he rejected because the employer is a racist and is convinced that DeShawn Williams is black? Or did he reject him because “DeShawn” sounds like someone from a low-income, low-education family? A résumé is a fairly undependable set of clues—a recent study showed that more than 50 percent of them contain lies—so “DeShawn” may simply signal a disadvantaged background to an employer who believes that workers from such backgrounds are undependable.
Nor do the black-white audit studies predict what might have happened in a job interview. What if the employer is racist, and if he unwittingly agreed to interview a black person who happened to have a white-sounding name—would he be any more likely to hire the black applicant after meeting face-to-face? Or is the interview a painful and discouraging waste of time for the black applicant—that is, an economic penalty for having a white-sounding name? Along those same lines, perhaps a black person with a white name pays an economic penalty in the black community; and what of the potential advantage to be gained in the black community by having a distinctively black name? But because the audit studies can’t measure the actual life outcomes of the fictitious DeShawn Williams versus Jake Williams, they can’t assess the broader impact of a distinctively black name.
Maybe DeShawn should just change his name.
People do this all the time, of course. The clerks in New York City’s civil court recently reported that name changes are at an all-time high. Some of the changes are purely, if bizarrely, aesthetic. A young couple named Natalie Jeremijenko and Dalton Conley recently renamed their four-year-old son Yo Xing Heyno Augustus Eisner Alexander Weiser Knuckles Jeremijenko-Conley. Some people change names for economic purposes: after a New York livery-cab driver named Michael Goldberg was shot in early 2004, it was reported that Mr. Goldberg was in fact an Indian-born Sikh who thought it advantageous to take a Jewish name upon immigrating to New York. Goldberg’s decision might have puzzled some people in show business circles, where it is a time-honored tradition to change Jewish names. Thus did Issur Danielovitch become Kirk Douglas; thus did the William Morris Agency rise to prominence under its namesake, the former Zelman Moses.
The question is, would Zelman Moses have done as well had he not become William Morris? And would DeShawn Williams do any better if he called himself Jake Williams or Connor Williams? It is tempting to think so—just as it is tempting to think that a truckload of children’s books will make a child smarter.
Though the audit studies can’t be used to truly measure how much a name matters, the California names data can.
How? The California data included not only each baby’s vital statistics but information about the mother’s level of education, income, and, most significantly, her own date of birth. This last fact made it possible to identify the hundreds of thousands of California mothers who had themselves been born in California and then to link them to their own birth records. Now a new and extremely potent story emerged from the data: it was possible to track the life outcome of any individual woman. This is the sort of data chain that researchers dream about, making it possible to identify a set of children who were born under similar circumstances, then locate them again twenty or thirty years later to see how they turned out. Among the hundreds of thousands of such women in the California data, many bore distinctively black names and many others did not. Using regression analysis to control for other factors that might influence life trajectories, it was then possible to measure the impact of a single factor—in this case, a woman’s first name—on her educational, income, and health outcomes.
So does a name matter?
The data show that, on average, a person with a distinctively black name—whether it is a woman named Imani or a man named DeShawn—does have a worse life outcome than a woman named Molly or a man named Jake. But it isn’t the fault of their names. If two black boys, Jake Williams and DeShawn Williams, are born in the same neighborhood and into the same familial and economic circumstances, they would likely have similar life outcomes. But the kind of parents who name their son Jake don’t tend to live in the same neighborhoods or share economic circumstances with the kind of parents who name their son DeShawn. And that’s why, on average, a boy named Jake will tend to earn more money and get more education than a boy named DeShawn. A DeShawn is more likely to have been handicapped by a low-income, low-education, single-parent background. His name is an indicator—not a cause—of his outcome. Just as a child with no books in his home isn’t likely to test well in school, a boy named DeShawn isn’t likely to do as well in life.
And what if DeShawn had changed his name to Jake or Connor: would his situation improve? Here’s a guess: anybody who bothers to change his name in the name of economic success is—like the high-school freshmen in Chicago who entered the school-choice lottery—at least highly motivated, and motivation is probably a stronger indicator of success than, well, a name.
 
Just as the ECLS data answered questions about parenting that went well beyond the black-white test gap, the California names data tell a lot of stories in addition to the one about distinctively black names. Broadly speaking, the data tell us how parents see themselves—and, more significantly, what kind of expectations they have for their children.
Here’s a question to begin with: where does a name come from, anyway? Not, that is, the actual source of the name—that much is usually obvious: there’s the Bible, there’s the huge cluster of traditional English and Germanic and Italian and French names, there are princess names and hippie names, nostalgic names and place names. Increasingly, there are brand names (Lexus, Armani, Bacardi, Timberland) and what might be called aspirational names. The California data show eight Harvards born during the 1990s (all of them black), fifteen Yales (all white), and eighteen Princetons (all black). There were no Doctors but three Lawyers (all black), nine Judges (eight of them white), three Senators (all white), and two Presidents (both black). Then there are the invented names. Roland G. Fryer Jr., while discussing his names research on a radio show, took a call from a black woman who was upset with the name just given to her baby niece. It was pronounced shuh-TEED but was in fact spelled “Shithead.”*
Shithead has yet to catch on among the masses, but other names do. How does a name migrate through the population, and why? Is it purely a matter of zeitgeist, or is there some sensible explanation? We all know that names rise and fall and rise—witness the return of Sophie and Max from near extinction—but is there a discernible pattern to these movements?
The answer lies in the California data, and the answer is yes.
Among the most interesting revelations in the data is the correlation between a baby’s name and the parents’ socioeconomic status. Consider the most common female names found in middle-income white households versus low-income white households. (These and other lists to follow include data from the 1990s alone, to ensure a large sample that is also current.)
Most Common Middle-Income White Girl Names
• 1. Sarah
• 2. Emily
• 3. Jessica
• 4. Lauren
• 5. Ashley
• 6. Amanda
• 7. Megan
• 8. Samantha
• 9. Hannah
• 10. Rachel
• 11. Nicole
• 12. Taylor
• 13. Elizabeth
• 14. Katherine
• 15. Madison
• 16. Jennifer
• 17. Alexandra
• 18. Brittany
• 19. Danielle
• 20. Rebecca
Most Common Low-Income White Girl Names
• 1. Ashley
• 2. Jessica
• 3. Amanda
• 4. Samantha
• 5. Brittany
• 6. Sarah
• 7. Kayla
• 8. Amber
• 9. Megan
• 10. Taylor
• 11. Emily
• 12. Nicole
• 13. Elizabeth
• 14. Heather
• 15. Alyssa
• 16. Stephanie
• 17. Jennifer
• 18. Hannah
• 19. Courtney
• 20. Rebecca
There is considerable overlap, to be sure. But keep in mind that these are the most common names of all, and consider the size of the data set. The difference between consecutive positions on these lists may represent several hundred or even several thousand children. So if Brittany is number five on the low-income list and number eighteen on the middle-income list, you can be assured that Brittany is a decidedly low-end name. Other examples are even more pronounced. Five names in each category don’t appear at all in the other category’s top twenty. Here are the top five names among high-end and low-end families, in order of their relative disparity with the other category:
Most Common High-End White Girl Names
• 1. Alexandra
• 2. Lauren
• 3. Katherine
• 4. Madison
• 5. Rachel
Most Common Low-End White Girl Names
• 1. Amber
• 2. Heather
• 3. Kayla
• 4. Stephanie
• 5. Alyssa
And for the boys:
Most Common High-End White Boy Names
• 1. Benjamin
• 2. Samuel
• 3. Jonathan
• 4. Alexander
• 5. Andrew
Most Common Low-End White Boy Names
• 1. Cody
• 2. Brandon
• 3. Anthony
• 4. Justin
• 5. Robert
Considering the relationship between income and names, and given the fact that income and education are strongly correlated, it is not surprising to find a similarly strong link between the parents’ level of education and the name they give their baby. Once again drawing from the pool of most common names among white children, here are the top picks of highly educated parents versus those with the least education:
Most Common White Girl Names Among High-Education Parents
• 1. Katherine
• 2. Emma
• 3. Alexandra
• 4. Julia
• 5. Rachel
Most Common White Girl Names Among Low-Education Parents
• 1. Kayla
• 2. Amber
• 3. Heather
• 4. Brittany
• 5. Brianna
Most Common White Boy Names Among High-Education Parents
• 1. Benjamin
• 2. Samuel
• 3. Alexander
• 4. John
• 5. William
Most Common White Boy Names Among Low-Education Parents
• 1. Cody
• 2. Travis
• 3. Brandon
• 4. Justin
• 5. Tyler
The effect is even more pronounced when the sample is widened beyond the most common names. Drawing from the entire California database, here are the names that signify the most poorly educated white parents.
The Twenty White Girl Names
That Best Signify Low-Education Parents*
 
(Average number of years of mother’s education in parentheses)
1. Angel (11.38)
2. Heaven (11.46)
3. Misty (11.61)
4. Destiny (11.66)
5. Brenda (11.71)
6. Tabatha (11.81)
7. Bobbie (11.87)
8. Brandy (11.89)
9. Destinee (11.91)
10. Cindy (11.92)
11. Jazmine (11.94)
12. Shyanne (11.96)
13. Britany (12.05)
14. Mercedes (12.06)
15. Tiffanie (12.08)
16. Ashly (12.11)
17. Tonya (12.13)
18. Crystal (12.15)
19. Brandie (12.16)
20. Brandi (12.17)
If you or someone you love is named Cindy or Brenda and is over, say, forty, and feels that those names did not formerly connote a low-education family, you are right. These names, like many others, have shifted hard and fast of late. Some of the other low-education names are obviously misspellings, whether intentional or not, of more standard names. In most cases the standard spellings of the names—Tabitha, Cheyenne, Tiffany, Brittany, and Jasmine—also signify low education. But the various spellings of even one name can reveal a strong disparity:
Ten “Jasmines” in Ascending Order of Maternal Education
 
(Years of mother’s education in parentheses)
1. Jazmine (11.94)
2. Jazmyne (12.08)
3. Jazzmin (12.14)
4. Jazzmine (12.16)
5. Jasmyne (12.18)
6. Jasmina (12.50)
7. Jazmyn (12.77)
8. Jasmine (12.88)
9. Jasmin (13.12)
10. Jasmyn (13.23)
Here is the list of low-education white boy names. It includes the occasional misspelling (Micheal and Tylor), but more common is the nickname-as-proper-name trend.
The Twenty White Boy Names
That Best Signify Low-Education Parents*
 
(Years of mother’s education in parentheses)
1. Ricky (11.55)
2. Joey (11.65)
3. Jessie (11.66)
4. Jimmy (11.66)
5. Billy (11.69)
6. Bobby (11.74)
7. Johnny (11.75)
8. Larry (11.80)
9. Edgar (11.81)
10. Steve (11.84)
11. Tommy (11.89)
12. Tony (11.96)
13. Micheal (11.98)
14. Ronnie (12.03)
15. Randy (12.07)
16. Jerry (12.08)
17. Tylor (12.14)
18. Terry (12.15)
19. Danny (12.17)
20. Harley (12.22)
Now for the names that signify the highest level of parental education. These names don’t have much in common, phonetically or aesthetically, with the low-education names. The girls’ names are in most regards diverse, though with a fair share of literary and otherwise artful touches. A caution to prospective parents who are shopping for a “smart” name: remember that such a name won’t make your child smart; it will, however, give her the same name as other smart kids—at least for a while. (For a much longer and more varied list of girls’ and boys’ names)
The Twenty White Girl Names
That Best Signify High-Education Parents*
 
(Years of mother’s education in parentheses)
1. Lucienne (16.60)
2. Marie-Claire (16.50)
3. Glynnis (16.40)
4. Adair (16.36)
5. Meira (16.27)
6. Beatrix (16.26)
7. Clementine (16.23)
8. Philippa (16.21)
9. Aviva (16.18)
10. Flannery (16.10)
11. Rotem (16.08)
12. Oona (16.00)
13. Atara (16.00)
14. Linden (15.94)
15. Waverly (15.93)
16. Zofia (15.88)
17. Pascale (15.82)
18. Eleanora (15.80)
19. Elika (15.80)
20. Neeka (15.77)
Now for the boys’ names that are turning up these days in high-education households. This list is particularly heavy on the Hebrew, with a noticeable trend toward Irish traditionalism.
The Twenty White Boy Names
That Best Signify High-Education Parents*
 
(Years of mother’s education in parentheses)
1. Dov (16.50)
2. Akiva (16.42)
3. Sander (16.29)
4. Yannick (16.20)
5. Sacha (16.18)
6. Guillaume (16.17)
7. Elon (16.16)
8. Ansel (16.14)
9. Yonah (16.14)
10. Tor (16.13)
11. Finnegan (16.13)
12. MacGregor (16.10)
13. Florian (15.94)
14. Zev (15.92)
15. Beckett (15.91)
16. Kia (15.90)
17. Ashkon (15.84)
18. Harper (15.83)
19. Sumner (15.77)
20. Calder (15.75)
If many names on the above lists were unfamiliar to you, don’t feel bad. Even boys’ names—which have always been scarcer than girls’—have been proliferating wildly. This means that even the most popular names today are less popular than they used to be. Consider the ten most popular names given to black baby boys in California in 1990 and then in 2000. The top ten in 1990 includes 3,375 babies (18.7 percent of those born that year), while the top ten in 2000 includes only 2,115 (14.6 percent of those born that year).
Most Popular Black Boy Names
 
(Number of occurrences in parentheses)
 1990
1. Michael (532)
2. Christopher (531)
3. Anthony (395)
4. Brandon (323)
5. James (303)
6. Joshua (301)
7. Robert (276)
8. David (243)
9. Kevin (240)
10. Justin (231)
 2000
1. Isaiah (308)
2. Jordan (267)
3. Elijah (262)
4. Michael (235)
5. Joshua (218)
6. Anthony (208)
7. Christopher (169)
8. Jalen (159)
9. Brandon (148)
10. Justin (141)
In the space of ten years, even the most popular name among black baby boys (532 occurrences for Michael) became far less popular (308 occurrences for Isaiah). So parents are plainly getting more diverse with names. But there’s another noteworthy shift in these lists: a very quick rate of turnover. Note that four of the 1990 names (James, Robert, David, and Kevin) fell out of the top ten by 2000. Granted, they made up the bottom half of the 1990 list. But the names that replaced them in 2000 weren’t bottom dwellers. Three of the new names—Isaiah, Jordan, and Elijah—were in fact numbers one, two, and three in 2000. For an even more drastic example of how quickly and thoroughly a name can cycle in and out of use, consider the ten most popular names given to white girls in California in 1960 and then in 2000.
Most Popular White Girl Names
 1960
1. Susan
2. Lisa
3. Karen
4. Mary
5. Cynthia
6. Deborah
7. Linda
8. Patricia
9. Debra
10. Sandra
 2000
1. Emily
2. Hannah
3. Madison
4. Sarah
5. Samantha
6. Lauren
7. Ashley
8. Emma
9. Taylor
10. Megan
Not a single name from 1960 remains in the top ten. But, you say, it’s hard to stay popular for forty years. So how about comparing today’s most popular names with the top ten from only twenty years earlier?
Most Popular White Girl Names
 1980
1. Jennifer
2. Sarah
3. Melissa
4. Jessica
5. Christina
6. Amanda
7. Nicole
8. Michelle
9. Heather
10. Amber
 2000
1. Emily
2. Hannah
3. Madison
4. Sarah
5. Samantha
6. Lauren
7. Ashley
8. Emma
9. Taylor
10. Megan
A single holdover: Sarah. So where do these Emilys and Emmas and Laurens all come from? Where on earth did Madison come from?* It’s easy enough to see that new names become very popular very fast—but why?
Let’s take another look at a pair of earlier lists. Here are the most popular names given to baby girls in the 1990s among low-income families and among families of middle income or higher.
Most Common “High-End” White Girl Names in the 1990s
• 1. Alexandra
• 2. Lauren
• 3. Katherine
• 4. Madison
• 5. Rachel
Most Common “Low-End” White Girl Names in the 1990s
• 1. Amber
• 2. Heather
• 3. Kayla
• 4. Stephanie
• 5. Alyssa
Notice anything? You might want to compare these names with the “Most Popular White Girl Names” list, which includes the top ten overall names from 1980 and 2000. Lauren and Madison, two of the most popular “high-end” names from the 1990s, made the 2000 top ten list. Amber and Heather, meanwhile, two of the overall most popular names from 1980, are now among the “low-end” names.
There is a clear pattern at play: once a name catches on among high-income, highly educated parents, it starts working its way down the socioeconomic ladder. Amber and Heather started out as high-end names, as did Stephanie and Brittany. For every high-end baby named Stephanie or Brittany, another five lower-income girls received those names within ten years.
So where do lower-end families go name-shopping? Many people assume that naming trends are driven by celebrities. But celebrities actually have a weak effect on baby names. As of 2000, the pop star Madonna had sold 130 million records worldwide but hadn’t generated even the ten copycat namings—in California, no less—required to make the master index of four thousand names from which the sprawling list of girls’ names was drawn. Or considering all the Brittanys, Britneys, Brittanis, Brittanies, Brittneys, and Brittnis you encounter these days, you might think of Britney Spears. But she is in fact a symptom, not a cause, of the Brittany/Britney/Brittani/ Brittanie/Brittney/Brittni explosion. With the most common spelling of the name, Brittany, at number eighteen among high-end families and number five among low-end families, it is surely approaching its pull date. Decades earlier, Shirley Temple was similarly a symptom of the Shirley boom, though she is often now remembered as its cause. (It should also be noted that many girls’ names, including Shirley, Carol, Leslie, Hilary, Renee, Stacy, and Tracy began life as boys’ names, but girls’ names almost never cross over to boys.)
So it isn’t famous people who drive the name game. It is the family just a few blocks over, the one with the bigger house and newer car. The kind of families that were the first to call their daughters Amber or Heather and are now calling them Lauren or Madison. The kind of families that used to name their sons Justin or Brandon and are now calling them Alexander or Benjamin. Parents are reluctant to poach a name from someone too near—family members or close friends—but many parents, whether they realize it or not, like the sound of names that sound “successful.”
But as a high-end name is adopted en masse, high-end parents begin to abandon it. Eventually, it is considered so common that even lower-end parents may not want it, whereby it falls out of the rotation entirely. The lower-end parents, meanwhile, go looking for the next name that the upper-end parents have broken in.
So the implication is clear: the parents of all those Alexandras, Laurens, Katherines, Madisons, and Rachels should not expect the cachet to last much longer. Those names are already on their way to overexposure. Where, then, will the new high-end names come from?
It wouldn’t be surprising to find them among the “smartest” girls’ and boys’ names in California, listed on pages 181–82, that are still fairly obscure. Granted, some of them—Oona and Glynnis, Florian and Kia—are bound to remain obscure. The same could be surmised of most of the Hebrew names (Rotem and Zofia, Akiva and Zev), even though many of today’s most mainstream names (David, Jonathan, Samuel, Benjamin, Rachel, Hannah, Sarah, Rebecca) are of course Hebrew biblical names. Aviva may be the one modern Hebrew name that is ready to break out: it’s easy to pronounce, pretty, peppy, and suitably flexible.
Drawn from a pair of “smart” databases, here is a sampling of today’s high-end names. Some of them, as unlikely as it seems, are bound to become tomorrow’s mainstream names. Before you scoff, ask yourself this: do any of them seem more ridiculous than “Madison” might have seemed ten years ago?
Most Popular Girls’ Names of 2015?
• Annika
• Ansley
• Ava
• Avery
• Aviva
• Clementine
• Eleanora
• Ella
• Emma
• Fiona
• Flannery
• Grace
• Isabel
• Kate
• Lara
• Linden
• Maeve
• Marie-Claire
• Maya
• Philippa
• Phoebe
• Quinn
• Sophie
• Waverly
Most Popular Boys’ Names of 2015?
• Aidan
• Aldo
• Anderson
• Ansel
• Asher
• Beckett
• Bennett
• Carter
• Cooper
• Finnegan
• Harper
• Jackson
• Johan
• Keyon
• Liam
• Maximilian
• McGregor
• Oliver
• Reagan
• Sander
• Sumner
• Will
Obviously, a variety of motives are at work when parents consider a name for their child. They may want something traditional or something bohemian, something unique or something perfectly trendy. It would be an overstatement to suggest that all parents are looking—whether consciously or not—for a “smart” name or a “high-end” name. But they are all trying to signal something with a name, whether the name is Winner or Loser, Madison or Amber, Shithead or Sander, DeShawn or Jake. What the California names data suggest is that an overwhelming number of parents use a name to signal their own expectations of how successful their children will be. The name isn’t likely to make a shard of difference. But the parents can at least feel better knowing that, from the very outset, they tried their best.


EPILOGUE:
Two Paths to Harvard
And now, with all these pages behind us, an early promise has been confirmed: this book indeed has no “unifying theme.”
But if there is no unifying theme to Freakonomics, there is at least a common thread running through the everyday application of Freakonomics. It has to do with thinking sensibly about how people behave in the real world. All it requires is a novel way of looking, of discerning, of measuring. This isn’t necessarily a difficult task, nor does it require supersophisticated thinking. We have essentially tried to figure out what the typical gang member or sumo wrestler figured out on his own (although we had to do so in reverse).
Will the ability to think such thoughts improve your life materially? Probably not. Perhaps you’ll put up a sturdy gate around your swimming pool or push your real-estate agent to work a little harder. But the net effect is likely to be more subtle than that. You might become more skeptical of the conventional wisdom; you may begin looking for hints as to how things aren’t quite what they seem; perhaps you will seek out some trove of data and sift through it, balancing your intelligence and your intuition to arrive at a glimmering new idea. Some of these ideas might make you uncomfortable, even unpopular. To claim that legalized abortion resulted in a massive drop in crime will inevitably lead to explosive moral reactions. But the fact of the matter is that Freakonomics-style thinking simply doesn’t traffic in morality. As we suggested near the beginning of this book, if morality represents an ideal world, then economics represents the actual world.
The most likely result of having read this book is a simple one: you may find yourself asking a lot of questions. Many of them will lead to nothing. But some will produce answers that are interesting, even surprising. Consider the question posed at the beginning of this book’s penultimate chapter: how much do parents really matter?
The data have by now made it clear that parents matter a great deal in some regards (most of which have been long determined by the time a child is born) and not at all in others (the ones we obsess about). You can’t blame parents for trying to do something—anything—to help their child succeed, even if it’s something as irrelevant as giving him a high-end first name.
But there is also a huge random effect that rains down on even the best parenting efforts. If you are in any way typical, you have known some intelligent and devoted parents whose child went badly off the rails. You may have also known of the opposite instance, where a child succeeds despite his parents’ worst intentions and habits.
Recall for a moment the two boys, one white and one black, who were described in chapter 5. The white boy who grew up outside Chicago had smart, solid, encouraging, loving parents who stressed education and family. The black boy from Daytona Beach was abandoned by his mother, was beaten by his father, and had become a full-fledged gangster by his teens. So what became of the two boys?
The second child, now twenty-eight years old, is Roland G. Fryer Jr., the Harvard economist studying black underachievement.
The white child also made it to Harvard. But soon after, things went badly for him. His name is Ted Kaczynski.


BONUS MATERIAL ADDED TO THE REVISED AND EXPANDED 2006 EDITION

• The original New York Times Magazine article about Steven D. Levitt by Stephen J. Dubner, which led to the creation of this book.
• Seven “Freakonomics” columns written for the New York Times Magazine, published between August 2005 and April 2006.
• Selected entries from the Freakonomics blog, posted between April 2005 and May 2006 at http://www.freakonomics.com/blog/.

 
 
THE PROBABILITY THAT A REAL-ESTATE AGENT IS CHEATING YOU (AND OTHER RIDDLES OF MODERN LIFE)
Inside the curious mind of the heralded young economist Steven Levitt
by Stephen J. Dubner
New York Times Magazine, August 3, 2003
The most brilliant young economist in America—the one so deemed, at least, by a jury of his elders—brakes to a stop at a traffic light on Chicago’s south side. It is a sunny day in mid-June. He drives an aging green Chevy Cavalier with a dusty dashboard and a window that doesn’t quite shut, producing a dull roar at highway speeds. But the car is quiet for now, as are the noontime streets: gas stations, boundless concrete, brick buildings with plywood windows.
An elderly homeless man approaches. It says he is homeless right on his sign, which also asks for money. He wears a torn jacket, too heavy for the warm day, and a grimy red baseball cap.
The economist doesn’t lock his doors or inch the car forward. Nor does he go scrounging for spare change. He just watches, as if through one-way glass. After a while, the homeless man moves along.
“He had nice headphones,” says the economist, still watching in the rearview mirror. “Well, nicer than the ones I have. Otherwise, it doesn’t look like he has many assets.”
 
Steven Levitt tends to see things differently than the average person. Differently, too, than the average economist. This is either a wonderful trait or a troubling one, depending on how you feel about economists. The average economist is known to wax oracularly about any and all monetary issues. But if you were to ask Levitt his opinion of some standard economic matter, he would probably swipe the hair from his eyes and plead ignorance. “I gave up a long time ago pretending that I knew stuff I didn’t know,” he says. “I mean, I just—I just don’t know very much about the field of economics. I’m not good at math, I don’t know a lot of econometrics, and I also don’t know how to do theory. If you ask me about whether the stock market’s going to go up or down, if you ask me whether the economy’s going to grow or shrink, if you ask me whether deflation’s good or bad, if you ask me about taxes—I mean, it would be total fakery if I said I knew anything about any of those things.”
In Levitt’s view, economics is a science with excellent tools for gaining answers but a serious shortage of interesting questions. His particular gift is the ability to ask such questions. For instance: If drug dealers make so much money, why do they still live with their mothers? Which is more dangerous, a gun or a swimming pool? What really caused crime rates to plunge during the past decade? Do real-estate agents have their clients’ best interests at heart? Why do black parents give their children names that may hurt their career prospects? Do schoolteachers cheat to meet high-stakes testing standards? Is sumo wrestling corrupt?
And how does a homeless man afford $50 headphones?
Many people—including a fair number of his peers—might not recognize Levitt’s work as economics at all. But he has merely distilled the so-called dismal science down to its most primal aim: explaining how people get what they want, or need. Unlike most academics, he is unafraid of using personal observations and curiosities (though he does fear calculus). He is an intuitionist. He sifts through a pile of data to find a story that no one else had found. He devises a way to measure an effect that veteran economists had declared unmeasurable. His abiding interests—though he says he has never trafficked in them himself—are cheating, corruption and crime.
His interest in the homeless man’s headphones, meanwhile, didn’t last long. “Maybe,” he said later, “it was just testimony to the fact I’m too disorganized to buy a set of headphones that I myself covet.”
Levitt is the first to say that some of his topics border on the trivial. But he has proved to be such an ingenious researcher and clear-eyed thinker that instead of being consigned to the fringe of his field, the opposite has happened: he has shown other economists just how well their tools can make sense of the real world.
“Levitt is considered a demigod, one of the most creative people in economics and maybe in all social science,” says Colin Camerer, an economist at the California Institute of Technology. “He represents something that everyone thinks they will be when they go to grad school in econ, but usually they have the creative spark bored out of them by endless math—namely, a kind of intellectual detective trying to figure stuff out.”
Levitt is a populist in a field that is undergoing a bout of popularization. Undergraduates are swarming the economics departments of elite universities. Economics is seen as the ideal blend of intellectual prestige (it does offer a Nobel, after all) and practical training for a high-flying finance career (unless, like Levitt, you choose to stay in academia). At the same time, economics is ever more visible in the real world, thanks to the continuing fetishization of the stock market and the continuing fixation with Alan Greenspan.
The greatest change, however, is within the scholarly ranks. Microeconomists are gaining on the macro crowd, empiricists gaining on the theorists. Behavioral economists have called into doubt the very notion of “homo economicus,” the supposedly rational decision-maker in each of us. Young economists of every stripe are more inclined to work on real-world subjects and dip into bordering disciplines—psychology, criminology, sociology, even neurology—with the intent of rescuing their science from its slavish dependence upon mathematical models.
Levitt fits everywhere and nowhere. He is a noetic butterfly that no one has pinned down—he was once offered a job on the Clinton economic team, and the Bush campaign approached him about being a crime adviser—but who is widely appreciated.
“Steve isn’t really a behavioral economist, but they’d be happy to have him,” says Austan Goolsbee, who teaches economics at the University of Chicago’s Graduate School of Business. “He’s not really an old price-theory guy, but these Chicago guys are happy to claim him. He’s not really a Cambridge guy”—although Levitt went to Harvard and then M.I.T.—“but they’d love him to come back.”
He has critics, to be sure. Daniel Hamermesh, a prominent labor economist at the University of Texas, has taught Levitt’s paper “The Impact of Legalized Abortion on Crime” to his undergraduates. “I’ve gone over this paper in draft, in its printed version, at great length, and for the life of me I can’t see anything wrong with it,” Hamermesh says. “On the other hand, I don’t believe a word of it. And his stuff on sumo wrestlers—well, this is not exactly fundamental, unless you’re Japanese and weigh 500 pounds.”
But at thirty-six, Levitt is a full professor in the University of Chicago’s economics department, the most legendary program in the country. (He received tenure after only two years.) He is an editor of the Journal of Political Economy, a leading journal in the field. And the American Economic Association recently awarded him its John Bates Clark Medal, given biennially to the country’s best economist under 40.
 
He is a prolific and diverse writer. But his paper linking a rise in abortion to a drop in crime has made more noise than the rest combined. Levitt and his co-author, John Donohue of Stanford Law School, argued that as much as 50 percent of the huge drop in crime since the early 1990s can be traced to Roe v. Wade. Their thinking goes like this: the women most likely to seek an abortion—poor, single, black or teenage mothers—were the very women whose children, if born, have been shown most likely to become criminals. But since those children weren’t born, crime began to decrease during the years they would have entered their criminal prime. In conversation, Levitt reduces the theory to a tidy syllogism: “Unwantedness leads to high crime; abortion leads to less unwantedness; abortion leads to less crime.”
Levitt had already published widely about crime and punishment. One paper he wrote as a graduate student is still regularly cited. His question was disarmingly simple: Do more police translate into less crime? The answer would seem obvious—yes—but had never been proved: since the number of police officers tends to rise along with the number of crimes, the effectiveness of the police was tricky to measure.
Levitt needed a mechanism that would unlink the crime rate from police hiring. He found it within politics. He noticed that mayors and governors running for re-election often hire more police officers. By measuring those police increases against crime rates, he was able to determine that additional officers do indeed bring down violent crime.
That paper was later disputed—another graduate student found a serious mathematical mistake in it—but Levitt’s ingenuity was obvious. He began to be acknowledged as a master of the simple, clever solution. He was the guy who, in the slapstick scene, sees all the engineers futzing with a broken machine—and then realizes that no one has thought to plug it in.
Arguing that the police help deter crime didn’t make Levitt any enemies. Arguing that abortion deterred crime was another matter.
In the abortion paper, published in 2001, he and Donohue warned that their findings should not be seen “as either an endorsement of abortion or a call for intervention by the state in the fertility decisions of women.” They suggested that crime might just as easily be curbed by “providing better environments for those children at greatest risk for future crime.”
Still, the very topic managed to offend nearly everyone. Conservatives were enraged that abortion could be construed as a crime-fighting tool. Liberals were aghast that poor and black women were singled out. Economists grumbled that Levitt’s methodology was not sound. A syllogism, after all, can be a magic trick: All cats die; Socrates died; therefore Socrates was a cat.
“I think he’s enormously clever in so many areas, focusing very much on the issue of reverse causality,” says Ted Joyce, an economist at Baruch College who has written a critical response to the abortion paper. “But in this case I think he ignored it, or didn’t tend to it well enough.”
As the news media gorged on the abortion-crime story, Levitt came under direct assault. He was called an ideologue (by conservatives and liberals alike), a eugenicist, a racist and downright evil.
In reality, he seems to be very much none of those. He has little taste for politics and less for moralizing. He is genial, low-key and unflappable, confident but not cocky. He is a respected teacher and colleague; he is a sought-after collaborator who, because of the breadth of his curiosities, often works with scholars outside his field—another rarity for an economist.
“I hesitate to use these words, but Steve is a con man, in the best sense,” says Sudhir Venkatesh, a sociologist at Columbia University. “He’s the Shakespearean jester. He’ll make you believe his ideas were yours.” Venkatesh was Levitt’s co-author on “An Economic Analysis of a Drug-Selling Gang’s Finances,” which found that the average street dealer lives with his mother because the take-home pay is, frankly, terrible. The paper analyzed one crack gang’s financial activities as if it were any corporation. (It was Venkatesh who procured the data, from a former gang member.) Such a thing had never been tried. “This lack of focus,” Levitt deadpanned in one version of the paper, “is perhaps partly attributable to the fact that few economists have been involved in the study of gangs.”
Levitt speaks with a boyish lisp. His appearance is High Nerd: a plaid button-down shirt, nondescript khakis and a braided belt, sensible shoes. His pocket calendar is branded with the National Bureau of Economic Research logo. “I wish he would get more than three haircuts a year,” his wife, Jeannette, says, “and that he wasn’t still wearing the same glasses he got fifteen years ago, which weren’t even in fashion then.” He was a good golfer in high school but has so physically atrophied that he calls himself “the weakest human being alive” and asks Jeannette to open jars around the house. There is nothing in his appearance or manner, in other words, that suggests a flamethrower. He will tell you that all he does is sit at his desk, day and night, wrestling with some strange mountain of data. He will tell you that he would do it for free (his salary is reportedly more than $200,000), and you tend to believe him. He may be an accidental provocateur, but he is a provocateur nonetheless.
He takes particular delight in catching wrongdoers. In one paper, he devised a set of algorithms that could identify teachers in the Chicago public-school system who were cheating. “Cheating classrooms will systematically differ from other classrooms along a number of dimensions,” he and his co-author, Brian Jacob of the Kennedy School of Government, wrote in “Catching Cheating Teachers.” “For instance, students in cheating classrooms are likely to experience unusually large test-score gains in the year of the cheating, followed by unusually small gains or even declines in the following year when the boost attributable to cheating disappears.”
Levitt used test-score data from the Chicago schools that had long been available to other researchers. There were a number of ways, he realized, that a teacher could cheat. If she were particularly brazen (and stupid), she might give students the correct answers. Or, after the test, she might actually erase students’ wrong answers and fill in correct ones. A sophisticated cheater would be careful to avoid conspicuous blocks of identical answers. But Levitt was more sophisticated. “The first step in analyzing suspicious strings is to estimate the probability each child would give a particular answer on each question,” he wrote. “This estimation is done using a multinomial logit framework with past test scores, demographics and socioeconomic characteristics as explanatory variables.”
So by measuring any number of factors—the difficulty of a particular question, the frequency with which students got hard questions right and easy ones wrong, the degree to which certain answers were highly correlated in one classroom—Levitt identified which teachers he thought were cheating. (Perhaps just as valuable, he was also able to identify the good teachers.) The Chicago school system, rather than disputing Levitt’s findings, invited him into the schools for retesting. As a result, the cheaters were fired.
Then there is his forthcoming “Understanding Why Crime Fell in the 1990’s: Four Factors That Explain the Decline and Seven That Do Not.” The entire drop in crime, Levitt says, was due to more police officers, more prisoners, the waning crack epidemic and Roe v. Wade.
One factor that probably didn’t make a difference, he argues, was the innovative policing strategy trumpeted in New York by Rudolph Giuliani and William Bratton. “I think,” Levitt says, “I’m pretty much alone in saying that.”
 
He comes from a Minneapolis family of high, if unusual, achievers. His father, a medical researcher, is considered a leading authority on intestinal gas. (He bills himself as “The Man Who Gave Status to Flatus and Class to Gas.”) One of Levitt’s great-uncles, Robert May, wrote Rudolph the Red-Nosed Reindeer—the book, that is; another great-uncle, Johnny Marks, later wrote the song.
At Harvard, Levitt wrote his senior thesis on thoroughbred breeding and graduated summa cum laude. (He is still obsessed with horse racing. He says he believes it is corrupt and has designed a betting system—the details of which he will not share—to take advantage of the corruption.) He worked for two years as a management consultant before enrolling at M.I.T. for a doctorate in economics. The M.I.T. program was famous for its mathematical intensity. Levitt had taken exactly one math course as an undergraduate and had forgotten even that. During his first graduate class, he asked the student next to him about a formula on the board: Is there any difference between the derivative sign that’s straight up-and-down and the curly one? “You are in so much trouble,” he was told.
“People wrote him off,” recalls Austan Goolsbee, the Chicago economist who was then a classmate. “They’d say, ‘That guy has no future.’”
Levitt set his own course. Other grad students stayed up all night working on problem sets, trying to make good grades. He stayed up researching and writing. “My view was that the way you succeed in this profession is you write great papers,” he says. “So I just started.”
Sometimes he would begin with a question. Sometimes it was a set of data that caught his eye. He spent one entire summer typing into his computer the results of years’ worth of Congressional elections. (Today, with so much information so easily available on the Internet, Levitt complains that he can’t get his students to input data at all.) All he had was a vague curiosity about why incumbents were so often re-elected.
Then he happened upon a political-science book whose authors claimed that money wins elections, period. “They were trying to explain election outcomes as a function of campaign expenditures,” he recalls, “completely ignoring the fact that contributors will only give money to challengers when they have a realistic chance of winning, and incumbents only spend a lot when they have a chance of losing. They convinced themselves this was the causal story even though it’s so obvious in retrospect that it’s a spurious effect.”
Obvious, at least, to Levitt. Within five minutes, he had a vision of the paper he would write. “It came to me,” he says, “in full bloom.”
The problem was that his data couldn’t tell him who was a good candidate and who wasn’t. It was therefore impossible to tease out the effect of the money. As with the police/crime rate puzzle, he had to trick the data.
Because he himself had typed in the data, he had noticed something: often, the same two candidates faced each other multiple times. By analyzing the data from only those elections, Levitt was able to find a true result. His conclusion: campaign money has about one-tenth the impact as was commonly accepted.
An unknown graduate student, he sent his paper to the Journal of Political Economy—one professor told him he was crazy for even trying—where it was published. He completed his Ph.D. in three years, but because of his priorities, he says, he was “invisible” to the faculty, “a real zero.” Then he stumbled upon what he now calls the turning point in his career.
He had an interview for the Society of Fellows, the venerable intellectual Harvard clubhouse that pays young scholars to do their own work, for three years, with no commitments. Levitt felt he didn’t stand a chance. For starters, he didn’t consider himself an intellectual. He would be interviewed over dinner by the senior fellows, a collection of world-renowned philosophers, scientists and historians. He worried he wouldn’t have enough conversation for even the first course.
Instead, he was on fire. Whatever subject came up—the brain, ants, philosophy—he just happened to remember something pithy he’d read. His wit crackled as it had never crackled before. When he told them about the two summers he spent betting the horses back in Minnesota, they ate it up!
Finally—disquietingly—one of them said: “I’m having a hard time seeing the unifying theme of your work. Could you explain it?”
Levitt was stymied. He had no idea what his unifying theme was, or if he even had one.
Amartya Sen, the future Nobel-winning economist, jumped in and neatly summarized what he saw as Levitt’s theme.
Yes, Levitt said eagerly, that’s my theme.
Another fellow then offered another theme.
You’re right, Levitt said, that’s my theme.
And so it went, like dogs tugging at a bone, until the philosopher Robert Nozick interrupted. If Levitt could have been said to have an intellectual hero, it would be Nozick.
“How old are you, Steve?” he asked.
“Twenty-six.”
Nozick turned to the other fellows: “He’s twenty-six years old. Why does he need to have a unifying theme? Maybe he’s going to be one of those people who’s so talented he doesn’t need one. He’ll take a question and he’ll just answer it, and it’ll be fine.”
 
The University of Chicago’s economics department had a famous unifying theme—the Gospel of Free Markets, with a conservative twist—and would therefore not have seemed the most likely fit for Levitt. As he sees it, Chicago is about theory, deep thinking and big ideas, while he is about empiricism, clever thinking and “cute but ultimately insubstantial ideas.”
But Chicago also had Gary Becker. To Levitt, Becker is the most influential economist of the past fifty years. Long before it was fashionable, Becker brought microeconomic theory to offbeat topics, the family and crime in particular. For years, Becker was demonized—a single phrase like “the price of children” would set off untold alarms. “I took a lot of heat over my career from people who thought my work was silly or irrelevant or not economics,” Becker says. But Chicago supported him; he persevered, winning the Nobel Prize in 1992; and he became Steven Levitt’s role model.
Becker told Levitt that Chicago would be a great environment for him. “Not everybody agrees with all your results,” he said, “but we agree what you’re doing is very interesting work, and we’ll support you in that.”
Levitt soon found that the support at Chicago went beyond the scholarly. The year after he was hired, his wife gave birth to their first child, Andrew. One day, just after Andrew turned a year old, he came down with a slight fever. The doctor diagnosed an ear infection. When he started vomiting the next morning, his parents took him to the hospital. A few days later he was dead of pneumococcal meningitis.
Amid the shock and grief, Levitt had an undergraduate class that needed teaching. It was Gary Becker—a Nobel laureate nearing his seventieth birthday—who sat in for him. Another colleague, D. Gale Johnson, sent a condolence card that Levitt still quotes from memory.
Levitt and Johnson, an agricultural economist in his eighties, began speaking regularly. Levitt learned that Johnson’s daughter was one of the first Americans to adopt a daughter from China. Soon the Levitts adopted a daughter of their own, whom they named Amanda. In addition to Amanda, they have since had a daughter, now almost three, and a son. But Andrew’s death has played on, in various ways. They have become close friends with the family of the little girl to whom they donated Andrew’s liver. (They also donated his heart, but that baby died.) And, not surprisingly for a scholar who pursues real-life subjects, the death also informed Levitt’s work.
He and Jeannette joined a support group for grieving parents. Levitt was struck by how many children had drowned in swimming pools. They were the kinds of deaths that don’t make the newspaper—unlike, for instance, a child who dies while playing with a gun.
Levitt was curious and went looking for numbers that would tell the story. He wrote up the results as an op-ed article for the Chicago Sun-Times. It featured the sort of plangent counterintuition for which he has become famous: “If you own a gun and have a swimming pool in the yard, the swimming pool is almost 100 times more likely to kill a child than the gun is.”
Trying to get his mind off death, Levitt took up a hobby: rehabbing and selling old houses in Oak Park, where he lives. This experience has led to yet another paper, about the real-estate market. It is his most Chicago-style paper yet, a romp in price theory, a sign that the university’s influence on him is perhaps as strong as his influence on it. But Levitt being Levitt, it also deals with corruption.
While negotiating to buy old houses, he found that the seller’s agent often encouraged him, albeit cagily, to underbid. This seemed odd: didn’t the agent represent the seller’s best interest? Then he thought more about the agent’s role. Like many other “experts” (auto mechanics and stockbrokers come to mind), a real-estate agent is thought to know his field far better than a lay person. A homeowner is encouraged to trust the agent’s information. So if the agent brings in a low offer and says it might just be the best the homeowner can expect, the homeowner tends to believe him. But the key, Levitt determined, lay in the fact that agents “receive only a small share of the incremental profit when a house sells for a higher value.” Like a stockbroker churning commissions or a bookie grabbing his vig, an agent was simply looking to make a deal, any deal. So he would push homeowners to sell too fast and too cheap.
Now if Levitt could only measure this effect. Once again, he found a clever mechanism. Using data from more than 50,000 home sales in Cook County, Ill., he compared the figures for homes owned by real-estate agents with those for homes for which they acted only as agents. The agents’ homes stayed on the market about 10 days longer and sold for 2 percent more.
 
Late on a summer afternoon, Levitt is in his office, deep inside one of the university’s Gothic behemoths. The ceiling is stained, the plaster around the window crumbling. He is just back from sabbatical at Stanford, and his desk is a holy mess: stacks of books and journals, a green sippy cup and a little orange squeeze hippo.
This is his afternoon to meet with students. Levitt drinks a Mountain Dew and talks softly. Some students come for research assignments, some for advice. One has just written her undergraduate thesis: “The Labor Market Consequence of Graduating College in a Bad Economy.” For a thesis, Levitt tells her, it’s very good. But now she wants to have it published.
“You write like a college student, and that’s a problem,” he says. “The thing is, you’re telling a story. There’s foreshadowing going on, all those tricks. You want the reader going down a particular path so when they get the results, they understand them and believe them. But you also want to be honest about your weaknesses. People are much less harsh on weaknesses that are clear than weaknesses that are hidden—as they should be.”
Be honest about your weaknesses. Has there ever been a prizewinning scholar as honest about his weaknesses as Steven Levitt? He doesn’t understand economics, he claims, or math. He’s a little thinker in a world of big thinkers. He can’t even open a jar of spaghetti sauce at home, poor guy.
Friends say that Levitt’s self-deprecation is as calculated as it is genuine. Within academia, economists take pride in being the most cutthroat of a cutthroat breed. Anyone who writes papers on Weakest Link (contestants discriminate against Latino and elderly peers, Levitt concluded, but not blacks or women) and sumo (to best manage their tournament rankings, wrestlers often conspire to throw matches) had better not also be arrogant.
Or maybe it is not self-deprecation at all. Maybe it is self-flagellation. Maybe what Steven Levitt really wants is to graduate from his “silly” and “trivial” and “shallow” topics.
He thinks he’s onto something with a new paper about black names. He wanted to know if someone with a distinctly black name suffers an economic penalty. His answer—contrary to other recent research—is no. But now he has a bigger question: Is black culture a cause of racial inequality or is it a consequence? For an economist, even for Levitt, this is new turf—“quantifying culture,” he calls it. As a task, he finds it thorny, messy, perhaps impossible and deeply tantalizing.
Driving home to Oak Park that evening, his Cavalier glumly thrumming along the Eisenhower Expressway, he dutifully addresses his future. Leaving academia for a hedge fund or a government job does not interest him (though he might, on the side, start a company to catch cheating teachers). He is said to be at the top of every economics department’s poaching list. But the tree he and Jeannette planted when Andrew died is getting too big to move. You get the feeling he may stay at Chicago awhile.
There are important problems, he says, that he feels ready to address. For instance? “Tax evasion. Money-laundering. I’d like to put together a set of tools that lets us catch terrorists. I mean, that’s the goal. I don’t necessarily know yet how I’d go about it. But given the right data, I have little doubt that I could figure out the answer.”
It might seem absurd for an economist to dream of catching terrorists. Just as it must have seemed absurd if you were a Chicago schoolteacher, called into an office and told that, ahem, the algorithms designed by that skinny man with thick glasses had determined that you are a cheater. And that you are being fired. Steven Levitt may not fully believe in himself, but he does believe in this: teachers and criminals and real-estate agents may lie, and politicians, and even C.I.A. analysts. But numbers don’t.


“Freakonomics” Columns from the New York Times Magazine
UP IN SMOKE
Whatever happened to crack cocaine?
August 7, 2005
If you rely on the news media for your information, you probably think that crack cocaine is a thing of the past. If you rely on data, however, you reach a different conclusion.
Measuring the use and impact of a drug like crack isn’t easy. There is no government Web site to provide crack data, and surveying dealers is bound to be pretty unreliable. So how can you get to the truth of crack use? One way is to look at a variety of imperfect but plausible proxies, including cocaine arrests, emergency-room visits and deaths. Unlike the volume of news coverage, the rates for all of these remain shockingly high. Cocaine arrests, for instance, have fallen only about 15 percent since the crack boom of the late 1980s. Cocaine-related deaths are actually higher now; so are the number of emergency-room visits due to cocaine. When combined in a sensible way, these proxies can be used to construct a useful index of crack.
And what does this index reveal? That crack use was nonexistent until the early 1980s and spiked like mad in 1985, peaking in 1989. That it arrived early on the West Coast, but became most prevalent in the cities of the Northeast and Middle Atlantic States. And that it produced a remarkable level of gun violence, particularly among young black men, who made up the bulk of street-level crack dealers. During the crack boom, the homicide rate among thirteen-to seventeen-year-old blacks more than quadrupled. But perhaps the biggest surprise in the crack index is the fact that, as of 2000—the most recent year for which the index data are available—Americans were still smoking about 70 percent as much crack as they smoked when consumption was at its peak.
If so much crack is still being sold and bought, why aren’t we hearing about it? Because crack-associated violence has largely disappeared. And it was the violence that made crack most relevant to the middle class. What made the violence go away? Simple economics. Urban street gangs were the main distributors of crack cocaine. In the beginning, demand for their product was phenomenal, and so were the potential profits. Most crack killings, it turns out, were not a result of some crackhead sticking up a grandmother for drug money but rather one crack dealer shooting another—and perhaps a few bystanders—in order to gain turf.
But the market changed fast. The destructive effects of the drug became apparent; young people saw the damage that crack inflicted on older users and began to stay away from it. (One recent survey showed that crack use is now three times as common among people in their late thirties as it is among those in their late teens and early twenties.) As demand fell, price wars broke out, driving down profits. And as the amount of money at stake grew smaller and smaller, the violence also dissipated. Young gang members are still selling crack on street corners, but when a corner becomes less valuable, there is less incentive to kill, or be killed, for it.
So how can it be that crack consumption is still so high? Part of the answer may have to do with geography. The index shows that consumption is actually up in states far from the coasts, like Arizona, Minnesota, Colorado and Michigan. But the main answer lies in the same price shift that made the crack trade less violent. The price has fallen about 75 percent from its peak, which has led to an interesting consumption pattern: there are far fewer users, but they are each smoking more crack. This, too, makes perfect economic sense. If you are a devoted crackhead and the price is one-fourth what it used to be, you can afford to smoke four times as much.
But as crack has matured into a drug that causes less social harm, the laws punishing its sale have stayed the same. In 1986, in the national frenzy that followed the death of Len Bias, a first-round N.B.A. draft pick and a cocaine user, Congress passed legislation requiring a five-year mandatory sentence for selling just five grams of crack; you would have to sell 500 grams of powder cocaine to get an equivalent sentence. This disparity has often been called racist, since it disproportionately imprisons blacks.
In fact, the law probably made sense at the time, when a gram of crack did have far more devastating social costs than a gram of powder cocaine. But it doesn’t anymore. Len Bias would now be forty years old, and he would have long outlived his usefulness to the Boston Celtics. It may be time to acknowledge that the law inspired by his death has done the same.

 
DOES THE TRUTH LIE WITHIN?
One professor’s lifetime of self-experimentation
September 11, 2005
Seth Roberts is a fifty-two-year-old psychology professor at the University of California at Berkeley. If you knew Roberts twenty-five years ago, you might remember him as a man with problems. He had acne, and most days he woke up too early, which left him exhausted. He wasn’t depressed, but he wasn’t always in the best of moods. Most troubling to Roberts, he was overweight: at 5-foot-11, he weighed 200 pounds.
When you encounter Seth Roberts today, he is a clear-skinned, well-rested, entirely affable man who weighs about 160 pounds and looks ten years younger than his age. How did this happen?
It began when Roberts was a graduate student. First he had the clever idea of turning his personal problems into research subjects. Then he decided that he would use his own body as a laboratory. Thus did Roberts embark on one of the longest bouts of scientific self-experimentation known to man—not only poking, prodding and measuring himself more than might be wise but also rigorously recording every data point along the way.
Self-experimentation, though hardly a new idea in the sciences, remains rare. Many modern scientists dismiss it as being not nearly scientific enough: there is no obvious control group, and you can hardly run a double-blind experiment when the researcher and subject are the same person. But might the not-quite-scientific nature of self-experimentation also be a good thing? A great many laboratory-based scientific experiments, especially those in the medical field, are later revealed to have been marred by poor methodology or blatant self-interest. In the case of Roberts, his self-interest is extreme, but at least it is obvious. His methodology is so simple—trying a million solutions until he finds one that works—that it creates the utmost transparency.
In some ways, self-experimentation has more in common with economics than with the hard sciences. Without the ability to run randomized experiments, economists are often left to exploit whatever data they can get hold of. Let’s say you’re an economist trying to measure the effect of imprisonment on crime rates. What you would ideally like to do is have a few randomly chosen states suddenly release 10,000 prisoners, while another few random states lock up an extra 10,000 people. In the absence of such a perfect experiment, you are forced to rely on creative proxies—like lawsuits that charge various states with prison overcrowding, which down the road lead to essentially random releases of large numbers of prisoners. (And yes, crime in those states does rise sharply after the prisoners are released.)
What could be a more opportunistic means of generating data than exploiting your own body? Roberts started small, with his acne, then moved on to his early waking. It took him more than ten years of experimenting, but he found that his morning insomnia could be cured if, on the previous day, he got lots of morning light, skipped breakfast and spent at least eight hours standing.
Stranger yet was the fix he discovered for lifting his mood: at least one hour each morning of TV viewing, specifically life-size talking heads—but never such TV at night. Once he stumbled upon this solution, Roberts, like many scientists, looked back to the Stone Age for explication. Anthropological research suggests that early humans had lots of face-to-face contact every morning but precious little after dark, a pattern that Roberts’s TV viewing now mimicked.
It was also the Stone Age that informed his system of weight control. Over the years, he had tried a sushi diet, a tubular-pasta diet, a five-liters-of-water-a-day diet and various others. They all proved ineffective or too hard or too boring to sustain. He had by now come to embrace the theory that our bodies are regulated by a “set point,” a sort of Stone Age thermostat that sets an optimal weight for each person. This thermostat, however, works the opposite of the one in your home. When your home gets cold, the thermostat turns on the furnace. But according to Roberts’s interpretation of the set-point theory, when food is scarcer, you become less hungry; and you get hungrier when there’s a lot of food around.
This may sound backward, like telling your home’s furnace to run only in the summer. But there is a key difference between home heat and calories: while there is no good way to store the warm air in your home for the next winter, there is a way to store today’s calories for future use. It’s called fat. In this regard, fat is like money: you can earn it today, put it in the bank and withdraw it later when needed.
During an era of scarcity—an era when the next meal depended on a successful hunt, not a successful phone call to Hunan Garden—this set-point system was vital. It allowed you to spend down your fat savings when food was scarce and make deposits when food was plentiful. Roberts was convinced that this system was accompanied by a powerful signaling mechanism: whenever you ate a food that was flavorful (which correlated with a time of abundance) and familiar (which indicated that you had eaten this food before and benefited from it), your body demanded that you bank as many of those calories as possible.
Roberts understood that these signals were learned associations—as dependable as Pavlov’s bell—that once upon a time served humankind well. Today, however, at least in places with constant opportunities to eat, these signals can lead to a big, fat problem: rampant overeating.
So Roberts tried to game this Stone Age system. What if he could keep his thermostat low by sending fewer flavor signals? One obvious solution was a bland diet, but that didn’t interest Roberts. (He is, in fact, a serious foodie.) After a great deal of experimenting, he discovered two agents capable of tricking the set-point system. A few tablespoons of unflavored oil (he used canola or extra light olive oil), swallowed a few times a day between mealtimes, gave his body some calories but didn’t trip the signal to stock up on more. Several ounces of sugar water (he used granulated fructose, which has a lower glycemic index than table sugar) produced the same effect. (Sweetness does not seem to act as a “flavor” in the body’s caloric-signaling system.)
The results were astounding. Roberts lost forty pounds and never gained it back. He could eat pretty much whenever and whatever he wanted, but he was far less hungry than he had ever been. Friends and colleagues tried his diet, usually with similar results. His regimen seems to satisfy a set of requirements that many commercial diets do not: it was easy, built on a scientific theory and, most important, it did not leave Roberts hungry.
In the academic community, Roberts’s self-experimentation has found critics but also serious admirers. Among the latter are the esteemed psychologist Robert Rosenthal, who has praised Roberts for “approaching data in an exploratory spirit more than, or at least in addition to, a confirmatory spirit” and for seeing data analysis “as the opportunity to confront a surprise.” Rosenthal went so far as to envision “a time in the future when ‘self-experimenter’ became a new part-time (or full-time) profession.”
But will Seth Roberts’s strange weight-control solution—he calls it the Shangri-La Diet—really work for the millions of people who need it? We may soon find out. With the Atkins diet company filing for bankruptcy, America is eager for its next diet craze. And a few spoonfuls of sugar may be just the kind of sacrifice that Americans can handle.

 
CURBING YOUR DOG
Can technology keep New York City scooped?
October 2, 2005
Twenty-five hundred tons. That’s how much manure was produced every day by the 200,000 horses that moved people and goods around New York City in the late nineteenth century. Much of the manure went uncollected, which posed a terrible problem. (This is to say nothing of the horse urine, the deafening clatter of hooves or the carcasses left to rot in the street.) The manure was so widespread and smelly and unsanitary that brownstones were built with their entrances on the second floor so that homeowners might rise above it.
Like so many seemingly overwhelming problems, this one was resolved, quite painlessly, by technology. The electric streetcar and then the automobile led to the disappearance of the horses, and with them went their dung.
Most of the animal dung produced in today’s New York comes from our dogs. (Estimates of the dog population vary widely, but one million is a good guess.) All their poop doesn’t just lie there, of course. In 1978, New York enacted its famous (and widely imitated) “pooper scooper” law, and the city is plainly cleaner, poop-wise, than it was. But with a fine of just $50 for the first offense, the law doesn’t provide much financial incentive to pick up after your dog. Nor does it seem to be vigorously enforced. Let’s pretend that 99 percent of all dog owners do obey the law. That still leaves 10,000 dogs whose poop is left in public spaces each day. Over the last year, the city ticketed only 471 dog-waste violations, which suggests that the typical offender stands a roughly 1-in-8,000 chance of getting a ticket. So here’s a puzzle: why do so many people pick up after their dogs? This would seem to be a case in which social incentives—the hard glare of a passer-by and the offender’s feelings of guilt—are at least as powerful as financial and legal incentives.
If social forces get us most of the way there, how do we deal with the occasional miscreant who fails to scoop? After all, a walk through just about any New York neighborhood confirms that compliance with the law is hardly complete. The Parks Department, meanwhile, which conducts regular cleanliness checks of parks and playgrounds, says that dog poop accounts for 20 percent of its “cleanliness failures.” Dog poop is plainly far less of a nuisance than horse manure ever was. But if you are, say, a parent who walks two kids to school every day and tries to keep all three of you from experiencing that telltale soft smush of a misstep, it is a nuisance nonetheless.
With horses, the solution was simply to eliminate them. Might there be a way to get rid of dog poop without getting rid of the dogs? It might help for a moment to think of a dog as if it were a gun. Using laws to eliminate guns has proved extremely difficult. A given gun lasts a very long time, and as with dogs, guns are widely loved. But getting rid of guns should never have been the point of gun control; the point, rather, ought to be getting rid of the misuse of guns—that is, the use of guns in crimes. Consequently, the most successful policies are those that directly punish misuse, like mandatory prison sentences for any crime involving a gun. In California and elsewhere, such measures have substantially reduced gun crime.
Similarly, the problem in New York is not so much with dogs per se. So perhaps attending to the real problem—their poop—will prompt a solution.
Here’s an idea: DNA sampling. During the licensing procedure, every dog will have to provide a sample of saliva or blood to establish a DNA file. Then, whenever a pile of poop is found on the sidewalk, a sample can be taken to establish the offender’s DNA. (Because stomachs and intestinal walls shed so many cells, poop is in fact a robust DNA source; during a murder trial in Indiana in 2002, the defendant was convicted in large part because the dog poop in his sneaker tread linked him to the scene of the crime.) Once the fecal DNA is matched to a given dog’s DNA file, the dog’s owner will be mailed a ticket. It might cost about $30 million to establish a DNA sample for all the dogs of New York. If people stop violating the law, then New York has spent $30 million for cleaner streets; if not, the $30 million is seed money for a new revenue stream.
Unfortunately, there’s a big drawback to this plan. In order to match a pile of poop with its source, you will need to have every dog’s DNA on file—and in 2003, the most recent year on record, only 102,004 dogs in New York were licensed. Even though a license is legally required, costs a mere $8.50 a year and can be easily obtained by mail, most dog owners ignore the law, and with good reason: last year, only 68 summonses were issued in New York City for unlicensed dogs. So even if the DNA plan were enacted today, most offenders would still go unpunished.
In fact, it stands to reason that the typical licensed dog is less likely to offend than the typical unlicensed dog, since the sort of owner who is responsible enough to license his dog is also most likely responsible enough to clean up after it. How, then, to get all of New York’s dogs licensed? Instead of charging even a nominal fee, the city may want to pay people to license their dogs. And then, instead of treating the licensing law as optional, enforce it for real. Setting up random street checks for dog licenses may offend some New Yorkers, but it certainly dovetails nicely with the Giuliani-era “broken windows” approach to low-level crime.
Before you dismiss the entire dog-DNA idea as idiotic—which, frankly, we were about to do the moment it popped into our heads—consider this: it turns out that civic leaders in Vienna and Dresden have recently floated the same idea. (Indeed, one Vienna politician cited Mayor Giuliani as his inspiration.) Closer to home, an eighth-grade girl in Hoboken, New Jersey, has also proposed the DNA solution.
During a meeting last year of the Hoboken City Council, Lauren Mecka, the daughter of a police captain, argued her dog-poop case. “While adults like yourselves are appalled and disgusted by the sight of the uncollected dog poop that adorns our parks and sidewalks,” she said, “it is children like myself and younger who run the greater risk of contact and exposure. We’re the ones who ride our bikes, throw our balls and roll our blades on the city’s sidewalks. And we’re the ones who have our picnics, stage our adventures and carry out our dragon-slaying fantasies on our parks’ grassy lawns.”
The council, Mecka says today, didn’t seem to take her proposal seriously. Why? “They dismissed it, basically, because I was a twelve-year-old kid.”

 
WHY VOTE?
There’s no good economic rationale for going to the polls. So what is it that drives the democratic instinct?
November 6, 2005
Within the economics departments at certain universities, there is a famous but probably apocryphal story about two world-class economists who run into each other at the voting booth.
“What are you doing here?” one asks.
“My wife made me come,” the other says.
The first economist gives a confirming nod. “The same.”
After a mutually sheepish moment, one of them hatches a plan: “If you promise never to tell anyone you saw me here, I’ll never tell anyone I saw you.” They shake hands, finish their polling business and scurry off.
Why would an economist be embarrassed to be seen at the voting booth? Because voting exacts a cost—in time, effort, lost productivity—with no discernible payoff except perhaps some vague sense of having done your “civic duty.” As the economist Patricia Funk wrote in a recent paper, “A rational individual should abstain from voting.”
The odds that your vote will actually affect the outcome of a given election are very, very, very slim. This was documented by the economists Casey Mulligan and Charles Hunter, who analyzed more than 56,000 Congressional and state-legislative elections since 1898. For all the attention paid in the media to close elections, it turns out that they are exceedingly rare. The median margin of victory in the Congressional elections was 22 percent; in the state-legislature elections, it was 25 percent. Even in the closest elections, it is almost never the case that a single vote is pivotal. Of the more than 40,000 elections for state legislator that Mulligan and Hunter analyzed, comprising nearly one billion votes, only seven elections were decided by a single vote, with two others tied. Of the more than 16,000 Congressional elections, in which many more people vote, only one election in the past one hundred years—a 1910 race in Buffalo—was decided by a single vote.
But there is a more important point: the closer an election is, the more likely that its outcome will be taken out of the voters’ hands—most vividly exemplified, of course, by the 2000 presidential race. It is true that the outcome of that election came down to a handful of voters; but their names were Kennedy, O’Connor, Rehnquist, Scalia and Thomas. And it was only the votes they cast while wearing their robes that mattered, not the ones they may have cast in their home precincts.
Still, people do continue to vote, in the millions. Why? Here are three possibilities:
• Perhaps we are just not very bright and therefore wrongly believe that our votes will affect the outcome.
• Perhaps we vote in the same spirit in which we buy lottery tickets. After all, your chances of winning a lottery and of affecting an election are pretty similar. From a financial perspective, playing the lottery is a bad investment. But it’s fun and relatively cheap: for the price of a ticket, you buy the right to fantasize how you’d spend the winnings—much as you get to fantasize that your vote will have some impact on policy.
• Perhaps we have been socialized into the voting-as-civic-duty idea, believing that it’s a good thing for society if people vote, even if it’s not particularly good for the individual. And thus we feel guilty for not voting.
But wait a minute, you say. If everyone thought about voting the way economists do, we might have no elections at all. No voter goes to the polls actually believing that her single vote will affect the outcome, does she? And isn’t it cruel to even suggest that her vote is not worth casting?
This is indeed a slippery slope—the seemingly meaningless behavior of an individual, which, in aggregate, becomes quite meaningful. Here’s a similar example in reverse. Imagine that you and your eight-year-old daughter are taking a walk through a botanical garden when she suddenly pulls a bright blossom off a tree.
“You shouldn’t do that,” you find yourself saying.
“Why not?” she asks.
“Well,” you reason, “because if everyone picked one, there wouldn’t be any flowers left at all.”
“Yeah, but everybody isn’t picking them,” she says with a look. “Only me.”
In the old days, there were more pragmatic incentives to vote. Political parties regularly paid voters $5 or $10 to cast the proper ballot; sometimes payment came in the form of a keg of whiskey, a barrel of flour or, in the case of an 1890 New Hampshire Congressional race, a live pig.
Now as then, many people worry about low voter turnout—only slightly more than half of eligible voters participated in the last presidential election—but it might be more worthwhile to stand this problem on its head and instead ask a different question: considering that an individual’s vote almost never matters, why do so many people bother to vote at all?
The answer may lie in Switzerland. That’s where Patricia Funk discovered a wonderful natural experiment that allowed her to take an acute measure of voter behavior.
The Swiss love to vote—on parliamentary elections, on plebiscites, on whatever may arise. But voter participation had begun to slip over the years (maybe they stopped handing out live pigs there too), so a new option was introduced: the mail-in ballot. Whereas each voter in the U.S. must register, that isn’t the case in Switzerland. Every eligible Swiss citizen began to automatically receive a ballot in the mail, which could then be completed and returned by mail.
From a social scientist’s perspective, there was beauty in the setup of this postal voting scheme: because it was introduced in different cantons (the twenty-six statelike districts that make up Switzerland) in different years, it allowed for a sophisticated measurement of its effects over time.
Never again would any Swiss voter have to tromp to the polls during a rainstorm; the cost of casting a ballot had been lowered significantly. An economic model would therefore predict voter turnout to increase substantially. Is that what happened?
Not at all. In fact, voter turnout often decreased, especially in smaller cantons and in the smaller communities within cantons. This finding may have serious implications for advocates of Internet voting—which, it has long been argued, would make voting easier and therefore increase turnout. But the Swiss model indicates that the exact opposite might hold true.
Why is this the case? Why on earth would fewer people vote when the cost of doing so is lowered?
It goes back to the incentives behind voting. If a given citizen doesn’t stand a chance of having her vote affect the outcome, why does she bother? In Switzerland, as in the U.S., “there exists a fairly strong social norm that a good citizen should go to the polls,” Funk writes. “As long as poll-voting was the only option, there was an incentive (or pressure) to go to the polls only to be seen handing in the vote. The motivation could be hope for social esteem, benefits from being perceived as a cooperator or just the avoidance of informal sanctions. Since in small communities, people know each other better and gossip about who fulfills civic duties and who doesn’t, the benefits of norm adherence were particularly high in this type of community.”
In other words, we do vote out of self-interest—a conclusion that will satisfy economists—but not necessarily the same self-interest as indicated by our actual ballot choice. For all the talk of how people “vote their pocketbooks,” the Swiss study suggests that we may be driven to vote less by a financial incentive than a social one. It may be that the most valuable payoff of voting is simply being seen at the polling place by your friends or co-workers.
Unless, of course, you happen to be an economist.

 
THE ECONOMY OF DESIRE
Can fear of AIDS change sexual preference?
December 11, 2005
What is a price?
Unless you’re an economist, you probably think of a price as simply the amount you pay for a given thing—the number of dollars you surrender for, let’s say, Sunday brunch at your favorite neighborhood restaurant. But to an economist, price is a much broader concept. The 20 minutes you spend waiting for a table is part of the price. So, too, is any nutritional downside of the meal itself: a cheeseburger, as the economist Kevin Murphy has calculated, costs $2.50 more than a salad in long-term health implications. There are moral and social costs to tally as well—for instance, the look of scorn delivered by your vegan dining partner as you order the burger. While the restaurant’s menu may list the price of the cheeseburger at $7.95, that is clearly just the beginning.
The most fundamental rule of economics is that a rise in price leads to less quantity demanded. This holds true for a restaurant meal, a real-estate deal, a college education or just about anything else you can think of. When the price of an item rises, you buy less of it (which is not to say, of course, that you want less of it).
But what about sex? Sex, that most irrational of human pursuits, couldn’t possibly respond to rational price theory, could it?
Outside of a few obvious situations, we generally don’t think about sex in terms of prices. Prostitution is one such situation; courtship is another: certain men seem to consider an expensive dinner a prudent investment in pursuit of a sexual dividend.
But how might price changes affect sexual behavior? And might those changes have something to tell us about the nature of sex itself?
Here is a stark example: A man who is sent to prison finds that the price of sex with a woman has spiked—talk about a supply shortage—and he becomes much more likely to start having sex with men. The reported prevalence of oral sex among affluent American teenagers would also seem to illustrate price theory: because of the possibility of disease or pregnancy, intercourse is expensive—and it has come to be seen by some teenagers as an unwanted and costly pledge of commitment. In this light, oral sex may be viewed as a cheaper alternative.
In recent decades, we have witnessed the most exorbitant new price associated with sex: the H.I.V. virus. Because AIDS is potentially deadly and because it can be spread relatively easily by sex between two men, the onset of AIDS in the early 1980s caused a significant increase in the price of gay sex. Andrew Francis, a graduate student in economics at the University of Chicago, has tried to affix a dollar figure to this change. Setting the value of an American life at $2 million, Francis calculated that in terms of AIDS-related mortality, it cost $1,923.75 in 1992 (the peak of the AIDS crisis) for a man to have unprotected sex once with a random gay American man versus less than $1 with a random woman. While the use of a condom greatly reduces the risk of contracting AIDS, a condom is, of course, yet another cost associated with sex. In a study of Mexican prostitution, the Berkeley economist Paul Gertler and two co-authors showed that when a client requested sex without a condom, a prostitute was typically paid a 24 percent premium over her standard fee.
Francis, in a draft paper titled “The Economics of Sexuality,” tries to go well beyond dollar figures. He puts forth an empirical argument that may fundamentally challenge how people think about sex.
As with any number of behaviors that social scientists try to measure, sex is a tricky subject. But Francis discovered a data set that offered some intriguing possibilities. The National Health and Social Life Survey, sponsored by the U.S. government and a handful of foundations, asked almost 3,500 people a rather astonishing variety of questions about sex: the different sexual acts received and performed and with whom and when; questions about sexual preference and identity; whether they knew anyone with AIDS. As with any self-reported data, there was the chance that the survey wasn’t reliable, but it had been designed to ensure anonymity and generate honest replies.
The survey was conducted in 1992, when the disease was much less treatable than it is today. Francis first looked to see if there was a positive correlation between having a friend with AIDS and expressing a preference for homosexual sex. As he expected, there was. “After all, people pick their friends,” he says, “and homosexuals are more likely to have other homosexuals as friends.”
But you don’t get to pick your family. So Francis next looked for a correlation between having a relative with AIDS and expressing a homosexual preference. This time, for men, the correlation was negative. This didn’t seem to make sense. Many scientists believe that a person’s sexual orientation is determined before birth, a function of genetic fate. If anything, people in the same family should be more likely to share the same orientation. “Then I realized, Oh, my God, they were scared of AIDS,” Francis says.
Francis zeroed in on this subset of about 150 survey respondents who had a relative with AIDS. Because the survey compiled these respondents’ sexual histories as well as their current answers about sex, it allowed Francis to measure, albeit crudely, how their lives may have changed as a result of having seen up close the costly horrors of AIDS.
Here’s what he found: Not a single man in the survey who had a relative with AIDS said he had had sex with a man in the previous five years; not a single man in that group declared himself to be attracted to men or to consider himself homosexual. Women in that group also shunned sex with men. For them, rates of recent sex with women and of declaring homosexual identity and attraction were more than twice as high as those who did not have a relative with AIDS.
Because the sample size was so small—simple chance suggests that no more than a handful of men in a group that size would be attracted to men—it is hard to reach definitive conclusions from the survey data. (Obviously, not every single man changes his sexual behavior or identity when a relative contracts AIDS.) But taken as a whole, the numbers in Francis’s study suggest that there may be a causal effect here—that having a relative with AIDS may change not just sexual behavior but also self-reported identity and desire.
In other words, sexual preference, while perhaps largely predetermined, may also be subject to the forces more typically associated with economics than biology. If this turns out to be true, it would change the way that everyone—scientists, politicians, theologians—thinks about sexuality. But it probably won’t much change the way economists think. To them, it has always been clear: whether we like it or not, everything has its price.

 
HOODWINKED?
Does it matter if an activist who exposes the inner workings of the Ku Klux Klan isn’t open about how he got those secrets?
January 8, 2006
Our book Freakonomics includes a chapter titled “How Is the Ku Klux Klan Like a Group of Real-Estate Agents?” This chapter was our effort to bring to life the economic concept known as information asymmetry, a state wherein one party to a transaction has better information than another party. It is probably obvious that real-estate agents typically have better information than their clients. The Klan story was perhaps less obvious. We argued that the Klan’s secrecy—its rituals, made-up language, passwords and so on—formed an information asymmetry that furthered its aim of terrorizing blacks and others.
But the Klan was not the hero of our story. The hero was a man named Stetson Kennedy, a white Floridian from an old-line family who from an early age sought to assail racial and social injustices. Out of all of his crusades—for unionism, voting rights and numberless other causes—Kennedy is best known for taking on the Klan in the 1940s. In his book The Klan Unmasked (originally published in 1954 as I Rode with the Ku Klux Klan), Kennedy describes how he adopted a false identity to infiltrate the Klan’s main chapter in Atlanta, was chosen to serve as a “klavalier” (a Klan strong-arm man) and repeatedly found himself at the center of astonishing events, all the while courting great personal risk.
What did Kennedy do with all the secret Klan information he gathered? He disseminated it like mad: to state prosecutors, to human rights groups and even to broadcasters like Drew Pearson and the producers of the Superman radio show, who publicly aired the Klan’s heretofore hidden workings. Kennedy took an information asymmetry and dumped it on its head. And in doing so, we wrote, he played a significant role in quashing the renaissance of the Klan in postwar America.
Kennedy has been duly celebrated for his activism: his friend Woody Guthrie once wrote a song about him, and a Stetson Kennedy Day was recently declared in St. John’s County, Florida, where Kennedy, eighty-nine, still lives. That is where we interviewed him nearly two years ago; our account of his amazing true story was based on those interviews, The Klan Unmasked and a small mountain of history books and newspaper articles.
But is Kennedy’s story as true as it is amazing?
That was the disturbing question that began to haunt another Florida author, Ben Green, who in 1992 began writing a book about Harry T. Moore, a black civil rights advocate who was murdered in1951. For a time, Stetson Kennedy was a collaborator on the book. Although Green was only tangentially interested in Kennedy’s Klan infiltration—it wasn’t central to the Moore story—he eventually checked out Kennedy’s voluminous archives, held in libraries in New York and Atlanta.
These papers charted the extraordinarily colorful life of a man who had been, among other things, a poet, a folklorist, a muckraking journalist and a union activist. But Green was dismayed to find that the story told in Kennedy’s own papers seemed to be quite different from what Kennedy wrote in The Klan Unmasked.
In The Klan Unmasked, Kennedy posed as an encyclopedia salesman named John S. Perkins who, in one of his first undercover maneuvers, visits the former governor of Georgia—a reputed Klan sympathizer—and ingratiates himself by offering to distribute some hate literature. A document in Kennedy’s archives, however, suggests that Kennedy had indeed met the ex-governor, but not in any undercover capacity. Rather, he had interviewed him for a book he was writing—nor did this document mention any hate literature.
A close examination of Kennedy’s archives seems to reveal a recurrent theme: legitimate interviews that he conducted with Klan leaders and sympathizers would reappear in The Klan Unmasked in different contexts and with different facts. In a similar vein, the archives offer evidence that Kennedy covered public Klan events as a reporter but then recast them in his book as undercover exploits. Kennedy had also amassed a great deal of literature about the Klan and other hate groups that he joined, but his own archives suggest that he joined most of these groups by mail.
So did Kennedy personally infiltrate the Klan in Atlanta, as portrayed in The Klan Unmasked?
In his archives are a series of memos that were submitted to the Anti-Defamation League, one of several civil rights groups to which Kennedy reported. Some of the memos were written by him; others were written by a man identified as John Brown, a union worker and former Klan official who had changed his ways and offered to infiltrate the Klan. “This worker is joining the Klan for me,” Kennedy wrote in one memo in early 1946. “I am certain that he can be relied on.”
In Kennedy’s subsequent memos—indeed, in hundreds of pages of Kennedy’s various correspondence from the era—he matter-offactly attributed some of his most powerful Klan information to John Brown: one of the memos he declared “a report from my informant inside the Klan on the meeting of Atlanta Klan No. 1 on August 12 and Atlanta Klan No. 297 on August 15.” As John Brown fed inside information to Kennedy, Kennedy would then relay it to groups like the A.D.L., as well as to prosecutors and journalists. It wasn’t until he wrote The Klan Unmasked, several years later, that Kennedy placed himself, Zelig-like, at the center of all the action.
Ben Green, despite months spent immersed in Kennedy’s archives, could not identify the man once known as John Brown. Green did manage to interview Dan Duke, a former state prosecutor who, as rendered in The Klan Unmasked, worked closely with Kennedy. Duke agreed that Kennedy “got inside of some [Klan] meetings” but openly disputed Kennedy’s dramatized account of their relationship. “None of that happened,” he told Green. In 1999, when Green finally published his Harry T. Moore book, Before His Time, it contained a footnote labeling The Klan Unmasked “a novelization.”
Green is not the only person to have concluded that Kennedy has bent the truth. Jim Clark, who teaches history at the University of Central Florida, says that Kennedy “built a national reputation on many things that didn’t happen.” Meredith Babb, director of the University Press of Florida, which has published four of Kennedy’s books, now calls Kennedy “an entrepreneurial folklorist.” But except for Green’s footnote, they all kept quiet until the retelling of Kennedy’s exploits in Freakonomics produced a new round of attention. Why? “It would be like killing Santa Claus,” Green says. “To me, the saddest part of this story is that what he actually did wasn’t enough for him, and he has felt compelled to make up, embellish or take credit for things he didn’t do.”
When presented with documents from his own archives and asked outright, several weeks ago over lunch near his Florida home, if The Klan Unmasked was “somewhat conflated or fictionalized,” Kennedy said no. “There may have been a bit of dialogue that was not as I remembered it,” he answered. “But beyond that, no.” When pressed, Kennedy did concede that “in some cases I took the reports and actions of this other guy and incorporated them into one narrative.” As it turns out, Kennedy has made such an admission at least once before. Peggy Bulger, director of the American Folklife Center in the Library of Congress, wrote a 1992 dissertation called “Stetson Kennedy: Applied Folklore and Cultural Advocacy,” based in part on extensive interviews with her subject. In an endnote, Bulger writes that “Kennedy combined his personal experiences undercover with the narratives provided by John Brown in writing ‘I Rode with the Ku Klux Klan’ in 1954.”
We weren’t very happy, of course, to learn that a story we included in Freakonomics was built on such shaky foundations—especially since the book is devoted to upending conventional wisdoms rather than reinforcing them, and concerning Stetson Kennedy, the most conventional wisdom of all is his reputation as a Klan infiltrator.
There is also the fact that in our work we make a point of depending less on anecdote in favor of data, the idea being that numbers tend to lie less baldly than people do. But the story of Stetson Kennedy was one long series of anecdotes—which, no matter how many times they were cited over the decades, were nearly all generated by the same self-interested source.
Perhaps Kennedy’s long life of fighting the good fight is all that matters. Perhaps, to borrow Peggy Bulger’s phraseology, a goal of “cultural advocacy” calls for the use of “applied folklore” rather than the sort of forthrightness that should be more typical of history or journalism. One thing that does remain true is that Kennedy was certainly a master of information asymmetry. Until, that is, the data caught up with him.

 
FILLING IN THE TAX GAP
Why Americans should be clamoring for the I.R.S. to do more audits, not fewer
April 2, 2006
This is the time of year when American citizens inevitably think about the Internal Revenue Service and, also inevitably, about how deeply they hate it. But most people who hate the I.R.S. probably do so for the wrong reasons. They think it is a tough and cruel agency, but in fact it is not nearly as tough and cruel as it should be.
The first thing to remember is that the I.R.S. doesn’t write the tax code. The agency is quick to point its finger at the true villain: “In the United States, the Congress passes tax laws and requires taxpayers to comply,” its mission statement says. “The I.R.S. role is to help the large majority of compliant taxpayers with the tax law, while ensuring that the minority who are unwilling to comply pay their fair share.”
So the I.R.S. is like a street cop or, more precisely, the biggest fleet of street cops in the world, who are asked to enforce laws written by a few hundred people on behalf of a few hundred million people, a great many of whom find these laws too complex, too expensive and unfair.
And yet most Americans say they are proud to pay their taxes. In an independent poll conducted last year for the I.R.S. Oversight Board, 96 percent of the respondents agreed with the statement “It is every American’s civic duty to pay their fair share of taxes,” while 93 percent agreed that everyone “who cheats on their taxes should be held accountable.” On the other hand, when asked what influences their decision to report and pay taxes honestly, 62 percent answered “fear of an audit,” while 68 percent said it was the fact that their income was already being reported to the I.R.S. by third parties. For all the civic duty floating around, it would seem that most compliance is determined by good old-fashioned incentives.
So which of these incentives work and which do not? To find out, the I.R.S. conducted the National Research Program, a three-year study during which 46,000 randomly selected 2001 tax returns were intensively reviewed. (The I.R.S. doesn’t specify what these 46,000 people were subjected to, but it may well have been the kind of inquisition that has earned the agency its horrid reputation.) Using this sample, the study found a tax gap—the difference between taxes owed and taxes actually paid—of $345 billion, or nearly one-fifth of all taxes collected by the I.R.S. This sum happens to be just a few billion dollars less than the projected federal budget deficit for 2007; it also amounts to more than $1,000 worth of cheating by every man, woman and child in the United States.
But most people aren’t cheating. And when you take a look at who does cheat and who doesn’t, it becomes pretty clear just why people pay their taxes at all. The key statistic in the I.R.S.’s study is called the Net Misreporting Percentage. It measures the amount that was misreported on every major line item on those 46,000 returns. In the “wages, salaries, tips” category, for instance, Americans are underreporting only 1 percent of their actual income. Meanwhile, in the “nonfarm proprietor income” category—think of self-employed workers like a restaurateur or the boss of a small construction crew—57 percent of the income goes unreported. That’s $68 billion in unpaid taxes right there.
Why such a huge difference between the wage earner and a restaurateur? Simple: The only person reporting the restaurateur’s income to the I.R.S. is the restaurateur himself; for the wage earner, his employer is generating a W2 to let the I.R.S. know exactly how much he has been paid. And the wage earner’s taxes are automatically withheld from his every check, while the restaurateur has all year to decide if, and how much, he will pay.
Does this mean that the average self-employed worker is less honest than the average wage earner? Not necessarily. It’s just that he has much more incentive to cheat. He knows that the only chance the I.R.S. has of learning his true income and expenditures is to audit him. And all he has to do is look at the I.R.S.’s infinitesimal audit rate—last year, the agency conducted face-to-face audits on just 0.19 percent of all individual taxpayers—to feel pretty confident to go ahead and cheat.
So why do people really pay their taxes: because it is the right thing to do, or because they fear getting caught if they don’t? It sure seems to be the latter. A combination of good technology (employer reporting and withholding) and poor logic (most people who don’t cheat radically overestimate their chances of being audited) makes the system work. And while it sounds bad to hear that Americans underpay their taxes by nearly one-fifth, the tax economist Joel Slemrod estimates that the U.S. is easily within the upper tier of worldwide compliance rates.
Still, unless you are personally cheating by one-fifth or more, you should be mad at the I.R.S.—not because it’s too vigilant, but because it’s not nearly vigilant enough. Why should you pay your fair share when the agency lets a few hundred billion dollars of other people’s money go uncollected every year?
The I.R.S. itself would love to change this dynamic. In the past few years, it has significantly increased its enforcement revenue and its audit rate, despite a budget that is only fractionally larger. A main task of any I.R.S. commissioner (the current one is Mark Everson) is to beg Congress and the White House for resources. For all the obvious appeal of having the I.R.S. collect every dollar owed to the government, it is just as obviously unappealing for most politicians to advocate a more vigorous I.R.S. Michael Dukakis tried this during his 1988 presidential campaign, and—well, it didn’t work.
Left to enforce a tax code no one likes upon a public that knows it can practically cheat at will, the I.R.S. does its best to fiddle around the edges. Once in a while, it hits pay dirt.
In the early 1980s, an I.R.S. research officer in Washington named John Szilagyi had seen enough random audits to know that some taxpayers were incorrectly claiming dependents for the sake of an exemption. Sometimes it was a genuine mistake (a divorced wife and husband making duplicate claims on their children), and sometimes the claims were comically fraudulent (Szilagyi recalls at least one dependent’s name listed as Fluffy, who was quite obviously a pet rather than a child).
Szilagyi decided that the most efficient way to clean up this mess was to simply require taxpayers to list their children’s Social Security numbers. “Initially, there was a lot of resistance to the idea,” says Szilagyi, now 66 and retired to Florida. “The answer I got was that it was too much like ‘1984.’” The idea never made its way out of the agency.
A few years later, however, with Congress clamoring for more tax revenue, Szilagyi’s idea was dug up, rushed forward and put into law for tax year 1986. When the returns started coming in the following April, Szilagyi recalls, he and his bosses were shocked: seven million dependents had suddenly vanished from the tax rolls, some incalculable combination of real pets and phantom children. Szilagyi’s clever twist generated nearly $3 billion in revenues in a single year.
Szilagyi’s immediate bosses felt he should get some kind of reward for his idea, but their superiors weren’t convinced. So Szilagyi called his congressman, who got the reward process back on track. Finally, five years after his brainstorm became the law, Szilagyi, who earned about $80,000 annually at the time, was given a check for $25,000. By this point, his idea had generated roughly $14 billion.
Which suggests at least one legitimate reason to dislike the I.R.S.: if the agency hadn’t been so stingy with Szilagyi’s reward back then, it probably would have attracted a lot more of the anti-cheating wizards it really needs today.


From the Freakonomics Blog
The following excerpts are inevitably pockmarked with incomplete thoughts (at the very least), since blog writing is by nature more impetuous, more colloquial, even more random than what one would write in a book or a newspaper. But hopefully such casual discourse provides its own sort of value. The excerpts here have been slightly edited, mostly to compensate for the fact that, unlike a website, a book that is printed on paper, cannot (yet) allow you to click here to read further. The excerpts are divided into four categories:
• Ruminations on Freakonomics itself, and its aftermath
• A continuation of the abortion/crime discussion presented in Freakonomics
• Random reflections on random subjects, most of them related to Freakonomics in some loose way—in the way, perhaps, that “kosher style” food isn’t quite kosher but also isn’t shrimp
• Rants and raves of a more personal nature
These postings represent perhaps 3 percent of what we’ve written on our blog since it began, and we haven’t included any readers’ comments, which are often far more involved (and entertaining) than our own posts. The entire blog can be found at www.freakonomics.com/ blog/.
Another major difference between the blog and our book is that all but the first two excerpts that follow were written by one of us, not both of us, and are accordingly notated with a signoff of either “SDL” (Levitt) or “SJD” (Dubner).
1. ON FREAKONOMICS ITSELF
A brief compendium of thoughts about how the book was written, published, and received.
“Unleashing Our Baby”
Every parent thinks he has the most beautiful baby in the world. Evolution, it seems, has molded our brains so that if you stare at your own baby’s face day after day after day, it starts to look beautiful. When other people’s children have food clotted on their faces, it looks disgusting; with your own kid, it’s somehow endearing.
Well, we’ve been staring at the Freakonomics manuscript so much that it now looks beautiful to us—warts, clotted food, and all. So we started to think that maybe some people would actually want to read it, and after reading it, might even want to express their opinions about it. Thus, the birth of this website. We hope it’s a happy (or at least happily contentious) home for some time to come.
—SDL & SJD (March 30, 2005)
“Does Freakonomics Suck?”
Our publisher has been busily promoting and selling Freakonomics—which, of course, is its job, and which we, not surprisingly, applaud. When something good happens—a nice review in the Wall Street Journal, for instance, or an upcoming appearance on The Daily Show with Jon Stewart—the publisher assiduously spreads the word. But we think it’s worth considering some alternative views. That, after all, is the spirit of Freakonomics—examining the data, whatever it may be, and following it through, wherever that may lead. So here are some people who think that Freakonomics is, in part or in sum, a big fat stink bomb:
Felix Salmon, a journalist and blogger, wrote a lengthy and exasperated review calling Freakonomics “a series of disjointed chapters” in which “Levitt and Dubner like to get holier-than-thou” and “lap up the conventional wisdom” Steve Sailer, who has vigorously argued against the link between Roe v. Wade and falling crime (a Google search of “Sailer” and “Freakonomics” will turn up a wide variety of comments); a Newsday review (Apr. 24, 2005), by Scott McLemee, which chided the book’s “style of evasive lucidity” a review in Time magazine (May 2, 2005), by Amanda Ripley, who writes that the “unfortunately titled Freakonomics” has “no unifying theory … which is a shame.” In fairness to ourselves, we should note that both the Time and Newsday reviews were largely positive. But we should also note that one well-known American writer of non-fiction, when sent an early copy of Freakonomics for a blurb, refused to endorse it on the grounds that “the one thing missing from the section on crime is a sense of humility.”
Do these comments make us unhappy? On a personal level, sure. But on a Freakonomics level, no. Years ago, the Harvard law professor Alan Dershowitz opened a kosher deli in Harvard Square, which came under protest on various grounds. Dershowitz, known as much for his embrace of free speech as his legal acumen, said—and here we are paraphrasing loosely at best—that nothing was more precious to him than the right of people to protest his deli.
So please don’t take our word that Freakonomics is a good book. Don’t believe the good reviews either. Feel free to make up your own mind—you can poke around a good bit here, on this very website. Maybe you will decide that Freakonomics is, after all, a piece of trash. We cherish your right to think so.
—SDL & SJD (April 26, 2005)
“A Freakonomics Roundtable”
There has been a lot written about Freakonomics, but in terms of thoughtfulness, nothing matches the collection of essays assembled at the blog Crooked Timber (http://crookedtimber.org/2005/05/23/ steven-levitt-seminar-introduction/). There you will find five discussions of Freakonomics done by academics from a range of disciplines, along with my response to these essays.
I’ve also cut and pasted my response here, which basically makes sense even if you haven’t read the original essays.
Let’s start with the title. Freakonomics. We debated endlessly over the title. From a naming perspective, the difficulty with this book is that it doesn’t have a theme. We thought about a question title (“What Do Sumo Wrestlers and Schoolteachers Have in Common?”), some non-threatening titles (“The Hidden Side of Everything” or “Ain’t Necessarily So”), and some loopy titles (“E-Ray Vision,” with the “E” standing for economics).
In the end, though, Freakonomics became the obvious choice, for reasons anchored in the contrast between my own research on first names and that of others. Let’s just assume that my research is right and it is really true that a name on a résumé does matter for getting a job callback, but not for long-term life outcomes. This probably implies that names matter a little for first impressions, but then quickly get swept aside in importance once we gain some familiarity. When’s the last time you thought to yourself, Oprah is a ridiculous name, I certainly won’t watch her show? Or, The Beatles…what a ridiculous name for a band. No one would ever buy their records.
In naming a book, you need something attention-grabbing to cut through the clutter of the thousands of competing books, but as shocking as Freakonomics sounds the first time you hear it, by the twentieth time it becomes familiar, like Oprah. My guess is that the Crooked Timber commenters were already softening their hatred for the title by the time they finished writing. And a year from now, they may even forget that they ever hated the title. At least, that is what happened with our publisher, which initially dismissed the title out of hand, only allowed it at the eleventh hour, and now are telling us we need to sign up with them for a second book because no one else can market our books as well as they do. And if there is a second book, we have a title in mind that is so outrageous it will have to be loved.
So how about the absence of a unifying theme in the book? My own hunch, borne out by the public response to this book, is that nobody really cares about or even wants a unifying theme in a book. Everyone is just afraid not to have one, since almost all books do. (In this respect, I think unifying themes in books are a lot like campaign spending: all candidates feel compelled to spend a lot of money for fear of the disastrous consequences that could result if they take a chance and don’t spend, spend, spend.) But when I read Malcolm Gladwell’s incredible books, I don’t care about the theme, I just love his stories. His books top the charts because he has really good taste and he is the best storyteller going. For me, and others I talk to, the unifying themes sometimes get in the way of his stories which are individually so amazingly interesting. Books of short stories, similarly, have no unifying theme. I certainly don’t feel cheated by that either. More valuable than anything else I or Dubner ever does, perhaps, would be to make the world safe for books that have great stories but no unifying theme.
All of the Crooked Timber commentaries spent some time discussing where I fit into economics and the social sciences more broadly. If I got to make three wishes, perhaps one of them would be that I might turn into a truly interdisciplinary social scientist who uses data to inform human behavior in ways that both shed light on and draw upon not only economics, but sociology, political science, and psychology as well. But let’s be realistic. I’m having trouble even mastering the tools of my own discipline. If you ask my students whether I know calculus, they will say “not very well.” I’m not proud of that fact, but I am a realist. If you ask the really great economic thinkers like Gary Becker or Kevin Murphy how often I’m right when I try to apply Chicago price theory, they will simply tell you that I am showing a lot of improvement, because they are kind. The only things I’m good at, really and honestly, are asking questions that people seem to find interesting, and figuring out how to trick data into answering those questions. I will never be even a passable sociologist, political scientist, or psychologist. But that is okay. I think the thing that gets a lot of economists into trouble is the false belief that they can be good at everything.
A few years back, when I was on sabbatical at the Center for Advanced Study of Behavioral Sciences at Stanford, I gave a talk to the other fellows on my research. Some in the audience were indignant, asking why I called myself an economist given what I did. They said I was really a sociologist. One only had to look at the horror on the faces of the sociologists in the room to see that I wasn’t a sociologist either. But by starting from the position that I don’t know much, I am open-minded enough to co-author with an ethnographer (Sudhir Venkatesh), an econometrician ( Jack Porter), a political scientist (Tim Groseclose), and now a journalist (Stephen Dubner). And maybe, in addition to making it safe in the future for someone to publish a book without a theme, I will make it easier for academics from all social sciences to follow the sort of “adisciplinary” (as opposed to interdisciplinary) path I’m on.
Next, there is the question of incentives. In the same way that “utility maximization” can be turned into a tautology, the commenters point out that our use of the term “incentives” is moving in that direction as well. By widening incentives, as we did in Freakonomics, to encompass not only financial but also social and moral incentives, we have covered just about everything. Still, I think there isn’t really another choice. To focus just on financial incentives would obviously be misguided. On the flip side, for me—and I think this is the thing that makes me an economist ultimately—I just can’t get away from the idea that people are active decision makers trying to get what they want in a reasonably sophisticated fashion. The most real sense in which I think incentives are the unifying theme of my research (even in cases where they aren’t obviously present, as in the abortion-crime stuff ) is that whenever I try to answer a question, I put myself in the shoes of the actors and I ask myself, “What would I do if I were in that situation?” I am the kind of person who is always trying to concoct some scheme to beat the system or avoid getting scammed, so I presume the people I’m studying are thinking the same way. So when I think about legalized abortion, I think it sounds like a really sick form of insurance policy against an unwanted pregnancy. When I see that one sumo wrestler has more to gain from a win than the other foregoes by losing, I figure they’ll make a deal. When I think about real-estate agents, I’m constantly paranoid they are trying to screw me.
I am the first to admit that if all economists were like me, the field would probably be a disaster. But the fact that other economists more or less like me in spite of this fact tells me that there is plenty more room for rogue economists in the profession.
—SDL (May 23, 2005)
“Our California Trip”
Last week, we went to California. Our publisher, William Morrow/HarperCollins, had determined that Freakonomics wasn’t selling as well there as elsewhere. It may have been a simple case of late adoption—Levitt and I are based in Chicago and New York, respectively, two cities where the book started strong—but Harper was taking no chances. So, having to this point avoided anything resembling a book tour, we were shipped west for three days. This was more of a hardship for Levitt than for me. He hates human interaction (or so he says). Our first day there, in L.A., he constantly claimed to be feeling suicidal. But he said this casually, and with a bit of a smile. I felt like Mandy Patinkin in The Princess Bride, when he tells Wally Shawn, “I don’t think that word means what you think it means.” But hey: Levitt is more of a numbers guy than a word guy. Maybe what he meant was “homicidal.”
On the final day, we visited Google headquarters in Mountain View. The Google folks later asked us to write up our impressions, to be posted on the Google blog. Here’s what we had to say:
To: All Googlers
From: The Freakonomics Guys
Date: Aug. 4, 2005
Re: Our visit last week
We didn’t know quite what to expect at Google. A few months ago, we had been invited to give some kind of presentation at Google while we were in California. Were we interested? Sure, we said. When something is that far away, you’ll generally agree to it without much thought.
Because we got to the Googleplex late—we were coming from a meeting with some people who may want to turn Freakonomics into a board game (!)—our tour was cut a little short. Still, we did manage to see:
• —Your Google-logo-colored pylons at the extremely low-key “security” post.
• —Your very user-friendly name-tag-generating/sign-in computer.
• —Your very, very fancy toilets.
• —Your rack of primordial servers with the thin layers of cork that used to make the fire department so nervous.
• —Your roaming dogs, one friendlier than the next.
• —Your beautiful scrolling query screens, which are a great piece of conceptual art: Hilary Duff…pits puppies…Yenifer Lopez…Spanish Dictionary. (We were a little disappointed to not catch a glimpse of “Freakonomics” but maybe it got caught in your filter: people sometimes give it some pretty deviant spellings.)
• —Your quartz rug, robust cacti, fancy yurts, and ecologically sound staircase in the Africa building.
Then it was time for our “presentation.” Our guide, Hunter Walk, walked us over to the room where we’d be speaking: Whomp! It wasn’t some little room, with a conference table and a couple dozen people, as we’d imagined. It was a big big room, rows and rows of chairs, all of them filled with Googlers, and many many more Googlers sitting on the floor and standing in the back and—well, not exactly hanging from the rafters but it felt like it. The walls were black, the stage lights white-hot, the room alive with chatter. This wasn’t a presentation; this was a presentation. It was a Sally Field moment: They like us! They really like us! (We realize, of course, that the average Googler is far too young to catch this reference. Don’t worry; it’s not very funny anyway.) As we picked our way through the floor-sitting Googlers, it felt like we should have been carrying a couple of Telecasters; it was likely the closest that either of us will ever get to having a rock-star moment. (In truth, I was a minor-league rock star but that was in the late 1980s, so it doesn’t really count.)
The other thing is, Hunter had ordered a few hundred copies of Freakonomics from Amazon* and passed them around, so now, looking across the long rows of chairs, you could see one Googler after the next with the open book in his/her lap, as if preparing to hear a speech from Chairman Mao. It was, well, freaky. A bit like happening upon your own funeral.
We had to talk things over to decide what kind of talk to give. We are not very practiced at this. Hunter was encouraging, and patient. There was one podium and one microphone, so we decided to do a tag-team talk, to discuss the book (why crack dealers still live with their moms, e.g.) and to tell a few stories based on research that’s happened since the book (monkey prostitution at Yale, e.g.). We seemed to do okay, based on the fact that you all laughed a lot, although it’s quite possible you were just laughing at us. The biggest laugh came when Levitt mentioned that we spoke at Yahoo! a day earlier, and got a much smaller crowd. The funny thing is, that was really true. Your turnout was about double Yahoo!’s. On the other hand, that means Google may have lost twice the productivity—unless you think that our Freakonomics talk may have somehow increased productivity, in which case you thought a lot more of it than we did. The best question of the day was this: “What would you do with our data if we could give it to you?” Believe us, we’ve thought about that quite a bit. We’ll get back to you.
After our talk, we had a few minutes to hang around and talk with miscellaneous Googlers. This was the most impressive slice of the day. Not only were you all smart and inquisitive and friendly, but you were so damn happy. First of all, there is surely no company in the world where so many employees wear T-shirts with their company logo, which we took to be a sign of true pride (or perhaps simply a deep, deep discount). But the happiness shone through in a dozen other ways. It seems this is the by-product of doing interesting work with smart colleagues in beautiful environs, all with a profound sense of mission. A $297 stock price probably doesn’t hurt, either.
—SJD (Aug. 19, 2005)
2. ROE V. WADE AND CRIME, CONT’D.
Of all the topics covered in Freakonomics, one would have thought that the theory linking the legalization of abortion to a drop in crime would have engendered the most hate mail. But that wasn’t the case at all. It seems that when people read for themselves the argument as laid out in chapter 4, and see that it isn’t a remotely political or religious argument, they weigh for themselves how they feel about the theory and seldom resort to an overheated defense of their beliefs, wherever those beliefs may lie.
The same cannot be said for some of the other stories in the book. The study about real-estate agents, for instance, provoked hundreds of angry e-mails, most of them from Realtors who were unhappy with our description of how the incentive structure of their business encourages agents to exploit their own clients. There were also plenty of e-mails from teachers who didn’t like hearing about teachers who cheat; from parents who couldn’t accept some of our conclusions about parenting; and from readers who thought the entire chapter on first names was downright idiotic.
But if the abortion-crime story didn’t produce much reader outrage, it certainly did resonate in the media and elsewhere. This was never more true than when William Bennett cited the book in the process of creating a huge racial controversy for himself. Here are two blog postings addressing different elements of the abortion-crime debate. The first is an assessment of Bennett’s statements. The second is a response to an academic challenge to the abortion-crime theory; it is fairly technical (the faint of heart may wish to read just the last three paragraphs), but key to understanding the original research.
“Bill Bennett and Freakonomics”
Bill Bennett and I have a fair amount in common. We’ve both written about crime (his “superpredator” theory gets a quick discussion in Freakonomics), we have both thought a lot about illegal drugs and education (he was the original “drug czar” and is a former secretary of education), and we both love to gamble (although it seems I do it for much lower stakes and perhaps with greater success).
Now we also share the fact that we have made controversial statements about the link between abortion and crime.
Here’s what Bennett said during the Sept. 28 broadcast of Salem Radio Network’s Bill Bennett’s Morning in America:
 
CALLER: I noticed the national media, you know, they talk a lot about the loss of revenue, or the inability of the government to fund Social Security, and I was curious, and I’ve read articles in recent months here, that the abortions that have happened since Roev. Wade, the lost revenue from the people who have been aborted in the last thirty-something years, could fund Social Security as we know it today. And the media just doesn’t—never touches this at all.
BENNETT: Assuming they’re all productive citizens?
CALLER: Assuming that they are. Even if only a portion of them were, it would be an enormous amount of revenue.
BENNETT: Maybe, maybe, but we don’t know what the costs would be, too. I think—does abortion disproportionately occur among single women? No.
CALLER: I don’t know the exact statistics, but quite a bit are, yeah.
BENNETT: All right, well, I mean, I just don’t know. I would not argue for the pro-life position based on this, because you don’t know. I mean, it cuts both—you know, one of the arguments in this book Freakonomics that they make is that the declining crime rate, you know, they deal with this hypothesis, that one of the reasons crime is down is that abortion is up. Well—
CALLER: Well, I don’t think that statistic is accurate.
BENNETT: Well, I don’t think it is either, I don’t think it is either, because first of all, I think there’s just too much that you don’t know. But I do know that it’s true that if you wanted to reduce crime, you could—if that were your sole purpose, you could abort every black baby in this country, and your crime rate would go down. That would be an impossible, ridiculous, and morally reprehensible thing to do, but your crime rate would go down. So these far-out, these far-reaching, extensive extrapolations are, I think, tricky.
 
Bennett’s comments have, not surprisingly, ignited a furor—in the media and even at the White House, which denounced his statement.
Here are my thoughts on this exchange:
• People should bear in mind that this took place on an unscripted radio show in response to a caller’s question. It was clearly off-the-cuff. This is a very different situation than, say, Bennett’s writing an op-ed piece.
• Race is not an important part of the abortion-crime argument that John Donohue and I have made in academic papers and that Dubner and I discuss in Freakonomics. It is true that, on average, crime involvement in the U.S. is higher among blacks than whites. Importantly, however, once you control for income, the likelihood of growing up in a female-headed household, having a teenage mother, and how urban the environment is, the importance of race disappears for all crimes except homicide. (As we’ve written, the homicide gap is partly explained by crack markets.) In other words, for most crimes, a white person and a black person who grow up next door to each other with similar incomes and the same family structure would be predicted to have the same crime involvement. Empirically, what matters is the fact that abortions are disproportionately used on unwanted pregnancies, and disproportionately by teenage women and single women.
• Some people might think that my comments in point 2 above are just ducking the race issue because it is politically correct to do so. Anyone who has read Freakonomics knows that I am not afraid to take issues of race head-on. Much of the book deals with challenging issues of race (e.g., black-white test score gaps, black naming patterns, etc.). I mean it when I say that, from a purely fact-based and statistical perspective, race is not in any way central to our arguments about abortion and crime.
• When a woman gets an abortion, for the most part it is not changing the total number of children she has; rather, it is shifting the timing so those births come later in life. This is an important fact to remember. One in four pregnancies ends in abortion and this has been true for thirty years in the U.S. But the impact of abortion on the overall birth rate has been quite small.
• In light of point 4 above, it is hard to even know what Bennett means when he says “you could abort every black baby in this country, and your crime rate would go down.” Implicit in his comment is the idea that some external force, like a government, is forcing blacks to have abortions. This is obviously a completely different situation than abortion as we know it today, in which a woman chooses whether or not to have an abortion now, and then starts her family later in life, when her situation is more stable and conducive. The distinction between a woman choosing to control her fertility and the government choosing to limit her fertility is fundamental, and people often seem to lose sight of that.
• If we lived in a world in which the government chooses who gets to reproduce, then Bennett would be correct in saying that “you could abort every black baby in this country, and your crime rate would go down.” Of course, it would also be true that if we aborted every white, Asian, male, Republican, and Democratic baby in that world, crime would also fall. Immediately after he made the statement about blacks, he followed it up by saying, “That would be an impossible, ridiculous, and morally reprehensible thing to do, but your crime rate would go down.” He made a factual statement (if you prohibit any group from reproducing, then the crime rate will go down), and then he noted that just because a statement is true, it doesn’t mean that it is desirable or moral. That is, of course, an incredibly important distinction and one that we make over and over in Freakonomics.
• There is one thing I would take Bennett to task for: first saying that he doesn’t believe our abortion-crime hypothesis but then revealing that he does believe it with his comments about black babies. You can’t have it both ways.
• As an aside, the caller’s initial hypothesis is completely wrong. If abortion were illegal, our Social Security problems would not be solved. As noted above, most abortions just shift a child from being born today to a child being born to the same mother a few years later.
—SDL (Sept. 30, 2005)
“Back to the Drawing Board for Our Latest Critics”
Thanks to recent articles in the Wall Street Journal and the Economist, a working paper by Chris Foote and Chris Goetz that is sharply critical of John Donohue and me has gotten an enormous amount of attention.
In that working paper, Foote and Goetz criticized the analysis underlying one of the tables in our original article that suggested a link between legalized abortion and crime. (It is worth remembering that the approach they criticize was one of four distinct pieces of evidence we presented in that paper; they offer no criticisms of the other three approaches.)
Foote and Goetz made two basic changes to the original analysis we did. First, they correctly noted that the text of our article stated that we had included state-year interactions in our regression specifications, when indeed the table that got published did not include these state-year interactions. Second, they correctly argue that without controlling for changes in cohort size, the original analysis we performed provided a test of whether cohorts exposed to high rates of legalized abortion did less crime, but did not directly afford a test of whether “unwantedness” was one of the channels through which this crime reduction operated. (Note: we didn’t claim that this particular analysis was a direct test of the “unwantedness” hypothesis. This last section of the paper was the most speculative analysis of everything that we did, and frankly we were surprised it worked at all, given the great demands it put on the data.) They found that once you made those changes, the results in our original Table 7 essentially disappear.
There is, however, a fundamental problem with the Foote and Goetz analysis. The abortion data that are available are likely to be quite noisy. As one adds more and more control variables (e.g., nearly 1,000 individual state-year interactions), the meaningful variation in abortion rates gets eaten away. The signal-to-noise ratio in what remains of the variation in measured abortions gets worse and worse. That will lead the measured impact of abortions on crime to dwindle. Because this work uses a state/year/single year of age (e.g., 19-year-olds in Ohio in 1994) as the unit of analysis, the analyses performed are highly saturated with interactions: state-age interactions, age-year interactions, and state-year interactions. Together, these interactions account for more than 99 percent of the variance in arrest rates and more than 96 percent of the variation in the abortion proxy. It is an exercise that is very demanding of the data.
In light of this, it seems uncontroversial that one would want to do the best one could in measuring abortion when carrying out such an exercise.
The abortion measure used by Foote and Goetz is one that is produced by the Alan Guttmacher Institute. The Alan Guttmacher Institute makes estimates based on surveys of abortion providers of the number of abortions performed per live birth in each state and year.
To proxy for the abortion exposure of, say, 19-year-olds arrested in California in 1993, Foote and Goetz use the abortion rate in California in 1973. This is not an unreasonable first approximation (and indeed is the one we used in most parts of our original paper because it is simple and transparent), but it is just an approximation for a number of reasons:
• There is a great deal of cross-state mobility. Therefore, many of the 19-year-olds arrested in California in 1993 were not born in California. They were born in other states, or possibly other countries. Indeed, I believe that recent figures suggest that more than 30 percent of those in their late teens do not reside in the state in which they were born.
• Using a date of 20 years earlier to proxy for the abortion exposure of a 19-year-old induces an enormous amount of noise. If I am a 19-year-old sometime in 1993, I may have been born as early as Jan. 2, 1973 (that would make me still 19 on Jan. 1, 1993) or as late as Dec. 31, 1974 (that would have me turning 19 on Dec. 31, 1993). Abortions occur sometime in advance of birthdays, typically about 13 weeks into a pregnancy. So the relevant date (roughly) of when those who are 19 in 1993 would have been exposed to legalized abortion is about six months before they were born, or July 2, 1972, through June 30, 1974. While that window overlaps with the year 1973 (which is what Foote and Goetz use as their time period of abortion exposure), note that it also includes half of 1972 and half of 1974!
• A non-trivial fraction of abortions performed in the United States, especially in the time when legalization was taking place, involved women crossing state lines to get an abortion. As a consequence, measuring abortions in terms of the state in which the abortion is performed (that’s what the Foote/Goetz data does), rather than the state of residence of the woman getting the abortion, induces further measurement error into their abortion proxy.
• The Alan Guttmacher abortion numbers are, even by the admission of the people who collect the data, far from perfect. Indeed, the correlation between these abortion estimates and another time series collected by the CDC is well below one, suggesting that even if problems 1, 2, and 3 didn’t exist, there would be substantial measurement error. The correlation between the Alan Guttmacher measure and the CDC measure, not surprisingly, gets lower and lower the more control variables that are included. This is exactly what one would expect if the controls are taking the signal out of the abortion measures and leaving behind mostly noise.
What John Donohue and I have done (with fantastic research assistance from Ethan Lieber) is to attempt to address as best we can these four problems with the abortion measure that Foote and Goetz are using. In particular, we do the following:
• As we describe in our original paper on abortion, one can deal with cross-state mobility by using the decennial censuses to determine the state of birth for the current residents of a state. (The results from carrying out this correction in our crime regressions are reported in Table 5 of the original 1999 paper.) This is possible to do because the census micro data reports the state of birth and current state of residence for a 5 percent sample of the U.S. population. Note that the correction we are able to make is unlikely to be perfect, so it may not fully solve the problem, but it clearly moves us in the right direction.
• Given that the window of abortion exposure faced by 19-year-olds in 1993 spans the years 1972 to 1974, the obvious solution to this problem is to allow abortions performed in 1972, 1973, and 1974 to influence arrests of 19-year-olds in 1993. It is straightforward to work out roughly the weights that one wants to put on the different years’ abortion rates—or one can do it non-parametrically and let the data decide; the answers are virtually identical.
• In order to deal with the fact that many women were crossing state lines to get abortions in the 1970s, we use the Guttmacher Institute’s estimates of abortions performed on women residing in a state relative to live births in that state. (We were unaware of the existence of these better data when we wrote the initial paper, otherwise we would have used them at that time.) There is little question that measuring abortions by state of residence is superior to measuring them by where the procedure is performed.
• The standard solution to measurement error is to perform an instrumental-variables analysis in which you use one noisy proxy of the phenomenon that is poorly measured as an instrument for another noisy proxy. (I recognize that most readers of this blog will not understand what I mean by this.) In this setting, the CDC’s independently generated measure of legalized abortions is likely to be an excellent instrument. Because there is so much noise in each of the measures, the standard errors increase when doing this I.V. procedure, but under a standard set of assumptions, the estimates obtained will be purged of the attentuation bias that will be present due to measurement error.
I think that just about any empirical economist would tend to believe that each of these four corrections we make to the abortion measure will lead us closer to capturing the true impact of legalized abortion on crime. So the question becomes: What happens when we replicate the specifications reported in Foote and Goetz, but with this improved abortion proxy?
The results are summarized in the following table, which has two panels. The top panel shows the results for violent crime. The bottom panel corresponds to property crime.









Starting with the first panel, the top row reports the same specifications as Foote and Goetz (I don’t bother showing their estimates excluding state-age interactions because it makes no sense to exclude these and they themselves say that their preferred specifications include state-age interactions). We are able to replicate their results. As can be seen, the coefficients shrink as one adds state-year interactions and population controls.
The second row of the table presents the coefficients one obtains with our more thoughtfully constructed abortion measure (changes 1–3 on pages 259–60 having been made to their abortion measure). With a better measure of abortion, as expected, all the estimated abortion impacts increase across the board. The results are now statistically significant in all of the Foote and Goetz specifications. Even in the final, most demanding specification, the magnitude of the coefficient is about the same as in the original results we published that didn’t control for state-year interactions or population. The only difference between what Foote and Goetz did and what we report in row 2 is that we have done a better job of really measuring abortion. Everything else is identical.
The third row of the table reports the results of instrumental variables estimates using the CDC abortion measure as an instrument for our (more thoughtfully constructed) Guttmacher Institute proxy of abortions. The results all get a little bigger but are more imprecisely estimated.
The bottom panel of the table shows results for property crime. Moving from Foote and Goetz’s abortion measure in the top row to our more careful one in the second row (leaving everything else the same), the coefficients become more negative in three of the four specifications. Doing the instrumental variables estimation has a bigger impact on property crime than on violent crime. All four of the instrumental variables estimates of legalized abortion on property crime are negative (although again less precisely estimated).
The simple fact is that when you do a better job of measuring abortion, the results get much stronger. This is exactly what you expect of a theory that is true: doing empirical work closer to the theory should yield better results than empirical work more loosely reflecting the theory. The estimates without population controls, but including state-year interactions, are as big or bigger than what is in our original paper. As would be expected (since the unwantedness channel is not the only channel through which abortion is acting to reduce crime), the coefficients we obtain shrink when we include population controls. But, especially for violent crime, a large impact of abortion persists even when one measures arrests per capita.
The results we show in this new table are consistent with the impact of abortion on crime that we find in the three other types of analyses we presented in the original paper using different sources of variation. These results are consistent with the unwantedness hypothesis.
No doubt there will be future research that attempts to overturn our evidence on legalized abortion. Perhaps they will even succeed. But this one does not.
—SDL (Dec. 5, 2005)
3. WHAT DO THE KANSAS CITY ROYALS HAVE IN COMMON WITH AN iPOD?
One useful purpose of the Freakonomics blog (of any blog, really) is to make random reflections on random subjects—including, as it turns out, the subject of randomness itself.
 
“What Do the K.C. Royals and My iPod Have in Common?” On the surface, not much. The Royals have lost 19 straight games and are threatening to break the all-time record for futility in major-league baseball. My iPod, on the other hand, has quickly become one of my most beloved material possessions.
So what do they have in common? They both can teach us a lesson about randomness.
The human mind does badly with randomness. If you ask the typical person to generate a series of “heads” and “tails” to mimic a random sequence of coin tosses, the series doesn’t really look like a randomly generated sequence at all. You can try it yourself. First, before you read further, write down what you expect a random series of 20 coin tosses to look like. Then spend 15 or 20 minutes flipping coins (or use a random number generator in Excel). If you are like the typical person, the “random” sequence you generated will have many fewer long streaks of “all heads” or “all tails” than actually arise in real life.
My iPod shuffle reminds me of this every time I use it. I’m consistently surprised at how often it plays two, three, or even four songs by the same artist, even though I have songs by dozens of different artists on it. On a number of occasions, I’ve even become mistakenly convinced I don’t have the iPod on shuffle, but rather I’m playing all the songs by one artist. If someone is really bored, maybe they can repeatedly have the iPod shuffle the songs, record the data, and see if the shuffle function really is random. My guess is that it is, because what would be the point of Apple doing something different? I have a friend Tim Groseclose, a professor of political science at UCLA, who was convinced that the random button on his CD player knew which songs were his favorites and disproportionally played those. So I bet him one day, made him name his favorite songs in advance, and won lunch.
Which brings us to the Kansas City Royals. It seems like, when a team loses 19 games, that is so extreme that it can’t reasonably be the result of randomness. Clearly coaches, sportswriters, and most fans believe that to be true. How often have you heard of a coach holding a closed-door meeting to try to turn a team around? But if you look at it statistically, you expect 19-game losing streaks to occur, simply by randomness, about as often as they do.
The following calculations are admittedly crude, but they give you the basic idea. Each year, there are about two teams in the major leagues that have a winning percentage of around 35. (Sometimes no team is that bad, and in other years there are real stinkers like Detroit in 2003—they won only 26.5 percent of their games.) For a team that has a 35 percent chance of winning each game, the chance of losing its next 19 games is about one in 4,000. Each team plays 162 games a year and so has 162 chances to start such a streak. (They count streaks that begin in one year and end in the next year, so it is correct to use all 162 games.)
So each year, for these two bad teams that win 35 percent of their games, there are a total of 324 chances to have a 19-game losing streak. It takes about 12 or 13 years for these two bad teams to have a total of 4,000 chances for a 19-game losing streak. Thus we would expect a losing streak this long a little less than once a decade.
In practice, we see, if anything, slightly fewer long losing streaks than expected based on these calculations. The last really long losing streak was that of the Cubs in 1996–1997, which was 16 games. (There is actually a good reason that long streaks occur a little less than in the simple model I was using. It is because a team that wins 35 percent of their games doesn’t have the same likelihood of winning every game: sometimes it has a 50 percent chance and sometimes a 20 percent chance; that sort of variability lessens the likelihood of long streaks.)
So, one doesn’t need to resort to explanations like “lack of concentration,” being “snakebit,” or “demoralization” to explain why the Royals are losing so many games in a row. It’s just that they are a bad team getting some bad luck.
—SDL (Aug. 20, 2005)
“Wikipedia? Feh!”
I know, I know, I know: Wikipedia is one of the wonders of the online world. But if anyone ever needs a reason to be deeply skeptical of Wikipedia’s dependability, I urge you to click on the entry for “List of Economists,” which is introduced thusly: “This is an alphabetical list of well-known economists. Economists are scholars conducting research in the field of economics.”
It is true that the list includes George Akerlof and Paul Samuelson and Jeffrey Sachs and even Steve Levitt. But if you want to see how truly pathetic Wikipedia can be, check out the sixth “economist” listed under “D”: that’s right, yours truly. Although some of my best friends are economists, I am very much not. (Note: soon after I posted this entry, a reader was helpful/mischievous enough to quickly amend the Wikipedia entry, deleting my name.) The point is that the greatest strength of Wikipedia is also its greatest weakness: pretty much anyone can contribute anything anytime to an “encyclopedia” that most casual users will assume is in fact encyclopedic, but which in fact changes regularly, depending on the input of its users. For instance:
Freakonomics, we make a passing reference to the Chicago Black Sox, the name given to the Chicago White Sox after eight players were found to have colluded with gamblers to throw the 1919 World Series.
A reader recently wrote: The 1919 white sox were not known as the black sox because they threw the world weries [sic]. They were called that because their owner (whose name i do not have) was too stingy to have their uniforms cleaned regularly so that they frequently showed up on the diamond in dirty uniforms. You’re welcome.
This was in fact the second reader to write with this same correction. We had asked the first reader for his source; he said he thought he “heard it once on ESPN,” but couldn’t be sure. After receiving this second e-mail, I decided to investigate. Here is my reply to reader no. 2, and to anyone else who may care:
I looked into the Black Sox thing. It is true that the Wikipedia entry says this: Although many believe the Black Sox name to be related to the dark and corrupt nature of the consipiracy [sic], the term Black Sox had already existed before the fix was investigated. The name Black Sox was given because parsimonious owner Charles Comiskey refused to pay for the players’ uniforms to be laundered, instead insisting that the players themselves pay for the cleaning. The players refused, and the subsequent series of games saw the White Sox play in progressivly [sic] dirtier uniforms, as dust, sweat, and grime collected on the white, woollen [sic] uniforms until they took on a much darker shade. (does anyone have proof of this? sounds like urban legend to me)
Two things to say about this: 1. The parenthetical phrase at the end was just added—by me. 2. In other words, let’s remember that Wikipedia is an open-access “encyclopedia” that can be contributed to (or vandalized) at will.
Here’s a more reliable source: Eight Men Out: The Black Sox and the 1919 World Series, by Eliot Asinof (Holt, Rinehart and Winston,1963). Asinof writes that White Sox owner Charles Comiskey was indeed cheap when it came to his players: His generosity here [with reporters] was unmatched. Yet his great ball club might run out on the field in the filthiest uniforms the fans had ever seen: Comiskey had given orders to cut down on the cleaning bills.
So is it possible that the White Sox were known, even slightly or colloquially, as the Black Sox before the 1919 scandal?
Sure, it’s possible, but Asinof makes no such insinuation throughout the book. In fact, once you get past the book’s opening pages, I didn’t find the words “Black Sox”, where Asinof writes of the aftermath of the World Series scandal: “As the impact of the confessions sank in, the American people were at first shocked, then sickened. There was hardly a major newspaper that did not cry out its condemnation and despair. Henceforth, the ballplayers involved were called the Black Sox.”
Note the key word: henceforth. Is it possible that Asinof was wrong? Sure. But his book is a good one, commonly accepted as the definitive biography of the affair. I don’t feel compelled to check this out further until someone comes up with contrary evidence that’s more reliable than Wikipedia. But if you do, I’ll be happy to research further, or make a change in future editions of Freakonomics.
So please, dear blog readers: let us know if we’re right or wrong re the Black Sox. We’ll be a little sad to have been wrong, but a lot happy to correct the mistake. A Freakonomics T-shirt goes to the first person who offers hard evidence of the dirty-socks theory.
—SJD (May 20, 2005, and Aug. 5, 2005)
“‘Peak Oil’: Welcome to the Media’s New Version of Shark Attacks”
The cover story of the Aug. 21 New York Times Magazine, written by Peter Maass, is about “Peak Oil.” The idea behind “peak oil” is that the world has been on a path of increasing oil production for many years, and now we are about to peak and go into a situation where there are dwindling reserves, leading to triple-digit prices for a barrel of oil, an unparalleled worldwide depression, and as one web page puts it, “Civilization as we know it is coming to an end soon.”
One might think that doomsday proponents would be chastened by the long history of people of their ilk being wrong: Nostradamus, Malthus, Paul Ehrlich, et al. Clearly they are not.
What most of these doomsday scenarios have gotten wrong is the fundamental idea of economics: people respond to incentives. If the price of a good goes up, people demand less of it, the companies that make it figure out how to make more of it, and everyone tries to figure out how to produce substitutes for it. Add to that the march of technological innovation (like the green revolution, birth control, etc.). The end result: markets figure out how to deal with problems of supply and demand.
Which is exactly the situation with oil right now. I don’t know much about world oil reserves. I’m not even necessarily arguing with their facts about how much the output from existing oil fields is going to decline, or that world demand for oil is increasing. But these changes in supply and demand are slow and gradual—a few percent each year. Markets have a way of dealing with situations like this: prices rise a little bit. That is not a catastrophe; it is a message that some things that used to be worth doing at low oil prices are no longer worth doing. Some people will switch from SUVs to hybrids, for instance. Maybe we’ll be willing to build some nuclear power plants, or it will become worthwhile to put solar panels on more houses.
But the New York Times article totally flubs the economics time and again. Here is one example:
The consequences of an actual shortfall of supply would be immense. If consumption begins to exceed production by even a small amount, the price of a barrel of oil could soar to triple-digit levels. This, in turn, could bring on a global recession, a result of exorbitant prices for transport fuels and for products that rely on petrochemicals—which is to say, almost every product on the market. The impact on the American way of life would be profound: cars cannot be propelled by roof-borne windmills. The suburban and exurban lifestyles, hinged to two-car families and constant trips to work, school and Wal-Mart, might become unaffordable or, if gas rationing is imposed, impossible. Car-pools would be the least imposing of many inconveniences; the cost of home heating would soar—assuming, of course, that climate-controlled habitats do not become just a fond memory.
If oil prices rise, consumers of oil will be (a little) worse off. But we are talking about needing to cut demand by a few percent a year. That doesn’t mean putting windmills on cars, it means cutting out a few low-value trips. It doesn’t mean abandoning North Dakota, it means keeping the thermostat a degree or two cooler in the winter.
A little later, the author writes:
The onset of triple-digit prices might seem a blessing for the Saudis—they would receive greater amounts of money for their increasingly scarce oil. But one popular misunderstanding about the Saudis—and about OPEC in general—is that high prices, no matter how high, are to their benefit. Although oil costing more than $60 a barrel hasn’t caused a global recession, that could still happen: it can take a while for high prices to have their ruinous impact. And the higher above $60 that prices rise, the more likely a recession will become. High oil prices are inflationary; they raise the cost of virtually everything—from gasoline to jet fuel to plastics and fertilizers—and that means people buy less and travel less, which means a drop-off in economic activity. So after a brief windfall for producers, oil prices would slide as recession sets in and once-voracious economies slow down, using less oil. Prices have collapsed before, and not so long ago: in 1998, oil fell to $10 a barrel after an untimely increase in OPEC production and a reduction in demand from Asia, which was suffering through a financial crash.
Oops, there goes the whole peak-oil argument. When the price rises, demand falls, and oil prices slide. What happened to “the end of the world as we know it”? Now we are back to $10-a-barrel oil. Without realizing it, the author just invoked basic economics to invalidate the entire premise of the article!
Just for good measure, he goes on to write:
High prices can have another unfortunate effect for producers. When crude costs $10 a barrel or even $30 a barrel, alternative fuels are prohibitively expensive. For example, Canada has vast amounts of tar sands that can be rendered into heavy oil, but the cost of doing so is quite high. Yet those tar sands and other alternatives, like bioethanol, hydrogen fuel cells and liquid fuel from natural gas or coal, become economically viable as the going rate for a barrel rises past, say, $40 or more, especially if consuming governments choose to offer their own incentives or subsidies. So even if high prices don’t cause a recession, the Saudis risk losing market share to rivals into whose nonfundamentalist hands Americans would much prefer to channel their energy dollars.
As he notes, high prices lead people to develop substitutes. Which is exactly why we don’t need to panic over peak oil in the first place.
So why do I compare peak oil to shark attacks? It is because shark attacks mostly stay about constant, but fear of them goes up sharply when the media decides to report on them. The same thing, I bet, will now happen with peak oil. I expect tons of copycat journalism stoking the fears of consumers about oil-induced catastrophe, even though nothing fundamental has changed in the oil outlook in the last decade.
—SDL (Aug. 21, 2005)
“Is America Ready for an Organ-Donor Market?”
Probably not. But, in what is either a very odd coincidence or some kind of concerted effort to get out the organ-market message, there are op-eds in both the New York Times and Wall Street Journal today arguing the case.
The first one, headlined “Death’s Waiting List,” is by Sally Satel, a psychiatrist and American Enterprise Institute scholar. Satel herself received a kidney transplant and is now arguing that the delivery system is terrible and that the Institute of Medicine’s new report, “Organ Donation: Opportunities for Action,” is even worse. “Unfortunately,” Satel writes, “the report more properly should be subtitled ‘Recommendations for Inaction.’” Satel’s main point is that the conventional argument against an organ market—i.e., that no part of the human body should ever be “for sale”—has been made obsolete, and then some, by the “markets for human eggs, sperm and surrogate mothers.”
The WSJ piece, headlined “Kidney Beancounters,” is by Richard Epstein, the University of Chicago legal scholar and Hoover Institution fellow. Epstein is even more hostile to the IOM’s report (though maybe the Journal just let him get away with more than the Times let Satel get away with), saying the report is “so narrowminded and unimaginative that it should have been allowed to die inside the IOM.” Epstein writes further that “the major source of future improvement lies only in financial incentives; yet the IOM committee (which contains one lawyer but no economist) dismisses these incentives out of hand. … The key lesson in all this is that we should look with deep suspicion on any blanket objection to market incentives—especially from the high-minded moralists who have convinced themselves that their aesthetic sensibilities and instinctive revulsion should trump any humane efforts to save lives.”
Though his op-ed doesn’t say so, I am pretty sure that Epstein is an advisor to LifeSharers, a self-described “non-profit voluntary network of organ donors” that seeks to use non-financial incentives to encourage organ donation. A while ago, we received an e-mail from David Undis, the executive director of LifeSharers. He wrote:
Incentives are missing in organ donation. That’s one of the reasons so many people are dying waiting for organ transplants.
A free market in human organs would save thousands of lives a year, but politically speaking it’s a pipe dream. There’s very little likelihood Congress will legalize buying and selling organs in the foreseeable future.
I formed LifeSharers to introduce a legal non-monetary incentive to donate organs—if you agree to donate your organs when you die then you’ll receive a better chance of getting an organ if you ever need one to live.
It is surprising to me, and to many people much closer to the subject than me, that so little headway has been made in reforming the organ-donation process. I have never heard a single person say they were happy with the way things are—and, while I am sure Undis is right when he writes that a free market in organs is, politically speaking, a pipe dream, it seems that things are starting to move at least a bit in that direction. As Satel writes in her Times piece today, “Ethics committees of the United Network for Organ Sharing, the American Society of Transplant Surgeons and the World Transplant Congress, along with the President’s Council on Bioethics and others, have begun discussing the virtues” of offering organ donors incentives such as “tax breaks, guaranteed health insurance, college scholarships for their children, deposits in their retirement accounts, and so on.”
It is interesting that, while all these incentives are financial, none of them are in the form of cold hard cash, which may make them more palatable.
I wouldn’t be surprised if, between these two op-eds, at least a few minds are changed today.
—SJD (May 15, 2006)
4. WHY PAY $36.09 FOR RANCID CHICKEN?
A blog can also be a nice place to get things off your chest—rants (and, occasionally, raves) of a more personal nature.
“Why Pay $36.09 for Rancid Chicken?”
An old friend came to town not long ago and we met for a late lunch on the Upper West Side. Trilby ordered a burger, no bread, with Brie; I ordered half a roasted chicken with mashed potatoes. The food was slow in coming but we had so much catching up to do that we didn’t mind.
My chicken, when it arrived, didn’t look good but I took a bite. It was so rancid I had to spit it out into a napkin. Absolutely disgusting gagging rotten rancid. I summoned the waitress, who made a suitably horrified expression, then took the food away.
The manager appeared. She was older than the waitress, with long dark hair and a French accent. She apologized, said the chefs were checking out the dish now, trying to determine if perhaps the herbs or the butter had caused the problem.
“I don’t think so,” I told her. “I think your chicken is rotten. I cook a lot of chicken, and I know what rotten chicken smells like.” Trilby agreed: you could smell this plate across the table, probably across the restaurant.
The manager was reluctant to concede. They had just gotten the shipment of chicken that morning, she said, which struck me as not really relevant, like saying: No, so-and-so couldn’t have committed a murder today because he didn’t commit one yesterday.
The manager left and, five minutes later, returned. “You’re right!” she said. “The chicken was bad.” She said the chefs had checked the chicken, found it rotten, and were throwing it away. Victory! But for whom? The manager apologized again, asked if I’d like a free dessert or drink. “Well,” I said, “first of all let me try to find some food on your menu that doesn’t seem disgusting after that chicken.” I ordered a carrot-ginger-orange soup, some French fries, and sautéed spinach.
Trilby and I then ate, fairly happily, though the taste of the rancid chicken remained with me; in fact, it remains with me still. Trilby had had a glass of wine before we ordered, and took another glass with her meal, sauvignon blanc. I drank water. When the waitress cleared our plates, she asked again if we wanted free dessert. Just coffee, we said.
As Trilby and I talked, I mentioned that not long ago I had interviewed Richard Thaler, the godfather of behavioral economics, a fairly new field of study that tries to explain why the psychology of money is so complicated. I mentioned the behavioralists’ concept of “anchoring”—a concept that used-car salesmen in particular know so well: establish a price that may be 100 percent more than what you need in order to ensure that you’ll still walk away with, say, a 50 percent profit.
Talk turned to what we might say when our check came. There seemed two good options: “We don’t care for any free dessert, thanks, but considering what happened with the chicken, we’d like you to comp our entire meal.” That would establish an anchor at 0 percent of the check. Or this option: “We don’t care for any free dessert, thanks, but considering what happened with the chicken, would you please ask the manager what you can do about the check.” That would establish an anchor at 100 percent of the check.
Just then the waitress brought the check. It was for $31.09. Perhaps out of shyness, or haste, or—most likely—a desire to not appear cheap (when it comes to money, things are never simple), I blurted out option 2: Please see what the manager “can do about the check.”
The waitress replied, smiling, that we had already been given the two glasses of wine for free. To me in particular this felt like slim recompense, since it was Trilby who had drunk the wine while it was I who still radiated with the flavor of rancid chicken. But the waitress, still smiling, duly took the check and headed toward the manager. She zipped right over, also smiling.
“Considering what happened with the chicken,” I said, “I wonder what you can do about the check.”
“We didn’t charge you for the wines,” she said, with great kindness.
“Is that the best that you’re prepared to offer me?” I said (still unable to establish an anchor at 0 percent).
She looked at me intently, still friendly. Here she was making a calculation, preparing to make the sort of slight gamble that is both financial and psychological, the sort of gamble that each of us makes every day. She was about to gamble that I was not the kind of person who would make a scene. After all, I had been friendly throughout our dilemma, never raising my voice or even uttering aloud the words “vomit” or “rancid.” And she plainly thought this behavior would continue. She was gambling that I wouldn’t throw back my chair and holler, that I wouldn’t stand outside the restaurant telling potential customers that I’d gagged on my chicken, that the whole lot of it was rancid, that the chefs either must have smelled it and thought they could get away with it, or, if they hadn’t smelled it, were so spaced out that who knows what else—a spoon, a sliver of thumb, a dollop of disinfectant—might find its way into the next meal. And so, making this gamble, she said “Yes”: as in Yes, that is the best that she was prepared to offer me. “All right,” I said, and she walked away. I left a $5 tip—no sense penalizing the poor waitress, right?—walked outside and put Trilby in a cab. The manager had gambled that I wouldn’t cause trouble, and she was right.
Until now.
The restaurant, should you care to note, is called French Roast, and is on the northeast corner of 85th and Broadway, in Manhattan.
Last I checked, the roast chicken was still on the menu. Bon appétit.
—SJD (May 8, 2005)
“Making Profits from Incivility on the Roads”
I hardly ever drive anymore since I moved close to where I work. So whenever I do, the incivility on the roads leaps out at me. People do things in cars they would never do in other settings. Honking. Swearing. Cutting to the front of the line. And that is just my wife. The other drivers are far meaner.
One obvious reason is that you don’t have to live with the consequences for any length of time. If you cut in line at airport security, you will be in close proximity for quite some time to the people you insulted. But with a car, you make a quick getaway.
When I used to commute, there was one particular interchange where incivility ruled. (For those who know Chicago, it is where the Dan Ryan feeds into the Eisenhower.) There are two lanes when you exit the highway. One lane goes to the other highway, and one to a surface street. Hardly anyone ever wants to go to that surface street. There can be a half-mile backup of cars waiting patiently to get on the highway, and about 20 percent of the drivers rudely and illegally cut in at the last second after pretending they are heading toward the surface street. Every honest person that waits in line is delayed 15 minutes or more because of the cheaters.
Social scientists sometimes talk about the concept of “identity.” It is the idea that you have a particular vision of the kind of person you are, and you feel awful when you do things that are out of line with that vision. That leads you to take actions that are seemingly not in your short-run best interest. In economics, George Akerlof and Rachel Kranton popularized the idea. I had read their papers, but in general have such a weak sense of identity that I never really understood what they were talking about. The first time I really got what they meant was when I realized that a key part of my identity was that I was not the kind of person who would cut in line to shorten my commute, even though it would be easy to do so, and even though it seemed crazy to wait 15 minutes in this long line. But if I were to cut in line, I would have to fundamentally rethink the kind of person I was.
The fact that I don’t mind when my taxi driver cuts in these lines (actually, I kind of enjoy it) probably shows that I have a long ways to go in my moral development.
All this is actually just a rambling prelude to my main point. I was in New York City the other day and my taxi driver bypassed a long line of cars exiting the freeway to cut in at the last second. As usual, I enjoyed being an innocent bystander/beneficiary to this little crime. But what happened next was even more gratifying to the economist in me. A police officer was standing in the middle of the road, waving every car that cut in line—including my taxi—over to the shoulder, where a second officer was handing out tickets as if on an assembly line. By my rough estimate, these two officers were giving out 30 tickets an hour, at $115 a pop. At more than $1,500 per officer per hour (assuming the tickets get paid), this was a fantastic moneymaking proposition for the city. And it nails just the right people. Speeding doesn’t really hurt other people very much, except indirectly. So to my mind, it makes much more sense to go directly after the mean-spirited behavior like cutting in line. This is very much in the spirit of William Bratton’s “broken windows” policing philosophy. I’m not sure it cuts down the number of cheaters on the roads in any fundamental way, since the probability of getting caught remains vanishingly small. Still, the beauty of it is that a) every driver that follows the rules feels a rush of glee over the rude drivers getting nailed; and b) it is a very efficient way of taxing bad behavior.
So, my policy recommendation to police departments across the country is to find the spots on the roads that lend themselves to this sort of policing and let the fun begin.
—SDL (Nov. 18, 2005)
“Vegas Rules”
So Levitt and I were in Las Vegas this weekend, doing some research. (Seriously.) We had a little downtime and decided to play blackjack. It was New Year’s Eve, at Caesars Palace, about 9 p.m. We sat down at an empty table where the dealer, a nice young woman from Michigan, was very patient in teaching us the various fine points that neither of us knew and which indicated that we were both inexperienced. Keep one hand in your lap, e.g. When you want a card, just flick your cards twice on the felt. When you’re standing, tuck one card under your chip/s. And so on.
At one point, Levitt kind of gasped. He had had 21 but somehow had asked for another card. The last card was a 2. It wasn’t that he didn’t know how to play, or count; he was just distracted—talking to me, he’d later claim—and the dealer had seen him do something, or fail to do something else, that indicated he wanted another card. So here he was with 4 cards: a face card, a 4, a 7, and a 2. The dealer looked sympathetic. I vouched for Levitt, told her he wasn’t an idiot and surely wouldn’t have hit on 21 intentionally. She seemed to believe us. She said she’d call over her supervisor to see what could be done.
She called the supervisor’s name over her shoulder. I could see the supervisor, and I could see that he couldn’t hear her. Remember, this is a casino on New Year’s Eve; it was pretty noisy. She keeps calling, and I keep seeing that he’s not hearing her, but she won’t turn around to call him. That would mean turning her back on her table full of chips and even if Levitt were dumb enough to hit on 21, he presumably was smart enough to grab a bunch of chips and run. (Or maybe, she was thinking, he’s actually dumb like a fox and used this hitting-on-21 trick all the time, to get the dealer to turn her back on the table.)
Finally, I went over and fetched the supervisor myself. The dealer explained the situation. He seemed to accept Levitt’s explanation. Then he looked at me. “Did you want the card?” he asked, meaning the 2 that Levitt drew.
“Well, now that I see it, sure I want it,” I said. I had 17; I certainly wouldn’t have hit on 17, but a 2 would give me a lovely 19.
“Here,” he said, and gave me the 2. “Happy New Year.”
Then the dealer took a card and busted.
I don’t know much about gambling, but I do know that the next time I’m in Vegas and feel compelled to play some blackjack, I’m going to Caesars.
And just so you don’t think that Levitt really is a complete gambling idiot: the next day, we sat down at the sports book and he grabbed a Daily Racing Form and studied it for about 10 minutes and then went up and placed a bet. He found a horse, going off at 7/2, that had never run a race. But he saw something that he liked. He bet the horse to win and win only. And then we watched the race on one of the jumbo screens. It took a good 60 seconds for his horse to settle into the gate—we thought it would be scratched—but then it got in and the gates opened and his horse led wire to wire. It was a good bit more impressive than his blackjack.
—SJD (Jan. 3, 2006)
“I Almost Got Sent to Guantánamo”
I arrived at the West Palm Beach airport yesterday, trying to make my way back to Chicago, only to see my flight time listed on the departure board as simply “delayed.” They weren’t even pretending it was leaving in the foreseeable future. With a little detective work, I found another flight that could get me home on a different airline, bought a one-way ticket, and headed for airport security.
Of course, the last-minute purchase of a one-way ticket sets off the lights and buzzers for the TSA. So I’m pulled out of the line and searched. First the full-body search. Then the luggage.
It didn’t occur to me that my latest research was going to get me into trouble. I’ve been thinking a lot about terrorism lately. Among the things I had in my carry-on was a detailed description of the 9/11 terrorists’ activities, replete with pictures of each of the terrorists and information about their background. Also, pages of my scribblings on terrorist incentives, potential targets, etc. This stuff was the first thing the screener pulled out of my bag. The previously cheery mood turned dark. Four TSA employees suddenly surrounded me. They didn’t seem very impressed with my explanation. When the boss arrived, one of the screeners said, “He claims to be an economics professor who studies terrorism.”
They proceeded to take every last item out of both my bags. It has been longer since I cleaned out my book bag than since I updated my personal web page. This is a book bag with 12 separate pockets, all of which are filled with junk.
“What is this?” the screener asked.
“It is a Monsters, Inc. lip gloss and key chain,” I responded.
And so it went for 30 minutes. Other than the lip gloss, he was particularly interested in my passport (luckily it was really mine), my PowerPoint presentation, the random pills floating among the crevices of my bag (covered with lint and pencil lead from years in purgatory), and a beat-up book (When Bad Things Happen to Good People).
Finally satisfied that I was playing for the home team, he allowed me to board a plane to Chicago. Thank God I had left at home my copy of the terrorist handbook that I blogged about recently, or I would have instead been flying straight to Cuba.
—SDL (July 14, 2005)
“Nobel Prize Winner Thomas Schelling”
I’ve changed addresses 10 times since I graduated from college. And each time I’ve moved, I’ve looked at the battered old box of college notebooks and debated whether it was time to throw the box out. After all, it has been more than 15 years and the box has never once been opened.
Thomas Schelling winning the Nobel Prize in Economics finally gave me a reason to open the box. My sophomore year in college, I took Econ 1030 from Schelling. I believe the course was entitled something like “Conflict and Strategy.” I still have vivid memories of the course. A crew-cut Schelling paced back and forth across the stage (never with any notes, if I remember correctly), spewing forth story after story that illuminated the application of simple game-theory concepts in everyday life. The pauses between the stories were long enough that I had the impression he was coming up with them on the spot, although my own experience as a teacher makes me think otherwise.
For me, this first introduction to game theory was inspirational. For someone who thinks strategically, or would like to think strategically, the basic tools of game theory are essential. The beauty of Schelling’s class was how easy the math was and how readily it applied to real world settings. The topics of the course were basic: the Prisoner’s Dilemma in lecture 1; Schelling’s own “tipping point” model in lectures 2 and 3; the tragedy of the commons and public-goods games after that; then commitment devices, credible and non-credible threats, and the strategy and tactics of controlling one’s own behavior. (For those who are unaware, Schelling coined the term “tipping point” thirty years before Malcolm Gladwell made it popular.)
Any economist could have taught the subjects in the class, but no one would have taught it as Schelling did. Each concept was accompanied by a barrage of examples. My notes are so poorly done—I would write down only a few key words—that now I can only guess at what the story was behind the words: “when Rhodesia became Zimbabwe,” “VHS vs. Beta,” “the quality of play in bridge leagues,” “choosing colleges,” “Dulles vs. National airports,” “Bear Bryant should not have voted for USC,” “good weatherman takes fair bets,” “tailgating,” “Landon vs. Roosevelt,” “randomly flushing the toilet,” etc.
I even remember attempting to put Schelling’s lessons immediately into practice. People who know me know that I can fall asleep anywhere, anytime. I would guess that I slept through some portion of 90 percent of my college classes. So when Schelling taught us about commitment, I decided I would start sitting in the front row of class as a way of committing myself not to sleep. Unfortunately, the urge to sleep often proved all too powerful. If Schelling were to remember me, it would be as the only kid in the first row who always fell asleep.
To my mind, Schelling represents the very best of game theory. He was a pioneer in the field, a man of ideas. Unfortunately for game theory, the simple ideas that are so alluring were quickly mined. What followed was less interesting. Modern game theory has become extremely mathematical, notation heavy, and removed from everyday life. Many of my colleagues would not agree with me, but I think game theory has failed to deliver on its enormous initial promise. I’m not the only one who feels this way. I was recently speaking with a prominent game theorist. He told me that if he knew what he knew and he were just getting started in the profession today, no way would he be a game theorist.
Schelling was an early inspiration to me. His course and writings were one of the big influences pushing me toward economics. My approach to economics shares much with his approach. I was saying this last year to one of my colleagues, who happened to run into Schelling and told Schelling he should count me as one of his students. Schelling was unmoved.
—SDL (Oct. 20, 2005)


NOTES
The bulk of this book was drawn from the research of Steven D. Levitt, often done in concert with one or more collaborators. The notes below include citations for the academic papers on which the material was based; most of them are available for download at http://pricetheory.uchicago.edu/levitt/LevittCV.html. We have also made liberal use of other scholars’ research, which is cited below; we thank them not only for their work but for the subsequent conversations that allowed us to best present their ideas. Other material in this book comes from previously unpublished research or interviews by one or both of the authors. Material not listed in these notes was generally drawn from readily accessible databases, news reports, and reference works.
AN EXPLANATORY NOTE
THE ITALICIZED EXCERPT originally appeared in Stephen J. Dubner, “The Probability That a Real-Estate Agent Is Cheating You (and Other Riddles of Modern Life),” New York Times Magazine, August 3, 2003. 
INTRODUCTION: THE HIDDEN SIDE OF EVERYTHING
THE FALL AND FALL OF CRIME: The crime-drop argument can be found in Steven D. Levitt, “Understanding Why Crime Fell in the 1990’s: Four Factors That Explain the Decline and Six That Do Not,” Journal of Economic Perspectives 18, no. 1 (2004), pp. 163–90. /1–2 The superpredator: See Eric Pooley, “Kids with Guns,” New York Magazine, August 9, 1991; John J. DiIulio Jr., “The Coming of the Super-Predators,” Weekly Standard, November 27, 1995; Tom Morganthau, “The Lull Before the Storm?” Newsweek, December 4, 1995; Richard Zoglin, “Now for the Bad News: A Teenage Time Bomb,” Time, January 15, 1996; and Ted Gest, “Crime Time Bomb,” U.S. News & World Report, March 25, 1996. / 2 James Alan Fox’s dire predictions can be found in a pair of government reports: “Trends in Juvenile Violence: A Report to the United States Attorney General on Current and Future Rates of Juvenile Offending” (Washington, D.C.: Bureau of Justice Statistics, 1996) and “Trends in Juvenile Violence: An Update” (Washington, D.C.: Bureau of Justice Statistics, 1997). / 2 President Clinton’s fearful comment came during a 1997 speech in Boston announcing new anti-crime measures; see Alison Mitchell, “Clinton Urges Campaign Against Youth Crime,” New York Times, February 20, 1997. /3–4 The story of Norma McCorvey/Jane Roe: See Douglas S. Wood, “Who Is ‘Jane Roe’?: Anonymous No More, Norma McCorvey No Longer Supports Abortion Rights,” CNN.com, June 18, 2003; and Norma McCorvey with Andy Meisler, I Am Roe: My Life, Roe v. Wade, and Freedom of Choice (New York: HarperCollins, 1994). / 4 The abortion-crime link is laid out in John J. Donohue III and Steven D. Levitt, “The Impact of Legalized Abortion on Crime,” Quarterly Journal of Economics 116, no. 2 (2001), pp. 379–420. Other scholars have had disagreements with portions of the theory. See Ted Joyce, “Did Legalized Abortion Lower Crime?” Journal of Human Resources 39, no. 1 (2004), pp. 1–28; and the Donohue-Levitt response, “Further Evidence That Legalized Abortion Lowered Crime: A Response to Joyce,” Journal of Human Resources 39, no. 1 (2004), pp. 29–49. See also Christopher L. Foote and Christopher F. Goetz, “Testing Economic Hypotheses with State-Level Data: A Comment on Donohue and Levitt (2001),” Federal Reserve Bank of Boston working paper 05–15 (2005); and, again, the Donohue-Levitt response, “Measurement Error, Legalized Abortion, the Decline in Crime: A Response to Foote and Goetz (2005),” National Bureau of Economic Research working paper, 2006.
THE REAL REAL-ESTATE STORY: The study measuring how a real-estate agent treats the sale of her own home versus a client’s home is Steven D. Levitt and Chad Syverson, “Market Distortions When Agents Are Better Informed: A Theoretical and Empirical Exploration of the Value of Information in Real Estate Transactions,” National Bureau of Economic Research working paper, 2005. /5–6 The lax California auto mechanics are discussed in Thomas Hubbard, “An Empirical Examination of Moral Hazard in the Vehicle Inspection Market,” RAND Journal of Economics 29, no. 1 (1998), pp. 406–26; and in Thomas Hubbard, “How Do Consumers Motivate Experts? Reputational Incentives in an Auto Repair Market,” Journal of Law & Economics 45, no. 2 (2002), pp. 437–68. / 6 Doctors who perform extra C-sections are examined in Jonathan Gruber and Maria Owings, “Physician Financial Incentives and Caesarean Section Delivery,” RAND Journal of Economics 27, no. 1 (1996), pp. 99–123.
THE MYTH OF CAMPAIGN SPENDING is told in greater detail in a trio of papers: Steven D. Levitt, “Using Repeat Challengers to Estimate the Effect of Campaign Spending on Election Outcomes in the U.S. House,” Journal of Political Economy, August 1994, pp. 777–98; Steven D. Levitt, “Congressional Campaign Finance Reform,” Journal of Economic Perspectives 9 (1995), pp. 183–93; and Steven D. Levitt and James M. Snyder Jr., “The Impact of Federal Spending on House Election Outcomes,” Journal of Political Economy 105, no. 1 (1997), pp. 30–53.
EIGHT GLASSES OF WATER A DAY: See Robert J. Davis, “Can Water Aid Weight Loss?” Wall Street Journal, March 16, 2004, which cites an Institute of Medicine report concluding that “there is no scientific basis for the recommendation [of eight glasses of water a day] and that most people get enough water through normal consumption of foods and beverages.”
ADAM SMITH is still well worth reading, of course (especially if you have infinite patience); so too is Robert Heilbroner’s The Worldly Philosophers (New York: Simon & Schuster, 1953), which contains memorable profiles of Smith, Karl Marx, Thorstein Veblen, John Maynard Keynes, Joseph Schumpeter, and other giants of economics.
1. WHAT DO SCHOOLTEACHERS AND SUMO WRESTLERS HAVE IN COMMON?
THE ISRAELI DAY-CARE STUDY: See Uri Gneezy and Aldo Rustichini, “A Fine Is a Price,” Journal of Legal Studies 29, no. 1 (January 2000), pp. 1–17; and Uri Gneezy, “The ‘W’ Effect of Incentives,” University of Chicago working paper.
MURDER THROUGH THE AGES: See Manuel Eisner, “Secular Trends of Violence, Evidence, and Theoretical Interpretations,” Crime and Justice: A Review of Research 3 (2003); also presented in Manuel Eisner, “Violence and the Rise of Modern Society,” Criminology in Cambridge, October 2003, pp. 3–7.
THOMAS JEFFERSON ON CAUSE AND EFFECT: Autobiography of Thomas Jefferson (1829; reprint, New York: G. P. Putnam’s Sons, 1914), p. 156.
BLOOD FOR MONEY: See Richard M. Titmuss, “The Gift of Blood,” Transaction 8 (1971); also presented in The Philosophy of Welfare: Selected Writings by R. M. Titmuss, ed. B. Abel-Smith and K. Titmuss (London: Allen and Unwin, 1987). See also William E. Upton, “Altruism, Attribution, and Intrinsic Motivation in the Recruitment of Blood Donors,” Ph.D. diss., Cornell University, 1973.
WHEN SEVEN MILLION CHILDREN DISAPPEARED OVERNIGHT: See Jeffrey Liebman, “Who Are the Ineligible EITC Recipients?” National Tax Journal 53 (2000), pp. 1165–86. Liebman’s paper was citing John Szilagyi, “Where Some of Those Dependents Went,” 1990 Research Conference Report: How Do We Affect Taxpayer Behavior? (Internal Revenue Service, March 1991), pp. 162–63.
CHEATING TEACHERS IN CHICAGO: This study, which also provides considerable background on high-stakes testing, is detailed in two papers: Brian A. Jacob and Steven D. Levitt, “Rotten Apples: An Investigation of the Prevalence and Predictors of Teacher Cheating,” Quarterly Journal of Economics 118, no. 3 (2003), pp. 843–77; and Brian A. Jacob and Steven D. Levitt, “Catching Cheating Teachers: The Results of an Unusual Experiment in Implementing Theory,” Brookings-Wharton Papers on Urban Affairs, 2003, pp. 185–209. / 23 The Oakland fifth-grader with the extra-helpful teacher: Based on an author interview with a former assistant superintendent of the Oakland Public Schools. / 30–31 Cheating among North Carolina teachers: See G. H. Gay, “Standardized Tests: Irregularities in Administering of Tests Affect Test Results,” Journal of Instructional Psychology 17, no. 2 (1990), pp. 93–103. / 31–33 The story of Arne Duncan, CEO of the Chicago schools, was based largely on author interviews; see also Amy D’Orio, “The Outsider Comes In,” District Administration: The Magazine for K–12 Education Leaders, August 2002; and various Chicago Tribune articles by Ray Quintanilla.
THE UNIVERSITY OF GEORGIA BASKETBALL TEST was made public when the university released 1,500 pages of documents in response to an investigation by the National Collegiate Athletic Association.
THE CHICAGO BLACK SOX: Several readers of the original version of Freakonomics have declared that the White Sox came to be called the Black Sox not because of the gambling scandal, but for another reason entirely. This is how the explanation plays out on the user-generated encyclopedia wikipedia.org: “The term ‘Black Sox’ came about earlier in [1919], when [team owner Charles] Comiskey decided to make players pay for their own laundry. The players stopped doing their laundry in protest, and as their white stockings became soiled and dark, the writers tagged them with that nickname.” As endearing as this explanation may seem, Levitt and Dubner found no support for it in the historical record.
CHEATING IN SUMO: See Mark Duggan and Steven D. Levitt, “Winning Isn’t Everything: Corruption in Sumo Wrestling,” American Economic Review 92, no. 5 (December 2002), pp. 1594–1605. / 35–41 There is a lot to know about sumo, and quite a bit can be found in these books: Mina Hall, The Big Book of Sumo (Berkeley, Calif.: Stonebridge Press, 1997); Keisuke Itai, Nakabon (Tokyo: Shogakkan Press, 2000); and Onaruto, Yaocho (Tokyo:Line Books, 2000). / 40 Two sumo whistle-blowers die mysteriously: See Sheryl WuDunn, “Sumo Wrestlers (They’re BIG) Facing a Hard Fall,” New York Times, June 28, 1996; and Anthony Spaeth, “Sumo Quake: Japan’s Revered Sport Is Marred by Charges of Tax Evasion, Match Fixing, Ties to Organized Crime, and Two Mysterious Deaths,” reporting by Irene M. Kunii and Hiroki Tashiro, Time (International Edition), September 30, 1996.
THE BAGEL MAN: Paul Feldman was looking for a research economist to take an interest in his data, and brought himself to Steven Levitt’s attention. (Several other scholars had passed.) Levitt and then Dubner subsequently visited Feldman’s bagel operation near Washington, D.C. Their research led to an article that was substantially similar to the version of the story published here: Stephen J. Dubner and Steven D. Levitt, “What the Bagel Man Saw,” The New York Times Magazine, June 6, 2004. Levitt has also written an academic paper about Feldman’s bagel operation: “An Economist Sells Bagels: A Case Study in Profit Maximization,” National Bureau of Economic Research working paper, 2006. / 43 The “Beer on the Beach” study is discussed in Richard H. Thaler, “Mental Accounting and Consumer Choice,” Marketing Science 4 (Summer 1985), pp. 119–214; also worth reading is Richard H. Thaler, The Winner’s Curse: Paradoxes and Anomalies of Economic Life (New York: Free Press, 1992).
2. HOW IS THE KU KLUX KLAN LIKE A GROUP OF REAL-ESTATE AGENTS?
SPILLING THE KLAN’S SECRETS: This section has been substantially revised since the original version of Freakonomics was published, owing to the authors’ discovery that Stetson Kennedy—in both his memoir, The Klan Unmasked, and in interviews with the authors—had misrepresented his role in personally infiltrating and attacking the Klan. ([“Hoodwinked?” New York Times, January 8, 2006] for a fuller explanation of this issue.) For general Klan history, see Col. Winfield Jones, Knights of the Ku Klux Klan (1941); David M. Chalmers, Hooded Americanism: The First Century of the Ku Klux Klan, 1865–1965 (Garden City, NY: Doubleday, 1965); Wyn Craig Wade, The Fiery Cross: The Ku Klux Klan in America (New York: Simon & Schuster, 1987); and many others. The most relevant writings of Stetson Kennedy include Southern Exposure (Garden City, NY: Doubleday, 1946; republished in 1991 by Florida Atlantic University Press) and The Klan Unmasked (Boca Raton: Florida Atlantic University Press, 1990), which was originally published as I Rode with the Ku Klux Klan (London: Arco Publishers, 1954). Also helpful was Ben Green, Before His Time: The Untold Story of Harry T. Moore, America’s First Civil Rights Martyr (New York: Simon & Schuster, 1999). Stetson Kennedy’s documents relating to the Klan, as well as the reports of “John Brown” and other related material, can be found in various archives, including the Schomburg Center for Research in Black Culture, a public library in New York City; the Georgia State University Library in Atlanta; and the archives of the Anti-Defamation League in New York City. Transcripts of the Drew Pearson Washington Merry-Go-Round radio program can be found at http://www.aladin.wrlc.org/gsdl/ collect/pearson/pearson.shtml.
WHAT HAPPENED TO TERM-LIFE RATES? See Jeffrey R. Brown and Austan Goolsbee, “Does the Internet Make Markets More Competitive? Evidence from the Life Insurance Industry,” Journal of Political Economy 110, no. 3 (June 2002), pp. 481–507.
SUPREME COURT JUSTICE LOUIS D. BRANDEIS writing that “Sunlight is said to be the best of disinfectants”: See Louis D. Brandeis, Other People’s Money—and How Bankers Use It (New York: Frederick A. Stokes, 1914).
THE BRAND-NEW USED-CAR CONUNDRUM: This thesis, and indeed much of what we think today about “asymmetric information,” stems from a paper that George A. Akerlof wrote during his first year as an assistant professor at Berkeley in 1966–67. It was rejected three times—two of the journals told Akerlof that they “did not publish papers on topics of such triviality,” as he later recalled—before being published as George A. Akerlof, “The Market for ‘Lemons’: Quality Uncertainty and the Market Mechanism,” Quarterly Journal of Economics, August 1970. Some thirty years later, the paper won Akerlof the Nobel Prize in Economics; he is widely considered the nicest man to have ever won the award.
THE ENRON TAPES: As of this writing, the tapes could be heard on http:// www.cbsnews.com/stories/2004/06/01/eveningnews/main6_20626.shtml. See also Richard A. Oppel Jr., “Enron Traders on Grandma Millie and Making Out Like Bandits,” New York Times, June 13, 2004.
ARE ANGIOPLASTIES NECESSARY? See Gina Kolata, “New Heart Studies Question the Value of Opening Arteries,” New York Times, March 21, 2004.
THE REAL REAL-ESTATE STORY, REVISITED: See Steven D. Levitt and Chad Syverson, “Market Distortions When Agents Are Better Informed: A Theoretical and Empirical Exploration of the Value of Information in Real-Estate Transactions,” National Bureau of Economic Research working paper, 2005.
TRENT LOTT, NOT-SO-SECRET SEGREGATIONIST? The circumstances surrounding Lott’s damaging comments are well summarized in Dan Goodgame and Karen Tumulty, “Lott: Tripped Up by History,” Time.com/cnn.com, December 16, 2002.
THE WEAKEST LINK: See Steven D. Levitt, “Testing Theories of Discrimination: Evidence from The Weakest Link,” Journal of Law and Economics (October 2004), pp. 431–52. / 72 The theory of taste-based discrimination originates with Gary S. Becker, The Economics of Discrimination (Chicago: University of Chicago Press, 1957). / 72 The theory of information-based discrimination is derived from a number of papers, including Edmund Phelps, “A Statistical Theory of Racism and Sexism,” American Economic Review 62, no. 4 (1972), pp. 659–61; and Kenneth Arrow, “The Theory of Discrimination,” Discrimination in Labor Markets, ed. Orley Ashenfelter and Albert Rees (Princeton, N.J.: Princeton University Press, 1973).
THE ONLINE DATING STORY: See Günter J. Hitsch, Ali Hortaçsu, and Dan Ariely, “What Makes You Click: An Empirical Analysis of Online Dating,” University of Chicago working paper, 2005.
VOTERS LYING ABOUT DINKINS / GIULIANI: See Timur Kuran, Private Truths, Public Lies: The Social Consequences of Preference Falsification (Cambridge, Mass.: Harvard University Press, 1995); also Kevin Sack, “Governor Joins Dinkins Attack Against Rival,” New York Times, October 27, 1989; and Sam Roberts, “Uncertainty over Polls Clouds Strategy in Mayor Race,” New York Times, October 31, 1989.
VOTERS LYING ABOUT DAVID DUKE: See Kuran, Private Truths, Public Lies; also Peter Applebome, “Republican Quits Louisiana Race in Effort to Defeat Ex-Klansman,” New York Times, October 5, 1990; and Peter Applebome, “Racial Politics in South’s Contests: Hot Wind of Hate or Last Gasp?” New York Times, November 5, 1990.
DAVID DUKE, MASTER OF INFORMATION ABUSE: Among the many helpful sources for this material were Karen Henderson, “David Duke’s Work-Release Program,” National Public Radio, May 14, 2004; and the exhaustive John McQuaid, “Duke’s Decline,” New Orleans Times-Picayune, April 13, 2003.
3. WHY DO DRUG DEALERS STILL LIVE WITH THEIR MOMS?
JOHN KENNETH GALBRAITH’S “CONVENTIONAL WISDOM”: See “The Concept of the Conventional Wisdom,” the second chapter of The Affluent Society (Boston: Houghton Mifflin, 1958).
MITCH SNYDER AND THE HOMELESS MILLIONS: The controversy over Snyder’s activism was covered widely, particularly in Colorado newspapers, during the early 1980s and was revisited in 1990 when Snyder committed suicide. A good overview is provided in Gary S. Becker and Guity Nashat Becker, “How the Homeless ‘Crisis’ Was Hyped,” in The Economics of Life (New York: McGraw-Hill, 1997), pp. 175–76; the chapter was adapted from a 1994 Business Week article by the same authors.
THE INVENTION OF CHRONIC HALITOSIS: The strange and compelling story of Listerine is beautifully told in James B. Twitchell, Twenty Ads That Shook the World: The Century’s Most Groundbreaking Advertising and How It Changed Us All (New York: Crown, 2000), pp. 60–69.
GEORGE W. BUSH AS A MAKE-BELIEVE COWBOY: See Paul Krugman, “New Year’s Resolutions,” New York Times, December 26, 2003.
NOT AS MUCH RAPE AS IS COMMONLY THOUGHT: The 2002 statistics from the National Crime Survey, which is designed to elicit honest responses, suggests that the lifetime risk of a woman’s being the victim of unwanted sexual activity or attempted unwanted sexual activity is about one in eight (not one in three, as is typically argued by advocates). For men, the National Crime Survey suggests a one-in-forty incidence, rather than the one-in-nine incidence cited by advocates.
NOT AS MUCH CRIME AS THERE ACTUALLY WAS: See Mark Niesse, “Report Says Atlanta Underreported Crimes to Help Land 1996 Olympics,” Associated Press, February 20, 2004.
SUDHIR VENKATESH’s LONG, STRANGE TRIP INTO THE CRACK DEN: As of this writing, Venkatesh is a professor of sociology and African American studies at Columbia University. / 83–99 The biographical material on Venkatesh was drawn largely from author interviews; see also Jordan Marsh, “The Gang Way,” Chicago Reader, August 8, 1997; and Robert L. Kaiser, “The Science of Fitting In,” Chicago Tribune, December 10, 2000. / 89–99 The particulars of the crack gang are covered in four papers by Sudhir Alladi Venkatesh and Steven D. Levitt: “The Financial Activities of an Urban Street Gang,” Quarterly Journal of Economics 115, no. 3 (August 2000), pp. 755–89; “‘Are We a Family or a Business?’ History and Disjuncture in the Urban American Street Gang,” Theory and Society 29 (Autumn 2000), pp. 427–62; “Growing Up in the Projects: The Economic Lives of a Cohort of Men Who Came of Age in Chicago Public Housing,” American Economic Review 91, no. 2 (2001), pp. 79–84; and “The Political Economy of an American Street Gang,” American Bar Foundation working paper, 1998. See also Sudhir Alladi Venkatesh, American Project: The Rise and Fall of a Modern Ghetto (Cambridge, Mass.: Harvard University Press, 2000). / 94 Crack dealing as the most dangerous job in America: According to the Bureau of Labor Statistics, the ten most dangerous legitimate occupations are timber cutters, fishers, pilots and navigators, structural metal workers, drivers/sales workers, roofers, electrical power installers, farm occupations, construction laborers, and truck drivers.
THE INVENTION OF NYLON STOCKINGS: It was Wallace Carothers, a young Iowa-born chemist employed by DuPont, who, after seven years of trying, found a way to blow liquid polymers through tiny nozzles to create a fiber of superstrong strands. This was nylon. Several years later, DuPont introduced nylon stockings in New York and London. Contrary to lore, the miracle fabric’s name did not derive from a combination of those two cities’ names. Nor was it, as rumored, an acronym for “Now You’ve Lost, Old Nippon,” a snub to Japan’s dominant silk market. The name was actually a hepped-up rendering of “No Run,” a slogan that the new stockings could not in fact uphold, but whose failure hardly diminished their success. Carothers, a longtime depressive, did not live to see his invention blossom: he killed himself in 1937 by drinking cyanide. See Matthew E. Hermes, Enough for One Lifetime: Wallace Carothers, Inventor of Nylon (Philadelphia: Chemical Heritage Foundation, 1996).
CRACK SLANG: The Greater Dallas Council on Alcohol and Drug Abuse has compiled an extraordinarily entertaining index of cocaine street names. For cocaine powder: Badrock, Bazooka, Beam, Berni, Bernice, Big C, Blast, Blizzard, Blow, Blunt, Bouncing Powder, Bump, C, Caballo, Caine, Candy, Caviar, Charlie, Chicken Scratch, Coca, Cocktail, Coconut, Coke, Cola, Damablanca, Dust, Flake, Flex, Florida Snow, Foo Foo, Freeze, G-Rock, Girl, Goofball, Happy Dust, Happy Powder, Happy Trails, Heaven, King, Lady, Lady Caine, Late Night, Line, Mama Coca, Marching Dust/Powder, Mojo, Monster, Mujer, Nieve, Nose, Nose Candy, P-Dogs, Peruvian, Powder, Press, Prime Time, Rush, Shot, Sleighride, Sniff, Snort, Snow, Snow-birds, Soda, Speedball, Sporting, Stardust, Sugar, Sweet Stuff, Toke, Trails, White Lady, White Powder, Yeyo, Zip. For smokeable cocaine: Base, Ball, Beat, Bisquits, Bones, Boost, Boulders, Brick, Bump, Cakes, Casper, Chalk, Cookies, Crumbs, Cubes, Fatbags, Freebase, Gravel, Hardball, Hell, Kibbles’n Bits, Kryptonite, Love, Moonrocks, Nuggets, Onion, Pebbles, Piedras, Piece, Ready Rock, Roca, Rock(s), Rock Star, Scotty, Scrabble, Smoke House, Stones, Teeth, Tornado.
THE JOHNNY APPLESEED OF CRACK: Oscar Danilo Blandon and his purported alliance with the Central Intelligence Agency are discussed in great detail, and in a manner that stirred great controversy, in a three-part San Jose Mercury News series by Gary Webb, beginning on August 18, 1996. See also Tim Golden, “Though Evidence Is Thin, Tale of C.I.A. and Drugs Has a Life of Its Own,” New York Times, October 21, 1996; and Gary Webb, Dark Alliance: The CIA, the Contras, and the Crack Cocaine Explosion (New York: Seven Stories Press, 1998). The U.S. Department of Justice later examined the matter in detail in “The C.I.A.–Contra–Crack Cocaine Controversy: A Review of the Justice Department’s Investigations and Prosecutions,” available as of this writing at www.usdoj.gov/oig/special/9712/ch01p1.htm.
GANGS IN AMERICA: See Frederick Thrasher, The Gang (Chicago: University of Chicago Press, 1927).
THE SHRINKING OF VARIOUS BLACK-WHITe GAPS, PRE-CRACK: See Rebecca Blank, “An Overview of Social and Economic Trends by Race,” in America Becoming: Racial Trends and Their Consequences, ed. Neil J. Smelser, William Julius Wilson, and Faith Mitchell (Washington, D.C.: National Academy Press, 2001), pp. 21–40. / 103 Regarding black infant mortality, see Douglas V. Almond, Kenneth Y. Chay, and Michael Greenstone, “Civil Rights, the War on Poverty, and Black-White Convergence in Infant Mortality in Mississippi,” National Bureau of Economic Research working paper, 2003.
THE VARIOUS DESTRUCTIVE EFFECTS OF CRACK are discussed in Roland G. Fryer Jr., Paul Heaton, Steven D. Levitt, and Kevin Murphy, “The Impact of Crack Cocaine,” University of Chicago working paper, 2005.
4. WHERE HAVE ALL THE CRIMINALS GONE?
NICOLAE CEAUşESCU’S ABORTION BAN: Background information on Romania and the Ceauşescus was drawn from a variety of sources, including “Eastern Europe, the Third Communism,” Time, March 18, 1966; “Ceauşescu Ruled with an Iron Grip,” Washington Post, December 26, 1989; Ralph Blumenthal, “The Ceauşescus: 24 Years of Fierce Repression, Isolation and Independence,” New York Times, December 26, 1989; Serge Schmemann, “In Cradle of Rumanian Revolt, Anger Quickly Overcame Fear,” New York Times, December 30, 1989; Karen Breslau, “Overplanned Parenthood: Ceauşescu’s Cruel Law,” Newsweek, January 22, 1990; and Nicolas Holman, “The Economic Legacy of Ceauşescu,” Student Economic Review, 1994. / 106 The link between the Romanian abortion ban and life outcomes has been explored in a pair of papers: Cristian Pop-Eleches, “The Impact of an Abortion Ban on Socio-Economic Outcomes of Children: Evidence from Romania,” Columbia University working paper, 2002; and Cristian Pop-Eleches, “The Supply of Birth Control Methods, Education and Fertility: Evidence from Romania,” Columbia University working paper, 2002.
THE GREAT AMERICAN CRIME DROP: As noted earlier, this material is drawn from Steven D. Levitt, “Understanding Why Crime Fell in the 1990’s: Four Factors That Explain the Decline and Six That Do Not,” Journal of Economic Perspectives 18, no. 1 (2004), pp. 163–90. / 108 James Alan Fox’s “intentional overstatement”: See Torsten Ove, “No Simple Solution for Solving Violent Crimes,” Pittsburgh Post-Gazette, September 12, 1999.
POLITICIANS WERE GROWING INCREASINGLY SOFTER ON CRIME: This and a number of related issues are discussed in Gary S. Becker and Guity Nashat Becker, “Stiffer Jail Terms Will Make Gunmen More Gun-Shy,” “How to Tackle Crime? Take a Tough, Head-On Stance,” and “The Economic Approach to Fighting Crime,” all in The Economics of Life (New York: McGraw-Hill, 1997), pp. 135–44; the chapters were adapted from Business Week articles by the same authors.
INCREASED RELIANCE ON PRISONS: Concerning the fifteenfold increase in drug-crime prisoners, see Ilyana Kuziemko and Steven D. Levitt, “An Empirical Analysis of Imprisoning Drug Offenders,” Journal of Public Economics 88, nos. 9–10 (2004), pp. 2043–66. / 111 What if we just turn all the prisoners loose? See William Nagel, “On Behalf of a Moratorium on Prison Construction,” Crime and Delinquency 23 (1977), pp. 152–74. / 111 “Apparently, it takes a Ph.D….”: See John J. DiIulio Jr., “Arresting Ideas: Tougher Law Enforcement Is Driving Down Urban Crime,” Policy Review, no. 75 (Fall 1995).
CAPITAL PUNISHMENT: For a full report on New York State’s failure to execute a single criminal, see “Capital Punishment in New York State: Statistics from Eight Years of Representation, 1995–2003” (New York: The Capital Defender Office, August 2003), which is available as of this writing at nycdo.org/8yr.html. More recently, New York’s Court of Appeals found the death penalty itself unconstitutional, effectively halting all executions. / 113 Executing 1 criminal translates into 7 fewer homicides: See Isaac Ehrlich, “The Deterrent Effect of Capital Punishment: A Question of Life and Death,” American Economic Review 65 (1975), pp. 397–417; and Isaac Ehrlich, “Capital Punishment and Deterrence: Some Further Thoughts and Evidence,” Journal of Political Economy 85 (1977), pp. 741–88. / 113 “I no longer shall tinker with the machinery of death”: From Justice Harry A. Blackmun’s dissenting opinion in a 1994 Supreme Court decision denying review of a Texas death-penalty case: Callins v. Collins, 510 U.S. 1141 (1994); cited in Congressional Quarterly Researcher 5, no. 9 (March 10, 1995). It should be noted that American juries also seem to have lost their appetite for the death penalty—in part, it seems, because of the frequency with which innocent people have been executed in recent years or exonerated while on death row. During the 1990s, an average of 290 criminals were given the death sentence each year; in the first four years of the 2000s, that number had dropped to 174. See Adam Liptak, “Fewer Death Sentences Being Imposed in U.S.,” New York Times, September 15, 2004.
DO POLICE ACTUALLY LOWER CRIME? See Steven D. Levitt, “Using Electoral Cycles in Police Hiring to Estimate the Effect of Police on Crime,” American Economic Review 87, no. 3 (1997), pp. 270–90; Steven D. Levitt, “Why Do Increased Arrest Rates Appear to Reduce Crime: Deterrence, Incapacitation, or Measurement Error?” Economic Inquiry 36, no. 3 (1998), pp. 353–72; and Steven D. Levitt, “The Response of Crime Reporting Behavior to Changes in the Size of the Police Force: Implications for Studies of Police Effectiveness Using Reported Crime Data,” Journal of Quantitative Criminology 14 (February 1998), pp. 62–81. / 114–15 The 1960s as a great time to be a criminal: See Gary S. Becker and Guity Nashat Becker, The Economics of Life (New York: McGraw-Hill, 1997), pp. 142–43.
NEW YORK CITY’S CRIME “MIRACLE”: The “Athenian period” quote came from an author interview with former police captain William J. Gorta, one of CompStat’s inventors. / 116 The broken window theory: See James Q. Wilson and George L. Kelling, “Broken Windows: The Police and Neighborhood Safety,” Atlantic Monthly, March 1982. / 118 Bratton hiring more police in Los Angeles: See Terry McCarthy, “The Gang Buster,” Time, January 19, 2004.
GUN LAWS: Concerning the fact that the United States has more guns than it has adults, see Philip Cook and Jens Ludwig, Guns in America: Results of a Comprehensive Survey of Gun Ownership and Use (Washington, D.C.: Police Foundation, 1996). / 119 The gun-crime link: See Mark Duggan, “More Guns, More Crime,” Journal of Political Economy 109, no. 5 (2001), pp. 1086–1114. / 119 Guns in Switzerland: See Stephen P. Halbrook, “Armed to the Teeth, and Free,” Wall Street Journal Europe, June 4, 1999. / 120 The impotent Brady Act: See Jens Ludwig and Philip Cook, “Homicide and Suicide Rates Associated with Implementation of the Brady Handgun Violence Prevention Act,” Journal of the American Medical Association 284, no. 5 (2000), pp. 585–91. / 120 Felons buying black-market guns: See James D. Wright and Peter H. Rossi, Armed and Considered Dangerous: A Survey of Felons and Their Firearms (Hawthorne, N.Y.: Aldine de Gruyter, 1986). / 121 The gun-for-psychotherapy swap: See “Wise Climb-Down, Bad Veto,” Los Angeles Times, October 5, 1994. / 121 Why gun buybacks don’t work: See C. Callahan, F. Rivera, and T. Koepsell, “Money for Guns: Evaluation of the Seattle Gun Buy-Back Program,” Public Health Reports 109, no. 4 (1994), pp. 472–77; David Kennedy, Anne Piehl, and Anthony Braga, “Youth Violence in Boston: Gun Markets, Serious Youth Offenders, and a Use-Reduction Strategy,” Law and Contemporary Problems 59 (1996), pp. 147–83; and Peter Reuter and Jenny Mouzon, “Australia: A Massive Buyback of Low-Risk Guns,” in Evaluating Gun Policy: Effects on Crime and Violence, ed. Jens Ludwig and Philip Cook (Washington, D.C.: Brookings Institution, 2003). /121 John Lott’s right-to-carry theory: See John R. Lott Jr. and David Mustard, “Right-to-Carry Concealed Guns and the Importance of Deterrence,” Journal of Legal Studies 26 (January 1997), pp. 1–68; and John R. Lott Jr., More Guns, Less Crime: Understanding Crime and Gun Control Laws (Chicago: University of Chicago Press, 1998). / 121 John Lott as Mary Rosh: See Julian Sanchez, “The Mystery of Mary Rosh,” Reason, May 2003; and Richard Morin, “Scholar Invents Fan to Answer His Critics,” Washington Post, February 1, 2003. / 121–22 Lott’s gun theory disproved: See Ian Ayres and John J. Donohue III, “Shooting Down the ‘More Guns, Less Crime’ Hypothesis,” Stanford Law Review 55 (2003), pp. 1193–1312; and Mark Duggan, “More Guns, More Crime,” Journal of Political Economy 109, no. 5 (2001), pp. 1086–1114.
THE BURSTING OF THE CRACK BUBBLE: For a discussion of crack’s history and particulars, see Roland G. Fryer Jr., Paul Heaton, Steven Levitt, and Kevin Murphy, “The Impact of Crack Cocaine,” University of Chicago working paper, 2005. / 122 More than 25 percent of homicides: See Paul J. Goldstein, Henry H. Brownstein, Patrick J. Ryan, and Patricia A. Bellucci, “Crack and Homicide in New York City: A Case Study in the Epidemiology of Violence,” in Crack in America: Demon Drugs and Social Justice, ed. Craig Reinarman and Harry G. Levine (Berkeley: University of California Press, 1997), pp. 113–30.
THE “AGING POPULATION” THEORY: See Steven D. Levitt, “The Limited Role of Changing Age Structure in Explaining Aggregate Crime Rates,” Criminology 37, no. 3 (1999), pp. 581–99. Although the aging theory has by now been widely discounted, learned experts continue to float it; see Matthew L. Wald, “Most Crimes of Violence and Property Hover at 30-Year Low,” New York Times, September 13, 2004, in which Lawrence A. Greenfield, director of the Bureau of Justice Statistics, says, “There is probably no single factor explanation for why the crime rates have been going down all these years and are now at the lowest level since we started measuring them in 1973. It probably has to do with demographics, and it probably has to do with having a lot of very high-rate offenders behind bars.” / 123 “There lurks a cloud”: See James Q. Wilson, “Crime and Public Policy,” in Crime, ed. James Q. Wilson and Joan Petersilia (San Francisco: ICS Press, 1995), p. 507.
THE ABORTION-CRIME LINK: For an overview, see John J. Donohue III and Steven D. Levitt, “The Impact of Legalized Abortion on Crime,” Quarterly Journal of Economics 116, no. 2 (2001), pp. 379–420; and John J. Donohue III and Steven D. Levitt, “Further Evidence That Legalized Abortion Low ered Crime: A Response to Joyce,”Journal of Human Resources 39, no. 1 (2004), pp. 29–49. / 124 Abortion studies in Eastern Europe and Scandinavia: See P. K. Dagg, “The Psychological Sequelae of Therapeutic Abortion—Denied and Completed,” American Journal of Psychiatry 148, no. 5 (May 1991), pp. 578–85; and Henry David, Zdenek Dytrych, et al., Born Unwanted: Developmental Effects of Denied Abortion (New York: Springer, 1988). / 125 The Roe v. Wade opinion: Roe v. Wade, 410 U.S. 113 (1973). / 126 One study has shown that the typical child: See Jonathan Gruber, Philip P. Levine, and Douglas Staiger, “Abortion Legalization and Child Living Circumstances: Who Is the ‘Marginal Child’?” Quarterly Journal of Economics 114 (1999), pp. 263–91. / 126 Strongest predictors of a criminal future: See Rolf Loeber and Magda Stouthamer-Loeber, “Family Factors as Correlates and Predictors of Juvenile Conduct Problems and Delinquency,” Crime and Justice, vol. 7, ed. Michael Tonry and Norval Morris (Chicago: University of Chicago Press, 1986); also, Robert Sampson and John Laub, Crime in the Making: Pathways and Turning Points Through Life (Cambridge, Mass.: Harvard University Press, 1993). / 127 So does having a teenage mother: See William S. Comanor and Llad Phillips, “The Impact of Income and Family Structure on Delinquency,” University of California–Santa Barbara working paper, 1999. / 127 Another study has shown that low maternal education: Pirkko Räsänen et al., “Maternal Smoking During Pregnancy and Risk of Criminal Behavior Among Adult Male Offspring in the Northern Finland 1966 Birth Cohort,” American Journal of Psychiatry 156 (1999), pp. 857–62. / 127 Infanticide fell dramatically: See Susan Sorenson, Douglas Wiebe, and Richard Berk, “Legalized Abortion and the Homicide of Young Children: An Empirical Investigation,” Analyses of Social Issues and Public Policy 2, no. 1 (2002), pp. 239–56. / 129 Studies of Australia and Canada: See Anindya Sen, “Does Increased Abortion Lead to Lower Crime? Evaluating the Relationship between Crime, Abortion, and Fertility,” unpublished manuscript; and Andrew Leigh and Justin Wolfers, “Abortion and Crime,” AQ: Journal of Contemporary Analysis 72, no. 4 (2000), pp. 28–30. / 129 Many of the aborted baby girls: See John J. Donohue III, Jeffrey Grogger, and Steven D. Levitt, “The Impact of Legalized Abortion on Teen Childbearing,” University of Chicago working paper, 2002. / 130 Abortion worse than slavery: See Michael S. Paulsen, “Accusing Justice: Some Variations on the Themes of Robert M. Cover’s Justice Accused,” Journal of Law and Religion 7, no. 33 (1989), pp. 33–97. / 130 Abortion as “the only effective crime-prevention device”: See Anthony V. Bouza, The Police Mystique: An Insider’s Look at Cops, Crime, and the Criminal Justice System (New York: Plenum, 1990). / 130 $9 million to save a spotted owl: See Gardner M. Brown and Jason F. Shogren, “Economics of the Endangered Species Act,” Journal of Economic Perspectives 12, no. 3 (1998), pp. 3–20. / 130 $31 to prevent another Exxon Valdez –type spill: See Glenn W. Harrison, “Assessing Damages for the Exxon Valdez Oil Spill,” University of Central Florida working paper, 2004. / 130–31 Body-part price list: Drawn from the state of Connecticut’s Workers’ Compensation Information Packet, p. 27, available as of this writing at wcc.state.ct.us/ download/acrobat/info-packet.pdf.
5. WHAT MAKES A PERFECT PARENT?
THE EVER CHANGING WISDOM OF PARENTING EXPERTS: Ann Hulbert, Raising America: Experts, Parents, and a Century of Advice About Children (New York: Knopf, 2003), is an extremely helpful compendium of parenting advice. / 134 Gary Ezzo’s “infant-management strategy” and sleep deprivation warning: See Gary Ezzo and Robert Bucknam, On Becoming Babywise (Sisters, Ore.: Multnomah, 1995), pp. 32 and 53. / 134 T. Berry Brazelton and the “interactive” child: T. Berry Brazelton, Infants and Mothers: Difference in Development, rev. ed. (New York: Delta/Seymour Lawrence, 1983), p. xxiii. / 134 L. Emmett Holt’s warning against “undue stimulation”: L. Emmett Holt, The Happy Baby (New York: Dodd, Mead, 1924), p. 7. / 134 Crying as “the baby’s exercise”: L. Emmett Holt, The Care and Feeding of Children: A Catechism for the Use of Mothers and Children’s Nurses (New York: Appleton, 1894), p. 53.
A GUN OR A SWIMMING POOL? See Steven Levitt, “Pools More Dangerous than Guns,” Chicago Sun-Times, July 28, 2001.
PETER SANDMAN ON MAD-COW DISEASE AND OTHER RISKS: See Amanda Hesser, “Squeaky Clean? Not Even Close,” New York Times, January 28, 2004; and “The Peter Sandman Risk Communication Web Site,” at http:// www.psandman.com/index.htm.
HOW MUCH DO PARENTS REALLY MATTER? See Judith Rich Harris, The Nurture Assumption: Why Children Turn Out the Way They Do (New York: Free Press, 1998); for a Harris profile that also provides an excellent review of the nature-nurture debate, see Malcolm Gladwell, “Do Parents Matter?” The New Yorker, August 17, 1998; and Carol Tavris, “Peer Pressure,” New York Times Book Review, September 13, 1998. / 141 “‘Here we go again’”: See Tavris, “Peer Pressure.” / 141 Pinker called Harris’s views “mind-boggling”: Steven Pinker, “Sibling Rivalry: Why the Nature/Nurture Debate Won’t Go Away,” Boston Globe, October 13, 2002, adapted from Steven Pinker, The Blank Slate: The Modern Denial of Human Nature (New York: Viking, 2002).
SCHOOL CHOICE IN CHICAGO: This material is drawn from Julie Berry Cullen, Brian Jacob, and Steven D. Levitt, “The Impact of School Choice on Student Outcomes: An Analysis of the Chicago Public Schools,” Journal of Public Economics, forthcoming; and Julie Berry Cullen, Brian Jacob, and Steven D. Levitt, “The Effect of School Choice on Student Outcomes: Evidence from Randomized Lotteries,” National Bureau of Economic Research working paper, 2003.
STUDENTS WHO ARRIVE AT HIGH SCHOOL NOT PREPARED TO DO HIGH SCHOOL WORK: See Tamar Lewin, “More Students Passing Regents, but Achievement Gap Persists,” New York Times, March 18, 2004.
THE BLACK-WHITE INCOME GAP TRACED TO EIGHTH-GRADE TEST SCORE GAP: See Derek Neal and William R. Johnson, “The Role of Pre-Market Factors in Black-White Wage Differences,” Journal of Political Economy 104 (1996), pp. 869–95; and June O’Neill, “The Role of Human Capital in Earnings Differences Between Black and White Men,” Journal of Economic Perspectives 4, no. 4 (1990), pp. 25–46. / 146 “Reducing the black-white test score gap”: See Christopher Jencks and Meredith Phillips, “America’s Next Achievement Test: Closing the Black-White Test Score Gap,” American Prospect 40 (September–October 1998), pp. 44–53.
“ACTING WHITE”: See David Austen-Smith and Roland G. Fryer Jr., “The Economics of ‘Acting White,’” National Bureau of Economic Research working paper, 2003. / 146 Kareem Abdul-Jabbar: Kareem Abdul-Jabbar and Peter Knobler, Giant Steps (New York: Bantam, 1983), p. 16.
THE BLACK-WHITE TEST SCORE GAP AND THE ECLS: This material was drawn from Roland G. Fryer Jr. and Steven D. Levitt, “Understanding the Black-White Test Score Gap in the First Two Years of School,” Review of Economics and Statistics 86, no. 2 (2004), pp. 447–64. While this paper contains little discussion of the correlation between test scores and home-based factors (television viewing, spanking, etc.), a regression of those data is included in the paper’s appendix. Regarding the ECLS study itself: as of this writing, an overview of the study was posted at nces.ed.gov/ecls/.
ADOPTIVE PARENTS WITH HIGHER IQS THAN BIRTH MOTHER: See Bruce Sacerdote, “The Nature and Nurture of Economic Outcomes,” National Bureau of Economic Research working paper, 2000.
FINNISH LITERACY: SEE LIZETTE ALVAREZ, “EDUCATORS FLOCKING TO FINLAND, AND OF LITERATE CHILDREN,” New York Times, April 9, 2004.
A BOOK FOR EVERY TOT: See John Keilman, “Governor Wants Books for Tots; Kids Would Get 60 by Age 5 in Effort to Boost Literacy,” Chicago Tribune, January 12, 2004.
THE INFLUENCE OF ADOPTIVE PARENTS: See Sacerdote, “The Nature and Nurture of Economic Outcomes.”
6. PERFECT PARENTING, PART II; OR: WOULD A ROSHANDA BY ANY OTHER NAME SMELL AS SWEET?
THE STORY OF LOSER LANE: Drawn from author interviews and from Sean Gardiner, “Winner and Loser: Names Don’t Decide Destiny,” Newsday, July 22, 2002.
THE JUDGE AND THE TEMPTRESS: Based on author interviews.
ROLAND G. FRYER AND THE STUDY OF BLACK UNDERACHIEVEMENT: Drawn from author interviews.
THE BLACK-WHITE CIGARETTE GAP: See Lloyd Johnston, Patrick O’Malley, Jerald Bachman, and John Schulenberg, “Cigarette Brand Preferences Among Adolescents,” Monitoring the Future Occasional Paper 45, Institute for Social Research, University of Michigan, 1999.
BLACK NAMES (AND OTHER BLACK-WHITE CULTURE GAPS): See Roland G. Fryer Jr. and Steven D. Levitt, “The Causes and Consequences of Distinctively Black Names,” Quarterly Journal of Economics 119, no. 3 (August 2004), pp. 767–805.
“WHITE” RéSUMéS BEATING OUT “BLACK” RéSUMéS: The most recent audit study to reach such a conclusion is Marianne Bertrand and Sendhil Mullainathan, “Are Emily and Greg More Employable than Lakisha and Jamal? A Field Experiment Evidence on Labor Market Discrimination,” National Bureau of Economic Research working paper, 2003.
YO XING HEYNO AUGUSTUS EISNER ALEXANDER WEISER KNUCKLES JEREMIJENKO-CONLEY: See Tara Bahrampour, “A Boy Named Yo, Etc.: Name Changes, Both Practical and Fanciful, Are on the Rise,” New York Times, September 25, 2003.
MICHAEL GOLDBERG, INDIAN-BORN SIKH: See Robert F. Worth, “Livery Driver Is Wounded in a Shooting,” New York Times, February 9, 2004.
WILLIAM MORRIS, Né ZELMAN MOSES: Author interview with Alan Kannof, former chief operating officer of the William Morris Agency.
BRAND NAMES AS FIRST NAMES: Drawn from California birth-certificate data and also discussed in Stephanie Kang, “Naming the Baby: Parents Brand Their Tot with What’s Hot,” Wall Street Journal, December 26, 2003.
A GIRL NAMED SHITHEAD: The woman who called the radio show to tell Roland Fryer about her niece Shithead might have been misinformed, of course, or even outright lying. Regardless, she was hardly alone in her feeling that black names sometimes go too far. Bill Cosby, during a speech in May 2004 at the NAACP’s Brown v. Board of Education fiftieth-anniversary gala, lambasted lower-income blacks for a variety of self-destructive behaviors, including the giving of “ghetto” names. Cosby was summarily excoriated by white and black critics alike. (See Barbara Ehrenreich, “The New Cosby Kids,” New York Times, July 8, 2004; and Debra Dickerson, “America’s Granddad Gets Ornery,” Slate, July 13, 2004.) Soon after, the California education secretary, Richard Riordan—the wealthy, white former mayor of Los Angeles—found himself under attack for a perceived racial slight. (See Tim Rutten, “Riordan Stung by ‘Gotcha’ News,” Los Angeles Times, July 10, 2004.) Riordan, visiting a Santa Barbara library to promote a reading program, met a six-year-old girl named Isis. She told Riordan that her name meant “Egyptian princess” Riordan, trying to make a joke, replied, “It means stupid, dirty girl.” The resultant outrage led black activists to call for Riordan’s resignation. Mervyn Dymally, a black assemblyman from Compton, explained that Isis was “a little African-American girl. Would he have done that to a white girl?” As it turned out, however, Isis was white. Some activists tried to keep the anti-Riordan protest alive, but Isis’s mother, Trinity, encouraged everyone to relax. Her daughter, she explained, hadn’t taken Riordan’s joke seriously. “I got the impression,” Trinity said, “that she didn’t think he was very bright.”
A MUCH LONGER LIST OF GIRLS’ AND BOYS’ NAMES: Here lies an arbitrary collection of names that are interesting, pretty, uncommon, very common, or somehow quintessential, along with the level of education that they signify. (Each name occurs at least ten times in the California names data.)
SOME GIRLS’ NAMES
(Years of mother’s education in parentheses)
Abigail (14.72), Adelaide (15.33), Alessandra (15.19), Alexandra (14.67), Alice (14.30), Alison (14.82), Allison (14.54), Amalia (15.25), Amanda (13.30), Amber (12.64), Amy (14.09), Anabelle (14.68), Anastasia (13.98), Angelina (12.74), Annabel (15.40), Anne (15.49), Anya (14.97), Ashley (12.89), Autumn (12.86), Ava (14.97), Aziza (11.52), Bailey (13.83), Beatrice (14.74), Beatriz (11.42), Belinda (12.79), Betty (11.50), Breanna (12.71), Britt (15.39), Brittany (12.87), Bronte (14.42), Brooklyn (13.50), Brooklynne (13.10), Caitlin (14.36), Caitlynn (13.03), Cammie (12.00), Campbell (15.69), Carly (14.25), Carmella (14.25), Cassandra (13.38), Cassidy (13.86), Cate (15.23), Cathleen (14.31), Cecilia (14.36), Chanel (13.00), Charisma (13.85), Charlotte (14.98), Chastity* (10.66), Cherokee (11.86), Chloe (14.52), Christina (13.59), Ciara (13.40), Cierra (12.97), Cordelia (15.19), Courtney (13.55), Crimson (11.53), Cynthia (12.79), Dahlia (14.94), Danielle (13.69), Daphne (14.42), Darlene (12.22), Dawn (12.71), Deborah (13.70), December (12.00), Delilah (13.00), Denise (12.71), Deniz (15.27), Desiree (12.62), Destiny (11.65), Diamond (11.70), Diana (13.54), Diane (14.10), Dora (14.31), Eden (14.41), Eileen (14.69), Ekaterina (15.09), Elizabeth (14.25), Elizabethann (12.46), Ella (15.30), Ellen (15.17), Emerald (13.17), Emily (14.17), Emma (15.23), Faith (13.39), Florence (14.83), Francesca (14.80), Frankie (12.52), Franziska (15.18), Gabrielle (14.26), Gennifer (14.75), Georgia (14.82), Geraldine (11.83), Ginger (13.54), Grace (15.03), Gracie (13.81), Gretchen (14.91), Gwyneth (15.04), Haley (13.84), Halle (14.86), Hannah (14.44), Hilary (14.59), Hillary (13.94), Ilana (15.83), Ilene (13.59), Indigo (14.38), Isabel (15.31), Isabell (13.50), Ivy (13.43), Jacquelin (12.78), Jacqueline (14.40), Jade (13.04), Jamie (13.52), Jane (15.12), Janet (12.94), Jeanette (13.43), Jeannette (13.86), Jemma (15.04), Jennifer (13.77), Johanna (14.76), Jordan (13.85), Joyce (12.80), Juliet (14.96), Kailey (13.76), Kara (13.95), Karissa (13.05), Kate (15.23), Katelynne (12.65), Katherine (14.95), Kayla (12.96), Kelsey (14.17), Kendra (13.63), Kennedy (14.17), Kimia (15.66), Kylie (13.83), Laci (12.41), Ladonna (11.60), Lauren (14.58), Leah (14.30), Lenora (13.26), Lexington (13.44), Lexus (12.55), Liberty (13.36), Liesl (15.42), Lily (14.84), Linda (12.76), Linden (15.94), Lizabeth (13.42), Lizbeth (9.66), Lucia (13.59), Lucille (14.76), Lucy (15.01), Lydia (14.40), MacKenzie (14.44), Madeline (15.12), Madison (14.13), Mandy (13.00), Mara (15.33), Margaret (15.14), Mariah (13.00), Mary (14.20), Matisse (15.36), Maya (15.26), Meadow (12.65), Megan (13.99), Melanie (13.90), Meredith (15.57), Michaela (14.13), Micheala (12.95), Millicent (14.61), Molly (14.84), Montana (13.70), Naomi (14.05), Naseem (15.23), Natalie (14.58), Nevada (14.61), Nicole (13.77), Nora (14.88), Olive (15.64), Olivia (14.79), Paige (14.04), Paisley (13.84), Paris (13.71), Patience (11.80), Pearl (13.48), Penelope (14.53), Phoebe (15.18), Phoenix (13.28), Phyllis (11.93), Portia (15.03), Precious (11.30), Quinn (15.20), Rachel (14.51), Rachell (11.76), Rebecca (14.05), Renee (13.79), Rhiannon (13.16), Rikki (12.54), Ronnie (12.72), Rosalind (15.26), Ruby (14.26), Sabrina (13.31), Sadie (13.69), Samantha (13.37), Sarah (14.16), Sasha (14.22), Sayeh (15.25), Scarlett (13.60), Selma (12.78), September (12.80), Shannon (14.11), Shayla (12.77), Shayna (14.00), Shelby (13.42), Sherri (12.32), Shira (15.60), Shirley (12.49), Simone (14.96), Siobhan (14.88), Skylynn (12.61), Solveig (14.36), Sophie (15.45), Stacy (13.08), Stephanie (13.45), Stevie (12.67), Storm (12.31), Sunshine (12.03), Susan (13.73), Suzanne (14.37), Svetlana (11.65), Tabitha (12.49), Talia (15.27), Tallulah (14.88), Tatiana (14.42), Tatum (14.25), Taylor (13.65), Tess (14.83), Tia (12.93), Tiffany (12.49), Tracy (13.50), Trinity (12.60), Trudy (14.88), Vanessa (12.94), Venus (12.73), Veronica (13.83), Veronique (15.80), Violet (13.72), Whitney (13.79), Willow (13.83), Yael (15.55), Yasmine (14.10), Yvonne (13.02), and Zoe (15.03).
SOME BOYS’ NAMES
(Years of mother’s education in parentheses)
Aaron (13.74), Abdelrahman (14.08), Ace (12.39), Adam (14.07), Aidan (15.35), Alexander (14.49), Alistair (15.34), Andrew (14.19), Aristotle (14.20), Ashley (12.95), Atticus (14.97), Baylor (14.84), Bjorn (15.12), Blane (13.55), Blue (13.85), Brian (13.92), Buck (12.81), Bud (12.21), Buddy (11.95), Caleb (13.91), Callum (15.20), Carter (14.98), Chaim (14.63), Christ (11.50), Christian (13.55), Clyde (12.94), Cooper (14.96), Dakota (12.92), Daniel (14.01), Dashiell (15.26), David (13.77), Deniz (15.65), Dylan (13.58), Eamon (15.39), Elton (12.23), Emil (14.05), Eric (14.02), Finn (15.87), Forrest (13.75), Franklin (13.55), Gabriel (14.39), Gary (12.56), Giancarlo (15.05), Giuseppe (13.24), Graydon (15.51), Gustavo (11.68), Hashem (12.76), Hugh (14.60), Hugo (13.00), Idean (14.35), Indiana (13.80), Isaiah (13.12), Jackson (15.22), Jacob (13.76), Jagger (13.27), Jamieson (15.13), Jedidiah (14.06), Jeffrey (13.88), Jeremy (13.46), Jesus (8.71), Jihad (11.60), Johan (15.11), John-Paul (14.22), Jonathan (13.86), Jordan (13.73), Jorge (10.49), Joshua (13.49), Josiah (13.98), Jules (15.48), Justice (12.45), Kai (14.85), Keanu (13.17), Keller (15.07), Kevin (14.03), Kieron (14.00), Kobe (13.12), Kramer (14.80), Kurt (14.33), Lachlan (15.60), Lars (15.09), Leo (14.76), Lev (14.35), Lincoln (14.87), Lonny (11.93), Luca (13.56), Malcolm (14.80), Marvin (11.86), Max (14.93), Maximilian (15.17), Michael (13.66), Michelangelo (15.58), Miro (15.00), Mohammad (12.45), Moises (9.69), Moses (13.11), Moshe (14.41), Muhammad (13.21), Mustafa (13.85), Nathaniel (14.13), Nicholas (14.02), Noah (14.45), Norman (12.90), Oliver (15.14), Orlando (12.72), Otto (13.73), Parker (14.69), Parsa (15.22), Patrick (14.25), Paul (14.13), Peter (15.00), Philip (14.82), Philippe (15.61), Phoenix (13.08), Presley (12.68), Quentin (13.84), Ralph (13.45), Raphael (14.63), Reagan (14.92), Rex (13.77), Rexford (14.89), Rocco (13.68), Rocky (11.47), Roland (13.95), Romain (15.69), Royce (13.73), Russell (13.68), Ryan (14.04), Sage (13.63), Saleh (10.15), Satchel (15.52), Schuyler (14.73), Sean (14.12), Sequoia (13.15), Sergei (14.28), Sergio (11.92), Shawn (12.72), Shelby (12.88), Simon (14.74), Slater (14.62), Solomon (14.20), Spencer (14.53), Stephen (14.01), Stetson (12.90), Steven (13.31), Tanner (13.82), Tariq (13.16), Tennyson (15.63), Terence (14.36), Terry (12.16), Thaddeus (14.56), Theodore (14.61), Thomas (14.08), Timothy (13.58), Toby (13.24), Trace (14.09), Trevor (13.89), Tristan (13.95), Troy (13.52), Ulysses (14.25), Uriel (15.00), Valentino (12.25), Virgil (11.87), Vladimir (13.37), Walker (14.75), Whitney (15.58), Willem (15.38), William (14.17), Willie (12.12), Winston (15.07), Xavier (13.37), Yasser (14.25), Zachary (14.02), Zachory (11.92), Zane (13.93), and Zebulon (15.00).
MOST POPULAR WHITE GIRL NAMES, 1960 AND 2000: The California names data actually begin in 1961, but the year-to-year difference is negligible.
SHIRLEY TEMPLE AS SYMPTOM, NOT CAUSE: See Stanley Lieberson, A Matter of Taste: How Names, Fashions, and Culture Change (New Haven, Conn.: Yale University Press, 2000). A Harvard sociologist, Lieberson is the acknowledged master of (among other subjects) the academic study of names. For instance, A Matter of Taste details how, from 1960, it was American Jewish families who first popularized many girls’ names (Amy, Danielle, Erica, Jennifer, Jessica, Melissa, Rachel, Rebecca, Sarah, Stacy, Stephanie, Tracy) while only a handful (Ashley, Kelly, and Kimberly) began in non-Jewish families. Another good discussion of naming habits can be found in Peggy Orenstein, “Where Have All the Lisas Gone?” New York Times Magazine, July 6, 2003; if only for entertainment, see The Sweetest Sound (2001), Alan Berliner’s documentary film about names; and for an excellent visual overview of how any given name waxes and wanes in popularity, see http://babynamewizard.com/namevoyager/lnv0105.html.
BOYS’ NAMES BECOMING GIRLS’ NAMES (BUT NOT VICE VERSA): This observation is drawn from the work of Cleveland Kent Evans, a psychologist and onomastician at Bellevue University in Bellevue, Nebraska. A sample of Evans’s work is available as of this writing at academic.bellevue.edu/~CKEvans/cevans.html; see also Cleveland Kent Evans, Unusual & Most Popular Baby Names (Lincolnwood, Ill.: Publications International/Signet, 1994); and Cleveland Kent Evans, The Ultimate Baby Name Book (Lincolnwood, Ill.: Publications International/Plume, 1997).
EPILOGUE: TWO PATHS TO HARVARD
THE WHITE BOY WHO GREW UP OUTSIDE CHICAGO: This passage, as well as the earlier passage about the same boy on pp. 141–42, was drawn from author interviews and from Ted Kaczynski, “Truth Versus Lies,” unpublished manuscript, 1998; see also Stephen J. Dubner, “I Don’t Want to Live Long. I Would Rather Get the Death Penalty than Spend the Rest of My Life in Prison,” Time, October 18, 1999.
THE BLACK BOY FROM DAYTONA BEACH: This passage, as well as the earlier passage about the same boy on p. 142, was drawn from author interviews with Roland G. Fryer Jr.


